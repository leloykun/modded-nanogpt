import os
import sys
with open(sys.argv[0]) as f:
    code = f.read() # read the code of this file ASAP, for logging
import uuid
import time
import glob
import subprocess
import contextlib
from dataclasses import dataclass

import torch
torch.empty(1, device='cuda', requires_grad=True).backward()
from torch import nn
import torch.nn.functional as F
import torch.distributed as dist
from torch.nn.parallel import DistributedDataParallel as DDP
# use of FlexAttention contributed by @KoszarskyB
from torch.nn.attention.flex_attention import BlockMask, flex_attention

# -----------------------------------------------------------------------------
# Muon optimizer

@torch.compile
def zeropower_via_newtonschulz5(G, steps):
    """
    Newton-Schulz iteration to compute the zeroth power / orthogonalization of G. We opt to use a
    quintic iteration whose coefficients are selected to maximize the slope at zero. For the purpose
    of minimizing steps, it turns out to be empirically effective to keep increasing the slope at
    zero even beyond the point where the iteration no longer converges all the way to one everywhere
    on the interval. This iteration therefore does not produce UV^T but rather something like US'V^T
    where S' is diagonal with S_{ii}' ~ Uniform(0.5, 1.5), which turns out not to hurt model
    performance at all relative to UV^T, where USV^T = G is the SVD.
    """
    assert len(G.shape) == 2
    a, b, c = (3.4445, -4.7750,  2.0315)
    X = G.bfloat16()
    if G.size(0) > G.size(1):
        X = X.T

    # Ensure spectral norm is at most 1
    X = X / (X.norm() + 1e-7)
    # Perform the NS iterations
    for _ in range(steps):
        A = X @ X.T
        B = b * A + c * A @ A # adapted from suggestion by @jxbz, @leloykun, and @YouJiacheng
        X = a * X + B @ X
    
    if G.size(0) > G.size(1):
        X = X.T
    X = torch.einsum("ij,ij,ab->ab", G.type_as(X), X, X)
    return X

class Muon(torch.optim.Optimizer):
    """
    Muon - MomentUm Orthogonalized by Newton-schulz

    Muon internally runs standard SGD-momentum, and then performs an orthogonalization post-
    processing step, in which each 2D parameter's update is replaced with the nearest orthogonal
    matrix. To efficiently orthogonalize each update, we use a Newton-Schulz iteration, which has
    the advantage that it can be stably run in bfloat16 on the GPU.

    Some warnings:
    - This optimizer assumes that all parameters passed in are 2D.
    - It should not be used for the embedding layer, the final fully connected layer, or any {0,1}-D
    parameters; those should all be optimized by a standard method (e.g., AdamW).
    - To use it with 4D convolutional filters, it works well to just flatten their last 3 dimensions.
    - We believe it is unlikely to work well for training with small batch size.
    - We believe it may not work well for finetuning pretrained models, but we haven't tested this.
    - We have not yet tried this optimizer for training scenarios larger than NanoGPT (124M).

    Arguments:
        lr: The learning rate used by the internal SGD.
        momentum: The momentum used by the internal SGD.
        nesterov: Whether to use Nesterov-style momentum in the internal SGD. (recommended)
        ns_steps: The number of Newton-Schulz iteration steps to use.
    """
    def __init__(self, params, lr=0.02, momentum=0.95, nesterov=True, ns_steps=5):
        self.world_size = int(os.environ['WORLD_SIZE'])
        self.rank = int(os.environ['RANK'])
        defaults = dict(lr=lr, momentum=momentum, nesterov=nesterov, ns_steps=ns_steps)
        assert all(isinstance(p, torch.Tensor) for p in params)
        sizes = {p.numel() for p in params}
        param_groups = [dict(params=[p for p in params if p.numel() == size],
                             update_buffer=[torch.empty(size, device='cuda', dtype=torch.bfloat16) for _ in range(self.world_size)])
                        for size in sizes]
        super().__init__(param_groups, defaults)

    def step(self):

        for group in self.param_groups:

            lr = group['lr']
            momentum = group['momentum']
            nesterov = group['nesterov']
            ns_steps = group['ns_steps']
            update_buffers = group['update_buffer']
            # generate weight updates in distributed fashion
            params = group['params']
            handle = None
            params_world = None
            def update_prev():
                if params_world is None:
                    return
                assert handle is not None
                handle.wait()
                for p_world, g_world in zip(params_world, update_buffers):
                    p_world.data.add_(
                        g_world.view_as(p_world),
                        alpha=-lr * max(1, p_world.size(0) / p_world.size(1)) ** 0.5,
                    )
            for base_i in range(len(params))[::self.world_size]:
                if base_i + rank < len(params):
                    p = params[base_i + self.rank]
                    g = p.grad
                    assert g is not None
                    state = self.state[p]
                    if 'momentum_buffer' not in state:
                        state['momentum_buffer'] = torch.zeros_like(g)
                    buf = state['momentum_buffer']
                    buf.lerp_(g, 1 - momentum)
                    g = g.lerp_(buf, momentum) if nesterov else buf
                    g = zeropower_via_newtonschulz5(g, steps=ns_steps).flatten()
                else:
                    g = update_buffers[rank]
                update_prev() # async all_gather instead of sync all_reduce by @YouJiacheng
                handle = dist.all_gather(update_buffers, g, async_op=True)
                params_world = params[base_i : base_i + self.world_size]
            update_prev()

# -----------------------------------------------------------------------------
# PyTorch nn.Module definitions for the GPT-2 model

def norm(x):
    return F.rms_norm(x, (x.size(-1),))

class CastedLinear(nn.Linear):

    def __init__(self, in_features, out_features):
        super().__init__(in_features, out_features, bias=False)

    def forward(self, x):
        return F.linear(x, self.weight.type_as(x))

class Rotary(nn.Module):

    def __init__(self, dim, max_seq_len=65536):
        super().__init__()
        # half-truncate RoPE by @YouJiacheng
        angular_freq = (1 / 1024) ** torch.linspace(0, 1, steps=dim//4, dtype=torch.float32)
        angular_freq = torch.cat([angular_freq, angular_freq.new_zeros(dim//4)])
        t = torch.arange(max_seq_len, dtype=torch.float32)
        theta = torch.einsum('i,j -> ij', t, angular_freq)
        self.cos = nn.Buffer(theta.cos(), persistent=False)
        self.sin = nn.Buffer(theta.sin(), persistent=False)

    def forward(self, x):
        cos, sin = self.cos[None, :x.size(-3), None, :], self.sin[None, :x.size(-3), None, :]
        x1, x2 = x.float().chunk(2, dim=-1)
        y1 = x1 * cos + x2 * sin
        y2 = x1 * (-sin) + x2 * cos
        return torch.cat((y1, y2), 3).type_as(x)

class CausalSelfAttention(nn.Module):

    def __init__(self, dim, num_heads):
        super().__init__()
        assert dim % num_heads == 0
        self.num_heads = num_heads
        self.c_q = CastedLinear(dim, dim)
        self.c_k = CastedLinear(dim, dim)
        self.c_v = CastedLinear(dim, dim)
        self.lambdas = nn.Parameter(torch.tensor([0.5, 0.5]))
        self.rotary = Rotary(dim // num_heads) # dim // num_heads = head_dim
        self.c_proj = CastedLinear(dim, dim)
        self.c_proj.weight.data.zero_() # zero init suggested by @Grad62304977

    def forward(self, x, ve, block_mask):
        B, T = x.size(0), x.size(1) # batch size, sequence length
        assert B == 1, 'Must use batch size = 1 for FlexAttention'
        q = self.c_q(x).view(B, T, self.num_heads, -1)
        k = self.c_k(x).view(B, T, self.num_heads, -1)
        v = self.c_v(x).view(B, T, self.num_heads, -1)
        if ve is not None:
            v = self.lambdas[0] * v + self.lambdas[1] * ve.view_as(v) # @KoszarskyB & @Grad62304977
        else: # skip mid-layers token value embeddings by @YouJiacheng
            v = self.lambdas[0] * v
        q, k = norm(q), norm(k) # QK norm @Grad62304977
        q, k = self.rotary(q), self.rotary(k)
        y = flex_attention(q.transpose(1, 2), k.transpose(1, 2), v.transpose(1, 2), block_mask=block_mask)
        y = y.transpose(1, 2).contiguous().view_as(x) # re-assemble all head outputs side by side
        y = self.c_proj(y)
        return y

class MLP(nn.Module):

    def __init__(self, dim):
        super().__init__()
        self.c_fc = CastedLinear(dim, 4 * dim)
        self.c_proj = CastedLinear(4 * dim, dim)
        self.c_proj.weight.data.zero_() # zero init suggested by @Grad62304977

    def forward(self, x):
        x = self.c_fc(x)
        x = F.relu(x).square() # https://arxiv.org/abs/2109.08668v2; ~1-2% better than GELU; suggested by @SKYLINEZ007 and @Grad62304977
        x = self.c_proj(x)
        return x

class Block(nn.Module):

    def __init__(self, model_dim, num_heads, use_attn=True):
        super().__init__()
        self.attn = CausalSelfAttention(model_dim, num_heads) if use_attn else None
        self.mlp = MLP(model_dim)
        self.lambdas = nn.Parameter(torch.tensor([1., 0.]))

    def forward(self, x, ve, x0, block_mask):
        x = self.lambdas[0] * x + self.lambdas[1] * x0
        if self.attn is not None:
            x = x + self.attn(norm(x), ve, block_mask)
        x = x + self.mlp(norm(x))
        return x

class ValueEmbedding(nn.Module):
    def __init__(self, vocab_size, model_dim):
        super().__init__()
        self.embed = nn.ModuleList([nn.Embedding(vocab_size, model_dim) for _ in range(3)])

    def forward(self, inputs):
        ve = [emb(inputs).bfloat16() for emb in self.embed]
        # 012 ... 012 structure on token value embeddings by @YouJiacheng, improved on @leloykun's U-net structure
        ve = [ve[0], ve[1], ve[2], None, None, None, None, None, None, ve[0], ve[1], ve[2]]
        return ve

# -----------------------------------------------------------------------------
# The main GPT-2 model

class GPT(nn.Module):

    def __init__(self, vocab_size, num_layers, num_heads, model_dim):
        super().__init__()
        self.embed = nn.Embedding(vocab_size, model_dim)
        # skip attention of blocks.7 (the 8th layer) by @YouJiacheng
        self.blocks = nn.ModuleList([Block(model_dim, num_heads, use_attn=(i != 7))
                                     for i in range(num_layers)])
        # token value embeddings by @KoszarskyB - inspired by @Grad62304977's value residual learning
        # U-net structure on token value embeddings by @leloykun
        self.value_embeds = ValueEmbedding(vocab_size, model_dim)
        self.lm_head = CastedLinear(model_dim, vocab_size)
        self.lm_head.weight.data.zero_() # @Grad62304977
        # U-net design by @brendanh0gan
        self.num_encoder_layers = num_layers // 2 # Half of the layers for encoder
        self.num_decoder_layers = num_layers - self.num_encoder_layers # Remaining for decoder
        # Add learnable skip connection weights for decoder layers
        self.skip_weights = nn.Parameter(torch.ones(self.num_decoder_layers))

    def forward(self, inputs, targets, sliding_window_num_blocks):
        BLOCK_SIZE = 128
        seq_len = len(inputs)
        assert seq_len % BLOCK_SIZE == 0
        total_num_blocks = seq_len // BLOCK_SIZE
        assert inputs.ndim == 1
        docs = (inputs == 50256).cumsum(0)
        docs_low = docs.view(-1, BLOCK_SIZE)[:, 0].contiguous()
        docs_high = docs.view(-1, BLOCK_SIZE)[:, -1].contiguous()

        def document_causal(b, h, q_idx, kv_idx):
            causal_mask = q_idx >= kv_idx
            document_mask = docs[q_idx] == docs[kv_idx]
            return causal_mask & document_mask

        def dense_to_ordered(dense_mask):
            num_blocks = dense_mask.sum(dim=-1, dtype=torch.int32)
            indices = dense_mask.argsort(dim=-1, descending=True, stable=True).to(torch.int32)
            return num_blocks[None, None].contiguous(), indices[None, None].contiguous()

        def create_doc_swc_block_mask(sliding_window_num_blocks):
            kv_idx = block_idx = torch.arange(total_num_blocks, dtype=torch.int32, device='cuda')
            q_idx = block_idx[:, None]
            causal_bm = q_idx >= kv_idx
            causal_full_bm = q_idx > kv_idx
            window_bm = q_idx - kv_idx < sliding_window_num_blocks
            window_full_bm = window_bm # block-wise sliding window by @YouJiacheng
            # document_bm = (docs_low[q_idx] <= docs_high[kv_idx]) & (docs_low[kv_idx] <= docs_high[q_idx])
            document_bm = (docs_low[:, None] <= docs_high) & (docs_low <= docs_high[:, None])
            document_full_bm = (docs_low[:, None] == docs_high) & (docs_low == docs_high[:, None])
            nonzero_bm = causal_bm & window_bm & document_bm
            full_bm  = causal_full_bm & window_full_bm & document_full_bm
            kv_num_blocks, kv_indices = dense_to_ordered(nonzero_bm & ~full_bm)
            full_kv_num_blocks, full_kv_indices = dense_to_ordered(full_bm)
            return BlockMask.from_kv_blocks(
                kv_num_blocks,
                kv_indices,
                full_kv_num_blocks,
                full_kv_indices,
                BLOCK_SIZE=BLOCK_SIZE,
                mask_mod=document_causal,
            )

        block_mask = create_doc_swc_block_mask(sliding_window_num_blocks)

        x0 = norm(self.embed(inputs[None]).bfloat16()) # use of norm here by @Grad62304977
        x = x0
        ve = self.value_embeds(inputs)
        assert len(ve) == len(self.blocks)
        ve_enc, ve_dec = ve[:self.num_encoder_layers], ve[self.num_encoder_layers:]

        # Store outputs for U-Net skip connections
        skip_connections = []
        # Encoder pass - process only the first half of the blocks
        for i in range(self.num_encoder_layers):
            x = self.blocks[i](x, ve_enc[i], x0, block_mask)
            skip_connections.append(x)
        # Decoder pass - process the remaining blocks with weighted skip connections
        for i in range(self.num_decoder_layers):
            x = x + self.skip_weights[i] * skip_connections.pop()
            # U-net structure on token value embeddings by @leloykun
            x = self.blocks[self.num_encoder_layers + i](x, ve_dec[i], x0, block_mask)

        x = norm(x)
        logits = self.lm_head(x)
        logits = 15 * torch.tanh(logits / 15) # @Grad62304977 added tanh softcapping, @KoszarskyB reduced it from 30 to 15
        logits = logits.float()
        loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets)
        return loss

# -----------------------------------------------------------------------------
# Our own simple Distributed Data Loader

def _load_data_shard(path):
    # only reads the header, returns header data
    # header is 256 int32
    header = torch.from_file(path, False, 256, dtype=torch.int32)
    assert header[0] == 20240520, 'magic number mismatch in the data .bin file'
    assert header[1] == 1, 'unsupported version'
    num_tokens = int(header[2]) # number of tokens (claimed)
    with open(path, 'rb', buffering=0) as f:
        tokens = torch.empty(num_tokens, dtype=torch.uint16, pin_memory=True) # avoid pin_memory copy by @YouJiacheng
        f.seek(256 * 4)
        nbytes = f.readinto(tokens.numpy()) # avoid bytes->array copy by @YouJiacheng
        assert nbytes == 2 * num_tokens, 'number of tokens read does not match header'
    return tokens

class DistributedDataLoader:

    def __init__(self, filename_pattern):
        self.rank = int(os.environ['RANK'])
        self.world_size = int(os.environ['WORLD_SIZE'])
        self.files = sorted(glob.glob(filename_pattern))
        self.reset()

    def reset(self):
        self.current_shard = -1
        self.advance()

    def advance(self):
        self.current_shard = (self.current_shard + 1) % len(self.files)
        self.current_position = 0
        self.tokens = _load_data_shard(self.files[self.current_shard])

    def next_batch(self, batch_size):
        assert batch_size % self.world_size == 0
        device_batch_size = batch_size // self.world_size
        # load next shard if necessary
        if self.current_position + batch_size + 1 >= len(self.tokens):
            self.advance()
        pos = self.current_position + self.rank * device_batch_size
        device_batch_tokens = self.tokens[pos:pos+device_batch_size+1]
        # advance current position
        self.current_position += batch_size
        inputs = device_batch_tokens[:-1].to(device='cuda', dtype=torch.int32, non_blocking=True)
        targets = device_batch_tokens[1:].to(device='cuda', dtype=torch.int64, non_blocking=True)
        return inputs, targets

# -----------------------------------------------------------------------------
# int main

@dataclass
class Hyperparameters:
    # data
    train_files = 'data/fineweb10B/fineweb_train_*.bin' # input .bin to train on
    val_files = 'data/fineweb10B/fineweb_val_*.bin' # input .bin to eval validation loss on
    val_tokens = 10485760 # how many tokens of validation data? it's important to keep this fixed for consistent comparisons
    # optimization
    batch_size = 8*64*1024 # batch size in tokens
    num_iterations = 1390 # number of iterations to run
    cooldown_frac = 0.4 # fraction of training spent cooling down the learning rate
    bf16_embeds = True
    # evaluation and logging
    val_loss_every = 125 # every how many steps to evaluate val loss? 0 for only at the end
    # implementation
    max_device_batch_size = 64*1024 # batch size per device in tokens
    save_checkpoint = False
args = Hyperparameters()

micro_bs = args.max_device_batch_size

# set up DDP (distributed data parallel). torchrun sets this env variable
rank = int(os.environ['RANK'])
local_rank = int(os.environ['LOCAL_RANK'])
world_size = int(os.environ['WORLD_SIZE'])
assert torch.cuda.is_available()
torch.cuda.set_device(local_rank)
dist.init_process_group(backend='nccl', device_id=torch.device(local_rank))
dist.barrier()
master_process = (rank == 0) # this process will do logging, checkpointing etc.

# begin logging
logfile = None
if master_process:
    run_id = uuid.uuid4()
    os.makedirs('logs', exist_ok=True)
    logfile = f'logs/{run_id}.txt'
    print(logfile)

def print0(s, console=False):
    if master_process:
        with open(logfile, 'a') as f:
            if console:
                print(s)
            print(s, file=f)

# begin by printing this file (the Python code)
print0(code)
print0('='*100)
# log information about the hardware/software environment this is running on
print0(f'Running Python {sys.version}')
print0(f'Running PyTorch {torch.version.__version__} compiled for CUDA {torch.version.cuda}')
print0(subprocess.run(['nvidia-smi'], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True).stdout)
print0('='*100)

# load data
train_loader = DistributedDataLoader(args.train_files)
val_loader = DistributedDataLoader(args.val_files)
print0(f'Training dataloader files: {train_loader.files}')
print0(f'Validation dataloader files: {val_loader.files}')
print0('='*100)

# there are only 50257 unique GPT-2 tokens; we extend to nearest multiple of 128 for efficiency. suggested to me by @Grad62304977.
# this originates from Karpathy's experiments.
model = GPT(vocab_size=50304, num_layers=12, num_heads=6, model_dim=768)
model = model.cuda()
if args.bf16_embeds:
    for m in model.modules():
        if isinstance(m, nn.Embedding):
            m.bfloat16()
model = torch.compile(model)
ddp_model = DDP(model, device_ids=[local_rank], broadcast_buffers=False, gradient_as_bucket_view=True)

# collect the parameters to optimize
hidden_matrix_params = [p for p in model.blocks.parameters() if p.ndim == 2]
embed_params = [model.embed.weight, *model.value_embeds.parameters()]
scalar_params = [p for p in model.parameters() if p.ndim < 2]
head_params = [model.lm_head.weight]

# init the optimizer(s)
optimizer1 = torch.optim.Adam([dict(params=embed_params, lr=0.6),
                               dict(params=head_params, lr=0.008),
                               dict(params=scalar_params, lr=0.04)],
                              betas=(0.8, 0.95), fused=True)
# optimizer2 = Muon(hidden_matrix_params, lr=0.5, momentum=0.95)
# optimizer2 = Muon(hidden_matrix_params, lr=0.25, momentum=0.95)  # done
# optimizer2 = Muon(hidden_matrix_params, lr=0.1, momentum=0.95)  # done
# optimizer2 = Muon(hidden_matrix_params, lr=0.05, momentum=0.95)  # done
# optimizer2 = Muon(hidden_matrix_params, lr=0.025, momentum=0.95)  # done
optimizer2 = Muon(hidden_matrix_params, lr=0.01, momentum=0.95)
# optimizer2 = Muon(hidden_matrix_params, lr=0.005, momentum=0.95)
optimizers = [optimizer1, optimizer2]

# learning rate schedule: stable then decay
def get_lr(it):
    t = 1 - it / args.num_iterations # time remaining in training
    assert 1 >= t > 0
    # 1) constant lr for first part of training
    if t >= args.cooldown_frac:
        return 1.0
    # 2) then linear cooldown
    else:
        return t / args.cooldown_frac
schedulers = [torch.optim.lr_scheduler.LambdaLR(opt, get_lr) for opt in optimizers]

# sliding window size schedule: linear increase over training in chunks of 128 from 128 -> 1792. By @fernbear.bsky.social
def get_sliding_window_blocks(it):
    x = it / args.num_iterations # training progress
    assert 0 <= x <= 1
    return int(((1 - x) * 128 + x * 1856) // 128)
sliding_window_num_blocks = torch.tensor(1, dtype=torch.int32, device='cuda')

# Start training loop
training_time_ms = 0
# start the clock
torch.cuda.synchronize()
t0 = time.perf_counter()
# begin training
train_steps = args.num_iterations
for step in range(train_steps + 1):
    last_step = (step == train_steps)
    # This effectively ignores timing first 10 steps, which are slower for weird reasons.
    # Alternately, and slightly more correctly in terms of benchmarking, we could do 10
    # steps with dummy data first, and then re-initialize the model and reset the loader.
    if step == 10:
        training_time_ms = 0
        t0 = time.perf_counter()
    timed_steps = float('nan') if step <= 11 else (step - 10) + 1 # <= 11 to avoid bug in val

    sliding_window_num_blocks.copy_(get_sliding_window_blocks(step))

    # --------------- VALIDATION SECTION -----------------
    if last_step or (args.val_loss_every > 0 and step % args.val_loss_every == 0):
        # stop the clock
        torch.cuda.synchronize()
        training_time_ms += 1000 * (time.perf_counter() - t0)
        # run validation batches
        model.eval()
        val_loader.reset()
        val_loss = 0.0
        # calculate the number of steps to take in the val loop.
        val_batch_size = world_size * micro_bs
        assert args.val_tokens % val_batch_size == 0
        val_steps = args.val_tokens // val_batch_size
        for _ in range(val_steps):
            with torch.no_grad():
                inputs_val, targets_val = val_loader.next_batch(val_batch_size)
                val_loss += ddp_model(inputs_val, targets_val, sliding_window_num_blocks)
        dist.all_reduce(val_loss, op=dist.ReduceOp.AVG)
        val_loss /= val_steps
        # logging
        print0(f'step:{step}/{train_steps} val_loss:{val_loss:.4f} train_time:{training_time_ms:.0f}ms step_avg:{training_time_ms/(timed_steps-1):.2f}ms', console=True)
        # start the clock again
        torch.cuda.synchronize()
        t0 = time.perf_counter()

    if last_step:
        if master_process and args.save_checkpoint:
            log = dict(step=step, code=code, model=model.state_dict(), optimizers=[opt.state_dict() for opt in optimizers])
            os.makedirs(f'logs/{run_id}', exist_ok=True)
            torch.save(log, f'logs/{run_id}/state_step{step:06d}.pt')
        # the last step only has the validation loop, so break to avoid training
        break

    # --------------- TRAINING SECTION -----------------
    model.train()
    batch_size = args.batch_size
    assert batch_size % world_size == 0
    inputs_train, targets_train = train_loader.next_batch(batch_size)
    assert len(inputs_train) <= micro_bs or len(inputs_train) % micro_bs == 0
    for micro_inputs_train, micro_targets_train in zip(inputs_train.split(micro_bs), targets_train.split(micro_bs)):
        ddp_model(micro_inputs_train, micro_targets_train, sliding_window_num_blocks).backward()
    # momentum warmup for Muon
    frac = min(step/300, 1)
    for group in optimizer2.param_groups:
        group['momentum'] = (1 - frac) * 0.85 + frac * 0.95
    # step the optimizers and schedulers
    for opt, sched in zip(optimizers, schedulers):
        opt.step()
        if step != train_steps-1:
            sched.step()
    # null the gradients
    model.zero_grad(set_to_none=True)
    # logging
    approx_time = training_time_ms + 1000 * (time.perf_counter() - t0)
    print0(f'step:{step+1}/{train_steps} train_time:{approx_time:.0f}ms step_avg:{approx_time/timed_steps:.2f}ms', console=True)

print0(f'peak memory consumption: {torch.cuda.max_memory_allocated() // 1024 // 1024} MiB')
dist.destroy_process_group()

====================================================================================================
Running Python 3.10.12 (main, Sep 11 2024, 15:47:36) [GCC 11.4.0]
Running PyTorch 2.6.0.dev20241231+cu126 compiled for CUDA 12.6
Tue Jan 14 17:43:34 2025       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.183.06             Driver Version: 535.183.06   CUDA Version: 12.4     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA H100 80GB HBM3          On  | 00000000:19:00.0 Off |                    0 |
| N/A   37C    P0             125W / 700W |   7713MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   1  NVIDIA H100 80GB HBM3          On  | 00000000:3B:00.0 Off |                    0 |
| N/A   31C    P0             114W / 700W |   3451MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   2  NVIDIA H100 80GB HBM3          On  | 00000000:4C:00.0 Off |                    0 |
| N/A   29C    P0             117W / 700W |   3451MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   3  NVIDIA H100 80GB HBM3          On  | 00000000:5D:00.0 Off |                    0 |
| N/A   36C    P0             128W / 700W |   3451MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   4  NVIDIA H100 80GB HBM3          On  | 00000000:9B:00.0 Off |                    0 |
| N/A   37C    P0             122W / 700W |   3451MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   5  NVIDIA H100 80GB HBM3          On  | 00000000:BB:00.0 Off |                    0 |
| N/A   29C    P0             114W / 700W |   3451MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   6  NVIDIA H100 80GB HBM3          On  | 00000000:CB:00.0 Off |                    0 |
| N/A   35C    P0             115W / 700W |   3451MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   7  NVIDIA H100 80GB HBM3          On  | 00000000:DB:00.0 Off |                    0 |
| N/A   29C    P0             116W / 700W |   3211MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
+---------------------------------------------------------------------------------------+

====================================================================================================
Training dataloader files: ['data/fineweb10B/fineweb_train_000001.bin', 'data/fineweb10B/fineweb_train_000002.bin', 'data/fineweb10B/fineweb_train_000003.bin', 'data/fineweb10B/fineweb_train_000004.bin', 'data/fineweb10B/fineweb_train_000005.bin', 'data/fineweb10B/fineweb_train_000006.bin', 'data/fineweb10B/fineweb_train_000007.bin', 'data/fineweb10B/fineweb_train_000008.bin', 'data/fineweb10B/fineweb_train_000009.bin']
Validation dataloader files: ['data/fineweb10B/fineweb_val_000000.bin']
====================================================================================================
step:0/1390 val_loss:10.8258 train_time:0ms step_avg:nanms
step:1/1390 train_time:27691ms step_avg:nanms
step:2/1390 train_time:27783ms step_avg:nanms
step:3/1390 train_time:27998ms step_avg:nanms
step:4/1390 train_time:28130ms step_avg:nanms
step:5/1390 train_time:28265ms step_avg:nanms
step:6/1390 train_time:28401ms step_avg:nanms
step:7/1390 train_time:28534ms step_avg:nanms
step:8/1390 train_time:28669ms step_avg:nanms
step:9/1390 train_time:28805ms step_avg:nanms
step:10/1390 train_time:28946ms step_avg:nanms
step:11/1390 train_time:137ms step_avg:nanms
step:12/1390 train_time:273ms step_avg:nanms
step:13/1390 train_time:409ms step_avg:136.24ms
step:14/1390 train_time:545ms step_avg:136.23ms
step:15/1390 train_time:679ms step_avg:135.79ms
step:16/1390 train_time:812ms step_avg:135.39ms
step:17/1390 train_time:951ms step_avg:135.89ms
step:18/1390 train_time:1089ms step_avg:136.07ms
step:19/1390 train_time:1227ms step_avg:136.31ms
step:20/1390 train_time:1364ms step_avg:136.38ms
step:21/1390 train_time:1500ms step_avg:136.35ms
step:22/1390 train_time:1637ms step_avg:136.41ms
step:23/1390 train_time:1772ms step_avg:136.28ms
step:24/1390 train_time:1908ms step_avg:136.31ms
step:25/1390 train_time:2045ms step_avg:136.30ms
step:26/1390 train_time:2182ms step_avg:136.39ms
step:27/1390 train_time:2318ms step_avg:136.37ms
step:28/1390 train_time:2456ms step_avg:136.45ms
step:29/1390 train_time:2591ms step_avg:136.39ms
step:30/1390 train_time:2727ms step_avg:136.36ms
step:31/1390 train_time:2864ms step_avg:136.40ms
step:32/1390 train_time:3000ms step_avg:136.37ms
step:33/1390 train_time:3137ms step_avg:136.39ms
step:34/1390 train_time:3273ms step_avg:136.37ms
step:35/1390 train_time:3409ms step_avg:136.37ms
step:36/1390 train_time:3546ms step_avg:136.37ms
step:37/1390 train_time:3682ms step_avg:136.37ms
step:38/1390 train_time:3818ms step_avg:136.35ms
step:39/1390 train_time:3956ms step_avg:136.42ms
step:40/1390 train_time:4091ms step_avg:136.38ms
step:41/1390 train_time:4226ms step_avg:136.31ms
step:42/1390 train_time:4362ms step_avg:136.31ms
step:43/1390 train_time:4498ms step_avg:136.32ms
step:44/1390 train_time:4635ms step_avg:136.31ms
step:45/1390 train_time:4771ms step_avg:136.32ms
step:46/1390 train_time:4910ms step_avg:136.38ms
step:47/1390 train_time:5044ms step_avg:136.33ms
step:48/1390 train_time:5180ms step_avg:136.32ms
step:49/1390 train_time:5316ms step_avg:136.31ms
step:50/1390 train_time:5453ms step_avg:136.33ms
step:51/1390 train_time:5587ms step_avg:136.27ms
step:52/1390 train_time:5724ms step_avg:136.29ms
step:53/1390 train_time:5860ms step_avg:136.29ms
step:54/1390 train_time:5999ms step_avg:136.34ms
step:55/1390 train_time:6135ms step_avg:136.33ms
step:56/1390 train_time:6270ms step_avg:136.31ms
step:57/1390 train_time:6407ms step_avg:136.33ms
step:58/1390 train_time:6543ms step_avg:136.31ms
step:59/1390 train_time:6679ms step_avg:136.31ms
step:60/1390 train_time:6815ms step_avg:136.30ms
step:61/1390 train_time:6952ms step_avg:136.32ms
step:62/1390 train_time:7087ms step_avg:136.29ms
step:63/1390 train_time:7223ms step_avg:136.29ms
step:64/1390 train_time:7359ms step_avg:136.28ms
step:65/1390 train_time:7495ms step_avg:136.27ms
step:66/1390 train_time:7630ms step_avg:136.25ms
step:67/1390 train_time:7766ms step_avg:136.25ms
step:68/1390 train_time:7905ms step_avg:136.29ms
step:69/1390 train_time:8041ms step_avg:136.28ms
step:70/1390 train_time:8177ms step_avg:136.29ms
step:71/1390 train_time:8314ms step_avg:136.30ms
step:72/1390 train_time:8450ms step_avg:136.29ms
step:73/1390 train_time:8585ms step_avg:136.28ms
step:74/1390 train_time:8722ms step_avg:136.28ms
step:75/1390 train_time:8859ms step_avg:136.30ms
step:76/1390 train_time:8996ms step_avg:136.30ms
step:77/1390 train_time:9132ms step_avg:136.29ms
step:78/1390 train_time:9269ms step_avg:136.32ms
step:79/1390 train_time:9406ms step_avg:136.32ms
step:80/1390 train_time:9541ms step_avg:136.30ms
step:81/1390 train_time:9676ms step_avg:136.29ms
step:82/1390 train_time:9813ms step_avg:136.29ms
step:83/1390 train_time:9951ms step_avg:136.32ms
step:84/1390 train_time:10086ms step_avg:136.30ms
step:85/1390 train_time:10223ms step_avg:136.30ms
step:86/1390 train_time:10362ms step_avg:136.34ms
step:87/1390 train_time:10498ms step_avg:136.34ms
step:88/1390 train_time:10635ms step_avg:136.35ms
step:89/1390 train_time:10772ms step_avg:136.35ms
step:90/1390 train_time:10909ms step_avg:136.36ms
step:91/1390 train_time:11044ms step_avg:136.35ms
step:92/1390 train_time:11181ms step_avg:136.35ms
step:93/1390 train_time:11319ms step_avg:136.37ms
step:94/1390 train_time:11455ms step_avg:136.37ms
step:95/1390 train_time:11591ms step_avg:136.36ms
step:96/1390 train_time:11728ms step_avg:136.37ms
step:97/1390 train_time:11865ms step_avg:136.37ms
step:98/1390 train_time:12002ms step_avg:136.39ms
step:99/1390 train_time:12138ms step_avg:136.38ms
step:100/1390 train_time:12276ms step_avg:136.40ms
step:101/1390 train_time:12413ms step_avg:136.41ms
step:102/1390 train_time:12550ms step_avg:136.41ms
step:103/1390 train_time:12686ms step_avg:136.41ms
step:104/1390 train_time:12826ms step_avg:136.44ms
step:105/1390 train_time:12966ms step_avg:136.48ms
step:106/1390 train_time:13104ms step_avg:136.49ms
step:107/1390 train_time:13242ms step_avg:136.52ms
step:108/1390 train_time:13382ms step_avg:136.55ms
step:109/1390 train_time:13521ms step_avg:136.58ms
step:110/1390 train_time:13661ms step_avg:136.61ms
step:111/1390 train_time:13800ms step_avg:136.63ms
step:112/1390 train_time:13938ms step_avg:136.65ms
step:113/1390 train_time:14078ms step_avg:136.68ms
step:114/1390 train_time:14218ms step_avg:136.71ms
step:115/1390 train_time:14358ms step_avg:136.74ms
step:116/1390 train_time:14496ms step_avg:136.75ms
step:117/1390 train_time:14636ms step_avg:136.78ms
step:118/1390 train_time:14775ms step_avg:136.81ms
step:119/1390 train_time:14914ms step_avg:136.83ms
step:120/1390 train_time:15056ms step_avg:136.88ms
step:121/1390 train_time:15198ms step_avg:136.91ms
step:122/1390 train_time:15336ms step_avg:136.93ms
step:123/1390 train_time:15475ms step_avg:136.95ms
step:124/1390 train_time:15614ms step_avg:136.96ms
step:125/1390 train_time:15755ms step_avg:137.00ms
step:125/1390 val_loss:5.2987 train_time:15816ms step_avg:137.53ms
step:126/1390 train_time:15894ms step_avg:137.02ms
step:127/1390 train_time:16038ms step_avg:137.07ms
step:128/1390 train_time:16177ms step_avg:137.10ms
step:129/1390 train_time:16317ms step_avg:137.12ms
step:130/1390 train_time:16457ms step_avg:137.14ms
step:131/1390 train_time:16595ms step_avg:137.15ms
step:132/1390 train_time:16734ms step_avg:137.17ms
step:133/1390 train_time:16877ms step_avg:137.21ms
step:134/1390 train_time:17020ms step_avg:137.26ms
step:135/1390 train_time:17159ms step_avg:137.28ms
step:136/1390 train_time:17299ms step_avg:137.30ms
step:137/1390 train_time:17438ms step_avg:137.30ms
step:138/1390 train_time:17578ms step_avg:137.33ms
step:139/1390 train_time:17718ms step_avg:137.35ms
step:140/1390 train_time:17859ms step_avg:137.38ms
step:141/1390 train_time:18000ms step_avg:137.41ms
step:142/1390 train_time:18141ms step_avg:137.43ms
step:143/1390 train_time:18282ms step_avg:137.46ms
step:144/1390 train_time:18422ms step_avg:137.48ms
step:145/1390 train_time:18562ms step_avg:137.49ms
step:146/1390 train_time:18702ms step_avg:137.51ms
step:147/1390 train_time:18841ms step_avg:137.53ms
step:148/1390 train_time:18983ms step_avg:137.56ms
step:149/1390 train_time:19123ms step_avg:137.57ms
step:150/1390 train_time:19263ms step_avg:137.60ms
step:151/1390 train_time:19404ms step_avg:137.62ms
step:152/1390 train_time:19543ms step_avg:137.63ms
step:153/1390 train_time:19683ms step_avg:137.64ms
step:154/1390 train_time:19824ms step_avg:137.66ms
step:155/1390 train_time:19965ms step_avg:137.69ms
step:156/1390 train_time:20107ms step_avg:137.72ms
step:157/1390 train_time:20246ms step_avg:137.73ms
step:158/1390 train_time:20387ms step_avg:137.75ms
step:159/1390 train_time:20527ms step_avg:137.76ms
step:160/1390 train_time:20667ms step_avg:137.78ms
step:161/1390 train_time:20808ms step_avg:137.80ms
step:162/1390 train_time:20948ms step_avg:137.82ms
step:163/1390 train_time:21088ms step_avg:137.83ms
step:164/1390 train_time:21229ms step_avg:137.85ms
step:165/1390 train_time:21368ms step_avg:137.86ms
step:166/1390 train_time:21509ms step_avg:137.88ms
step:167/1390 train_time:21649ms step_avg:137.89ms
step:168/1390 train_time:21788ms step_avg:137.90ms
step:169/1390 train_time:21929ms step_avg:137.92ms
step:170/1390 train_time:22070ms step_avg:137.94ms
step:171/1390 train_time:22211ms step_avg:137.96ms
step:172/1390 train_time:22351ms step_avg:137.97ms
step:173/1390 train_time:22490ms step_avg:137.98ms
step:174/1390 train_time:22630ms step_avg:137.99ms
step:175/1390 train_time:22769ms step_avg:138.00ms
step:176/1390 train_time:22911ms step_avg:138.02ms
step:177/1390 train_time:23051ms step_avg:138.03ms
step:178/1390 train_time:23192ms step_avg:138.05ms
step:179/1390 train_time:23332ms step_avg:138.06ms
step:180/1390 train_time:23472ms step_avg:138.07ms
step:181/1390 train_time:23614ms step_avg:138.09ms
step:182/1390 train_time:23752ms step_avg:138.10ms
step:183/1390 train_time:23895ms step_avg:138.12ms
step:184/1390 train_time:24034ms step_avg:138.13ms
step:185/1390 train_time:24176ms step_avg:138.15ms
step:186/1390 train_time:24320ms step_avg:138.18ms
step:187/1390 train_time:24460ms step_avg:138.19ms
step:188/1390 train_time:24600ms step_avg:138.20ms
step:189/1390 train_time:24740ms step_avg:138.21ms
step:190/1390 train_time:24882ms step_avg:138.23ms
step:191/1390 train_time:25064ms step_avg:138.47ms
step:192/1390 train_time:25203ms step_avg:138.48ms
step:193/1390 train_time:25340ms step_avg:138.47ms
step:194/1390 train_time:25479ms step_avg:138.47ms
step:195/1390 train_time:25618ms step_avg:138.47ms
step:196/1390 train_time:25757ms step_avg:138.48ms
step:197/1390 train_time:25897ms step_avg:138.49ms
step:198/1390 train_time:26042ms step_avg:138.52ms
step:199/1390 train_time:26183ms step_avg:138.53ms
step:200/1390 train_time:26323ms step_avg:138.54ms
step:201/1390 train_time:26462ms step_avg:138.54ms
step:202/1390 train_time:26601ms step_avg:138.55ms
step:203/1390 train_time:26739ms step_avg:138.55ms
step:204/1390 train_time:26882ms step_avg:138.56ms
step:205/1390 train_time:27025ms step_avg:138.59ms
step:206/1390 train_time:27166ms step_avg:138.60ms
step:207/1390 train_time:27308ms step_avg:138.62ms
step:208/1390 train_time:27451ms step_avg:138.64ms
step:209/1390 train_time:27593ms step_avg:138.66ms
step:210/1390 train_time:27733ms step_avg:138.66ms
step:211/1390 train_time:27874ms step_avg:138.67ms
step:212/1390 train_time:28017ms step_avg:138.70ms
step:213/1390 train_time:28161ms step_avg:138.72ms
step:214/1390 train_time:28303ms step_avg:138.74ms
step:215/1390 train_time:28446ms step_avg:138.76ms
step:216/1390 train_time:28587ms step_avg:138.77ms
step:217/1390 train_time:28729ms step_avg:138.79ms
step:218/1390 train_time:28873ms step_avg:138.81ms
step:219/1390 train_time:29016ms step_avg:138.83ms
step:220/1390 train_time:29160ms step_avg:138.86ms
step:221/1390 train_time:29303ms step_avg:138.88ms
step:222/1390 train_time:29446ms step_avg:138.89ms
step:223/1390 train_time:29588ms step_avg:138.91ms
step:224/1390 train_time:29729ms step_avg:138.92ms
step:225/1390 train_time:29870ms step_avg:138.93ms
step:226/1390 train_time:30012ms step_avg:138.95ms
step:227/1390 train_time:30155ms step_avg:138.96ms
step:228/1390 train_time:30297ms step_avg:138.98ms
step:229/1390 train_time:30438ms step_avg:138.99ms
step:230/1390 train_time:30580ms step_avg:139.00ms
step:231/1390 train_time:30722ms step_avg:139.01ms
step:232/1390 train_time:30864ms step_avg:139.03ms
step:233/1390 train_time:31007ms step_avg:139.05ms
step:234/1390 train_time:31149ms step_avg:139.06ms
step:235/1390 train_time:31291ms step_avg:139.07ms
step:236/1390 train_time:31433ms step_avg:139.09ms
step:237/1390 train_time:31577ms step_avg:139.10ms
step:238/1390 train_time:31720ms step_avg:139.12ms
step:239/1390 train_time:31862ms step_avg:139.13ms
step:240/1390 train_time:32004ms step_avg:139.15ms
step:241/1390 train_time:32145ms step_avg:139.16ms
step:242/1390 train_time:32287ms step_avg:139.17ms
step:243/1390 train_time:32429ms step_avg:139.18ms
step:244/1390 train_time:32572ms step_avg:139.20ms
step:245/1390 train_time:32715ms step_avg:139.21ms
step:246/1390 train_time:32857ms step_avg:139.23ms
step:247/1390 train_time:33001ms step_avg:139.24ms
step:248/1390 train_time:33143ms step_avg:139.25ms
step:249/1390 train_time:33285ms step_avg:139.27ms
step:250/1390 train_time:33426ms step_avg:139.28ms
step:250/1390 val_loss:4.8616 train_time:33491ms step_avg:139.55ms
step:251/1390 train_time:33571ms step_avg:139.30ms
step:252/1390 train_time:33718ms step_avg:139.33ms
step:253/1390 train_time:33861ms step_avg:139.34ms
step:254/1390 train_time:34002ms step_avg:139.35ms
step:255/1390 train_time:34143ms step_avg:139.36ms
step:256/1390 train_time:34283ms step_avg:139.36ms
step:257/1390 train_time:34424ms step_avg:139.37ms
step:258/1390 train_time:34569ms step_avg:139.39ms
step:259/1390 train_time:34711ms step_avg:139.40ms
step:260/1390 train_time:34853ms step_avg:139.41ms
step:261/1390 train_time:34995ms step_avg:139.42ms
step:262/1390 train_time:35137ms step_avg:139.43ms
step:263/1390 train_time:35280ms step_avg:139.45ms
step:264/1390 train_time:35424ms step_avg:139.47ms
step:265/1390 train_time:35566ms step_avg:139.47ms
step:266/1390 train_time:35708ms step_avg:139.49ms
step:267/1390 train_time:35850ms step_avg:139.49ms
step:268/1390 train_time:35991ms step_avg:139.50ms
step:269/1390 train_time:36132ms step_avg:139.51ms
step:270/1390 train_time:36274ms step_avg:139.52ms
step:271/1390 train_time:36416ms step_avg:139.53ms
step:272/1390 train_time:36560ms step_avg:139.54ms
step:273/1390 train_time:36704ms step_avg:139.56ms
step:274/1390 train_time:36848ms step_avg:139.57ms
step:275/1390 train_time:36988ms step_avg:139.58ms
step:276/1390 train_time:37129ms step_avg:139.58ms
step:277/1390 train_time:37272ms step_avg:139.59ms
step:278/1390 train_time:37415ms step_avg:139.61ms
step:279/1390 train_time:37558ms step_avg:139.62ms
step:280/1390 train_time:37701ms step_avg:139.63ms
step:281/1390 train_time:37844ms step_avg:139.65ms
step:282/1390 train_time:37986ms step_avg:139.66ms
step:283/1390 train_time:38128ms step_avg:139.66ms
step:284/1390 train_time:38268ms step_avg:139.66ms
step:285/1390 train_time:38410ms step_avg:139.67ms
step:286/1390 train_time:38553ms step_avg:139.69ms
step:287/1390 train_time:38696ms step_avg:139.70ms
step:288/1390 train_time:38839ms step_avg:139.71ms
step:289/1390 train_time:38982ms step_avg:139.72ms
step:290/1390 train_time:39124ms step_avg:139.73ms
step:291/1390 train_time:39266ms step_avg:139.74ms
step:292/1390 train_time:39408ms step_avg:139.75ms
step:293/1390 train_time:39553ms step_avg:139.76ms
step:294/1390 train_time:39693ms step_avg:139.76ms
step:295/1390 train_time:39836ms step_avg:139.78ms
step:296/1390 train_time:39980ms step_avg:139.79ms
step:297/1390 train_time:40123ms step_avg:139.80ms
step:298/1390 train_time:40266ms step_avg:139.81ms
step:299/1390 train_time:40409ms step_avg:139.82ms
step:300/1390 train_time:40553ms step_avg:139.84ms
step:301/1390 train_time:40697ms step_avg:139.85ms
step:302/1390 train_time:40839ms step_avg:139.86ms
step:303/1390 train_time:40980ms step_avg:139.86ms
step:304/1390 train_time:41123ms step_avg:139.87ms
step:305/1390 train_time:41265ms step_avg:139.88ms
step:306/1390 train_time:41407ms step_avg:139.89ms
step:307/1390 train_time:41551ms step_avg:139.90ms
step:308/1390 train_time:41693ms step_avg:139.91ms
step:309/1390 train_time:41837ms step_avg:139.92ms
step:310/1390 train_time:41981ms step_avg:139.94ms
step:311/1390 train_time:42127ms step_avg:139.96ms
step:312/1390 train_time:42270ms step_avg:139.97ms
step:313/1390 train_time:42413ms step_avg:139.98ms
step:314/1390 train_time:42560ms step_avg:140.00ms
step:315/1390 train_time:42706ms step_avg:140.02ms
step:316/1390 train_time:42851ms step_avg:140.03ms
step:317/1390 train_time:42995ms step_avg:140.05ms
step:318/1390 train_time:43140ms step_avg:140.06ms
step:319/1390 train_time:43284ms step_avg:140.08ms
step:320/1390 train_time:43428ms step_avg:140.09ms
step:321/1390 train_time:43572ms step_avg:140.10ms
step:322/1390 train_time:43717ms step_avg:140.12ms
step:323/1390 train_time:43861ms step_avg:140.13ms
step:324/1390 train_time:44005ms step_avg:140.14ms
step:325/1390 train_time:44149ms step_avg:140.16ms
step:326/1390 train_time:44293ms step_avg:140.17ms
step:327/1390 train_time:44440ms step_avg:140.19ms
step:328/1390 train_time:44588ms step_avg:140.21ms
step:329/1390 train_time:44732ms step_avg:140.23ms
step:330/1390 train_time:44877ms step_avg:140.24ms
step:331/1390 train_time:45023ms step_avg:140.26ms
step:332/1390 train_time:45167ms step_avg:140.27ms
step:333/1390 train_time:45311ms step_avg:140.28ms
step:334/1390 train_time:45456ms step_avg:140.30ms
step:335/1390 train_time:45602ms step_avg:140.31ms
step:336/1390 train_time:45748ms step_avg:140.33ms
step:337/1390 train_time:45893ms step_avg:140.35ms
step:338/1390 train_time:46037ms step_avg:140.36ms
step:339/1390 train_time:46181ms step_avg:140.37ms
step:340/1390 train_time:46327ms step_avg:140.38ms
step:341/1390 train_time:46471ms step_avg:140.40ms
step:342/1390 train_time:46615ms step_avg:140.41ms
step:343/1390 train_time:46760ms step_avg:140.42ms
step:344/1390 train_time:46907ms step_avg:140.44ms
step:345/1390 train_time:47051ms step_avg:140.45ms
step:346/1390 train_time:47195ms step_avg:140.46ms
step:347/1390 train_time:47339ms step_avg:140.47ms
step:348/1390 train_time:47485ms step_avg:140.49ms
step:349/1390 train_time:47629ms step_avg:140.50ms
step:350/1390 train_time:47773ms step_avg:140.51ms
step:351/1390 train_time:47917ms step_avg:140.52ms
step:352/1390 train_time:48062ms step_avg:140.53ms
step:353/1390 train_time:48207ms step_avg:140.55ms
step:354/1390 train_time:48351ms step_avg:140.55ms
step:355/1390 train_time:48496ms step_avg:140.57ms
step:356/1390 train_time:48641ms step_avg:140.58ms
step:357/1390 train_time:48788ms step_avg:140.60ms
step:358/1390 train_time:48931ms step_avg:140.61ms
step:359/1390 train_time:49075ms step_avg:140.62ms
step:360/1390 train_time:49222ms step_avg:140.63ms
step:361/1390 train_time:49366ms step_avg:140.64ms
step:362/1390 train_time:49509ms step_avg:140.65ms
step:363/1390 train_time:49654ms step_avg:140.66ms
step:364/1390 train_time:49801ms step_avg:140.68ms
step:365/1390 train_time:49945ms step_avg:140.69ms
step:366/1390 train_time:50090ms step_avg:140.70ms
step:367/1390 train_time:50236ms step_avg:140.72ms
step:368/1390 train_time:50382ms step_avg:140.73ms
step:369/1390 train_time:50526ms step_avg:140.74ms
step:370/1390 train_time:50671ms step_avg:140.75ms
step:371/1390 train_time:50814ms step_avg:140.76ms
step:372/1390 train_time:50958ms step_avg:140.77ms
step:373/1390 train_time:51104ms step_avg:140.78ms
step:374/1390 train_time:51249ms step_avg:140.79ms
step:375/1390 train_time:51393ms step_avg:140.80ms
step:375/1390 val_loss:4.6176 train_time:51459ms step_avg:140.98ms
step:376/1390 train_time:51538ms step_avg:140.81ms
step:377/1390 train_time:51686ms step_avg:140.83ms
step:378/1390 train_time:51830ms step_avg:140.84ms
step:379/1390 train_time:51974ms step_avg:140.85ms
step:380/1390 train_time:52119ms step_avg:140.86ms
step:381/1390 train_time:52298ms step_avg:140.97ms
step:382/1390 train_time:52441ms step_avg:140.97ms
step:383/1390 train_time:52584ms step_avg:140.98ms
step:384/1390 train_time:52726ms step_avg:140.98ms
step:385/1390 train_time:52870ms step_avg:140.99ms
step:386/1390 train_time:53013ms step_avg:140.99ms
step:387/1390 train_time:53160ms step_avg:141.01ms
step:388/1390 train_time:53307ms step_avg:141.02ms
step:389/1390 train_time:53450ms step_avg:141.03ms
step:390/1390 train_time:53595ms step_avg:141.04ms
step:391/1390 train_time:53740ms step_avg:141.05ms
step:392/1390 train_time:53884ms step_avg:141.06ms
step:393/1390 train_time:54027ms step_avg:141.06ms
step:394/1390 train_time:54172ms step_avg:141.07ms
step:395/1390 train_time:54319ms step_avg:141.09ms
step:396/1390 train_time:54465ms step_avg:141.10ms
step:397/1390 train_time:54608ms step_avg:141.11ms
step:398/1390 train_time:54754ms step_avg:141.12ms
step:399/1390 train_time:54898ms step_avg:141.13ms
step:400/1390 train_time:55044ms step_avg:141.14ms
step:401/1390 train_time:55188ms step_avg:141.15ms
step:402/1390 train_time:55335ms step_avg:141.16ms
step:403/1390 train_time:55482ms step_avg:141.17ms
step:404/1390 train_time:55625ms step_avg:141.18ms
step:405/1390 train_time:55770ms step_avg:141.19ms
step:406/1390 train_time:55914ms step_avg:141.20ms
step:407/1390 train_time:56059ms step_avg:141.21ms
step:408/1390 train_time:56205ms step_avg:141.22ms
step:409/1390 train_time:56350ms step_avg:141.23ms
step:410/1390 train_time:56496ms step_avg:141.24ms
step:411/1390 train_time:56641ms step_avg:141.25ms
step:412/1390 train_time:56786ms step_avg:141.26ms
step:413/1390 train_time:56932ms step_avg:141.27ms
step:414/1390 train_time:57079ms step_avg:141.29ms
step:415/1390 train_time:57225ms step_avg:141.30ms
step:416/1390 train_time:57372ms step_avg:141.31ms
step:417/1390 train_time:57523ms step_avg:141.33ms
step:418/1390 train_time:57667ms step_avg:141.34ms
step:419/1390 train_time:57812ms step_avg:141.35ms
step:420/1390 train_time:57960ms step_avg:141.37ms
step:421/1390 train_time:58105ms step_avg:141.38ms
step:422/1390 train_time:58252ms step_avg:141.39ms
step:423/1390 train_time:58401ms step_avg:141.41ms
step:424/1390 train_time:58547ms step_avg:141.42ms
step:425/1390 train_time:58693ms step_avg:141.43ms
step:426/1390 train_time:58841ms step_avg:141.44ms
step:427/1390 train_time:58986ms step_avg:141.45ms
step:428/1390 train_time:59133ms step_avg:141.47ms
step:429/1390 train_time:59281ms step_avg:141.48ms
step:430/1390 train_time:59426ms step_avg:141.49ms
step:431/1390 train_time:59575ms step_avg:141.51ms
step:432/1390 train_time:59722ms step_avg:141.52ms
step:433/1390 train_time:59868ms step_avg:141.53ms
step:434/1390 train_time:60014ms step_avg:141.54ms
step:435/1390 train_time:60163ms step_avg:141.56ms
step:436/1390 train_time:60308ms step_avg:141.57ms
step:437/1390 train_time:60454ms step_avg:141.58ms
step:438/1390 train_time:60603ms step_avg:141.59ms
step:439/1390 train_time:60749ms step_avg:141.61ms
step:440/1390 train_time:60896ms step_avg:141.62ms
step:441/1390 train_time:61043ms step_avg:141.63ms
step:442/1390 train_time:61188ms step_avg:141.64ms
step:443/1390 train_time:61337ms step_avg:141.66ms
step:444/1390 train_time:61483ms step_avg:141.67ms
step:445/1390 train_time:61630ms step_avg:141.68ms
step:446/1390 train_time:61779ms step_avg:141.69ms
step:447/1390 train_time:61925ms step_avg:141.70ms
step:448/1390 train_time:62072ms step_avg:141.72ms
step:449/1390 train_time:62221ms step_avg:141.73ms
step:450/1390 train_time:62368ms step_avg:141.74ms
step:451/1390 train_time:62515ms step_avg:141.76ms
step:452/1390 train_time:62662ms step_avg:141.77ms
step:453/1390 train_time:62808ms step_avg:141.78ms
step:454/1390 train_time:62956ms step_avg:141.79ms
step:455/1390 train_time:63103ms step_avg:141.80ms
step:456/1390 train_time:63249ms step_avg:141.81ms
step:457/1390 train_time:63395ms step_avg:141.82ms
step:458/1390 train_time:63544ms step_avg:141.84ms
step:459/1390 train_time:63689ms step_avg:141.85ms
step:460/1390 train_time:63837ms step_avg:141.86ms
step:461/1390 train_time:63985ms step_avg:141.87ms
step:462/1390 train_time:64133ms step_avg:141.89ms
step:463/1390 train_time:64281ms step_avg:141.90ms
step:464/1390 train_time:64426ms step_avg:141.91ms
step:465/1390 train_time:64572ms step_avg:141.92ms
step:466/1390 train_time:64720ms step_avg:141.93ms
step:467/1390 train_time:64866ms step_avg:141.94ms
step:468/1390 train_time:65012ms step_avg:141.95ms
step:469/1390 train_time:65159ms step_avg:141.96ms
step:470/1390 train_time:65306ms step_avg:141.97ms
step:471/1390 train_time:65451ms step_avg:141.98ms
step:472/1390 train_time:65599ms step_avg:141.99ms
step:473/1390 train_time:65745ms step_avg:142.00ms
step:474/1390 train_time:65892ms step_avg:142.01ms
step:475/1390 train_time:66039ms step_avg:142.02ms
step:476/1390 train_time:66185ms step_avg:142.03ms
step:477/1390 train_time:66332ms step_avg:142.04ms
step:478/1390 train_time:66480ms step_avg:142.05ms
step:479/1390 train_time:66626ms step_avg:142.06ms
step:480/1390 train_time:66774ms step_avg:142.07ms
step:481/1390 train_time:66922ms step_avg:142.09ms
step:482/1390 train_time:67068ms step_avg:142.09ms
step:483/1390 train_time:67215ms step_avg:142.10ms
step:484/1390 train_time:67362ms step_avg:142.11ms
step:485/1390 train_time:67508ms step_avg:142.12ms
step:486/1390 train_time:67655ms step_avg:142.13ms
step:487/1390 train_time:67803ms step_avg:142.14ms
step:488/1390 train_time:67948ms step_avg:142.15ms
step:489/1390 train_time:68095ms step_avg:142.16ms
step:490/1390 train_time:68243ms step_avg:142.17ms
step:491/1390 train_time:68388ms step_avg:142.18ms
step:492/1390 train_time:68535ms step_avg:142.19ms
step:493/1390 train_time:68683ms step_avg:142.20ms
step:494/1390 train_time:68828ms step_avg:142.21ms
step:495/1390 train_time:68977ms step_avg:142.22ms
step:496/1390 train_time:69123ms step_avg:142.23ms
step:497/1390 train_time:69268ms step_avg:142.24ms
step:498/1390 train_time:69416ms step_avg:142.24ms
step:499/1390 train_time:69563ms step_avg:142.26ms
step:500/1390 train_time:69708ms step_avg:142.26ms
step:500/1390 val_loss:4.4308 train_time:69775ms step_avg:142.40ms
step:501/1390 train_time:69857ms step_avg:142.27ms
step:502/1390 train_time:70003ms step_avg:142.28ms
step:503/1390 train_time:70150ms step_avg:142.29ms
step:504/1390 train_time:70297ms step_avg:142.30ms
step:505/1390 train_time:70442ms step_avg:142.31ms
step:506/1390 train_time:70587ms step_avg:142.31ms
step:507/1390 train_time:70737ms step_avg:142.33ms
step:508/1390 train_time:70885ms step_avg:142.34ms
step:509/1390 train_time:71035ms step_avg:142.35ms
step:510/1390 train_time:71181ms step_avg:142.36ms
step:511/1390 train_time:71328ms step_avg:142.37ms
step:512/1390 train_time:71476ms step_avg:142.38ms
step:513/1390 train_time:71621ms step_avg:142.39ms
step:514/1390 train_time:71770ms step_avg:142.40ms
step:515/1390 train_time:71918ms step_avg:142.41ms
step:516/1390 train_time:72065ms step_avg:142.42ms
step:517/1390 train_time:72216ms step_avg:142.44ms
step:518/1390 train_time:72363ms step_avg:142.45ms
step:519/1390 train_time:72511ms step_avg:142.46ms
step:520/1390 train_time:72659ms step_avg:142.47ms
step:521/1390 train_time:72807ms step_avg:142.48ms
step:522/1390 train_time:72956ms step_avg:142.49ms
step:523/1390 train_time:73104ms step_avg:142.50ms
step:524/1390 train_time:73254ms step_avg:142.52ms
step:525/1390 train_time:73401ms step_avg:142.53ms
step:526/1390 train_time:73550ms step_avg:142.54ms
step:527/1390 train_time:73699ms step_avg:142.55ms
step:528/1390 train_time:73846ms step_avg:142.56ms
step:529/1390 train_time:73995ms step_avg:142.57ms
step:530/1390 train_time:74143ms step_avg:142.58ms
step:531/1390 train_time:74292ms step_avg:142.59ms
step:532/1390 train_time:74440ms step_avg:142.61ms
step:533/1390 train_time:74588ms step_avg:142.62ms
step:534/1390 train_time:74738ms step_avg:142.63ms
step:535/1390 train_time:74885ms step_avg:142.64ms
step:536/1390 train_time:75036ms step_avg:142.65ms
step:537/1390 train_time:75183ms step_avg:142.66ms
step:538/1390 train_time:75333ms step_avg:142.68ms
step:539/1390 train_time:75481ms step_avg:142.69ms
step:540/1390 train_time:75629ms step_avg:142.70ms
step:541/1390 train_time:75779ms step_avg:142.71ms
step:542/1390 train_time:75927ms step_avg:142.72ms
step:543/1390 train_time:76077ms step_avg:142.73ms
step:544/1390 train_time:76223ms step_avg:142.74ms
step:545/1390 train_time:76373ms step_avg:142.75ms
step:546/1390 train_time:76520ms step_avg:142.76ms
step:547/1390 train_time:76670ms step_avg:142.78ms
step:548/1390 train_time:76820ms step_avg:142.79ms
step:549/1390 train_time:76970ms step_avg:142.80ms
step:550/1390 train_time:77119ms step_avg:142.81ms
step:551/1390 train_time:77268ms step_avg:142.83ms
step:552/1390 train_time:77418ms step_avg:142.84ms
step:553/1390 train_time:77565ms step_avg:142.85ms
step:554/1390 train_time:77716ms step_avg:142.86ms
step:555/1390 train_time:77863ms step_avg:142.87ms
step:556/1390 train_time:78012ms step_avg:142.88ms
step:557/1390 train_time:78160ms step_avg:142.89ms
step:558/1390 train_time:78310ms step_avg:142.90ms
step:559/1390 train_time:78457ms step_avg:142.91ms
step:560/1390 train_time:78605ms step_avg:142.92ms
step:561/1390 train_time:78754ms step_avg:142.93ms
step:562/1390 train_time:78902ms step_avg:142.94ms
step:563/1390 train_time:79049ms step_avg:142.95ms
step:564/1390 train_time:79198ms step_avg:142.96ms
step:565/1390 train_time:79347ms step_avg:142.97ms
step:566/1390 train_time:79496ms step_avg:142.98ms
step:567/1390 train_time:79643ms step_avg:142.99ms
step:568/1390 train_time:79791ms step_avg:143.00ms
step:569/1390 train_time:79941ms step_avg:143.01ms
step:570/1390 train_time:80090ms step_avg:143.02ms
step:571/1390 train_time:80282ms step_avg:143.11ms
step:572/1390 train_time:80429ms step_avg:143.11ms
step:573/1390 train_time:80578ms step_avg:143.12ms
step:574/1390 train_time:80727ms step_avg:143.13ms
step:575/1390 train_time:80875ms step_avg:143.14ms
step:576/1390 train_time:81020ms step_avg:143.15ms
step:577/1390 train_time:81171ms step_avg:143.16ms
step:578/1390 train_time:81322ms step_avg:143.17ms
step:579/1390 train_time:81472ms step_avg:143.18ms
step:580/1390 train_time:81620ms step_avg:143.19ms
step:581/1390 train_time:81768ms step_avg:143.20ms
step:582/1390 train_time:81916ms step_avg:143.21ms
step:583/1390 train_time:82062ms step_avg:143.21ms
step:584/1390 train_time:82213ms step_avg:143.23ms
step:585/1390 train_time:82362ms step_avg:143.24ms
step:586/1390 train_time:82512ms step_avg:143.25ms
step:587/1390 train_time:82660ms step_avg:143.26ms
step:588/1390 train_time:82808ms step_avg:143.27ms
step:589/1390 train_time:82957ms step_avg:143.28ms
step:590/1390 train_time:83103ms step_avg:143.28ms
step:591/1390 train_time:83253ms step_avg:143.29ms
step:592/1390 train_time:83403ms step_avg:143.30ms
step:593/1390 train_time:83553ms step_avg:143.32ms
step:594/1390 train_time:83701ms step_avg:143.32ms
step:595/1390 train_time:83850ms step_avg:143.33ms
step:596/1390 train_time:84000ms step_avg:143.34ms
step:597/1390 train_time:84146ms step_avg:143.35ms
step:598/1390 train_time:84295ms step_avg:143.36ms
step:599/1390 train_time:84442ms step_avg:143.37ms
step:600/1390 train_time:84592ms step_avg:143.38ms
step:601/1390 train_time:84741ms step_avg:143.39ms
step:602/1390 train_time:84889ms step_avg:143.39ms
step:603/1390 train_time:85039ms step_avg:143.41ms
step:604/1390 train_time:85187ms step_avg:143.41ms
step:605/1390 train_time:85337ms step_avg:143.42ms
step:606/1390 train_time:85484ms step_avg:143.43ms
step:607/1390 train_time:85633ms step_avg:143.44ms
step:608/1390 train_time:85782ms step_avg:143.45ms
step:609/1390 train_time:85930ms step_avg:143.46ms
step:610/1390 train_time:86081ms step_avg:143.47ms
step:611/1390 train_time:86230ms step_avg:143.48ms
step:612/1390 train_time:86378ms step_avg:143.48ms
step:613/1390 train_time:86527ms step_avg:143.49ms
step:614/1390 train_time:86676ms step_avg:143.50ms
step:615/1390 train_time:86822ms step_avg:143.51ms
step:616/1390 train_time:86972ms step_avg:143.52ms
step:617/1390 train_time:87122ms step_avg:143.53ms
step:618/1390 train_time:87271ms step_avg:143.54ms
step:619/1390 train_time:87420ms step_avg:143.55ms
step:620/1390 train_time:87571ms step_avg:143.56ms
step:621/1390 train_time:87720ms step_avg:143.57ms
step:622/1390 train_time:87871ms step_avg:143.58ms
step:623/1390 train_time:88021ms step_avg:143.59ms
step:624/1390 train_time:88172ms step_avg:143.60ms
step:625/1390 train_time:88322ms step_avg:143.61ms
step:625/1390 val_loss:4.2528 train_time:88394ms step_avg:143.73ms
step:626/1390 train_time:88476ms step_avg:143.63ms
step:627/1390 train_time:88627ms step_avg:143.64ms
step:628/1390 train_time:88775ms step_avg:143.65ms
step:629/1390 train_time:88925ms step_avg:143.66ms
step:630/1390 train_time:89072ms step_avg:143.66ms
step:631/1390 train_time:89220ms step_avg:143.67ms
step:632/1390 train_time:89372ms step_avg:143.68ms
step:633/1390 train_time:89524ms step_avg:143.70ms
step:634/1390 train_time:89674ms step_avg:143.71ms
step:635/1390 train_time:89825ms step_avg:143.72ms
step:636/1390 train_time:89973ms step_avg:143.73ms
step:637/1390 train_time:90123ms step_avg:143.74ms
step:638/1390 train_time:90271ms step_avg:143.74ms
step:639/1390 train_time:90424ms step_avg:143.76ms
step:640/1390 train_time:90575ms step_avg:143.77ms
step:641/1390 train_time:90727ms step_avg:143.78ms
step:642/1390 train_time:90876ms step_avg:143.79ms
step:643/1390 train_time:91028ms step_avg:143.80ms
step:644/1390 train_time:91177ms step_avg:143.81ms
step:645/1390 train_time:91329ms step_avg:143.82ms
step:646/1390 train_time:91479ms step_avg:143.83ms
step:647/1390 train_time:91630ms step_avg:143.85ms
step:648/1390 train_time:91783ms step_avg:143.86ms
step:649/1390 train_time:91932ms step_avg:143.87ms
step:650/1390 train_time:92083ms step_avg:143.88ms
step:651/1390 train_time:92232ms step_avg:143.89ms
step:652/1390 train_time:92382ms step_avg:143.90ms
step:653/1390 train_time:92532ms step_avg:143.91ms
step:654/1390 train_time:92684ms step_avg:143.92ms
step:655/1390 train_time:92834ms step_avg:143.93ms
step:656/1390 train_time:92985ms step_avg:143.94ms
step:657/1390 train_time:93133ms step_avg:143.95ms
step:658/1390 train_time:93285ms step_avg:143.96ms
step:659/1390 train_time:93435ms step_avg:143.97ms
step:660/1390 train_time:93587ms step_avg:143.98ms
step:661/1390 train_time:93736ms step_avg:143.99ms
step:662/1390 train_time:93887ms step_avg:144.00ms
step:663/1390 train_time:94036ms step_avg:144.01ms
step:664/1390 train_time:94189ms step_avg:144.02ms
step:665/1390 train_time:94339ms step_avg:144.03ms
step:666/1390 train_time:94489ms step_avg:144.04ms
step:667/1390 train_time:94640ms step_avg:144.05ms
step:668/1390 train_time:94793ms step_avg:144.06ms
step:669/1390 train_time:94943ms step_avg:144.07ms
step:670/1390 train_time:95092ms step_avg:144.08ms
step:671/1390 train_time:95244ms step_avg:144.09ms
step:672/1390 train_time:95393ms step_avg:144.10ms
step:673/1390 train_time:95543ms step_avg:144.11ms
step:674/1390 train_time:95692ms step_avg:144.11ms
step:675/1390 train_time:95844ms step_avg:144.13ms
step:676/1390 train_time:95993ms step_avg:144.13ms
step:677/1390 train_time:96144ms step_avg:144.14ms
step:678/1390 train_time:96292ms step_avg:144.15ms
step:679/1390 train_time:96444ms step_avg:144.16ms
step:680/1390 train_time:96593ms step_avg:144.17ms
step:681/1390 train_time:96746ms step_avg:144.18ms
step:682/1390 train_time:96895ms step_avg:144.19ms
step:683/1390 train_time:97045ms step_avg:144.20ms
step:684/1390 train_time:97194ms step_avg:144.20ms
step:685/1390 train_time:97345ms step_avg:144.21ms
step:686/1390 train_time:97492ms step_avg:144.22ms
step:687/1390 train_time:97644ms step_avg:144.23ms
step:688/1390 train_time:97794ms step_avg:144.24ms
step:689/1390 train_time:97946ms step_avg:144.25ms
step:690/1390 train_time:98096ms step_avg:144.26ms
step:691/1390 train_time:98248ms step_avg:144.27ms
step:692/1390 train_time:98397ms step_avg:144.28ms
step:693/1390 train_time:98548ms step_avg:144.29ms
step:694/1390 train_time:98698ms step_avg:144.29ms
step:695/1390 train_time:98848ms step_avg:144.30ms
step:696/1390 train_time:98998ms step_avg:144.31ms
step:697/1390 train_time:99149ms step_avg:144.32ms
step:698/1390 train_time:99298ms step_avg:144.33ms
step:699/1390 train_time:99448ms step_avg:144.34ms
step:700/1390 train_time:99596ms step_avg:144.34ms
step:701/1390 train_time:99748ms step_avg:144.35ms
step:702/1390 train_time:99900ms step_avg:144.36ms
step:703/1390 train_time:100051ms step_avg:144.37ms
step:704/1390 train_time:100202ms step_avg:144.38ms
step:705/1390 train_time:100353ms step_avg:144.39ms
step:706/1390 train_time:100506ms step_avg:144.40ms
step:707/1390 train_time:100653ms step_avg:144.41ms
step:708/1390 train_time:100804ms step_avg:144.42ms
step:709/1390 train_time:100954ms step_avg:144.43ms
step:710/1390 train_time:101107ms step_avg:144.44ms
step:711/1390 train_time:101256ms step_avg:144.45ms
step:712/1390 train_time:101409ms step_avg:144.46ms
step:713/1390 train_time:101559ms step_avg:144.47ms
step:714/1390 train_time:101709ms step_avg:144.47ms
step:715/1390 train_time:101857ms step_avg:144.48ms
step:716/1390 train_time:102010ms step_avg:144.49ms
step:717/1390 train_time:102159ms step_avg:144.50ms
step:718/1390 train_time:102310ms step_avg:144.51ms
step:719/1390 train_time:102459ms step_avg:144.51ms
step:720/1390 train_time:102610ms step_avg:144.52ms
step:721/1390 train_time:102759ms step_avg:144.53ms
step:722/1390 train_time:102912ms step_avg:144.54ms
step:723/1390 train_time:103063ms step_avg:144.55ms
step:724/1390 train_time:103214ms step_avg:144.56ms
step:725/1390 train_time:103366ms step_avg:144.57ms
step:726/1390 train_time:103517ms step_avg:144.58ms
step:727/1390 train_time:103671ms step_avg:144.59ms
step:728/1390 train_time:103823ms step_avg:144.60ms
step:729/1390 train_time:103973ms step_avg:144.61ms
step:730/1390 train_time:104125ms step_avg:144.62ms
step:731/1390 train_time:104275ms step_avg:144.63ms
step:732/1390 train_time:104427ms step_avg:144.64ms
step:733/1390 train_time:104578ms step_avg:144.64ms
step:734/1390 train_time:104730ms step_avg:144.65ms
step:735/1390 train_time:104884ms step_avg:144.67ms
step:736/1390 train_time:105035ms step_avg:144.68ms
step:737/1390 train_time:105187ms step_avg:144.69ms
step:738/1390 train_time:105337ms step_avg:144.69ms
step:739/1390 train_time:105490ms step_avg:144.70ms
step:740/1390 train_time:105644ms step_avg:144.72ms
step:741/1390 train_time:105796ms step_avg:144.73ms
step:742/1390 train_time:105949ms step_avg:144.74ms
step:743/1390 train_time:106100ms step_avg:144.75ms
step:744/1390 train_time:106250ms step_avg:144.75ms
step:745/1390 train_time:106403ms step_avg:144.77ms
step:746/1390 train_time:106552ms step_avg:144.77ms
step:747/1390 train_time:106705ms step_avg:144.78ms
step:748/1390 train_time:106855ms step_avg:144.79ms
step:749/1390 train_time:107008ms step_avg:144.80ms
step:750/1390 train_time:107159ms step_avg:144.81ms
step:750/1390 val_loss:4.1361 train_time:107231ms step_avg:144.91ms
step:751/1390 train_time:107314ms step_avg:144.82ms
step:752/1390 train_time:107464ms step_avg:144.83ms
step:753/1390 train_time:107614ms step_avg:144.84ms
step:754/1390 train_time:107764ms step_avg:144.84ms
step:755/1390 train_time:107914ms step_avg:144.85ms
step:756/1390 train_time:108066ms step_avg:144.86ms
step:757/1390 train_time:108220ms step_avg:144.87ms
step:758/1390 train_time:108372ms step_avg:144.88ms
step:759/1390 train_time:108525ms step_avg:144.89ms
step:760/1390 train_time:108673ms step_avg:144.90ms
step:761/1390 train_time:108866ms step_avg:144.96ms
step:762/1390 train_time:109014ms step_avg:144.97ms
step:763/1390 train_time:109166ms step_avg:144.98ms
step:764/1390 train_time:109316ms step_avg:144.98ms
step:765/1390 train_time:109467ms step_avg:144.99ms
step:766/1390 train_time:109616ms step_avg:145.00ms
step:767/1390 train_time:109771ms step_avg:145.01ms
step:768/1390 train_time:109924ms step_avg:145.02ms
step:769/1390 train_time:110077ms step_avg:145.03ms
step:770/1390 train_time:110229ms step_avg:145.04ms
step:771/1390 train_time:110379ms step_avg:145.05ms
step:772/1390 train_time:110530ms step_avg:145.05ms
step:773/1390 train_time:110683ms step_avg:145.06ms
step:774/1390 train_time:110835ms step_avg:145.07ms
step:775/1390 train_time:110987ms step_avg:145.08ms
step:776/1390 train_time:111139ms step_avg:145.09ms
step:777/1390 train_time:111292ms step_avg:145.10ms
step:778/1390 train_time:111443ms step_avg:145.11ms
step:779/1390 train_time:111593ms step_avg:145.11ms
step:780/1390 train_time:111745ms step_avg:145.12ms
step:781/1390 train_time:111896ms step_avg:145.13ms
step:782/1390 train_time:112048ms step_avg:145.14ms
step:783/1390 train_time:112199ms step_avg:145.15ms
step:784/1390 train_time:112351ms step_avg:145.16ms
step:785/1390 train_time:112503ms step_avg:145.17ms
step:786/1390 train_time:112655ms step_avg:145.17ms
step:787/1390 train_time:112807ms step_avg:145.18ms
step:788/1390 train_time:112958ms step_avg:145.19ms
step:789/1390 train_time:113110ms step_avg:145.20ms
step:790/1390 train_time:113260ms step_avg:145.21ms
step:791/1390 train_time:113413ms step_avg:145.22ms
step:792/1390 train_time:113566ms step_avg:145.23ms
step:793/1390 train_time:113715ms step_avg:145.23ms
step:794/1390 train_time:113869ms step_avg:145.24ms
step:795/1390 train_time:114021ms step_avg:145.25ms
step:796/1390 train_time:114174ms step_avg:145.26ms
step:797/1390 train_time:114325ms step_avg:145.27ms
step:798/1390 train_time:114479ms step_avg:145.28ms
step:799/1390 train_time:114634ms step_avg:145.29ms
step:800/1390 train_time:114786ms step_avg:145.30ms
step:801/1390 train_time:114936ms step_avg:145.30ms
step:802/1390 train_time:115089ms step_avg:145.31ms
step:803/1390 train_time:115237ms step_avg:145.32ms
step:804/1390 train_time:115389ms step_avg:145.33ms
step:805/1390 train_time:115545ms step_avg:145.34ms
step:806/1390 train_time:115697ms step_avg:145.35ms
step:807/1390 train_time:115849ms step_avg:145.36ms
step:808/1390 train_time:115999ms step_avg:145.36ms
step:809/1390 train_time:116149ms step_avg:145.37ms
step:810/1390 train_time:116301ms step_avg:145.38ms
step:811/1390 train_time:116454ms step_avg:145.39ms
step:812/1390 train_time:116606ms step_avg:145.39ms
step:813/1390 train_time:116756ms step_avg:145.40ms
step:814/1390 train_time:116909ms step_avg:145.41ms
step:815/1390 train_time:117059ms step_avg:145.42ms
step:816/1390 train_time:117213ms step_avg:145.43ms
step:817/1390 train_time:117365ms step_avg:145.43ms
step:818/1390 train_time:117515ms step_avg:145.44ms
step:819/1390 train_time:117669ms step_avg:145.45ms
step:820/1390 train_time:117820ms step_avg:145.46ms
step:821/1390 train_time:117972ms step_avg:145.46ms
step:822/1390 train_time:118123ms step_avg:145.47ms
step:823/1390 train_time:118276ms step_avg:145.48ms
step:824/1390 train_time:118430ms step_avg:145.49ms
step:825/1390 train_time:118584ms step_avg:145.50ms
step:826/1390 train_time:118737ms step_avg:145.51ms
step:827/1390 train_time:118891ms step_avg:145.52ms
step:828/1390 train_time:119042ms step_avg:145.53ms
step:829/1390 train_time:119193ms step_avg:145.54ms
step:830/1390 train_time:119346ms step_avg:145.54ms
step:831/1390 train_time:119497ms step_avg:145.55ms
step:832/1390 train_time:119651ms step_avg:145.56ms
step:833/1390 train_time:119805ms step_avg:145.57ms
step:834/1390 train_time:119958ms step_avg:145.58ms
step:835/1390 train_time:120113ms step_avg:145.59ms
step:836/1390 train_time:120270ms step_avg:145.61ms
step:837/1390 train_time:120421ms step_avg:145.61ms
step:838/1390 train_time:120574ms step_avg:145.62ms
step:839/1390 train_time:120726ms step_avg:145.63ms
step:840/1390 train_time:120877ms step_avg:145.63ms
step:841/1390 train_time:121032ms step_avg:145.65ms
step:842/1390 train_time:121185ms step_avg:145.65ms
step:843/1390 train_time:121337ms step_avg:145.66ms
step:844/1390 train_time:121491ms step_avg:145.67ms
step:845/1390 train_time:121644ms step_avg:145.68ms
step:846/1390 train_time:121797ms step_avg:145.69ms
step:847/1390 train_time:121951ms step_avg:145.70ms
step:848/1390 train_time:122105ms step_avg:145.71ms
step:849/1390 train_time:122257ms step_avg:145.72ms
step:850/1390 train_time:122413ms step_avg:145.73ms
step:851/1390 train_time:122566ms step_avg:145.74ms
step:852/1390 train_time:122718ms step_avg:145.75ms
step:853/1390 train_time:122871ms step_avg:145.75ms
step:854/1390 train_time:123025ms step_avg:145.76ms
step:855/1390 train_time:123176ms step_avg:145.77ms
step:856/1390 train_time:123329ms step_avg:145.78ms
step:857/1390 train_time:123483ms step_avg:145.79ms
step:858/1390 train_time:123640ms step_avg:145.80ms
step:859/1390 train_time:123793ms step_avg:145.81ms
step:860/1390 train_time:123947ms step_avg:145.82ms
step:861/1390 train_time:124100ms step_avg:145.83ms
step:862/1390 train_time:124252ms step_avg:145.84ms
step:863/1390 train_time:124407ms step_avg:145.85ms
step:864/1390 train_time:124558ms step_avg:145.85ms
step:865/1390 train_time:124711ms step_avg:145.86ms
step:866/1390 train_time:124870ms step_avg:145.88ms
step:867/1390 train_time:125020ms step_avg:145.88ms
step:868/1390 train_time:125172ms step_avg:145.89ms
step:869/1390 train_time:125325ms step_avg:145.90ms
step:870/1390 train_time:125478ms step_avg:145.91ms
step:871/1390 train_time:125632ms step_avg:145.91ms
step:872/1390 train_time:125784ms step_avg:145.92ms
step:873/1390 train_time:125935ms step_avg:145.93ms
step:874/1390 train_time:126091ms step_avg:145.94ms
step:875/1390 train_time:126242ms step_avg:145.94ms
step:875/1390 val_loss:4.0450 train_time:126313ms step_avg:146.03ms
step:876/1390 train_time:126394ms step_avg:145.95ms
step:877/1390 train_time:126551ms step_avg:145.96ms
step:878/1390 train_time:126703ms step_avg:145.97ms
step:879/1390 train_time:126855ms step_avg:145.98ms
step:880/1390 train_time:127008ms step_avg:145.99ms
step:881/1390 train_time:127158ms step_avg:145.99ms
step:882/1390 train_time:127315ms step_avg:146.00ms
step:883/1390 train_time:127472ms step_avg:146.02ms
step:884/1390 train_time:127625ms step_avg:146.02ms
step:885/1390 train_time:127777ms step_avg:146.03ms
step:886/1390 train_time:127933ms step_avg:146.04ms
step:887/1390 train_time:128084ms step_avg:146.05ms
step:888/1390 train_time:128239ms step_avg:146.06ms
step:889/1390 train_time:128392ms step_avg:146.07ms
step:890/1390 train_time:128546ms step_avg:146.07ms
step:891/1390 train_time:128699ms step_avg:146.08ms
step:892/1390 train_time:128853ms step_avg:146.09ms
step:893/1390 train_time:129006ms step_avg:146.10ms
step:894/1390 train_time:129160ms step_avg:146.11ms
step:895/1390 train_time:129319ms step_avg:146.12ms
step:896/1390 train_time:129473ms step_avg:146.13ms
step:897/1390 train_time:129625ms step_avg:146.14ms
step:898/1390 train_time:129779ms step_avg:146.15ms
step:899/1390 train_time:129932ms step_avg:146.16ms
step:900/1390 train_time:130083ms step_avg:146.16ms
step:901/1390 train_time:130240ms step_avg:146.17ms
step:902/1390 train_time:130392ms step_avg:146.18ms
step:903/1390 train_time:130545ms step_avg:146.19ms
step:904/1390 train_time:130698ms step_avg:146.19ms
step:905/1390 train_time:130851ms step_avg:146.20ms
step:906/1390 train_time:131004ms step_avg:146.21ms
step:907/1390 train_time:131161ms step_avg:146.22ms
step:908/1390 train_time:131315ms step_avg:146.23ms
step:909/1390 train_time:131471ms step_avg:146.24ms
step:910/1390 train_time:131629ms step_avg:146.25ms
step:911/1390 train_time:131779ms step_avg:146.26ms
step:912/1390 train_time:131933ms step_avg:146.27ms
step:913/1390 train_time:132087ms step_avg:146.28ms
step:914/1390 train_time:132240ms step_avg:146.28ms
step:915/1390 train_time:132394ms step_avg:146.29ms
step:916/1390 train_time:132549ms step_avg:146.30ms
step:917/1390 train_time:132699ms step_avg:146.31ms
step:918/1390 train_time:132854ms step_avg:146.32ms
step:919/1390 train_time:133008ms step_avg:146.32ms
step:920/1390 train_time:133160ms step_avg:146.33ms
step:921/1390 train_time:133313ms step_avg:146.34ms
step:922/1390 train_time:133471ms step_avg:146.35ms
step:923/1390 train_time:133622ms step_avg:146.35ms
step:924/1390 train_time:133775ms step_avg:146.36ms
step:925/1390 train_time:133931ms step_avg:146.37ms
step:926/1390 train_time:134081ms step_avg:146.38ms
step:927/1390 train_time:134234ms step_avg:146.38ms
step:928/1390 train_time:134390ms step_avg:146.39ms
step:929/1390 train_time:134545ms step_avg:146.40ms
step:930/1390 train_time:134699ms step_avg:146.41ms
step:931/1390 train_time:134854ms step_avg:146.42ms
step:932/1390 train_time:135008ms step_avg:146.43ms
step:933/1390 train_time:135160ms step_avg:146.44ms
step:934/1390 train_time:135314ms step_avg:146.44ms
step:935/1390 train_time:135472ms step_avg:146.46ms
step:936/1390 train_time:135626ms step_avg:146.46ms
step:937/1390 train_time:135784ms step_avg:146.48ms
step:938/1390 train_time:135939ms step_avg:146.49ms
step:939/1390 train_time:136094ms step_avg:146.49ms
step:940/1390 train_time:136249ms step_avg:146.50ms
step:941/1390 train_time:136403ms step_avg:146.51ms
step:942/1390 train_time:136556ms step_avg:146.52ms
step:943/1390 train_time:136712ms step_avg:146.53ms
step:944/1390 train_time:136869ms step_avg:146.54ms
step:945/1390 train_time:137024ms step_avg:146.55ms
step:946/1390 train_time:137180ms step_avg:146.56ms
step:947/1390 train_time:137334ms step_avg:146.57ms
step:948/1390 train_time:137489ms step_avg:146.58ms
step:949/1390 train_time:137644ms step_avg:146.59ms
step:950/1390 train_time:137801ms step_avg:146.60ms
step:951/1390 train_time:138007ms step_avg:146.66ms
step:952/1390 train_time:138158ms step_avg:146.67ms
step:953/1390 train_time:138313ms step_avg:146.67ms
step:954/1390 train_time:138466ms step_avg:146.68ms
step:955/1390 train_time:138618ms step_avg:146.69ms
step:956/1390 train_time:138773ms step_avg:146.69ms
step:957/1390 train_time:138930ms step_avg:146.71ms
step:958/1390 train_time:139086ms step_avg:146.72ms
step:959/1390 train_time:139246ms step_avg:146.73ms
step:960/1390 train_time:139401ms step_avg:146.74ms
step:961/1390 train_time:139554ms step_avg:146.74ms
step:962/1390 train_time:139708ms step_avg:146.75ms
step:963/1390 train_time:139869ms step_avg:146.77ms
step:964/1390 train_time:140024ms step_avg:146.78ms
step:965/1390 train_time:140178ms step_avg:146.78ms
step:966/1390 train_time:140332ms step_avg:146.79ms
step:967/1390 train_time:140486ms step_avg:146.80ms
step:968/1390 train_time:140639ms step_avg:146.80ms
step:969/1390 train_time:140794ms step_avg:146.81ms
step:970/1390 train_time:140950ms step_avg:146.82ms
step:971/1390 train_time:141108ms step_avg:146.83ms
step:972/1390 train_time:141260ms step_avg:146.84ms
step:973/1390 train_time:141412ms step_avg:146.85ms
step:974/1390 train_time:141567ms step_avg:146.85ms
step:975/1390 train_time:141723ms step_avg:146.86ms
step:976/1390 train_time:141876ms step_avg:146.87ms
step:977/1390 train_time:142031ms step_avg:146.88ms
step:978/1390 train_time:142184ms step_avg:146.88ms
step:979/1390 train_time:142337ms step_avg:146.89ms
step:980/1390 train_time:142492ms step_avg:146.90ms
step:981/1390 train_time:142643ms step_avg:146.90ms
step:982/1390 train_time:142797ms step_avg:146.91ms
step:983/1390 train_time:142951ms step_avg:146.92ms
step:984/1390 train_time:143105ms step_avg:146.92ms
step:985/1390 train_time:143260ms step_avg:146.93ms
step:986/1390 train_time:143416ms step_avg:146.94ms
step:987/1390 train_time:143569ms step_avg:146.95ms
step:988/1390 train_time:143721ms step_avg:146.95ms
step:989/1390 train_time:143874ms step_avg:146.96ms
step:990/1390 train_time:144030ms step_avg:146.97ms
step:991/1390 train_time:144184ms step_avg:146.98ms
step:992/1390 train_time:144341ms step_avg:146.99ms
step:993/1390 train_time:144507ms step_avg:147.01ms
step:994/1390 train_time:144659ms step_avg:147.01ms
step:995/1390 train_time:144812ms step_avg:147.02ms
step:996/1390 train_time:144964ms step_avg:147.02ms
step:997/1390 train_time:145115ms step_avg:147.03ms
step:998/1390 train_time:145270ms step_avg:147.03ms
step:999/1390 train_time:145424ms step_avg:147.04ms
step:1000/1390 train_time:145579ms step_avg:147.05ms
step:1000/1390 val_loss:3.9685 train_time:145651ms step_avg:147.12ms
step:1001/1390 train_time:145734ms step_avg:147.06ms
step:1002/1390 train_time:145897ms step_avg:147.07ms
step:1003/1390 train_time:146051ms step_avg:147.08ms
step:1004/1390 train_time:146205ms step_avg:147.09ms
step:1005/1390 train_time:146358ms step_avg:147.09ms
step:1006/1390 train_time:146509ms step_avg:147.10ms
step:1007/1390 train_time:146665ms step_avg:147.11ms
step:1008/1390 train_time:146823ms step_avg:147.12ms
step:1009/1390 train_time:146982ms step_avg:147.13ms
step:1010/1390 train_time:147134ms step_avg:147.13ms
step:1011/1390 train_time:147289ms step_avg:147.14ms
step:1012/1390 train_time:147442ms step_avg:147.15ms
step:1013/1390 train_time:147598ms step_avg:147.16ms
step:1014/1390 train_time:147753ms step_avg:147.16ms
step:1015/1390 train_time:147908ms step_avg:147.17ms
step:1016/1390 train_time:148062ms step_avg:147.18ms
step:1017/1390 train_time:148216ms step_avg:147.19ms
step:1018/1390 train_time:148369ms step_avg:147.19ms
step:1019/1390 train_time:148525ms step_avg:147.20ms
step:1020/1390 train_time:148681ms step_avg:147.21ms
step:1021/1390 train_time:148835ms step_avg:147.22ms
step:1022/1390 train_time:148991ms step_avg:147.22ms
step:1023/1390 train_time:149145ms step_avg:147.23ms
step:1024/1390 train_time:149298ms step_avg:147.24ms
step:1025/1390 train_time:149451ms step_avg:147.24ms
step:1026/1390 train_time:149605ms step_avg:147.25ms
step:1027/1390 train_time:149758ms step_avg:147.26ms
step:1028/1390 train_time:149914ms step_avg:147.26ms
step:1029/1390 train_time:150069ms step_avg:147.27ms
step:1030/1390 train_time:150224ms step_avg:147.28ms
step:1031/1390 train_time:150376ms step_avg:147.28ms
step:1032/1390 train_time:150528ms step_avg:147.29ms
step:1033/1390 train_time:150684ms step_avg:147.30ms
step:1034/1390 train_time:150839ms step_avg:147.30ms
step:1035/1390 train_time:150997ms step_avg:147.31ms
step:1036/1390 train_time:151154ms step_avg:147.32ms
step:1037/1390 train_time:151313ms step_avg:147.33ms
step:1038/1390 train_time:151468ms step_avg:147.34ms
step:1039/1390 train_time:151623ms step_avg:147.35ms
step:1040/1390 train_time:151777ms step_avg:147.36ms
step:1041/1390 train_time:151932ms step_avg:147.36ms
step:1042/1390 train_time:152085ms step_avg:147.37ms
step:1043/1390 train_time:152241ms step_avg:147.38ms
step:1044/1390 train_time:152398ms step_avg:147.39ms
step:1045/1390 train_time:152555ms step_avg:147.40ms
step:1046/1390 train_time:152709ms step_avg:147.40ms
step:1047/1390 train_time:152863ms step_avg:147.41ms
step:1048/1390 train_time:153019ms step_avg:147.42ms
step:1049/1390 train_time:153175ms step_avg:147.43ms
step:1050/1390 train_time:153330ms step_avg:147.43ms
step:1051/1390 train_time:153487ms step_avg:147.44ms
step:1052/1390 train_time:153642ms step_avg:147.45ms
step:1053/1390 train_time:153795ms step_avg:147.45ms
step:1054/1390 train_time:153953ms step_avg:147.46ms
step:1055/1390 train_time:154105ms step_avg:147.47ms
step:1056/1390 train_time:154261ms step_avg:147.48ms
step:1057/1390 train_time:154417ms step_avg:147.49ms
step:1058/1390 train_time:154575ms step_avg:147.50ms
step:1059/1390 train_time:154731ms step_avg:147.50ms
step:1060/1390 train_time:154888ms step_avg:147.51ms
step:1061/1390 train_time:155043ms step_avg:147.52ms
step:1062/1390 train_time:155198ms step_avg:147.53ms
step:1063/1390 train_time:155354ms step_avg:147.53ms
step:1064/1390 train_time:155507ms step_avg:147.54ms
step:1065/1390 train_time:155664ms step_avg:147.55ms
step:1066/1390 train_time:155824ms step_avg:147.56ms
step:1067/1390 train_time:155981ms step_avg:147.57ms
step:1068/1390 train_time:156134ms step_avg:147.57ms
step:1069/1390 train_time:156295ms step_avg:147.59ms
step:1070/1390 train_time:156447ms step_avg:147.59ms
step:1071/1390 train_time:156605ms step_avg:147.60ms
step:1072/1390 train_time:156758ms step_avg:147.61ms
step:1073/1390 train_time:156913ms step_avg:147.61ms
step:1074/1390 train_time:157066ms step_avg:147.62ms
step:1075/1390 train_time:157224ms step_avg:147.63ms
step:1076/1390 train_time:157378ms step_avg:147.63ms
step:1077/1390 train_time:157531ms step_avg:147.64ms
step:1078/1390 train_time:157692ms step_avg:147.65ms
step:1079/1390 train_time:157853ms step_avg:147.66ms
step:1080/1390 train_time:158007ms step_avg:147.67ms
step:1081/1390 train_time:158161ms step_avg:147.68ms
step:1082/1390 train_time:158317ms step_avg:147.68ms
step:1083/1390 train_time:158472ms step_avg:147.69ms
step:1084/1390 train_time:158629ms step_avg:147.70ms
step:1085/1390 train_time:158784ms step_avg:147.71ms
step:1086/1390 train_time:158941ms step_avg:147.71ms
step:1087/1390 train_time:159099ms step_avg:147.72ms
step:1088/1390 train_time:159255ms step_avg:147.73ms
step:1089/1390 train_time:159416ms step_avg:147.74ms
step:1090/1390 train_time:159573ms step_avg:147.75ms
step:1091/1390 train_time:159731ms step_avg:147.76ms
step:1092/1390 train_time:159884ms step_avg:147.77ms
step:1093/1390 train_time:160043ms step_avg:147.78ms
step:1094/1390 train_time:160197ms step_avg:147.78ms
step:1095/1390 train_time:160353ms step_avg:147.79ms
step:1096/1390 train_time:160511ms step_avg:147.80ms
step:1097/1390 train_time:160667ms step_avg:147.81ms
step:1098/1390 train_time:160824ms step_avg:147.82ms
step:1099/1390 train_time:160978ms step_avg:147.82ms
step:1100/1390 train_time:161131ms step_avg:147.83ms
step:1101/1390 train_time:161285ms step_avg:147.83ms
step:1102/1390 train_time:161443ms step_avg:147.84ms
step:1103/1390 train_time:161601ms step_avg:147.85ms
step:1104/1390 train_time:161754ms step_avg:147.86ms
step:1105/1390 train_time:161910ms step_avg:147.86ms
step:1106/1390 train_time:162065ms step_avg:147.87ms
step:1107/1390 train_time:162221ms step_avg:147.88ms
step:1108/1390 train_time:162379ms step_avg:147.89ms
step:1109/1390 train_time:162533ms step_avg:147.89ms
step:1110/1390 train_time:162690ms step_avg:147.90ms
step:1111/1390 train_time:162848ms step_avg:147.91ms
step:1112/1390 train_time:163005ms step_avg:147.92ms
step:1113/1390 train_time:163160ms step_avg:147.92ms
step:1114/1390 train_time:163316ms step_avg:147.93ms
step:1115/1390 train_time:163471ms step_avg:147.94ms
step:1116/1390 train_time:163624ms step_avg:147.94ms
step:1117/1390 train_time:163782ms step_avg:147.95ms
step:1118/1390 train_time:163944ms step_avg:147.96ms
step:1119/1390 train_time:164100ms step_avg:147.97ms
step:1120/1390 train_time:164254ms step_avg:147.98ms
step:1121/1390 train_time:164407ms step_avg:147.98ms
step:1122/1390 train_time:164561ms step_avg:147.99ms
step:1123/1390 train_time:164717ms step_avg:147.99ms
step:1124/1390 train_time:164876ms step_avg:148.00ms
step:1125/1390 train_time:165033ms step_avg:148.01ms
step:1125/1390 val_loss:3.9075 train_time:165105ms step_avg:148.08ms
step:1126/1390 train_time:165189ms step_avg:148.02ms
step:1127/1390 train_time:165344ms step_avg:148.02ms
step:1128/1390 train_time:165501ms step_avg:148.03ms
step:1129/1390 train_time:165660ms step_avg:148.04ms
step:1130/1390 train_time:165814ms step_avg:148.05ms
step:1131/1390 train_time:165970ms step_avg:148.06ms
step:1132/1390 train_time:166125ms step_avg:148.06ms
step:1133/1390 train_time:166279ms step_avg:148.07ms
step:1134/1390 train_time:166435ms step_avg:148.07ms
step:1135/1390 train_time:166591ms step_avg:148.08ms
step:1136/1390 train_time:166751ms step_avg:148.09ms
step:1137/1390 train_time:166902ms step_avg:148.09ms
step:1138/1390 train_time:167058ms step_avg:148.10ms
step:1139/1390 train_time:167214ms step_avg:148.11ms
step:1140/1390 train_time:167371ms step_avg:148.12ms
step:1141/1390 train_time:167567ms step_avg:148.16ms
step:1142/1390 train_time:167721ms step_avg:148.16ms
step:1143/1390 train_time:167882ms step_avg:148.18ms
step:1144/1390 train_time:168042ms step_avg:148.18ms
step:1145/1390 train_time:168194ms step_avg:148.19ms
step:1146/1390 train_time:168352ms step_avg:148.20ms
step:1147/1390 train_time:168508ms step_avg:148.20ms
step:1148/1390 train_time:168664ms step_avg:148.21ms
step:1149/1390 train_time:168821ms step_avg:148.22ms
step:1150/1390 train_time:168976ms step_avg:148.22ms
step:1151/1390 train_time:169133ms step_avg:148.23ms
step:1152/1390 train_time:169290ms step_avg:148.24ms
step:1153/1390 train_time:169447ms step_avg:148.25ms
step:1154/1390 train_time:169601ms step_avg:148.25ms
step:1155/1390 train_time:169758ms step_avg:148.26ms
step:1156/1390 train_time:169920ms step_avg:148.27ms
step:1157/1390 train_time:170077ms step_avg:148.28ms
step:1158/1390 train_time:170234ms step_avg:148.29ms
step:1159/1390 train_time:170390ms step_avg:148.29ms
step:1160/1390 train_time:170544ms step_avg:148.30ms
step:1161/1390 train_time:170701ms step_avg:148.31ms
step:1162/1390 train_time:170859ms step_avg:148.31ms
step:1163/1390 train_time:171015ms step_avg:148.32ms
step:1164/1390 train_time:171173ms step_avg:148.33ms
step:1165/1390 train_time:171328ms step_avg:148.34ms
step:1166/1390 train_time:171483ms step_avg:148.34ms
step:1167/1390 train_time:171637ms step_avg:148.35ms
step:1168/1390 train_time:171793ms step_avg:148.35ms
step:1169/1390 train_time:171951ms step_avg:148.36ms
step:1170/1390 train_time:172107ms step_avg:148.37ms
step:1171/1390 train_time:172266ms step_avg:148.38ms
step:1172/1390 train_time:172422ms step_avg:148.38ms
step:1173/1390 train_time:172578ms step_avg:148.39ms
step:1174/1390 train_time:172744ms step_avg:148.41ms
step:1175/1390 train_time:172904ms step_avg:148.42ms
step:1176/1390 train_time:173064ms step_avg:148.43ms
step:1177/1390 train_time:173227ms step_avg:148.44ms
step:1178/1390 train_time:173382ms step_avg:148.44ms
step:1179/1390 train_time:173537ms step_avg:148.45ms
step:1180/1390 train_time:173704ms step_avg:148.47ms
step:1181/1390 train_time:173862ms step_avg:148.47ms
step:1182/1390 train_time:174015ms step_avg:148.48ms
step:1183/1390 train_time:174174ms step_avg:148.49ms
step:1184/1390 train_time:174331ms step_avg:148.49ms
step:1185/1390 train_time:174490ms step_avg:148.50ms
step:1186/1390 train_time:174646ms step_avg:148.51ms
step:1187/1390 train_time:174809ms step_avg:148.52ms
step:1188/1390 train_time:174965ms step_avg:148.53ms
step:1189/1390 train_time:175125ms step_avg:148.54ms
step:1190/1390 train_time:175282ms step_avg:148.54ms
step:1191/1390 train_time:175440ms step_avg:148.55ms
step:1192/1390 train_time:175594ms step_avg:148.56ms
step:1193/1390 train_time:175750ms step_avg:148.56ms
step:1194/1390 train_time:175906ms step_avg:148.57ms
step:1195/1390 train_time:176062ms step_avg:148.58ms
step:1196/1390 train_time:176220ms step_avg:148.58ms
step:1197/1390 train_time:176378ms step_avg:148.59ms
step:1198/1390 train_time:176541ms step_avg:148.60ms
step:1199/1390 train_time:176697ms step_avg:148.61ms
step:1200/1390 train_time:176854ms step_avg:148.62ms
step:1201/1390 train_time:177009ms step_avg:148.62ms
step:1202/1390 train_time:177178ms step_avg:148.64ms
step:1203/1390 train_time:177336ms step_avg:148.65ms
step:1204/1390 train_time:177493ms step_avg:148.65ms
step:1205/1390 train_time:177649ms step_avg:148.66ms
step:1206/1390 train_time:177806ms step_avg:148.67ms
step:1207/1390 train_time:177961ms step_avg:148.67ms
step:1208/1390 train_time:178118ms step_avg:148.68ms
step:1209/1390 train_time:178275ms step_avg:148.69ms
step:1210/1390 train_time:178436ms step_avg:148.70ms
step:1211/1390 train_time:178594ms step_avg:148.70ms
step:1212/1390 train_time:178750ms step_avg:148.71ms
step:1213/1390 train_time:178905ms step_avg:148.72ms
step:1214/1390 train_time:179063ms step_avg:148.72ms
step:1215/1390 train_time:179219ms step_avg:148.73ms
step:1216/1390 train_time:179374ms step_avg:148.73ms
step:1217/1390 train_time:179530ms step_avg:148.74ms
step:1218/1390 train_time:179683ms step_avg:148.74ms
step:1219/1390 train_time:179836ms step_avg:148.75ms
step:1220/1390 train_time:179992ms step_avg:148.75ms
step:1221/1390 train_time:180148ms step_avg:148.76ms
step:1222/1390 train_time:180303ms step_avg:148.76ms
step:1223/1390 train_time:180460ms step_avg:148.77ms
step:1224/1390 train_time:180619ms step_avg:148.78ms
step:1225/1390 train_time:180775ms step_avg:148.79ms
step:1226/1390 train_time:180932ms step_avg:148.79ms
step:1227/1390 train_time:181090ms step_avg:148.80ms
step:1228/1390 train_time:181244ms step_avg:148.80ms
step:1229/1390 train_time:181399ms step_avg:148.81ms
step:1230/1390 train_time:181560ms step_avg:148.82ms
step:1231/1390 train_time:181717ms step_avg:148.83ms
step:1232/1390 train_time:181877ms step_avg:148.84ms
step:1233/1390 train_time:182034ms step_avg:148.84ms
step:1234/1390 train_time:182189ms step_avg:148.85ms
step:1235/1390 train_time:182344ms step_avg:148.85ms
step:1236/1390 train_time:182499ms step_avg:148.86ms
step:1237/1390 train_time:182655ms step_avg:148.86ms
step:1238/1390 train_time:182820ms step_avg:148.88ms
step:1239/1390 train_time:182978ms step_avg:148.88ms
step:1240/1390 train_time:183138ms step_avg:148.89ms
step:1241/1390 train_time:183298ms step_avg:148.90ms
step:1242/1390 train_time:183454ms step_avg:148.91ms
step:1243/1390 train_time:183612ms step_avg:148.91ms
step:1244/1390 train_time:183769ms step_avg:148.92ms
step:1245/1390 train_time:183926ms step_avg:148.93ms
step:1246/1390 train_time:184083ms step_avg:148.93ms
step:1247/1390 train_time:184246ms step_avg:148.95ms
step:1248/1390 train_time:184401ms step_avg:148.95ms
step:1249/1390 train_time:184555ms step_avg:148.96ms
step:1250/1390 train_time:184710ms step_avg:148.96ms
step:1250/1390 val_loss:3.8596 train_time:184785ms step_avg:149.02ms
step:1251/1390 train_time:184872ms step_avg:148.97ms
step:1252/1390 train_time:185027ms step_avg:148.98ms
step:1253/1390 train_time:185182ms step_avg:148.98ms
step:1254/1390 train_time:185336ms step_avg:148.98ms
step:1255/1390 train_time:185502ms step_avg:149.00ms
step:1256/1390 train_time:185658ms step_avg:149.00ms
step:1257/1390 train_time:185816ms step_avg:149.01ms
step:1258/1390 train_time:185979ms step_avg:149.02ms
step:1259/1390 train_time:186138ms step_avg:149.03ms
step:1260/1390 train_time:186293ms step_avg:149.03ms
step:1261/1390 train_time:186453ms step_avg:149.04ms
step:1262/1390 train_time:186612ms step_avg:149.05ms
step:1263/1390 train_time:186768ms step_avg:149.06ms
step:1264/1390 train_time:186924ms step_avg:149.06ms
step:1265/1390 train_time:187082ms step_avg:149.07ms
step:1266/1390 train_time:187240ms step_avg:149.08ms
step:1267/1390 train_time:187397ms step_avg:149.08ms
step:1268/1390 train_time:187554ms step_avg:149.09ms
step:1269/1390 train_time:187716ms step_avg:149.10ms
step:1270/1390 train_time:187875ms step_avg:149.11ms
step:1271/1390 train_time:188032ms step_avg:149.11ms
step:1272/1390 train_time:188188ms step_avg:149.12ms
step:1273/1390 train_time:188342ms step_avg:149.12ms
step:1274/1390 train_time:188498ms step_avg:149.13ms
step:1275/1390 train_time:188653ms step_avg:149.13ms
step:1276/1390 train_time:188808ms step_avg:149.14ms
step:1277/1390 train_time:188967ms step_avg:149.14ms
step:1278/1390 train_time:189122ms step_avg:149.15ms
step:1279/1390 train_time:189280ms step_avg:149.16ms
step:1280/1390 train_time:189443ms step_avg:149.17ms
step:1281/1390 train_time:189601ms step_avg:149.17ms
step:1282/1390 train_time:189755ms step_avg:149.18ms
step:1283/1390 train_time:189910ms step_avg:149.18ms
step:1284/1390 train_time:190073ms step_avg:149.19ms
step:1285/1390 train_time:190231ms step_avg:149.20ms
step:1286/1390 train_time:190388ms step_avg:149.21ms
step:1287/1390 train_time:190543ms step_avg:149.21ms
step:1288/1390 train_time:190703ms step_avg:149.22ms
step:1289/1390 train_time:190866ms step_avg:149.23ms
step:1290/1390 train_time:191027ms step_avg:149.24ms
step:1291/1390 train_time:191187ms step_avg:149.25ms
step:1292/1390 train_time:191345ms step_avg:149.25ms
step:1293/1390 train_time:191504ms step_avg:149.26ms
step:1294/1390 train_time:191661ms step_avg:149.27ms
step:1295/1390 train_time:191816ms step_avg:149.27ms
step:1296/1390 train_time:191975ms step_avg:149.28ms
step:1297/1390 train_time:192136ms step_avg:149.29ms
step:1298/1390 train_time:192294ms step_avg:149.30ms
step:1299/1390 train_time:192450ms step_avg:149.30ms
step:1300/1390 train_time:192607ms step_avg:149.31ms
step:1301/1390 train_time:192764ms step_avg:149.31ms
step:1302/1390 train_time:192923ms step_avg:149.32ms
step:1303/1390 train_time:193084ms step_avg:149.33ms
step:1304/1390 train_time:193243ms step_avg:149.34ms
step:1305/1390 train_time:193397ms step_avg:149.34ms
step:1306/1390 train_time:193556ms step_avg:149.35ms
step:1307/1390 train_time:193711ms step_avg:149.35ms
step:1308/1390 train_time:193874ms step_avg:149.36ms
step:1309/1390 train_time:194029ms step_avg:149.37ms
step:1310/1390 train_time:194185ms step_avg:149.37ms
step:1311/1390 train_time:194339ms step_avg:149.38ms
step:1312/1390 train_time:194494ms step_avg:149.38ms
step:1313/1390 train_time:194649ms step_avg:149.39ms
step:1314/1390 train_time:194806ms step_avg:149.39ms
step:1315/1390 train_time:194962ms step_avg:149.40ms
step:1316/1390 train_time:195118ms step_avg:149.40ms
step:1317/1390 train_time:195274ms step_avg:149.41ms
step:1318/1390 train_time:195436ms step_avg:149.42ms
step:1319/1390 train_time:195593ms step_avg:149.42ms
step:1320/1390 train_time:195753ms step_avg:149.43ms
step:1321/1390 train_time:195913ms step_avg:149.44ms
step:1322/1390 train_time:196074ms step_avg:149.45ms
step:1323/1390 train_time:196230ms step_avg:149.45ms
step:1324/1390 train_time:196384ms step_avg:149.46ms
step:1325/1390 train_time:196540ms step_avg:149.46ms
step:1326/1390 train_time:196700ms step_avg:149.47ms
step:1327/1390 train_time:196856ms step_avg:149.47ms
step:1328/1390 train_time:197012ms step_avg:149.48ms
step:1329/1390 train_time:197186ms step_avg:149.50ms
step:1330/1390 train_time:197345ms step_avg:149.50ms
step:1331/1390 train_time:197541ms step_avg:149.54ms
step:1332/1390 train_time:197704ms step_avg:149.55ms
step:1333/1390 train_time:197862ms step_avg:149.56ms
step:1334/1390 train_time:198018ms step_avg:149.56ms
step:1335/1390 train_time:198172ms step_avg:149.56ms
step:1336/1390 train_time:198337ms step_avg:149.58ms
step:1337/1390 train_time:198497ms step_avg:149.58ms
step:1338/1390 train_time:198655ms step_avg:149.59ms
step:1339/1390 train_time:198813ms step_avg:149.60ms
step:1340/1390 train_time:198972ms step_avg:149.60ms
step:1341/1390 train_time:199126ms step_avg:149.61ms
step:1342/1390 train_time:199287ms step_avg:149.61ms
step:1343/1390 train_time:199443ms step_avg:149.62ms
step:1344/1390 train_time:199599ms step_avg:149.62ms
step:1345/1390 train_time:199757ms step_avg:149.63ms
step:1346/1390 train_time:199914ms step_avg:149.64ms
step:1347/1390 train_time:200076ms step_avg:149.65ms
step:1348/1390 train_time:200236ms step_avg:149.65ms
step:1349/1390 train_time:200395ms step_avg:149.66ms
step:1350/1390 train_time:200551ms step_avg:149.66ms
step:1351/1390 train_time:200708ms step_avg:149.67ms
step:1352/1390 train_time:200873ms step_avg:149.68ms
step:1353/1390 train_time:201034ms step_avg:149.69ms
step:1354/1390 train_time:201192ms step_avg:149.70ms
step:1355/1390 train_time:201350ms step_avg:149.70ms
step:1356/1390 train_time:201507ms step_avg:149.71ms
step:1357/1390 train_time:201666ms step_avg:149.71ms
step:1358/1390 train_time:201829ms step_avg:149.72ms
step:1359/1390 train_time:201988ms step_avg:149.73ms
step:1360/1390 train_time:202150ms step_avg:149.74ms
step:1361/1390 train_time:202308ms step_avg:149.75ms
step:1362/1390 train_time:202466ms step_avg:149.75ms
step:1363/1390 train_time:202630ms step_avg:149.76ms
step:1364/1390 train_time:202786ms step_avg:149.77ms
step:1365/1390 train_time:202941ms step_avg:149.77ms
step:1366/1390 train_time:203099ms step_avg:149.78ms
step:1367/1390 train_time:203257ms step_avg:149.78ms
step:1368/1390 train_time:203414ms step_avg:149.79ms
step:1369/1390 train_time:203581ms step_avg:149.80ms
step:1370/1390 train_time:203740ms step_avg:149.81ms
step:1371/1390 train_time:203900ms step_avg:149.82ms
step:1372/1390 train_time:204061ms step_avg:149.82ms
step:1373/1390 train_time:204217ms step_avg:149.83ms
step:1374/1390 train_time:204375ms step_avg:149.84ms
step:1375/1390 train_time:204533ms step_avg:149.84ms
step:1375/1390 val_loss:3.8337 train_time:204605ms step_avg:149.89ms
step:1376/1390 train_time:204689ms step_avg:149.85ms
step:1377/1390 train_time:204846ms step_avg:149.85ms
step:1378/1390 train_time:205003ms step_avg:149.86ms
step:1379/1390 train_time:205162ms step_avg:149.86ms
step:1380/1390 train_time:205318ms step_avg:149.87ms
step:1381/1390 train_time:205480ms step_avg:149.88ms
step:1382/1390 train_time:205638ms step_avg:149.88ms
step:1383/1390 train_time:205800ms step_avg:149.89ms
step:1384/1390 train_time:205962ms step_avg:149.90ms
step:1385/1390 train_time:206117ms step_avg:149.90ms
step:1386/1390 train_time:206275ms step_avg:149.91ms
step:1387/1390 train_time:206435ms step_avg:149.92ms
step:1388/1390 train_time:206594ms step_avg:149.92ms
step:1389/1390 train_time:206754ms step_avg:149.93ms
step:1390/1390 train_time:206910ms step_avg:149.93ms
step:1390/1390 val_loss:3.8331 train_time:206982ms step_avg:149.99ms
peak memory consumption: 31565 MiB
