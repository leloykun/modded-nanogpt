import os
import sys
with open(sys.argv[0]) as f:
    code = f.read() # read the code of this file ASAP, for logging
import uuid
import time
import glob
import subprocess
import contextlib
from dataclasses import dataclass

import torch
torch.empty(1, device='cuda', requires_grad=True).backward()
from torch import nn
import torch.nn.functional as F
import torch.distributed as dist
from torch.nn.parallel import DistributedDataParallel as DDP
# use of FlexAttention contributed by @KoszarskyB
from torch.nn.attention.flex_attention import BlockMask, flex_attention

# -----------------------------------------------------------------------------
# Muon optimizer

@torch.compile
def zeropower_via_newtonschulz5(G, steps):
    """
    Newton-Schulz iteration to compute the zeroth power / orthogonalization of G. We opt to use a
    quintic iteration whose coefficients are selected to maximize the slope at zero. For the purpose
    of minimizing steps, it turns out to be empirically effective to keep increasing the slope at
    zero even beyond the point where the iteration no longer converges all the way to one everywhere
    on the interval. This iteration therefore does not produce UV^T but rather something like US'V^T
    where S' is diagonal with S_{ii}' ~ Uniform(0.5, 1.5), which turns out not to hurt model
    performance at all relative to UV^T, where USV^T = G is the SVD.
    """
    assert len(G.shape) == 2
    a, b, c = (3.4445, -4.7750,  2.0315)
    X = G.bfloat16()
    if G.size(0) > G.size(1):
        X = X.T

    # Ensure spectral norm is at most 1
    X = X / (X.norm() + 1e-7)
    # Perform the NS iterations
    for _ in range(steps):
        A = X @ X.T
        B = b * A + c * A @ A # adapted from suggestion by @jxbz, @leloykun, and @YouJiacheng
        X = a * X + B @ X
    
    if G.size(0) > G.size(1):
        X = X.T
    X = torch.einsum("ij,ij,ab->ab", G.type_as(X), X, X)
    return X

class Muon(torch.optim.Optimizer):
    """
    Muon - MomentUm Orthogonalized by Newton-schulz

    Muon internally runs standard SGD-momentum, and then performs an orthogonalization post-
    processing step, in which each 2D parameter's update is replaced with the nearest orthogonal
    matrix. To efficiently orthogonalize each update, we use a Newton-Schulz iteration, which has
    the advantage that it can be stably run in bfloat16 on the GPU.

    Some warnings:
    - This optimizer assumes that all parameters passed in are 2D.
    - It should not be used for the embedding layer, the final fully connected layer, or any {0,1}-D
    parameters; those should all be optimized by a standard method (e.g., AdamW).
    - To use it with 4D convolutional filters, it works well to just flatten their last 3 dimensions.
    - We believe it is unlikely to work well for training with small batch size.
    - We believe it may not work well for finetuning pretrained models, but we haven't tested this.
    - We have not yet tried this optimizer for training scenarios larger than NanoGPT (124M).

    Arguments:
        lr: The learning rate used by the internal SGD.
        momentum: The momentum used by the internal SGD.
        nesterov: Whether to use Nesterov-style momentum in the internal SGD. (recommended)
        ns_steps: The number of Newton-Schulz iteration steps to use.
    """
    def __init__(self, params, lr=0.02, momentum=0.95, nesterov=True, ns_steps=5):
        self.world_size = int(os.environ['WORLD_SIZE'])
        self.rank = int(os.environ['RANK'])
        defaults = dict(lr=lr, momentum=momentum, nesterov=nesterov, ns_steps=ns_steps)
        assert all(isinstance(p, torch.Tensor) for p in params)
        sizes = {p.numel() for p in params}
        param_groups = [dict(params=[p for p in params if p.numel() == size],
                             update_buffer=[torch.empty(size, device='cuda', dtype=torch.bfloat16) for _ in range(self.world_size)])
                        for size in sizes]
        super().__init__(param_groups, defaults)

    def step(self):

        for group in self.param_groups:

            lr = group['lr']
            momentum = group['momentum']
            nesterov = group['nesterov']
            ns_steps = group['ns_steps']
            update_buffers = group['update_buffer']
            # generate weight updates in distributed fashion
            params = group['params']
            handle = None
            params_world = None
            def update_prev():
                if params_world is None:
                    return
                assert handle is not None
                handle.wait()
                for p_world, g_world in zip(params_world, update_buffers):
                    p_world.data.add_(
                        g_world.view_as(p_world),
                        alpha=-lr * max(1, p_world.size(0) / p_world.size(1)) ** 0.5,
                    )
            for base_i in range(len(params))[::self.world_size]:
                if base_i + rank < len(params):
                    p = params[base_i + self.rank]
                    g = p.grad
                    assert g is not None
                    state = self.state[p]
                    if 'momentum_buffer' not in state:
                        state['momentum_buffer'] = torch.zeros_like(g)
                    buf = state['momentum_buffer']
                    buf.lerp_(g, 1 - momentum)
                    g = g.lerp_(buf, momentum) if nesterov else buf
                    g = zeropower_via_newtonschulz5(g, steps=ns_steps).flatten()
                else:
                    g = update_buffers[rank]
                update_prev() # async all_gather instead of sync all_reduce by @YouJiacheng
                handle = dist.all_gather(update_buffers, g, async_op=True)
                params_world = params[base_i : base_i + self.world_size]
            update_prev()

# -----------------------------------------------------------------------------
# PyTorch nn.Module definitions for the GPT-2 model

def norm(x):
    return F.rms_norm(x, (x.size(-1),))

class CastedLinear(nn.Linear):

    def __init__(self, in_features, out_features):
        super().__init__(in_features, out_features, bias=False)

    def forward(self, x):
        return F.linear(x, self.weight.type_as(x))

class Rotary(nn.Module):

    def __init__(self, dim, max_seq_len=65536):
        super().__init__()
        # half-truncate RoPE by @YouJiacheng
        angular_freq = (1 / 1024) ** torch.linspace(0, 1, steps=dim//4, dtype=torch.float32)
        angular_freq = torch.cat([angular_freq, angular_freq.new_zeros(dim//4)])
        t = torch.arange(max_seq_len, dtype=torch.float32)
        theta = torch.einsum('i,j -> ij', t, angular_freq)
        self.cos = nn.Buffer(theta.cos(), persistent=False)
        self.sin = nn.Buffer(theta.sin(), persistent=False)

    def forward(self, x):
        cos, sin = self.cos[None, :x.size(-3), None, :], self.sin[None, :x.size(-3), None, :]
        x1, x2 = x.float().chunk(2, dim=-1)
        y1 = x1 * cos + x2 * sin
        y2 = x1 * (-sin) + x2 * cos
        return torch.cat((y1, y2), 3).type_as(x)

class CausalSelfAttention(nn.Module):

    def __init__(self, dim, num_heads):
        super().__init__()
        assert dim % num_heads == 0
        self.num_heads = num_heads
        self.c_q = CastedLinear(dim, dim)
        self.c_k = CastedLinear(dim, dim)
        self.c_v = CastedLinear(dim, dim)
        self.lambdas = nn.Parameter(torch.tensor([0.5, 0.5]))
        self.rotary = Rotary(dim // num_heads) # dim // num_heads = head_dim
        self.c_proj = CastedLinear(dim, dim)
        self.c_proj.weight.data.zero_() # zero init suggested by @Grad62304977

    def forward(self, x, ve, block_mask):
        B, T = x.size(0), x.size(1) # batch size, sequence length
        assert B == 1, 'Must use batch size = 1 for FlexAttention'
        q = self.c_q(x).view(B, T, self.num_heads, -1)
        k = self.c_k(x).view(B, T, self.num_heads, -1)
        v = self.c_v(x).view(B, T, self.num_heads, -1)
        if ve is not None:
            v = self.lambdas[0] * v + self.lambdas[1] * ve.view_as(v) # @KoszarskyB & @Grad62304977
        else: # skip mid-layers token value embeddings by @YouJiacheng
            v = self.lambdas[0] * v
        q, k = norm(q), norm(k) # QK norm @Grad62304977
        q, k = self.rotary(q), self.rotary(k)
        y = flex_attention(q.transpose(1, 2), k.transpose(1, 2), v.transpose(1, 2), block_mask=block_mask)
        y = y.transpose(1, 2).contiguous().view_as(x) # re-assemble all head outputs side by side
        y = self.c_proj(y)
        return y

class MLP(nn.Module):

    def __init__(self, dim):
        super().__init__()
        self.c_fc = CastedLinear(dim, 4 * dim)
        self.c_proj = CastedLinear(4 * dim, dim)
        self.c_proj.weight.data.zero_() # zero init suggested by @Grad62304977

    def forward(self, x):
        x = self.c_fc(x)
        x = F.relu(x).square() # https://arxiv.org/abs/2109.08668v2; ~1-2% better than GELU; suggested by @SKYLINEZ007 and @Grad62304977
        x = self.c_proj(x)
        return x

class Block(nn.Module):

    def __init__(self, model_dim, num_heads, use_attn=True):
        super().__init__()
        self.attn = CausalSelfAttention(model_dim, num_heads) if use_attn else None
        self.mlp = MLP(model_dim)
        self.lambdas = nn.Parameter(torch.tensor([1., 0.]))

    def forward(self, x, ve, x0, block_mask):
        x = self.lambdas[0] * x + self.lambdas[1] * x0
        if self.attn is not None:
            x = x + self.attn(norm(x), ve, block_mask)
        x = x + self.mlp(norm(x))
        return x

class ValueEmbedding(nn.Module):
    def __init__(self, vocab_size, model_dim):
        super().__init__()
        self.embed = nn.ModuleList([nn.Embedding(vocab_size, model_dim) for _ in range(3)])

    def forward(self, inputs):
        ve = [emb(inputs).bfloat16() for emb in self.embed]
        # 012 ... 012 structure on token value embeddings by @YouJiacheng, improved on @leloykun's U-net structure
        ve = [ve[0], ve[1], ve[2], None, None, None, None, None, None, ve[0], ve[1], ve[2]]
        return ve

# -----------------------------------------------------------------------------
# The main GPT-2 model

class GPT(nn.Module):

    def __init__(self, vocab_size, num_layers, num_heads, model_dim):
        super().__init__()
        self.embed = nn.Embedding(vocab_size, model_dim)
        # skip attention of blocks.7 (the 8th layer) by @YouJiacheng
        self.blocks = nn.ModuleList([Block(model_dim, num_heads, use_attn=(i != 7))
                                     for i in range(num_layers)])
        # token value embeddings by @KoszarskyB - inspired by @Grad62304977's value residual learning
        # U-net structure on token value embeddings by @leloykun
        self.value_embeds = ValueEmbedding(vocab_size, model_dim)
        self.lm_head = CastedLinear(model_dim, vocab_size)
        self.lm_head.weight.data.zero_() # @Grad62304977
        # U-net design by @brendanh0gan
        self.num_encoder_layers = num_layers // 2 # Half of the layers for encoder
        self.num_decoder_layers = num_layers - self.num_encoder_layers # Remaining for decoder
        # Add learnable skip connection weights for decoder layers
        self.skip_weights = nn.Parameter(torch.ones(self.num_decoder_layers))

    def forward(self, inputs, targets, sliding_window_num_blocks):
        BLOCK_SIZE = 128
        seq_len = len(inputs)
        assert seq_len % BLOCK_SIZE == 0
        total_num_blocks = seq_len // BLOCK_SIZE
        assert inputs.ndim == 1
        docs = (inputs == 50256).cumsum(0)
        docs_low = docs.view(-1, BLOCK_SIZE)[:, 0].contiguous()
        docs_high = docs.view(-1, BLOCK_SIZE)[:, -1].contiguous()

        def document_causal(b, h, q_idx, kv_idx):
            causal_mask = q_idx >= kv_idx
            document_mask = docs[q_idx] == docs[kv_idx]
            return causal_mask & document_mask

        def dense_to_ordered(dense_mask):
            num_blocks = dense_mask.sum(dim=-1, dtype=torch.int32)
            indices = dense_mask.argsort(dim=-1, descending=True, stable=True).to(torch.int32)
            return num_blocks[None, None].contiguous(), indices[None, None].contiguous()

        def create_doc_swc_block_mask(sliding_window_num_blocks):
            kv_idx = block_idx = torch.arange(total_num_blocks, dtype=torch.int32, device='cuda')
            q_idx = block_idx[:, None]
            causal_bm = q_idx >= kv_idx
            causal_full_bm = q_idx > kv_idx
            window_bm = q_idx - kv_idx < sliding_window_num_blocks
            window_full_bm = window_bm # block-wise sliding window by @YouJiacheng
            # document_bm = (docs_low[q_idx] <= docs_high[kv_idx]) & (docs_low[kv_idx] <= docs_high[q_idx])
            document_bm = (docs_low[:, None] <= docs_high) & (docs_low <= docs_high[:, None])
            document_full_bm = (docs_low[:, None] == docs_high) & (docs_low == docs_high[:, None])
            nonzero_bm = causal_bm & window_bm & document_bm
            full_bm  = causal_full_bm & window_full_bm & document_full_bm
            kv_num_blocks, kv_indices = dense_to_ordered(nonzero_bm & ~full_bm)
            full_kv_num_blocks, full_kv_indices = dense_to_ordered(full_bm)
            return BlockMask.from_kv_blocks(
                kv_num_blocks,
                kv_indices,
                full_kv_num_blocks,
                full_kv_indices,
                BLOCK_SIZE=BLOCK_SIZE,
                mask_mod=document_causal,
            )

        block_mask = create_doc_swc_block_mask(sliding_window_num_blocks)

        x0 = norm(self.embed(inputs[None]).bfloat16()) # use of norm here by @Grad62304977
        x = x0
        ve = self.value_embeds(inputs)
        assert len(ve) == len(self.blocks)
        ve_enc, ve_dec = ve[:self.num_encoder_layers], ve[self.num_encoder_layers:]

        # Store outputs for U-Net skip connections
        skip_connections = []
        # Encoder pass - process only the first half of the blocks
        for i in range(self.num_encoder_layers):
            x = self.blocks[i](x, ve_enc[i], x0, block_mask)
            skip_connections.append(x)
        # Decoder pass - process the remaining blocks with weighted skip connections
        for i in range(self.num_decoder_layers):
            x = x + self.skip_weights[i] * skip_connections.pop()
            # U-net structure on token value embeddings by @leloykun
            x = self.blocks[self.num_encoder_layers + i](x, ve_dec[i], x0, block_mask)

        x = norm(x)
        logits = self.lm_head(x)
        logits = 15 * torch.tanh(logits / 15) # @Grad62304977 added tanh softcapping, @KoszarskyB reduced it from 30 to 15
        logits = logits.float()
        loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets)
        return loss

# -----------------------------------------------------------------------------
# Our own simple Distributed Data Loader

def _load_data_shard(path):
    # only reads the header, returns header data
    # header is 256 int32
    header = torch.from_file(path, False, 256, dtype=torch.int32)
    assert header[0] == 20240520, 'magic number mismatch in the data .bin file'
    assert header[1] == 1, 'unsupported version'
    num_tokens = int(header[2]) # number of tokens (claimed)
    with open(path, 'rb', buffering=0) as f:
        tokens = torch.empty(num_tokens, dtype=torch.uint16, pin_memory=True) # avoid pin_memory copy by @YouJiacheng
        f.seek(256 * 4)
        nbytes = f.readinto(tokens.numpy()) # avoid bytes->array copy by @YouJiacheng
        assert nbytes == 2 * num_tokens, 'number of tokens read does not match header'
    return tokens

class DistributedDataLoader:

    def __init__(self, filename_pattern):
        self.rank = int(os.environ['RANK'])
        self.world_size = int(os.environ['WORLD_SIZE'])
        self.files = sorted(glob.glob(filename_pattern))
        self.reset()

    def reset(self):
        self.current_shard = -1
        self.advance()

    def advance(self):
        self.current_shard = (self.current_shard + 1) % len(self.files)
        self.current_position = 0
        self.tokens = _load_data_shard(self.files[self.current_shard])

    def next_batch(self, batch_size):
        assert batch_size % self.world_size == 0
        device_batch_size = batch_size // self.world_size
        # load next shard if necessary
        if self.current_position + batch_size + 1 >= len(self.tokens):
            self.advance()
        pos = self.current_position + self.rank * device_batch_size
        device_batch_tokens = self.tokens[pos:pos+device_batch_size+1]
        # advance current position
        self.current_position += batch_size
        inputs = device_batch_tokens[:-1].to(device='cuda', dtype=torch.int32, non_blocking=True)
        targets = device_batch_tokens[1:].to(device='cuda', dtype=torch.int64, non_blocking=True)
        return inputs, targets

# -----------------------------------------------------------------------------
# int main

@dataclass
class Hyperparameters:
    # data
    train_files = 'data/fineweb10B/fineweb_train_*.bin' # input .bin to train on
    val_files = 'data/fineweb10B/fineweb_val_*.bin' # input .bin to eval validation loss on
    val_tokens = 10485760 # how many tokens of validation data? it's important to keep this fixed for consistent comparisons
    # optimization
    batch_size = 8*64*1024 # batch size in tokens
    num_iterations = 1390 # number of iterations to run
    cooldown_frac = 0.4 # fraction of training spent cooling down the learning rate
    bf16_embeds = True
    # evaluation and logging
    val_loss_every = 125 # every how many steps to evaluate val loss? 0 for only at the end
    # implementation
    max_device_batch_size = 64*1024 # batch size per device in tokens
    save_checkpoint = False
args = Hyperparameters()

micro_bs = args.max_device_batch_size

# set up DDP (distributed data parallel). torchrun sets this env variable
rank = int(os.environ['RANK'])
local_rank = int(os.environ['LOCAL_RANK'])
world_size = int(os.environ['WORLD_SIZE'])
assert torch.cuda.is_available()
torch.cuda.set_device(local_rank)
dist.init_process_group(backend='nccl', device_id=torch.device(local_rank))
dist.barrier()
master_process = (rank == 0) # this process will do logging, checkpointing etc.

# begin logging
logfile = None
if master_process:
    run_id = uuid.uuid4()
    os.makedirs('logs', exist_ok=True)
    logfile = f'logs/{run_id}.txt'
    print(logfile)

def print0(s, console=False):
    if master_process:
        with open(logfile, 'a') as f:
            if console:
                print(s)
            print(s, file=f)

# begin by printing this file (the Python code)
print0(code)
print0('='*100)
# log information about the hardware/software environment this is running on
print0(f'Running Python {sys.version}')
print0(f'Running PyTorch {torch.version.__version__} compiled for CUDA {torch.version.cuda}')
print0(subprocess.run(['nvidia-smi'], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True).stdout)
print0('='*100)

# load data
train_loader = DistributedDataLoader(args.train_files)
val_loader = DistributedDataLoader(args.val_files)
print0(f'Training dataloader files: {train_loader.files}')
print0(f'Validation dataloader files: {val_loader.files}')
print0('='*100)

# there are only 50257 unique GPT-2 tokens; we extend to nearest multiple of 128 for efficiency. suggested to me by @Grad62304977.
# this originates from Karpathy's experiments.
model = GPT(vocab_size=50304, num_layers=12, num_heads=6, model_dim=768)
model = model.cuda()
if args.bf16_embeds:
    for m in model.modules():
        if isinstance(m, nn.Embedding):
            m.bfloat16()
model = torch.compile(model)
ddp_model = DDP(model, device_ids=[local_rank], broadcast_buffers=False, gradient_as_bucket_view=True)

# collect the parameters to optimize
hidden_matrix_params = [p for p in model.blocks.parameters() if p.ndim == 2]
embed_params = [model.embed.weight, *model.value_embeds.parameters()]
scalar_params = [p for p in model.parameters() if p.ndim < 2]
head_params = [model.lm_head.weight]

# init the optimizer(s)
optimizer1 = torch.optim.Adam([dict(params=embed_params, lr=0.6),
                               dict(params=head_params, lr=0.008),
                               dict(params=scalar_params, lr=0.04)],
                              betas=(0.8, 0.95), fused=True)
# optimizer2 = Muon(hidden_matrix_params, lr=0.5, momentum=0.95)
optimizer2 = Muon(hidden_matrix_params, lr=0.25, momentum=0.95)
# optimizer2 = Muon(hidden_matrix_params, lr=0.1, momentum=0.95)
# optimizer2 = Muon(hidden_matrix_params, lr=0.05, momentum=0.95)  # done
# optimizer2 = Muon(hidden_matrix_params, lr=0.01, momentum=0.95)
# optimizer2 = Muon(hidden_matrix_params, lr=0.025, momentum=0.95)
# optimizer2 = Muon(hidden_matrix_params, lr=0.005, momentum=0.95)
optimizers = [optimizer1, optimizer2]

# learning rate schedule: stable then decay
def get_lr(it):
    t = 1 - it / args.num_iterations # time remaining in training
    assert 1 >= t > 0
    # 1) constant lr for first part of training
    if t >= args.cooldown_frac:
        return 1.0
    # 2) then linear cooldown
    else:
        return t / args.cooldown_frac
schedulers = [torch.optim.lr_scheduler.LambdaLR(opt, get_lr) for opt in optimizers]

# sliding window size schedule: linear increase over training in chunks of 128 from 128 -> 1792. By @fernbear.bsky.social
def get_sliding_window_blocks(it):
    x = it / args.num_iterations # training progress
    assert 0 <= x <= 1
    return int(((1 - x) * 128 + x * 1856) // 128)
sliding_window_num_blocks = torch.tensor(1, dtype=torch.int32, device='cuda')

# Start training loop
training_time_ms = 0
# start the clock
torch.cuda.synchronize()
t0 = time.perf_counter()
# begin training
train_steps = args.num_iterations
for step in range(train_steps + 1):
    last_step = (step == train_steps)
    # This effectively ignores timing first 10 steps, which are slower for weird reasons.
    # Alternately, and slightly more correctly in terms of benchmarking, we could do 10
    # steps with dummy data first, and then re-initialize the model and reset the loader.
    if step == 10:
        training_time_ms = 0
        t0 = time.perf_counter()
    timed_steps = float('nan') if step <= 11 else (step - 10) + 1 # <= 11 to avoid bug in val

    sliding_window_num_blocks.copy_(get_sliding_window_blocks(step))

    # --------------- VALIDATION SECTION -----------------
    if last_step or (args.val_loss_every > 0 and step % args.val_loss_every == 0):
        # stop the clock
        torch.cuda.synchronize()
        training_time_ms += 1000 * (time.perf_counter() - t0)
        # run validation batches
        model.eval()
        val_loader.reset()
        val_loss = 0.0
        # calculate the number of steps to take in the val loop.
        val_batch_size = world_size * micro_bs
        assert args.val_tokens % val_batch_size == 0
        val_steps = args.val_tokens // val_batch_size
        for _ in range(val_steps):
            with torch.no_grad():
                inputs_val, targets_val = val_loader.next_batch(val_batch_size)
                val_loss += ddp_model(inputs_val, targets_val, sliding_window_num_blocks)
        dist.all_reduce(val_loss, op=dist.ReduceOp.AVG)
        val_loss /= val_steps
        # logging
        print0(f'step:{step}/{train_steps} val_loss:{val_loss:.4f} train_time:{training_time_ms:.0f}ms step_avg:{training_time_ms/(timed_steps-1):.2f}ms', console=True)
        # start the clock again
        torch.cuda.synchronize()
        t0 = time.perf_counter()

    if last_step:
        if master_process and args.save_checkpoint:
            log = dict(step=step, code=code, model=model.state_dict(), optimizers=[opt.state_dict() for opt in optimizers])
            os.makedirs(f'logs/{run_id}', exist_ok=True)
            torch.save(log, f'logs/{run_id}/state_step{step:06d}.pt')
        # the last step only has the validation loop, so break to avoid training
        break

    # --------------- TRAINING SECTION -----------------
    model.train()
    batch_size = args.batch_size
    assert batch_size % world_size == 0
    inputs_train, targets_train = train_loader.next_batch(batch_size)
    assert len(inputs_train) <= micro_bs or len(inputs_train) % micro_bs == 0
    for micro_inputs_train, micro_targets_train in zip(inputs_train.split(micro_bs), targets_train.split(micro_bs)):
        ddp_model(micro_inputs_train, micro_targets_train, sliding_window_num_blocks).backward()
    # momentum warmup for Muon
    frac = min(step/300, 1)
    for group in optimizer2.param_groups:
        group['momentum'] = (1 - frac) * 0.85 + frac * 0.95
    # step the optimizers and schedulers
    for opt, sched in zip(optimizers, schedulers):
        opt.step()
        if step != train_steps-1:
            sched.step()
    # null the gradients
    model.zero_grad(set_to_none=True)
    # logging
    approx_time = training_time_ms + 1000 * (time.perf_counter() - t0)
    print0(f'step:{step+1}/{train_steps} train_time:{approx_time:.0f}ms step_avg:{approx_time/timed_steps:.2f}ms', console=True)

print0(f'peak memory consumption: {torch.cuda.max_memory_allocated() // 1024 // 1024} MiB')
dist.destroy_process_group()

====================================================================================================
Running Python 3.10.12 (main, Sep 11 2024, 15:47:36) [GCC 11.4.0]
Running PyTorch 2.6.0.dev20241231+cu126 compiled for CUDA 12.6
Tue Jan 14 17:33:21 2025       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.183.06             Driver Version: 535.183.06   CUDA Version: 12.4     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA H100 80GB HBM3          On  | 00000000:19:00.0 Off |                    0 |
| N/A   31C    P0             120W / 700W |   7713MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   1  NVIDIA H100 80GB HBM3          On  | 00000000:3B:00.0 Off |                    0 |
| N/A   30C    P0             113W / 700W |   3451MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   2  NVIDIA H100 80GB HBM3          On  | 00000000:4C:00.0 Off |                    0 |
| N/A   27C    P0             116W / 700W |   3451MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   3  NVIDIA H100 80GB HBM3          On  | 00000000:5D:00.0 Off |                    0 |
| N/A   30C    P0             122W / 700W |   3451MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   4  NVIDIA H100 80GB HBM3          On  | 00000000:9B:00.0 Off |                    0 |
| N/A   31C    P0             119W / 700W |   3451MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   5  NVIDIA H100 80GB HBM3          On  | 00000000:BB:00.0 Off |                    0 |
| N/A   27C    P0             112W / 700W |   3451MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   6  NVIDIA H100 80GB HBM3          On  | 00000000:CB:00.0 Off |                    0 |
| N/A   30C    P0             111W / 700W |   3451MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   7  NVIDIA H100 80GB HBM3          On  | 00000000:DB:00.0 Off |                    0 |
| N/A   27C    P0             115W / 700W |   3211MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
+---------------------------------------------------------------------------------------+

====================================================================================================
Training dataloader files: ['data/fineweb10B/fineweb_train_000001.bin', 'data/fineweb10B/fineweb_train_000002.bin', 'data/fineweb10B/fineweb_train_000003.bin', 'data/fineweb10B/fineweb_train_000004.bin', 'data/fineweb10B/fineweb_train_000005.bin', 'data/fineweb10B/fineweb_train_000006.bin', 'data/fineweb10B/fineweb_train_000007.bin', 'data/fineweb10B/fineweb_train_000008.bin', 'data/fineweb10B/fineweb_train_000009.bin']
Validation dataloader files: ['data/fineweb10B/fineweb_val_000000.bin']
====================================================================================================
step:0/1390 val_loss:10.8258 train_time:0ms step_avg:nanms
step:1/1390 train_time:27388ms step_avg:nanms
step:2/1390 train_time:27477ms step_avg:nanms
step:3/1390 train_time:27687ms step_avg:nanms
step:4/1390 train_time:27819ms step_avg:nanms
step:5/1390 train_time:27952ms step_avg:nanms
step:6/1390 train_time:28086ms step_avg:nanms
step:7/1390 train_time:28220ms step_avg:nanms
step:8/1390 train_time:28353ms step_avg:nanms
step:9/1390 train_time:28486ms step_avg:nanms
step:10/1390 train_time:28624ms step_avg:nanms
step:11/1390 train_time:139ms step_avg:nanms
step:12/1390 train_time:275ms step_avg:nanms
step:13/1390 train_time:411ms step_avg:136.93ms
step:14/1390 train_time:545ms step_avg:136.13ms
step:15/1390 train_time:678ms step_avg:135.59ms
step:16/1390 train_time:815ms step_avg:135.78ms
step:17/1390 train_time:949ms step_avg:135.57ms
step:18/1390 train_time:1086ms step_avg:135.71ms
step:19/1390 train_time:1221ms step_avg:135.65ms
step:20/1390 train_time:1357ms step_avg:135.73ms
step:21/1390 train_time:1492ms step_avg:135.67ms
step:22/1390 train_time:1627ms step_avg:135.61ms
step:23/1390 train_time:1762ms step_avg:135.50ms
step:24/1390 train_time:1898ms step_avg:135.57ms
step:25/1390 train_time:2033ms step_avg:135.52ms
step:26/1390 train_time:2169ms step_avg:135.58ms
step:27/1390 train_time:2305ms step_avg:135.57ms
step:28/1390 train_time:2440ms step_avg:135.58ms
step:29/1390 train_time:2576ms step_avg:135.58ms
step:30/1390 train_time:2712ms step_avg:135.59ms
step:31/1390 train_time:2847ms step_avg:135.55ms
step:32/1390 train_time:2981ms step_avg:135.49ms
step:33/1390 train_time:3116ms step_avg:135.46ms
step:34/1390 train_time:3253ms step_avg:135.55ms
step:35/1390 train_time:3387ms step_avg:135.48ms
step:36/1390 train_time:3523ms step_avg:135.51ms
step:37/1390 train_time:3660ms step_avg:135.56ms
step:38/1390 train_time:3796ms step_avg:135.56ms
step:39/1390 train_time:3931ms step_avg:135.56ms
step:40/1390 train_time:4066ms step_avg:135.54ms
step:41/1390 train_time:4201ms step_avg:135.52ms
step:42/1390 train_time:4337ms step_avg:135.53ms
step:43/1390 train_time:4472ms step_avg:135.52ms
step:44/1390 train_time:4607ms step_avg:135.51ms
step:45/1390 train_time:4743ms step_avg:135.52ms
step:46/1390 train_time:4879ms step_avg:135.52ms
step:47/1390 train_time:5016ms step_avg:135.56ms
step:48/1390 train_time:5152ms step_avg:135.58ms
step:49/1390 train_time:5286ms step_avg:135.55ms
step:50/1390 train_time:5422ms step_avg:135.54ms
step:51/1390 train_time:5558ms step_avg:135.55ms
step:52/1390 train_time:5693ms step_avg:135.55ms
step:53/1390 train_time:5830ms step_avg:135.57ms
step:54/1390 train_time:5966ms step_avg:135.58ms
step:55/1390 train_time:6101ms step_avg:135.57ms
step:56/1390 train_time:6237ms step_avg:135.59ms
step:57/1390 train_time:6372ms step_avg:135.57ms
step:58/1390 train_time:6507ms step_avg:135.56ms
step:59/1390 train_time:6642ms step_avg:135.55ms
step:60/1390 train_time:6778ms step_avg:135.56ms
step:61/1390 train_time:6916ms step_avg:135.60ms
step:62/1390 train_time:7052ms step_avg:135.62ms
step:63/1390 train_time:7188ms step_avg:135.62ms
step:64/1390 train_time:7323ms step_avg:135.61ms
step:65/1390 train_time:7459ms step_avg:135.62ms
step:66/1390 train_time:7595ms step_avg:135.63ms
step:67/1390 train_time:7731ms step_avg:135.63ms
step:68/1390 train_time:7867ms step_avg:135.63ms
step:69/1390 train_time:8002ms step_avg:135.63ms
step:70/1390 train_time:8139ms step_avg:135.64ms
step:71/1390 train_time:8275ms step_avg:135.66ms
step:72/1390 train_time:8413ms step_avg:135.69ms
step:73/1390 train_time:8549ms step_avg:135.70ms
step:74/1390 train_time:8685ms step_avg:135.70ms
step:75/1390 train_time:8819ms step_avg:135.68ms
step:76/1390 train_time:8956ms step_avg:135.69ms
step:77/1390 train_time:9090ms step_avg:135.68ms
step:78/1390 train_time:9226ms step_avg:135.68ms
step:79/1390 train_time:9362ms step_avg:135.68ms
step:80/1390 train_time:9499ms step_avg:135.70ms
step:81/1390 train_time:9636ms step_avg:135.71ms
step:82/1390 train_time:9771ms step_avg:135.71ms
step:83/1390 train_time:9906ms step_avg:135.70ms
step:84/1390 train_time:10041ms step_avg:135.69ms
step:85/1390 train_time:10178ms step_avg:135.70ms
step:86/1390 train_time:10315ms step_avg:135.72ms
step:87/1390 train_time:10453ms step_avg:135.75ms
step:88/1390 train_time:10587ms step_avg:135.73ms
step:89/1390 train_time:10722ms step_avg:135.72ms
step:90/1390 train_time:10858ms step_avg:135.72ms
step:91/1390 train_time:10994ms step_avg:135.73ms
step:92/1390 train_time:11130ms step_avg:135.73ms
step:93/1390 train_time:11266ms step_avg:135.73ms
step:94/1390 train_time:11402ms step_avg:135.73ms
step:95/1390 train_time:11537ms step_avg:135.74ms
step:96/1390 train_time:11674ms step_avg:135.75ms
step:97/1390 train_time:11812ms step_avg:135.77ms
step:98/1390 train_time:11947ms step_avg:135.76ms
step:99/1390 train_time:12082ms step_avg:135.76ms
step:100/1390 train_time:12220ms step_avg:135.78ms
step:101/1390 train_time:12358ms step_avg:135.80ms
step:102/1390 train_time:12495ms step_avg:135.81ms
step:103/1390 train_time:12631ms step_avg:135.82ms
step:104/1390 train_time:12769ms step_avg:135.84ms
step:105/1390 train_time:12908ms step_avg:135.87ms
step:106/1390 train_time:13045ms step_avg:135.89ms
step:107/1390 train_time:13184ms step_avg:135.92ms
step:108/1390 train_time:13323ms step_avg:135.95ms
step:109/1390 train_time:13462ms step_avg:135.98ms
step:110/1390 train_time:13603ms step_avg:136.03ms
step:111/1390 train_time:13742ms step_avg:136.06ms
step:112/1390 train_time:13881ms step_avg:136.09ms
step:113/1390 train_time:14021ms step_avg:136.13ms
step:114/1390 train_time:14160ms step_avg:136.15ms
step:115/1390 train_time:14299ms step_avg:136.18ms
step:116/1390 train_time:14439ms step_avg:136.21ms
step:117/1390 train_time:14580ms step_avg:136.26ms
step:118/1390 train_time:14721ms step_avg:136.30ms
step:119/1390 train_time:14860ms step_avg:136.33ms
step:120/1390 train_time:14999ms step_avg:136.36ms
step:121/1390 train_time:15139ms step_avg:136.39ms
step:122/1390 train_time:15278ms step_avg:136.41ms
step:123/1390 train_time:15419ms step_avg:136.45ms
step:124/1390 train_time:15559ms step_avg:136.49ms
step:125/1390 train_time:15698ms step_avg:136.50ms
step:125/1390 val_loss:4.5349 train_time:15762ms step_avg:137.06ms
step:126/1390 train_time:15842ms step_avg:136.57ms
step:127/1390 train_time:15986ms step_avg:136.63ms
step:128/1390 train_time:16126ms step_avg:136.66ms
step:129/1390 train_time:16265ms step_avg:136.68ms
step:130/1390 train_time:16403ms step_avg:136.70ms
step:131/1390 train_time:16541ms step_avg:136.70ms
step:132/1390 train_time:16679ms step_avg:136.72ms
step:133/1390 train_time:16821ms step_avg:136.76ms
step:134/1390 train_time:16961ms step_avg:136.78ms
step:135/1390 train_time:17101ms step_avg:136.81ms
step:136/1390 train_time:17242ms step_avg:136.84ms
step:137/1390 train_time:17382ms step_avg:136.87ms
step:138/1390 train_time:17520ms step_avg:136.87ms
step:139/1390 train_time:17659ms step_avg:136.89ms
step:140/1390 train_time:17798ms step_avg:136.91ms
step:141/1390 train_time:17937ms step_avg:136.93ms
step:142/1390 train_time:18078ms step_avg:136.96ms
step:143/1390 train_time:18218ms step_avg:136.98ms
step:144/1390 train_time:18359ms step_avg:137.00ms
step:145/1390 train_time:18498ms step_avg:137.02ms
step:146/1390 train_time:18636ms step_avg:137.03ms
step:147/1390 train_time:18778ms step_avg:137.07ms
step:148/1390 train_time:18917ms step_avg:137.08ms
step:149/1390 train_time:19058ms step_avg:137.11ms
step:150/1390 train_time:19198ms step_avg:137.13ms
step:151/1390 train_time:19337ms step_avg:137.14ms
step:152/1390 train_time:19478ms step_avg:137.17ms
step:153/1390 train_time:19618ms step_avg:137.19ms
step:154/1390 train_time:19757ms step_avg:137.20ms
step:155/1390 train_time:19896ms step_avg:137.22ms
step:156/1390 train_time:20036ms step_avg:137.24ms
step:157/1390 train_time:20177ms step_avg:137.26ms
step:158/1390 train_time:20317ms step_avg:137.28ms
step:159/1390 train_time:20458ms step_avg:137.30ms
step:160/1390 train_time:20597ms step_avg:137.31ms
step:161/1390 train_time:20737ms step_avg:137.33ms
step:162/1390 train_time:20877ms step_avg:137.35ms
step:163/1390 train_time:21017ms step_avg:137.37ms
step:164/1390 train_time:21158ms step_avg:137.39ms
step:165/1390 train_time:21297ms step_avg:137.40ms
step:166/1390 train_time:21436ms step_avg:137.41ms
step:167/1390 train_time:21577ms step_avg:137.43ms
step:168/1390 train_time:21715ms step_avg:137.44ms
step:169/1390 train_time:21855ms step_avg:137.46ms
step:170/1390 train_time:21995ms step_avg:137.47ms
step:171/1390 train_time:22134ms step_avg:137.48ms
step:172/1390 train_time:22275ms step_avg:137.50ms
step:173/1390 train_time:22416ms step_avg:137.52ms
step:174/1390 train_time:22556ms step_avg:137.54ms
step:175/1390 train_time:22696ms step_avg:137.55ms
step:176/1390 train_time:22836ms step_avg:137.57ms
step:177/1390 train_time:22975ms step_avg:137.58ms
step:178/1390 train_time:23115ms step_avg:137.59ms
step:179/1390 train_time:23256ms step_avg:137.61ms
step:180/1390 train_time:23396ms step_avg:137.62ms
step:181/1390 train_time:23536ms step_avg:137.64ms
step:182/1390 train_time:23676ms step_avg:137.65ms
step:183/1390 train_time:23816ms step_avg:137.67ms
step:184/1390 train_time:23956ms step_avg:137.68ms
step:185/1390 train_time:24095ms step_avg:137.69ms
step:186/1390 train_time:24235ms step_avg:137.70ms
step:187/1390 train_time:24376ms step_avg:137.72ms
step:188/1390 train_time:24516ms step_avg:137.73ms
step:189/1390 train_time:24658ms step_avg:137.75ms
step:190/1390 train_time:24797ms step_avg:137.76ms
step:191/1390 train_time:24973ms step_avg:137.97ms
step:192/1390 train_time:25110ms step_avg:137.97ms
step:193/1390 train_time:25248ms step_avg:137.97ms
step:194/1390 train_time:25387ms step_avg:137.97ms
step:195/1390 train_time:25526ms step_avg:137.98ms
step:196/1390 train_time:25665ms step_avg:137.98ms
step:197/1390 train_time:25808ms step_avg:138.01ms
step:198/1390 train_time:25955ms step_avg:138.06ms
step:199/1390 train_time:26095ms step_avg:138.07ms
step:200/1390 train_time:26234ms step_avg:138.07ms
step:201/1390 train_time:26372ms step_avg:138.07ms
step:202/1390 train_time:26510ms step_avg:138.08ms
step:203/1390 train_time:26649ms step_avg:138.08ms
step:204/1390 train_time:26789ms step_avg:138.09ms
step:205/1390 train_time:26931ms step_avg:138.11ms
step:206/1390 train_time:27074ms step_avg:138.13ms
step:207/1390 train_time:27217ms step_avg:138.16ms
step:208/1390 train_time:27360ms step_avg:138.18ms
step:209/1390 train_time:27502ms step_avg:138.20ms
step:210/1390 train_time:27643ms step_avg:138.22ms
step:211/1390 train_time:27787ms step_avg:138.24ms
step:212/1390 train_time:27930ms step_avg:138.27ms
step:213/1390 train_time:28074ms step_avg:138.30ms
step:214/1390 train_time:28217ms step_avg:138.32ms
step:215/1390 train_time:28360ms step_avg:138.34ms
step:216/1390 train_time:28502ms step_avg:138.36ms
step:217/1390 train_time:28643ms step_avg:138.37ms
step:218/1390 train_time:28785ms step_avg:138.39ms
step:219/1390 train_time:28929ms step_avg:138.41ms
step:220/1390 train_time:29072ms step_avg:138.44ms
step:221/1390 train_time:29215ms step_avg:138.46ms
step:222/1390 train_time:29358ms step_avg:138.48ms
step:223/1390 train_time:29499ms step_avg:138.50ms
step:224/1390 train_time:29641ms step_avg:138.51ms
step:225/1390 train_time:29783ms step_avg:138.53ms
step:226/1390 train_time:29926ms step_avg:138.55ms
step:227/1390 train_time:30070ms step_avg:138.57ms
step:228/1390 train_time:30213ms step_avg:138.59ms
step:229/1390 train_time:30357ms step_avg:138.61ms
step:230/1390 train_time:30500ms step_avg:138.64ms
step:231/1390 train_time:30640ms step_avg:138.64ms
step:232/1390 train_time:30782ms step_avg:138.66ms
step:233/1390 train_time:30924ms step_avg:138.67ms
step:234/1390 train_time:31067ms step_avg:138.69ms
step:235/1390 train_time:31211ms step_avg:138.72ms
step:236/1390 train_time:31355ms step_avg:138.74ms
step:237/1390 train_time:31497ms step_avg:138.75ms
step:238/1390 train_time:31640ms step_avg:138.77ms
step:239/1390 train_time:31782ms step_avg:138.79ms
step:240/1390 train_time:31925ms step_avg:138.80ms
step:241/1390 train_time:32068ms step_avg:138.82ms
step:242/1390 train_time:32212ms step_avg:138.84ms
step:243/1390 train_time:32355ms step_avg:138.86ms
step:244/1390 train_time:32496ms step_avg:138.87ms
step:245/1390 train_time:32638ms step_avg:138.89ms
step:246/1390 train_time:32779ms step_avg:138.89ms
step:247/1390 train_time:32921ms step_avg:138.91ms
step:248/1390 train_time:33064ms step_avg:138.93ms
step:249/1390 train_time:33207ms step_avg:138.94ms
step:250/1390 train_time:33352ms step_avg:138.97ms
step:250/1390 val_loss:4.1159 train_time:33416ms step_avg:139.24ms
step:251/1390 train_time:33498ms step_avg:139.00ms
step:252/1390 train_time:33642ms step_avg:139.02ms
step:253/1390 train_time:33786ms step_avg:139.04ms
step:254/1390 train_time:33926ms step_avg:139.04ms
step:255/1390 train_time:34067ms step_avg:139.05ms
step:256/1390 train_time:34208ms step_avg:139.06ms
step:257/1390 train_time:34351ms step_avg:139.07ms
step:258/1390 train_time:34495ms step_avg:139.09ms
step:259/1390 train_time:34639ms step_avg:139.11ms
step:260/1390 train_time:34783ms step_avg:139.13ms
step:261/1390 train_time:34927ms step_avg:139.15ms
step:262/1390 train_time:35071ms step_avg:139.17ms
step:263/1390 train_time:35212ms step_avg:139.18ms
step:264/1390 train_time:35354ms step_avg:139.19ms
step:265/1390 train_time:35499ms step_avg:139.21ms
step:266/1390 train_time:35643ms step_avg:139.23ms
step:267/1390 train_time:35787ms step_avg:139.25ms
step:268/1390 train_time:35931ms step_avg:139.27ms
step:269/1390 train_time:36073ms step_avg:139.28ms
step:270/1390 train_time:36214ms step_avg:139.29ms
step:271/1390 train_time:36356ms step_avg:139.29ms
step:272/1390 train_time:36499ms step_avg:139.31ms
step:273/1390 train_time:36641ms step_avg:139.32ms
step:274/1390 train_time:36785ms step_avg:139.34ms
step:275/1390 train_time:36929ms step_avg:139.36ms
step:276/1390 train_time:37073ms step_avg:139.37ms
step:277/1390 train_time:37214ms step_avg:139.38ms
step:278/1390 train_time:37357ms step_avg:139.39ms
step:279/1390 train_time:37499ms step_avg:139.40ms
step:280/1390 train_time:37643ms step_avg:139.42ms
step:281/1390 train_time:37788ms step_avg:139.44ms
step:282/1390 train_time:37932ms step_avg:139.46ms
step:283/1390 train_time:38076ms step_avg:139.47ms
step:284/1390 train_time:38218ms step_avg:139.48ms
step:285/1390 train_time:38360ms step_avg:139.49ms
step:286/1390 train_time:38504ms step_avg:139.51ms
step:287/1390 train_time:38648ms step_avg:139.52ms
step:288/1390 train_time:38792ms step_avg:139.54ms
step:289/1390 train_time:38936ms step_avg:139.56ms
step:290/1390 train_time:39079ms step_avg:139.57ms
step:291/1390 train_time:39221ms step_avg:139.58ms
step:292/1390 train_time:39362ms step_avg:139.58ms
step:293/1390 train_time:39505ms step_avg:139.60ms
step:294/1390 train_time:39650ms step_avg:139.61ms
step:295/1390 train_time:39794ms step_avg:139.63ms
step:296/1390 train_time:39936ms step_avg:139.64ms
step:297/1390 train_time:40080ms step_avg:139.65ms
step:298/1390 train_time:40222ms step_avg:139.66ms
step:299/1390 train_time:40366ms step_avg:139.67ms
step:300/1390 train_time:40508ms step_avg:139.68ms
step:301/1390 train_time:40650ms step_avg:139.69ms
step:302/1390 train_time:40794ms step_avg:139.71ms
step:303/1390 train_time:40936ms step_avg:139.71ms
step:304/1390 train_time:41081ms step_avg:139.73ms
step:305/1390 train_time:41226ms step_avg:139.75ms
step:306/1390 train_time:41370ms step_avg:139.76ms
step:307/1390 train_time:41514ms step_avg:139.78ms
step:308/1390 train_time:41656ms step_avg:139.78ms
step:309/1390 train_time:41800ms step_avg:139.80ms
step:310/1390 train_time:41942ms step_avg:139.81ms
step:311/1390 train_time:42089ms step_avg:139.83ms
step:312/1390 train_time:42235ms step_avg:139.85ms
step:313/1390 train_time:42380ms step_avg:139.87ms
step:314/1390 train_time:42524ms step_avg:139.88ms
step:315/1390 train_time:42669ms step_avg:139.90ms
step:316/1390 train_time:42814ms step_avg:139.91ms
step:317/1390 train_time:42961ms step_avg:139.94ms
step:318/1390 train_time:43106ms step_avg:139.95ms
step:319/1390 train_time:43252ms step_avg:139.97ms
step:320/1390 train_time:43398ms step_avg:139.99ms
step:321/1390 train_time:43542ms step_avg:140.01ms
step:322/1390 train_time:43687ms step_avg:140.02ms
step:323/1390 train_time:43833ms step_avg:140.04ms
step:324/1390 train_time:43980ms step_avg:140.06ms
step:325/1390 train_time:44125ms step_avg:140.08ms
step:326/1390 train_time:44271ms step_avg:140.10ms
step:327/1390 train_time:44418ms step_avg:140.12ms
step:328/1390 train_time:44563ms step_avg:140.13ms
step:329/1390 train_time:44708ms step_avg:140.15ms
step:330/1390 train_time:44854ms step_avg:140.17ms
step:331/1390 train_time:45000ms step_avg:140.19ms
step:332/1390 train_time:45144ms step_avg:140.20ms
step:333/1390 train_time:45291ms step_avg:140.22ms
step:334/1390 train_time:45436ms step_avg:140.23ms
step:335/1390 train_time:45582ms step_avg:140.25ms
step:336/1390 train_time:45727ms step_avg:140.27ms
step:337/1390 train_time:45873ms step_avg:140.28ms
step:338/1390 train_time:46019ms step_avg:140.30ms
step:339/1390 train_time:46163ms step_avg:140.31ms
step:340/1390 train_time:46309ms step_avg:140.33ms
step:341/1390 train_time:46454ms step_avg:140.34ms
step:342/1390 train_time:46599ms step_avg:140.36ms
step:343/1390 train_time:46743ms step_avg:140.37ms
step:344/1390 train_time:46889ms step_avg:140.39ms
step:345/1390 train_time:47035ms step_avg:140.40ms
step:346/1390 train_time:47179ms step_avg:140.41ms
step:347/1390 train_time:47323ms step_avg:140.42ms
step:348/1390 train_time:47469ms step_avg:140.44ms
step:349/1390 train_time:47613ms step_avg:140.45ms
step:350/1390 train_time:47759ms step_avg:140.47ms
step:351/1390 train_time:47904ms step_avg:140.48ms
step:352/1390 train_time:48050ms step_avg:140.50ms
step:353/1390 train_time:48195ms step_avg:140.51ms
step:354/1390 train_time:48339ms step_avg:140.52ms
step:355/1390 train_time:48484ms step_avg:140.53ms
step:356/1390 train_time:48632ms step_avg:140.55ms
step:357/1390 train_time:48776ms step_avg:140.57ms
step:358/1390 train_time:48920ms step_avg:140.57ms
step:359/1390 train_time:49065ms step_avg:140.59ms
step:360/1390 train_time:49211ms step_avg:140.60ms
step:361/1390 train_time:49358ms step_avg:140.62ms
step:362/1390 train_time:49502ms step_avg:140.63ms
step:363/1390 train_time:49648ms step_avg:140.65ms
step:364/1390 train_time:49795ms step_avg:140.66ms
step:365/1390 train_time:49939ms step_avg:140.67ms
step:366/1390 train_time:50084ms step_avg:140.68ms
step:367/1390 train_time:50229ms step_avg:140.70ms
step:368/1390 train_time:50374ms step_avg:140.71ms
step:369/1390 train_time:50521ms step_avg:140.73ms
step:370/1390 train_time:50666ms step_avg:140.74ms
step:371/1390 train_time:50811ms step_avg:140.75ms
step:372/1390 train_time:50957ms step_avg:140.77ms
step:373/1390 train_time:51101ms step_avg:140.78ms
step:374/1390 train_time:51246ms step_avg:140.79ms
step:375/1390 train_time:51392ms step_avg:140.80ms
step:375/1390 val_loss:3.9407 train_time:51457ms step_avg:140.98ms
step:376/1390 train_time:51538ms step_avg:140.81ms
step:377/1390 train_time:51686ms step_avg:140.83ms
step:378/1390 train_time:51832ms step_avg:140.85ms
step:379/1390 train_time:51976ms step_avg:140.86ms
step:380/1390 train_time:52120ms step_avg:140.86ms
step:381/1390 train_time:52304ms step_avg:140.98ms
step:382/1390 train_time:52448ms step_avg:140.99ms
step:383/1390 train_time:52592ms step_avg:141.00ms
step:384/1390 train_time:52735ms step_avg:141.00ms
step:385/1390 train_time:52880ms step_avg:141.01ms
step:386/1390 train_time:53025ms step_avg:141.02ms
step:387/1390 train_time:53172ms step_avg:141.04ms
step:388/1390 train_time:53320ms step_avg:141.06ms
step:389/1390 train_time:53465ms step_avg:141.07ms
step:390/1390 train_time:53610ms step_avg:141.08ms
step:391/1390 train_time:53755ms step_avg:141.09ms
step:392/1390 train_time:53898ms step_avg:141.10ms
step:393/1390 train_time:54042ms step_avg:141.10ms
step:394/1390 train_time:54190ms step_avg:141.12ms
step:395/1390 train_time:54337ms step_avg:141.13ms
step:396/1390 train_time:54482ms step_avg:141.15ms
step:397/1390 train_time:54628ms step_avg:141.16ms
step:398/1390 train_time:54773ms step_avg:141.17ms
step:399/1390 train_time:54917ms step_avg:141.18ms
step:400/1390 train_time:55061ms step_avg:141.18ms
step:401/1390 train_time:55207ms step_avg:141.20ms
step:402/1390 train_time:55353ms step_avg:141.21ms
step:403/1390 train_time:55499ms step_avg:141.22ms
step:404/1390 train_time:55644ms step_avg:141.23ms
step:405/1390 train_time:55790ms step_avg:141.24ms
step:406/1390 train_time:55934ms step_avg:141.25ms
step:407/1390 train_time:56079ms step_avg:141.26ms
step:408/1390 train_time:56222ms step_avg:141.26ms
step:409/1390 train_time:56368ms step_avg:141.27ms
step:410/1390 train_time:56514ms step_avg:141.28ms
step:411/1390 train_time:56659ms step_avg:141.29ms
step:412/1390 train_time:56804ms step_avg:141.30ms
step:413/1390 train_time:56952ms step_avg:141.32ms
step:414/1390 train_time:57099ms step_avg:141.33ms
step:415/1390 train_time:57246ms step_avg:141.35ms
step:416/1390 train_time:57393ms step_avg:141.36ms
step:417/1390 train_time:57540ms step_avg:141.38ms
step:418/1390 train_time:57689ms step_avg:141.39ms
step:419/1390 train_time:57835ms step_avg:141.41ms
step:420/1390 train_time:57983ms step_avg:141.42ms
step:421/1390 train_time:58132ms step_avg:141.44ms
step:422/1390 train_time:58278ms step_avg:141.45ms
step:423/1390 train_time:58425ms step_avg:141.46ms
step:424/1390 train_time:58573ms step_avg:141.48ms
step:425/1390 train_time:58721ms step_avg:141.50ms
step:426/1390 train_time:58868ms step_avg:141.51ms
step:427/1390 train_time:59015ms step_avg:141.52ms
step:428/1390 train_time:59162ms step_avg:141.53ms
step:429/1390 train_time:59310ms step_avg:141.55ms
step:430/1390 train_time:59456ms step_avg:141.56ms
step:431/1390 train_time:59602ms step_avg:141.57ms
step:432/1390 train_time:59750ms step_avg:141.59ms
step:433/1390 train_time:59896ms step_avg:141.60ms
step:434/1390 train_time:60042ms step_avg:141.61ms
step:435/1390 train_time:60191ms step_avg:141.63ms
step:436/1390 train_time:60339ms step_avg:141.64ms
step:437/1390 train_time:60487ms step_avg:141.66ms
step:438/1390 train_time:60633ms step_avg:141.67ms
step:439/1390 train_time:60780ms step_avg:141.68ms
step:440/1390 train_time:60926ms step_avg:141.69ms
step:441/1390 train_time:61074ms step_avg:141.70ms
step:442/1390 train_time:61222ms step_avg:141.72ms
step:443/1390 train_time:61369ms step_avg:141.73ms
step:444/1390 train_time:61516ms step_avg:141.74ms
step:445/1390 train_time:61663ms step_avg:141.75ms
step:446/1390 train_time:61811ms step_avg:141.77ms
step:447/1390 train_time:61958ms step_avg:141.78ms
step:448/1390 train_time:62106ms step_avg:141.79ms
step:449/1390 train_time:62254ms step_avg:141.81ms
step:450/1390 train_time:62400ms step_avg:141.82ms
step:451/1390 train_time:62548ms step_avg:141.83ms
step:452/1390 train_time:62695ms step_avg:141.84ms
step:453/1390 train_time:62840ms step_avg:141.85ms
step:454/1390 train_time:62989ms step_avg:141.87ms
step:455/1390 train_time:63136ms step_avg:141.88ms
step:456/1390 train_time:63283ms step_avg:141.89ms
step:457/1390 train_time:63431ms step_avg:141.90ms
step:458/1390 train_time:63578ms step_avg:141.92ms
step:459/1390 train_time:63725ms step_avg:141.93ms
step:460/1390 train_time:63873ms step_avg:141.94ms
step:461/1390 train_time:64021ms step_avg:141.95ms
step:462/1390 train_time:64169ms step_avg:141.97ms
step:463/1390 train_time:64316ms step_avg:141.98ms
step:464/1390 train_time:64462ms step_avg:141.99ms
step:465/1390 train_time:64610ms step_avg:142.00ms
step:466/1390 train_time:64758ms step_avg:142.01ms
step:467/1390 train_time:64906ms step_avg:142.03ms
step:468/1390 train_time:65053ms step_avg:142.04ms
step:469/1390 train_time:65199ms step_avg:142.05ms
step:470/1390 train_time:65347ms step_avg:142.06ms
step:471/1390 train_time:65495ms step_avg:142.07ms
step:472/1390 train_time:65640ms step_avg:142.08ms
step:473/1390 train_time:65788ms step_avg:142.09ms
step:474/1390 train_time:65934ms step_avg:142.10ms
step:475/1390 train_time:66081ms step_avg:142.11ms
step:476/1390 train_time:66229ms step_avg:142.12ms
step:477/1390 train_time:66376ms step_avg:142.13ms
step:478/1390 train_time:66523ms step_avg:142.14ms
step:479/1390 train_time:66671ms step_avg:142.16ms
step:480/1390 train_time:66818ms step_avg:142.17ms
step:481/1390 train_time:66966ms step_avg:142.18ms
step:482/1390 train_time:67113ms step_avg:142.19ms
step:483/1390 train_time:67260ms step_avg:142.20ms
step:484/1390 train_time:67408ms step_avg:142.21ms
step:485/1390 train_time:67557ms step_avg:142.22ms
step:486/1390 train_time:67704ms step_avg:142.24ms
step:487/1390 train_time:67852ms step_avg:142.25ms
step:488/1390 train_time:68000ms step_avg:142.26ms
step:489/1390 train_time:68147ms step_avg:142.27ms
step:490/1390 train_time:68293ms step_avg:142.28ms
step:491/1390 train_time:68439ms step_avg:142.28ms
step:492/1390 train_time:68588ms step_avg:142.30ms
step:493/1390 train_time:68735ms step_avg:142.31ms
step:494/1390 train_time:68883ms step_avg:142.32ms
step:495/1390 train_time:69032ms step_avg:142.33ms
step:496/1390 train_time:69179ms step_avg:142.34ms
step:497/1390 train_time:69325ms step_avg:142.35ms
step:498/1390 train_time:69472ms step_avg:142.36ms
step:499/1390 train_time:69620ms step_avg:142.37ms
step:500/1390 train_time:69767ms step_avg:142.38ms
step:500/1390 val_loss:3.8397 train_time:69834ms step_avg:142.52ms
step:501/1390 train_time:69914ms step_avg:142.39ms
step:502/1390 train_time:70061ms step_avg:142.40ms
step:503/1390 train_time:70208ms step_avg:142.41ms
step:504/1390 train_time:70354ms step_avg:142.42ms
step:505/1390 train_time:70500ms step_avg:142.42ms
step:506/1390 train_time:70645ms step_avg:142.43ms
step:507/1390 train_time:70794ms step_avg:142.44ms
step:508/1390 train_time:70944ms step_avg:142.46ms
step:509/1390 train_time:71092ms step_avg:142.47ms
step:510/1390 train_time:71239ms step_avg:142.48ms
step:511/1390 train_time:71384ms step_avg:142.48ms
step:512/1390 train_time:71531ms step_avg:142.49ms
step:513/1390 train_time:71678ms step_avg:142.50ms
step:514/1390 train_time:71825ms step_avg:142.51ms
step:515/1390 train_time:71975ms step_avg:142.52ms
step:516/1390 train_time:72123ms step_avg:142.54ms
step:517/1390 train_time:72273ms step_avg:142.55ms
step:518/1390 train_time:72420ms step_avg:142.56ms
step:519/1390 train_time:72570ms step_avg:142.57ms
step:520/1390 train_time:72719ms step_avg:142.59ms
step:521/1390 train_time:72868ms step_avg:142.60ms
step:522/1390 train_time:73017ms step_avg:142.61ms
step:523/1390 train_time:73165ms step_avg:142.62ms
step:524/1390 train_time:73316ms step_avg:142.64ms
step:525/1390 train_time:73463ms step_avg:142.65ms
step:526/1390 train_time:73614ms step_avg:142.66ms
step:527/1390 train_time:73762ms step_avg:142.67ms
step:528/1390 train_time:73912ms step_avg:142.69ms
step:529/1390 train_time:74060ms step_avg:142.70ms
step:530/1390 train_time:74212ms step_avg:142.71ms
step:531/1390 train_time:74360ms step_avg:142.72ms
step:532/1390 train_time:74510ms step_avg:142.74ms
step:533/1390 train_time:74659ms step_avg:142.75ms
step:534/1390 train_time:74806ms step_avg:142.76ms
step:535/1390 train_time:74956ms step_avg:142.77ms
step:536/1390 train_time:75104ms step_avg:142.78ms
step:537/1390 train_time:75254ms step_avg:142.80ms
step:538/1390 train_time:75403ms step_avg:142.81ms
step:539/1390 train_time:75553ms step_avg:142.82ms
step:540/1390 train_time:75701ms step_avg:142.83ms
step:541/1390 train_time:75848ms step_avg:142.84ms
step:542/1390 train_time:75997ms step_avg:142.85ms
step:543/1390 train_time:76144ms step_avg:142.86ms
step:544/1390 train_time:76294ms step_avg:142.87ms
step:545/1390 train_time:76442ms step_avg:142.88ms
step:546/1390 train_time:76592ms step_avg:142.90ms
step:547/1390 train_time:76740ms step_avg:142.91ms
step:548/1390 train_time:76889ms step_avg:142.92ms
step:549/1390 train_time:77039ms step_avg:142.93ms
step:550/1390 train_time:77189ms step_avg:142.94ms
step:551/1390 train_time:77337ms step_avg:142.95ms
step:552/1390 train_time:77485ms step_avg:142.96ms
step:553/1390 train_time:77636ms step_avg:142.98ms
step:554/1390 train_time:77783ms step_avg:142.98ms
step:555/1390 train_time:77934ms step_avg:143.00ms
step:556/1390 train_time:78082ms step_avg:143.01ms
step:557/1390 train_time:78233ms step_avg:143.02ms
step:558/1390 train_time:78381ms step_avg:143.03ms
step:559/1390 train_time:78531ms step_avg:143.04ms
step:560/1390 train_time:78679ms step_avg:143.05ms
step:561/1390 train_time:78829ms step_avg:143.07ms
step:562/1390 train_time:78977ms step_avg:143.07ms
step:563/1390 train_time:79125ms step_avg:143.08ms
step:564/1390 train_time:79275ms step_avg:143.10ms
step:565/1390 train_time:79422ms step_avg:143.10ms
step:566/1390 train_time:79574ms step_avg:143.12ms
step:567/1390 train_time:79722ms step_avg:143.13ms
step:568/1390 train_time:79874ms step_avg:143.14ms
step:569/1390 train_time:80022ms step_avg:143.15ms
step:570/1390 train_time:80171ms step_avg:143.16ms
step:571/1390 train_time:80362ms step_avg:143.25ms
step:572/1390 train_time:80508ms step_avg:143.25ms
step:573/1390 train_time:80658ms step_avg:143.26ms
step:574/1390 train_time:80807ms step_avg:143.27ms
step:575/1390 train_time:80954ms step_avg:143.28ms
step:576/1390 train_time:81101ms step_avg:143.29ms
step:577/1390 train_time:81253ms step_avg:143.30ms
step:578/1390 train_time:81404ms step_avg:143.32ms
step:579/1390 train_time:81555ms step_avg:143.33ms
step:580/1390 train_time:81702ms step_avg:143.34ms
step:581/1390 train_time:81851ms step_avg:143.35ms
step:582/1390 train_time:81999ms step_avg:143.35ms
step:583/1390 train_time:82145ms step_avg:143.36ms
step:584/1390 train_time:82297ms step_avg:143.37ms
step:585/1390 train_time:82446ms step_avg:143.39ms
step:586/1390 train_time:82596ms step_avg:143.40ms
step:587/1390 train_time:82743ms step_avg:143.40ms
step:588/1390 train_time:82894ms step_avg:143.42ms
step:589/1390 train_time:83042ms step_avg:143.42ms
step:590/1390 train_time:83191ms step_avg:143.43ms
step:591/1390 train_time:83340ms step_avg:143.44ms
step:592/1390 train_time:83492ms step_avg:143.46ms
step:593/1390 train_time:83640ms step_avg:143.47ms
step:594/1390 train_time:83788ms step_avg:143.47ms
step:595/1390 train_time:83936ms step_avg:143.48ms
step:596/1390 train_time:84084ms step_avg:143.49ms
step:597/1390 train_time:84234ms step_avg:143.50ms
step:598/1390 train_time:84382ms step_avg:143.51ms
step:599/1390 train_time:84532ms step_avg:143.52ms
step:600/1390 train_time:84680ms step_avg:143.53ms
step:601/1390 train_time:84830ms step_avg:143.54ms
step:602/1390 train_time:84978ms step_avg:143.54ms
step:603/1390 train_time:85126ms step_avg:143.55ms
step:604/1390 train_time:85275ms step_avg:143.56ms
step:605/1390 train_time:85423ms step_avg:143.57ms
step:606/1390 train_time:85574ms step_avg:143.58ms
step:607/1390 train_time:85721ms step_avg:143.59ms
step:608/1390 train_time:85872ms step_avg:143.60ms
step:609/1390 train_time:86019ms step_avg:143.60ms
step:610/1390 train_time:86168ms step_avg:143.61ms
step:611/1390 train_time:86316ms step_avg:143.62ms
step:612/1390 train_time:86466ms step_avg:143.63ms
step:613/1390 train_time:86617ms step_avg:143.64ms
step:614/1390 train_time:86765ms step_avg:143.65ms
step:615/1390 train_time:86914ms step_avg:143.66ms
step:616/1390 train_time:87063ms step_avg:143.67ms
step:617/1390 train_time:87213ms step_avg:143.68ms
step:618/1390 train_time:87363ms step_avg:143.69ms
step:619/1390 train_time:87512ms step_avg:143.70ms
step:620/1390 train_time:87662ms step_avg:143.71ms
step:621/1390 train_time:87812ms step_avg:143.72ms
step:622/1390 train_time:87962ms step_avg:143.73ms
step:623/1390 train_time:88114ms step_avg:143.74ms
step:624/1390 train_time:88265ms step_avg:143.75ms
step:625/1390 train_time:88416ms step_avg:143.77ms
step:625/1390 val_loss:3.7668 train_time:88485ms step_avg:143.88ms
step:626/1390 train_time:88567ms step_avg:143.78ms
step:627/1390 train_time:88718ms step_avg:143.79ms
step:628/1390 train_time:88868ms step_avg:143.80ms
step:629/1390 train_time:89018ms step_avg:143.81ms
step:630/1390 train_time:89169ms step_avg:143.82ms
step:631/1390 train_time:89317ms step_avg:143.83ms
step:632/1390 train_time:89469ms step_avg:143.84ms
step:633/1390 train_time:89621ms step_avg:143.85ms
step:634/1390 train_time:89771ms step_avg:143.86ms
step:635/1390 train_time:89920ms step_avg:143.87ms
step:636/1390 train_time:90070ms step_avg:143.88ms
step:637/1390 train_time:90219ms step_avg:143.89ms
step:638/1390 train_time:90370ms step_avg:143.90ms
step:639/1390 train_time:90521ms step_avg:143.91ms
step:640/1390 train_time:90671ms step_avg:143.92ms
step:641/1390 train_time:90821ms step_avg:143.93ms
step:642/1390 train_time:90971ms step_avg:143.94ms
step:643/1390 train_time:91123ms step_avg:143.95ms
step:644/1390 train_time:91273ms step_avg:143.96ms
step:645/1390 train_time:91426ms step_avg:143.98ms
step:646/1390 train_time:91575ms step_avg:143.99ms
step:647/1390 train_time:91726ms step_avg:144.00ms
step:648/1390 train_time:91879ms step_avg:144.01ms
step:649/1390 train_time:92030ms step_avg:144.02ms
step:650/1390 train_time:92182ms step_avg:144.03ms
step:651/1390 train_time:92333ms step_avg:144.04ms
step:652/1390 train_time:92482ms step_avg:144.05ms
step:653/1390 train_time:92634ms step_avg:144.06ms
step:654/1390 train_time:92786ms step_avg:144.08ms
step:655/1390 train_time:92935ms step_avg:144.09ms
step:656/1390 train_time:93087ms step_avg:144.10ms
step:657/1390 train_time:93236ms step_avg:144.10ms
step:658/1390 train_time:93387ms step_avg:144.12ms
step:659/1390 train_time:93535ms step_avg:144.12ms
step:660/1390 train_time:93686ms step_avg:144.13ms
step:661/1390 train_time:93837ms step_avg:144.14ms
step:662/1390 train_time:93989ms step_avg:144.16ms
step:663/1390 train_time:94138ms step_avg:144.16ms
step:664/1390 train_time:94290ms step_avg:144.17ms
step:665/1390 train_time:94439ms step_avg:144.18ms
step:666/1390 train_time:94590ms step_avg:144.19ms
step:667/1390 train_time:94739ms step_avg:144.20ms
step:668/1390 train_time:94892ms step_avg:144.21ms
step:669/1390 train_time:95042ms step_avg:144.22ms
step:670/1390 train_time:95193ms step_avg:144.23ms
step:671/1390 train_time:95342ms step_avg:144.24ms
step:672/1390 train_time:95493ms step_avg:144.25ms
step:673/1390 train_time:95641ms step_avg:144.25ms
step:674/1390 train_time:95792ms step_avg:144.27ms
step:675/1390 train_time:95943ms step_avg:144.27ms
step:676/1390 train_time:96094ms step_avg:144.28ms
step:677/1390 train_time:96245ms step_avg:144.30ms
step:678/1390 train_time:96395ms step_avg:144.30ms
step:679/1390 train_time:96547ms step_avg:144.32ms
step:680/1390 train_time:96696ms step_avg:144.32ms
step:681/1390 train_time:96847ms step_avg:144.33ms
step:682/1390 train_time:96996ms step_avg:144.34ms
step:683/1390 train_time:97148ms step_avg:144.35ms
step:684/1390 train_time:97297ms step_avg:144.36ms
step:685/1390 train_time:97450ms step_avg:144.37ms
step:686/1390 train_time:97599ms step_avg:144.38ms
step:687/1390 train_time:97749ms step_avg:144.39ms
step:688/1390 train_time:97900ms step_avg:144.40ms
step:689/1390 train_time:98051ms step_avg:144.40ms
step:690/1390 train_time:98201ms step_avg:144.41ms
step:691/1390 train_time:98352ms step_avg:144.42ms
step:692/1390 train_time:98502ms step_avg:144.43ms
step:693/1390 train_time:98653ms step_avg:144.44ms
step:694/1390 train_time:98802ms step_avg:144.45ms
step:695/1390 train_time:98953ms step_avg:144.46ms
step:696/1390 train_time:99102ms step_avg:144.46ms
step:697/1390 train_time:99252ms step_avg:144.47ms
step:698/1390 train_time:99400ms step_avg:144.48ms
step:699/1390 train_time:99552ms step_avg:144.49ms
step:700/1390 train_time:99700ms step_avg:144.49ms
step:701/1390 train_time:99852ms step_avg:144.50ms
step:702/1390 train_time:100003ms step_avg:144.51ms
step:703/1390 train_time:100153ms step_avg:144.52ms
step:704/1390 train_time:100302ms step_avg:144.53ms
step:705/1390 train_time:100454ms step_avg:144.54ms
step:706/1390 train_time:100608ms step_avg:144.55ms
step:707/1390 train_time:100760ms step_avg:144.56ms
step:708/1390 train_time:100910ms step_avg:144.57ms
step:709/1390 train_time:101060ms step_avg:144.58ms
step:710/1390 train_time:101211ms step_avg:144.59ms
step:711/1390 train_time:101361ms step_avg:144.59ms
step:712/1390 train_time:101511ms step_avg:144.60ms
step:713/1390 train_time:101664ms step_avg:144.61ms
step:714/1390 train_time:101814ms step_avg:144.62ms
step:715/1390 train_time:101966ms step_avg:144.63ms
step:716/1390 train_time:102116ms step_avg:144.64ms
step:717/1390 train_time:102267ms step_avg:144.65ms
step:718/1390 train_time:102416ms step_avg:144.66ms
step:719/1390 train_time:102565ms step_avg:144.66ms
step:720/1390 train_time:102715ms step_avg:144.67ms
step:721/1390 train_time:102868ms step_avg:144.68ms
step:722/1390 train_time:103019ms step_avg:144.69ms
step:723/1390 train_time:103171ms step_avg:144.70ms
step:724/1390 train_time:103322ms step_avg:144.71ms
step:725/1390 train_time:103473ms step_avg:144.72ms
step:726/1390 train_time:103626ms step_avg:144.73ms
step:727/1390 train_time:103780ms step_avg:144.74ms
step:728/1390 train_time:103933ms step_avg:144.75ms
step:729/1390 train_time:104083ms step_avg:144.76ms
step:730/1390 train_time:104236ms step_avg:144.77ms
step:731/1390 train_time:104387ms step_avg:144.78ms
step:732/1390 train_time:104537ms step_avg:144.79ms
step:733/1390 train_time:104692ms step_avg:144.80ms
step:734/1390 train_time:104842ms step_avg:144.81ms
step:735/1390 train_time:104996ms step_avg:144.82ms
step:736/1390 train_time:105148ms step_avg:144.83ms
step:737/1390 train_time:105299ms step_avg:144.84ms
step:738/1390 train_time:105451ms step_avg:144.85ms
step:739/1390 train_time:105603ms step_avg:144.86ms
step:740/1390 train_time:105755ms step_avg:144.87ms
step:741/1390 train_time:105907ms step_avg:144.88ms
step:742/1390 train_time:106060ms step_avg:144.89ms
step:743/1390 train_time:106211ms step_avg:144.90ms
step:744/1390 train_time:106361ms step_avg:144.91ms
step:745/1390 train_time:106514ms step_avg:144.92ms
step:746/1390 train_time:106667ms step_avg:144.93ms
step:747/1390 train_time:106818ms step_avg:144.94ms
step:748/1390 train_time:106969ms step_avg:144.94ms
step:749/1390 train_time:107120ms step_avg:144.95ms
step:750/1390 train_time:107272ms step_avg:144.96ms
step:750/1390 val_loss:3.7180 train_time:107343ms step_avg:145.06ms
step:751/1390 train_time:107425ms step_avg:144.97ms
step:752/1390 train_time:107582ms step_avg:144.99ms
step:753/1390 train_time:107731ms step_avg:144.99ms
step:754/1390 train_time:107882ms step_avg:145.00ms
step:755/1390 train_time:108034ms step_avg:145.01ms
step:756/1390 train_time:108185ms step_avg:145.02ms
step:757/1390 train_time:108340ms step_avg:145.03ms
step:758/1390 train_time:108491ms step_avg:145.04ms
step:759/1390 train_time:108644ms step_avg:145.05ms
step:760/1390 train_time:108795ms step_avg:145.06ms
step:761/1390 train_time:108988ms step_avg:145.12ms
step:762/1390 train_time:109137ms step_avg:145.13ms
step:763/1390 train_time:109286ms step_avg:145.13ms
step:764/1390 train_time:109439ms step_avg:145.14ms
step:765/1390 train_time:109589ms step_avg:145.15ms
step:766/1390 train_time:109743ms step_avg:145.16ms
step:767/1390 train_time:109899ms step_avg:145.18ms
step:768/1390 train_time:110053ms step_avg:145.19ms
step:769/1390 train_time:110206ms step_avg:145.20ms
step:770/1390 train_time:110359ms step_avg:145.21ms
step:771/1390 train_time:110509ms step_avg:145.22ms
step:772/1390 train_time:110660ms step_avg:145.22ms
step:773/1390 train_time:110813ms step_avg:145.23ms
step:774/1390 train_time:110971ms step_avg:145.25ms
step:775/1390 train_time:111123ms step_avg:145.26ms
step:776/1390 train_time:111277ms step_avg:145.27ms
step:777/1390 train_time:111428ms step_avg:145.28ms
step:778/1390 train_time:111581ms step_avg:145.29ms
step:779/1390 train_time:111730ms step_avg:145.29ms
step:780/1390 train_time:111884ms step_avg:145.30ms
step:781/1390 train_time:112038ms step_avg:145.31ms
step:782/1390 train_time:112187ms step_avg:145.32ms
step:783/1390 train_time:112339ms step_avg:145.33ms
step:784/1390 train_time:112490ms step_avg:145.34ms
step:785/1390 train_time:112641ms step_avg:145.34ms
step:786/1390 train_time:112794ms step_avg:145.35ms
step:787/1390 train_time:112946ms step_avg:145.36ms
step:788/1390 train_time:113100ms step_avg:145.37ms
step:789/1390 train_time:113249ms step_avg:145.38ms
step:790/1390 train_time:113401ms step_avg:145.39ms
step:791/1390 train_time:113551ms step_avg:145.39ms
step:792/1390 train_time:113702ms step_avg:145.40ms
step:793/1390 train_time:113853ms step_avg:145.41ms
step:794/1390 train_time:114005ms step_avg:145.41ms
step:795/1390 train_time:114160ms step_avg:145.43ms
step:796/1390 train_time:114310ms step_avg:145.43ms
step:797/1390 train_time:114462ms step_avg:145.44ms
step:798/1390 train_time:114616ms step_avg:145.45ms
step:799/1390 train_time:114772ms step_avg:145.46ms
step:800/1390 train_time:114922ms step_avg:145.47ms
step:801/1390 train_time:115076ms step_avg:145.48ms
step:802/1390 train_time:115226ms step_avg:145.49ms
step:803/1390 train_time:115379ms step_avg:145.50ms
step:804/1390 train_time:115528ms step_avg:145.50ms
step:805/1390 train_time:115684ms step_avg:145.51ms
step:806/1390 train_time:115836ms step_avg:145.52ms
step:807/1390 train_time:115987ms step_avg:145.53ms
step:808/1390 train_time:116139ms step_avg:145.54ms
step:809/1390 train_time:116289ms step_avg:145.54ms
step:810/1390 train_time:116441ms step_avg:145.55ms
step:811/1390 train_time:116594ms step_avg:145.56ms
step:812/1390 train_time:116745ms step_avg:145.57ms
step:813/1390 train_time:116898ms step_avg:145.58ms
step:814/1390 train_time:117047ms step_avg:145.58ms
step:815/1390 train_time:117200ms step_avg:145.59ms
step:816/1390 train_time:117353ms step_avg:145.60ms
step:817/1390 train_time:117504ms step_avg:145.61ms
step:818/1390 train_time:117655ms step_avg:145.61ms
step:819/1390 train_time:117807ms step_avg:145.62ms
step:820/1390 train_time:117961ms step_avg:145.63ms
step:821/1390 train_time:118112ms step_avg:145.64ms
step:822/1390 train_time:118264ms step_avg:145.65ms
step:823/1390 train_time:118417ms step_avg:145.65ms
step:824/1390 train_time:118568ms step_avg:145.66ms
step:825/1390 train_time:118722ms step_avg:145.67ms
step:826/1390 train_time:118878ms step_avg:145.68ms
step:827/1390 train_time:119029ms step_avg:145.69ms
step:828/1390 train_time:119182ms step_avg:145.70ms
step:829/1390 train_time:119336ms step_avg:145.71ms
step:830/1390 train_time:119489ms step_avg:145.72ms
step:831/1390 train_time:119641ms step_avg:145.73ms
step:832/1390 train_time:119796ms step_avg:145.74ms
step:833/1390 train_time:119948ms step_avg:145.75ms
step:834/1390 train_time:120102ms step_avg:145.76ms
step:835/1390 train_time:120256ms step_avg:145.76ms
step:836/1390 train_time:120409ms step_avg:145.77ms
step:837/1390 train_time:120563ms step_avg:145.78ms
step:838/1390 train_time:120717ms step_avg:145.79ms
step:839/1390 train_time:120870ms step_avg:145.80ms
step:840/1390 train_time:121023ms step_avg:145.81ms
step:841/1390 train_time:121178ms step_avg:145.82ms
step:842/1390 train_time:121330ms step_avg:145.83ms
step:843/1390 train_time:121483ms step_avg:145.84ms
step:844/1390 train_time:121635ms step_avg:145.85ms
step:845/1390 train_time:121786ms step_avg:145.85ms
step:846/1390 train_time:121940ms step_avg:145.86ms
step:847/1390 train_time:122094ms step_avg:145.87ms
step:848/1390 train_time:122245ms step_avg:145.88ms
step:849/1390 train_time:122400ms step_avg:145.89ms
step:850/1390 train_time:122556ms step_avg:145.90ms
step:851/1390 train_time:122709ms step_avg:145.91ms
step:852/1390 train_time:122863ms step_avg:145.92ms
step:853/1390 train_time:123016ms step_avg:145.93ms
step:854/1390 train_time:123168ms step_avg:145.93ms
step:855/1390 train_time:123320ms step_avg:145.94ms
step:856/1390 train_time:123473ms step_avg:145.95ms
step:857/1390 train_time:123625ms step_avg:145.96ms
step:858/1390 train_time:123783ms step_avg:145.97ms
step:859/1390 train_time:123937ms step_avg:145.98ms
step:860/1390 train_time:124087ms step_avg:145.98ms
step:861/1390 train_time:124241ms step_avg:145.99ms
step:862/1390 train_time:124395ms step_avg:146.00ms
step:863/1390 train_time:124548ms step_avg:146.01ms
step:864/1390 train_time:124702ms step_avg:146.02ms
step:865/1390 train_time:124854ms step_avg:146.03ms
step:866/1390 train_time:125012ms step_avg:146.04ms
step:867/1390 train_time:125165ms step_avg:146.05ms
step:868/1390 train_time:125320ms step_avg:146.06ms
step:869/1390 train_time:125474ms step_avg:146.07ms
step:870/1390 train_time:125627ms step_avg:146.08ms
step:871/1390 train_time:125781ms step_avg:146.09ms
step:872/1390 train_time:125933ms step_avg:146.09ms
step:873/1390 train_time:126085ms step_avg:146.10ms
step:874/1390 train_time:126240ms step_avg:146.11ms
step:875/1390 train_time:126394ms step_avg:146.12ms
step:875/1390 val_loss:3.6737 train_time:126465ms step_avg:146.20ms
step:876/1390 train_time:126548ms step_avg:146.13ms
step:877/1390 train_time:126704ms step_avg:146.14ms
step:878/1390 train_time:126857ms step_avg:146.15ms
step:879/1390 train_time:127009ms step_avg:146.16ms
step:880/1390 train_time:127163ms step_avg:146.16ms
step:881/1390 train_time:127314ms step_avg:146.17ms
step:882/1390 train_time:127468ms step_avg:146.18ms
step:883/1390 train_time:127623ms step_avg:146.19ms
step:884/1390 train_time:127778ms step_avg:146.20ms
step:885/1390 train_time:127930ms step_avg:146.21ms
step:886/1390 train_time:128087ms step_avg:146.22ms
step:887/1390 train_time:128240ms step_avg:146.23ms
step:888/1390 train_time:128394ms step_avg:146.24ms
step:889/1390 train_time:128550ms step_avg:146.25ms
step:890/1390 train_time:128703ms step_avg:146.25ms
step:891/1390 train_time:128856ms step_avg:146.26ms
step:892/1390 train_time:129009ms step_avg:146.27ms
step:893/1390 train_time:129162ms step_avg:146.28ms
step:894/1390 train_time:129317ms step_avg:146.29ms
step:895/1390 train_time:129476ms step_avg:146.30ms
step:896/1390 train_time:129627ms step_avg:146.31ms
step:897/1390 train_time:129783ms step_avg:146.32ms
step:898/1390 train_time:129936ms step_avg:146.32ms
step:899/1390 train_time:130087ms step_avg:146.33ms
step:900/1390 train_time:130241ms step_avg:146.34ms
step:901/1390 train_time:130395ms step_avg:146.35ms
step:902/1390 train_time:130545ms step_avg:146.35ms
step:903/1390 train_time:130700ms step_avg:146.36ms
step:904/1390 train_time:130853ms step_avg:146.37ms
step:905/1390 train_time:131007ms step_avg:146.38ms
step:906/1390 train_time:131161ms step_avg:146.39ms
step:907/1390 train_time:131317ms step_avg:146.40ms
step:908/1390 train_time:131468ms step_avg:146.40ms
step:909/1390 train_time:131625ms step_avg:146.41ms
step:910/1390 train_time:131784ms step_avg:146.43ms
step:911/1390 train_time:131935ms step_avg:146.43ms
step:912/1390 train_time:132088ms step_avg:146.44ms
step:913/1390 train_time:132244ms step_avg:146.45ms
step:914/1390 train_time:132395ms step_avg:146.46ms
step:915/1390 train_time:132550ms step_avg:146.46ms
step:916/1390 train_time:132704ms step_avg:146.47ms
step:917/1390 train_time:132855ms step_avg:146.48ms
step:918/1390 train_time:133007ms step_avg:146.48ms
step:919/1390 train_time:133162ms step_avg:146.49ms
step:920/1390 train_time:133314ms step_avg:146.50ms
step:921/1390 train_time:133467ms step_avg:146.51ms
step:922/1390 train_time:133626ms step_avg:146.52ms
step:923/1390 train_time:133777ms step_avg:146.53ms
step:924/1390 train_time:133930ms step_avg:146.53ms
step:925/1390 train_time:134087ms step_avg:146.54ms
step:926/1390 train_time:134243ms step_avg:146.55ms
step:927/1390 train_time:134394ms step_avg:146.56ms
step:928/1390 train_time:134547ms step_avg:146.57ms
step:929/1390 train_time:134704ms step_avg:146.58ms
step:930/1390 train_time:134859ms step_avg:146.59ms
step:931/1390 train_time:135011ms step_avg:146.59ms
step:932/1390 train_time:135167ms step_avg:146.60ms
step:933/1390 train_time:135322ms step_avg:146.61ms
step:934/1390 train_time:135476ms step_avg:146.62ms
step:935/1390 train_time:135630ms step_avg:146.63ms
step:936/1390 train_time:135786ms step_avg:146.64ms
step:937/1390 train_time:135945ms step_avg:146.65ms
step:938/1390 train_time:136098ms step_avg:146.66ms
step:939/1390 train_time:136252ms step_avg:146.66ms
step:940/1390 train_time:136406ms step_avg:146.67ms
step:941/1390 train_time:136561ms step_avg:146.68ms
step:942/1390 train_time:136713ms step_avg:146.69ms
step:943/1390 train_time:136872ms step_avg:146.70ms
step:944/1390 train_time:137032ms step_avg:146.71ms
step:945/1390 train_time:137187ms step_avg:146.72ms
step:946/1390 train_time:137344ms step_avg:146.73ms
step:947/1390 train_time:137498ms step_avg:146.74ms
step:948/1390 train_time:137652ms step_avg:146.75ms
step:949/1390 train_time:137808ms step_avg:146.76ms
step:950/1390 train_time:137963ms step_avg:146.77ms
step:951/1390 train_time:138154ms step_avg:146.82ms
step:952/1390 train_time:138307ms step_avg:146.82ms
step:953/1390 train_time:138462ms step_avg:146.83ms
step:954/1390 train_time:138616ms step_avg:146.84ms
step:955/1390 train_time:138767ms step_avg:146.84ms
step:956/1390 train_time:138922ms step_avg:146.85ms
step:957/1390 train_time:139077ms step_avg:146.86ms
step:958/1390 train_time:139234ms step_avg:146.87ms
step:959/1390 train_time:139391ms step_avg:146.88ms
step:960/1390 train_time:139547ms step_avg:146.89ms
step:961/1390 train_time:139701ms step_avg:146.90ms
step:962/1390 train_time:139854ms step_avg:146.91ms
step:963/1390 train_time:140015ms step_avg:146.92ms
step:964/1390 train_time:140168ms step_avg:146.93ms
step:965/1390 train_time:140321ms step_avg:146.93ms
step:966/1390 train_time:140474ms step_avg:146.94ms
step:967/1390 train_time:140627ms step_avg:146.95ms
step:968/1390 train_time:140781ms step_avg:146.95ms
step:969/1390 train_time:140934ms step_avg:146.96ms
step:970/1390 train_time:141086ms step_avg:146.97ms
step:971/1390 train_time:141244ms step_avg:146.98ms
step:972/1390 train_time:141397ms step_avg:146.98ms
step:973/1390 train_time:141550ms step_avg:146.99ms
step:974/1390 train_time:141705ms step_avg:147.00ms
step:975/1390 train_time:141860ms step_avg:147.00ms
step:976/1390 train_time:142013ms step_avg:147.01ms
step:977/1390 train_time:142167ms step_avg:147.02ms
step:978/1390 train_time:142320ms step_avg:147.03ms
step:979/1390 train_time:142472ms step_avg:147.03ms
step:980/1390 train_time:142627ms step_avg:147.04ms
step:981/1390 train_time:142781ms step_avg:147.05ms
step:982/1390 train_time:142932ms step_avg:147.05ms
step:983/1390 train_time:143086ms step_avg:147.06ms
step:984/1390 train_time:143240ms step_avg:147.06ms
step:985/1390 train_time:143395ms step_avg:147.07ms
step:986/1390 train_time:143554ms step_avg:147.08ms
step:987/1390 train_time:143707ms step_avg:147.09ms
step:988/1390 train_time:143861ms step_avg:147.10ms
step:989/1390 train_time:144015ms step_avg:147.10ms
step:990/1390 train_time:144170ms step_avg:147.11ms
step:991/1390 train_time:144325ms step_avg:147.12ms
step:992/1390 train_time:144484ms step_avg:147.13ms
step:993/1390 train_time:144647ms step_avg:147.15ms
step:994/1390 train_time:144801ms step_avg:147.16ms
step:995/1390 train_time:144953ms step_avg:147.16ms
step:996/1390 train_time:145105ms step_avg:147.17ms
step:997/1390 train_time:145258ms step_avg:147.17ms
step:998/1390 train_time:145413ms step_avg:147.18ms
step:999/1390 train_time:145567ms step_avg:147.19ms
step:1000/1390 train_time:145723ms step_avg:147.20ms
step:1000/1390 val_loss:3.6169 train_time:145795ms step_avg:147.27ms
step:1001/1390 train_time:145877ms step_avg:147.20ms
step:1002/1390 train_time:146036ms step_avg:147.21ms
step:1003/1390 train_time:146191ms step_avg:147.22ms
step:1004/1390 train_time:146347ms step_avg:147.23ms
step:1005/1390 train_time:146499ms step_avg:147.23ms
step:1006/1390 train_time:146650ms step_avg:147.24ms
step:1007/1390 train_time:146808ms step_avg:147.25ms
step:1008/1390 train_time:146966ms step_avg:147.26ms
step:1009/1390 train_time:147127ms step_avg:147.27ms
step:1010/1390 train_time:147279ms step_avg:147.28ms
step:1011/1390 train_time:147432ms step_avg:147.29ms
step:1012/1390 train_time:147588ms step_avg:147.29ms
step:1013/1390 train_time:147744ms step_avg:147.30ms
step:1014/1390 train_time:147897ms step_avg:147.31ms
step:1015/1390 train_time:148052ms step_avg:147.32ms
step:1016/1390 train_time:148208ms step_avg:147.32ms
step:1017/1390 train_time:148363ms step_avg:147.33ms
step:1018/1390 train_time:148515ms step_avg:147.34ms
step:1019/1390 train_time:148671ms step_avg:147.35ms
step:1020/1390 train_time:148826ms step_avg:147.35ms
step:1021/1390 train_time:148978ms step_avg:147.36ms
step:1022/1390 train_time:149134ms step_avg:147.37ms
step:1023/1390 train_time:149290ms step_avg:147.37ms
step:1024/1390 train_time:149442ms step_avg:147.38ms
step:1025/1390 train_time:149594ms step_avg:147.38ms
step:1026/1390 train_time:149749ms step_avg:147.39ms
step:1027/1390 train_time:149902ms step_avg:147.40ms
step:1028/1390 train_time:150056ms step_avg:147.40ms
step:1029/1390 train_time:150212ms step_avg:147.41ms
step:1030/1390 train_time:150369ms step_avg:147.42ms
step:1031/1390 train_time:150520ms step_avg:147.42ms
step:1032/1390 train_time:150674ms step_avg:147.43ms
step:1033/1390 train_time:150830ms step_avg:147.44ms
step:1034/1390 train_time:150983ms step_avg:147.44ms
step:1035/1390 train_time:151140ms step_avg:147.45ms
step:1036/1390 train_time:151295ms step_avg:147.46ms
step:1037/1390 train_time:151452ms step_avg:147.47ms
step:1038/1390 train_time:151606ms step_avg:147.48ms
step:1039/1390 train_time:151762ms step_avg:147.48ms
step:1040/1390 train_time:151916ms step_avg:147.49ms
step:1041/1390 train_time:152073ms step_avg:147.50ms
step:1042/1390 train_time:152224ms step_avg:147.50ms
step:1043/1390 train_time:152378ms step_avg:147.51ms
step:1044/1390 train_time:152538ms step_avg:147.52ms
step:1045/1390 train_time:152695ms step_avg:147.53ms
step:1046/1390 train_time:152850ms step_avg:147.54ms
step:1047/1390 train_time:153006ms step_avg:147.55ms
step:1048/1390 train_time:153163ms step_avg:147.56ms
step:1049/1390 train_time:153317ms step_avg:147.56ms
step:1050/1390 train_time:153474ms step_avg:147.57ms
step:1051/1390 train_time:153632ms step_avg:147.58ms
step:1052/1390 train_time:153789ms step_avg:147.59ms
step:1053/1390 train_time:153944ms step_avg:147.60ms
step:1054/1390 train_time:154103ms step_avg:147.61ms
step:1055/1390 train_time:154258ms step_avg:147.62ms
step:1056/1390 train_time:154415ms step_avg:147.62ms
step:1057/1390 train_time:154573ms step_avg:147.63ms
step:1058/1390 train_time:154733ms step_avg:147.65ms
step:1059/1390 train_time:154891ms step_avg:147.66ms
step:1060/1390 train_time:155046ms step_avg:147.66ms
step:1061/1390 train_time:155197ms step_avg:147.67ms
step:1062/1390 train_time:155352ms step_avg:147.67ms
step:1063/1390 train_time:155509ms step_avg:147.68ms
step:1064/1390 train_time:155664ms step_avg:147.69ms
step:1065/1390 train_time:155821ms step_avg:147.70ms
step:1066/1390 train_time:155978ms step_avg:147.71ms
step:1067/1390 train_time:156136ms step_avg:147.72ms
step:1068/1390 train_time:156292ms step_avg:147.72ms
step:1069/1390 train_time:156451ms step_avg:147.73ms
step:1070/1390 train_time:156605ms step_avg:147.74ms
step:1071/1390 train_time:156763ms step_avg:147.75ms
step:1072/1390 train_time:156916ms step_avg:147.75ms
step:1073/1390 train_time:157070ms step_avg:147.76ms
step:1074/1390 train_time:157224ms step_avg:147.77ms
step:1075/1390 train_time:157378ms step_avg:147.77ms
step:1076/1390 train_time:157533ms step_avg:147.78ms
step:1077/1390 train_time:157690ms step_avg:147.79ms
step:1078/1390 train_time:157850ms step_avg:147.80ms
step:1079/1390 train_time:158007ms step_avg:147.81ms
step:1080/1390 train_time:158163ms step_avg:147.82ms
step:1081/1390 train_time:158318ms step_avg:147.82ms
step:1082/1390 train_time:158472ms step_avg:147.83ms
step:1083/1390 train_time:158628ms step_avg:147.84ms
step:1084/1390 train_time:158786ms step_avg:147.85ms
step:1085/1390 train_time:158941ms step_avg:147.85ms
step:1086/1390 train_time:159099ms step_avg:147.86ms
step:1087/1390 train_time:159256ms step_avg:147.87ms
step:1088/1390 train_time:159411ms step_avg:147.88ms
step:1089/1390 train_time:159573ms step_avg:147.89ms
step:1090/1390 train_time:159732ms step_avg:147.90ms
step:1091/1390 train_time:159886ms step_avg:147.91ms
step:1092/1390 train_time:160041ms step_avg:147.91ms
step:1093/1390 train_time:160196ms step_avg:147.92ms
step:1094/1390 train_time:160351ms step_avg:147.93ms
step:1095/1390 train_time:160507ms step_avg:147.93ms
step:1096/1390 train_time:160666ms step_avg:147.94ms
step:1097/1390 train_time:160821ms step_avg:147.95ms
step:1098/1390 train_time:160976ms step_avg:147.96ms
step:1099/1390 train_time:161131ms step_avg:147.96ms
step:1100/1390 train_time:161285ms step_avg:147.97ms
step:1101/1390 train_time:161439ms step_avg:147.97ms
step:1102/1390 train_time:161595ms step_avg:147.98ms
step:1103/1390 train_time:161750ms step_avg:147.99ms
step:1104/1390 train_time:161905ms step_avg:147.99ms
step:1105/1390 train_time:162063ms step_avg:148.00ms
step:1106/1390 train_time:162220ms step_avg:148.01ms
step:1107/1390 train_time:162373ms step_avg:148.02ms
step:1108/1390 train_time:162532ms step_avg:148.03ms
step:1109/1390 train_time:162687ms step_avg:148.03ms
step:1110/1390 train_time:162842ms step_avg:148.04ms
step:1111/1390 train_time:163000ms step_avg:148.05ms
step:1112/1390 train_time:163153ms step_avg:148.05ms
step:1113/1390 train_time:163309ms step_avg:148.06ms
step:1114/1390 train_time:163468ms step_avg:148.07ms
step:1115/1390 train_time:163624ms step_avg:148.08ms
step:1116/1390 train_time:163776ms step_avg:148.08ms
step:1117/1390 train_time:163936ms step_avg:148.09ms
step:1118/1390 train_time:164096ms step_avg:148.10ms
step:1119/1390 train_time:164253ms step_avg:148.11ms
step:1120/1390 train_time:164410ms step_avg:148.12ms
step:1121/1390 train_time:164567ms step_avg:148.12ms
step:1122/1390 train_time:164720ms step_avg:148.13ms
step:1123/1390 train_time:164874ms step_avg:148.14ms
step:1124/1390 train_time:165033ms step_avg:148.14ms
step:1125/1390 train_time:165190ms step_avg:148.15ms
step:1125/1390 val_loss:3.5727 train_time:165261ms step_avg:148.22ms
step:1126/1390 train_time:165344ms step_avg:148.16ms
step:1127/1390 train_time:165501ms step_avg:148.17ms
step:1128/1390 train_time:165656ms step_avg:148.17ms
step:1129/1390 train_time:165812ms step_avg:148.18ms
step:1130/1390 train_time:165967ms step_avg:148.18ms
step:1131/1390 train_time:166124ms step_avg:148.19ms
step:1132/1390 train_time:166280ms step_avg:148.20ms
step:1133/1390 train_time:166434ms step_avg:148.20ms
step:1134/1390 train_time:166589ms step_avg:148.21ms
step:1135/1390 train_time:166744ms step_avg:148.22ms
step:1136/1390 train_time:166903ms step_avg:148.23ms
step:1137/1390 train_time:167057ms step_avg:148.23ms
step:1138/1390 train_time:167213ms step_avg:148.24ms
step:1139/1390 train_time:167370ms step_avg:148.25ms
step:1140/1390 train_time:167526ms step_avg:148.25ms
step:1141/1390 train_time:167723ms step_avg:148.30ms
step:1142/1390 train_time:167879ms step_avg:148.30ms
step:1143/1390 train_time:168038ms step_avg:148.31ms
step:1144/1390 train_time:168193ms step_avg:148.32ms
step:1145/1390 train_time:168345ms step_avg:148.32ms
step:1146/1390 train_time:168504ms step_avg:148.33ms
step:1147/1390 train_time:168664ms step_avg:148.34ms
step:1148/1390 train_time:168821ms step_avg:148.35ms
step:1149/1390 train_time:168975ms step_avg:148.35ms
step:1150/1390 train_time:169129ms step_avg:148.36ms
step:1151/1390 train_time:169287ms step_avg:148.37ms
step:1152/1390 train_time:169446ms step_avg:148.38ms
step:1153/1390 train_time:169606ms step_avg:148.39ms
step:1154/1390 train_time:169761ms step_avg:148.39ms
step:1155/1390 train_time:169916ms step_avg:148.40ms
step:1156/1390 train_time:170078ms step_avg:148.41ms
step:1157/1390 train_time:170236ms step_avg:148.42ms
step:1158/1390 train_time:170391ms step_avg:148.42ms
step:1159/1390 train_time:170547ms step_avg:148.43ms
step:1160/1390 train_time:170705ms step_avg:148.44ms
step:1161/1390 train_time:170862ms step_avg:148.45ms
step:1162/1390 train_time:171018ms step_avg:148.45ms
step:1163/1390 train_time:171172ms step_avg:148.46ms
step:1164/1390 train_time:171328ms step_avg:148.46ms
step:1165/1390 train_time:171483ms step_avg:148.47ms
step:1166/1390 train_time:171638ms step_avg:148.48ms
step:1167/1390 train_time:171793ms step_avg:148.48ms
step:1168/1390 train_time:171949ms step_avg:148.49ms
step:1169/1390 train_time:172106ms step_avg:148.50ms
step:1170/1390 train_time:172263ms step_avg:148.50ms
step:1171/1390 train_time:172421ms step_avg:148.51ms
step:1172/1390 train_time:172575ms step_avg:148.52ms
step:1173/1390 train_time:172734ms step_avg:148.52ms
step:1174/1390 train_time:172897ms step_avg:148.54ms
step:1175/1390 train_time:173053ms step_avg:148.54ms
step:1176/1390 train_time:173211ms step_avg:148.55ms
step:1177/1390 train_time:173377ms step_avg:148.57ms
step:1178/1390 train_time:173533ms step_avg:148.57ms
step:1179/1390 train_time:173689ms step_avg:148.58ms
step:1180/1390 train_time:173854ms step_avg:148.59ms
step:1181/1390 train_time:174008ms step_avg:148.60ms
step:1182/1390 train_time:174163ms step_avg:148.60ms
step:1183/1390 train_time:174319ms step_avg:148.61ms
step:1184/1390 train_time:174477ms step_avg:148.62ms
step:1185/1390 train_time:174636ms step_avg:148.63ms
step:1186/1390 train_time:174793ms step_avg:148.63ms
step:1187/1390 train_time:174956ms step_avg:148.65ms
step:1188/1390 train_time:175110ms step_avg:148.65ms
step:1189/1390 train_time:175270ms step_avg:148.66ms
step:1190/1390 train_time:175430ms step_avg:148.67ms
step:1191/1390 train_time:175586ms step_avg:148.68ms
step:1192/1390 train_time:175740ms step_avg:148.68ms
step:1193/1390 train_time:175899ms step_avg:148.69ms
step:1194/1390 train_time:176055ms step_avg:148.69ms
step:1195/1390 train_time:176209ms step_avg:148.70ms
step:1196/1390 train_time:176367ms step_avg:148.71ms
step:1197/1390 train_time:176526ms step_avg:148.72ms
step:1198/1390 train_time:176687ms step_avg:148.73ms
step:1199/1390 train_time:176843ms step_avg:148.73ms
step:1200/1390 train_time:177002ms step_avg:148.74ms
step:1201/1390 train_time:177158ms step_avg:148.75ms
step:1202/1390 train_time:177326ms step_avg:148.76ms
step:1203/1390 train_time:177485ms step_avg:148.77ms
step:1204/1390 train_time:177641ms step_avg:148.78ms
step:1205/1390 train_time:177797ms step_avg:148.78ms
step:1206/1390 train_time:177952ms step_avg:148.79ms
step:1207/1390 train_time:178107ms step_avg:148.79ms
step:1208/1390 train_time:178266ms step_avg:148.80ms
step:1209/1390 train_time:178424ms step_avg:148.81ms
step:1210/1390 train_time:178585ms step_avg:148.82ms
step:1211/1390 train_time:178741ms step_avg:148.83ms
step:1212/1390 train_time:178898ms step_avg:148.83ms
step:1213/1390 train_time:179054ms step_avg:148.84ms
step:1214/1390 train_time:179213ms step_avg:148.85ms
step:1215/1390 train_time:179371ms step_avg:148.86ms
step:1216/1390 train_time:179525ms step_avg:148.86ms
step:1217/1390 train_time:179682ms step_avg:148.87ms
step:1218/1390 train_time:179836ms step_avg:148.87ms
step:1219/1390 train_time:179992ms step_avg:148.88ms
step:1220/1390 train_time:180146ms step_avg:148.88ms
step:1221/1390 train_time:180302ms step_avg:148.89ms
step:1222/1390 train_time:180458ms step_avg:148.89ms
step:1223/1390 train_time:180613ms step_avg:148.90ms
step:1224/1390 train_time:180770ms step_avg:148.90ms
step:1225/1390 train_time:180927ms step_avg:148.91ms
step:1226/1390 train_time:181084ms step_avg:148.92ms
step:1227/1390 train_time:181242ms step_avg:148.93ms
step:1228/1390 train_time:181398ms step_avg:148.93ms
step:1229/1390 train_time:181552ms step_avg:148.94ms
step:1230/1390 train_time:181711ms step_avg:148.94ms
step:1231/1390 train_time:181872ms step_avg:148.95ms
step:1232/1390 train_time:182030ms step_avg:148.96ms
step:1233/1390 train_time:182185ms step_avg:148.97ms
step:1234/1390 train_time:182340ms step_avg:148.97ms
step:1235/1390 train_time:182498ms step_avg:148.98ms
step:1236/1390 train_time:182651ms step_avg:148.98ms
step:1237/1390 train_time:182805ms step_avg:148.99ms
step:1238/1390 train_time:182968ms step_avg:149.00ms
step:1239/1390 train_time:183126ms step_avg:149.00ms
step:1240/1390 train_time:183286ms step_avg:149.01ms
step:1241/1390 train_time:183451ms step_avg:149.03ms
step:1242/1390 train_time:183608ms step_avg:149.03ms
step:1243/1390 train_time:183766ms step_avg:149.04ms
step:1244/1390 train_time:183923ms step_avg:149.05ms
step:1245/1390 train_time:184079ms step_avg:149.05ms
step:1246/1390 train_time:184235ms step_avg:149.06ms
step:1247/1390 train_time:184394ms step_avg:149.07ms
step:1248/1390 train_time:184547ms step_avg:149.07ms
step:1249/1390 train_time:184703ms step_avg:149.07ms
step:1250/1390 train_time:184861ms step_avg:149.08ms
step:1250/1390 val_loss:3.5319 train_time:184934ms step_avg:149.14ms
step:1251/1390 train_time:185021ms step_avg:149.09ms
step:1252/1390 train_time:185176ms step_avg:149.09ms
step:1253/1390 train_time:185331ms step_avg:149.10ms
step:1254/1390 train_time:185486ms step_avg:149.10ms
step:1255/1390 train_time:185654ms step_avg:149.12ms
step:1256/1390 train_time:185811ms step_avg:149.13ms
step:1257/1390 train_time:185968ms step_avg:149.13ms
step:1258/1390 train_time:186130ms step_avg:149.14ms
step:1259/1390 train_time:186287ms step_avg:149.15ms
step:1260/1390 train_time:186443ms step_avg:149.15ms
step:1261/1390 train_time:186601ms step_avg:149.16ms
step:1262/1390 train_time:186760ms step_avg:149.17ms
step:1263/1390 train_time:186917ms step_avg:149.18ms
step:1264/1390 train_time:187073ms step_avg:149.18ms
step:1265/1390 train_time:187228ms step_avg:149.19ms
step:1266/1390 train_time:187387ms step_avg:149.19ms
step:1267/1390 train_time:187547ms step_avg:149.20ms
step:1268/1390 train_time:187706ms step_avg:149.21ms
step:1269/1390 train_time:187867ms step_avg:149.22ms
step:1270/1390 train_time:188026ms step_avg:149.23ms
step:1271/1390 train_time:188185ms step_avg:149.23ms
step:1272/1390 train_time:188342ms step_avg:149.24ms
step:1273/1390 train_time:188496ms step_avg:149.24ms
step:1274/1390 train_time:188651ms step_avg:149.25ms
step:1275/1390 train_time:188807ms step_avg:149.25ms
step:1276/1390 train_time:188962ms step_avg:149.26ms
step:1277/1390 train_time:189122ms step_avg:149.27ms
step:1278/1390 train_time:189277ms step_avg:149.27ms
step:1279/1390 train_time:189433ms step_avg:149.28ms
step:1280/1390 train_time:189598ms step_avg:149.29ms
step:1281/1390 train_time:189755ms step_avg:149.30ms
step:1282/1390 train_time:189910ms step_avg:149.30ms
step:1283/1390 train_time:190066ms step_avg:149.31ms
step:1284/1390 train_time:190228ms step_avg:149.32ms
step:1285/1390 train_time:190384ms step_avg:149.32ms
step:1286/1390 train_time:190542ms step_avg:149.33ms
step:1287/1390 train_time:190699ms step_avg:149.33ms
step:1288/1390 train_time:190856ms step_avg:149.34ms
step:1289/1390 train_time:191020ms step_avg:149.35ms
step:1290/1390 train_time:191180ms step_avg:149.36ms
step:1291/1390 train_time:191341ms step_avg:149.37ms
step:1292/1390 train_time:191498ms step_avg:149.37ms
step:1293/1390 train_time:191656ms step_avg:149.38ms
step:1294/1390 train_time:191813ms step_avg:149.39ms
step:1295/1390 train_time:191971ms step_avg:149.39ms
step:1296/1390 train_time:192129ms step_avg:149.40ms
step:1297/1390 train_time:192291ms step_avg:149.41ms
step:1298/1390 train_time:192447ms step_avg:149.42ms
step:1299/1390 train_time:192603ms step_avg:149.42ms
step:1300/1390 train_time:192760ms step_avg:149.43ms
step:1301/1390 train_time:192916ms step_avg:149.43ms
step:1302/1390 train_time:193073ms step_avg:149.44ms
step:1303/1390 train_time:193232ms step_avg:149.44ms
step:1304/1390 train_time:193392ms step_avg:149.45ms
step:1305/1390 train_time:193548ms step_avg:149.46ms
step:1306/1390 train_time:193709ms step_avg:149.47ms
step:1307/1390 train_time:193865ms step_avg:149.47ms
step:1308/1390 train_time:194022ms step_avg:149.48ms
step:1309/1390 train_time:194179ms step_avg:149.48ms
step:1310/1390 train_time:194334ms step_avg:149.49ms
step:1311/1390 train_time:194489ms step_avg:149.49ms
step:1312/1390 train_time:194646ms step_avg:149.50ms
step:1313/1390 train_time:194802ms step_avg:149.50ms
step:1314/1390 train_time:194959ms step_avg:149.51ms
step:1315/1390 train_time:195116ms step_avg:149.51ms
step:1316/1390 train_time:195272ms step_avg:149.52ms
step:1317/1390 train_time:195426ms step_avg:149.52ms
step:1318/1390 train_time:195588ms step_avg:149.53ms
step:1319/1390 train_time:195746ms step_avg:149.54ms
step:1320/1390 train_time:195903ms step_avg:149.54ms
step:1321/1390 train_time:196062ms step_avg:149.55ms
step:1322/1390 train_time:196224ms step_avg:149.56ms
step:1323/1390 train_time:196381ms step_avg:149.57ms
step:1324/1390 train_time:196536ms step_avg:149.57ms
step:1325/1390 train_time:196694ms step_avg:149.58ms
step:1326/1390 train_time:196855ms step_avg:149.59ms
step:1327/1390 train_time:197012ms step_avg:149.59ms
step:1328/1390 train_time:197168ms step_avg:149.60ms
step:1329/1390 train_time:197342ms step_avg:149.61ms
step:1330/1390 train_time:197503ms step_avg:149.62ms
step:1331/1390 train_time:197697ms step_avg:149.66ms
step:1332/1390 train_time:197858ms step_avg:149.67ms
step:1333/1390 train_time:198016ms step_avg:149.67ms
step:1334/1390 train_time:198172ms step_avg:149.68ms
step:1335/1390 train_time:198326ms step_avg:149.68ms
step:1336/1390 train_time:198490ms step_avg:149.69ms
step:1337/1390 train_time:198649ms step_avg:149.70ms
step:1338/1390 train_time:198807ms step_avg:149.70ms
step:1339/1390 train_time:198965ms step_avg:149.71ms
step:1340/1390 train_time:199125ms step_avg:149.72ms
step:1341/1390 train_time:199282ms step_avg:149.72ms
step:1342/1390 train_time:199442ms step_avg:149.73ms
step:1343/1390 train_time:199599ms step_avg:149.74ms
step:1344/1390 train_time:199756ms step_avg:149.74ms
step:1345/1390 train_time:199915ms step_avg:149.75ms
step:1346/1390 train_time:200073ms step_avg:149.76ms
step:1347/1390 train_time:200232ms step_avg:149.76ms
step:1348/1390 train_time:200390ms step_avg:149.77ms
step:1349/1390 train_time:200548ms step_avg:149.77ms
step:1350/1390 train_time:200704ms step_avg:149.78ms
step:1351/1390 train_time:200863ms step_avg:149.79ms
step:1352/1390 train_time:201026ms step_avg:149.80ms
step:1353/1390 train_time:201189ms step_avg:149.81ms
step:1354/1390 train_time:201347ms step_avg:149.81ms
step:1355/1390 train_time:201507ms step_avg:149.82ms
step:1356/1390 train_time:201667ms step_avg:149.83ms
step:1357/1390 train_time:201827ms step_avg:149.83ms
step:1358/1390 train_time:201988ms step_avg:149.84ms
step:1359/1390 train_time:202147ms step_avg:149.85ms
step:1360/1390 train_time:202307ms step_avg:149.86ms
step:1361/1390 train_time:202466ms step_avg:149.86ms
step:1362/1390 train_time:202625ms step_avg:149.87ms
step:1363/1390 train_time:202789ms step_avg:149.88ms
step:1364/1390 train_time:202944ms step_avg:149.88ms
step:1365/1390 train_time:203100ms step_avg:149.89ms
step:1366/1390 train_time:203257ms step_avg:149.89ms
step:1367/1390 train_time:203416ms step_avg:149.90ms
step:1368/1390 train_time:203574ms step_avg:149.91ms
step:1369/1390 train_time:203741ms step_avg:149.92ms
step:1370/1390 train_time:203902ms step_avg:149.93ms
step:1371/1390 train_time:204058ms step_avg:149.93ms
step:1372/1390 train_time:204221ms step_avg:149.94ms
step:1373/1390 train_time:204378ms step_avg:149.95ms
step:1374/1390 train_time:204538ms step_avg:149.95ms
step:1375/1390 train_time:204693ms step_avg:149.96ms
step:1375/1390 val_loss:3.5072 train_time:204764ms step_avg:150.01ms
step:1376/1390 train_time:204848ms step_avg:149.96ms
step:1377/1390 train_time:205005ms step_avg:149.97ms
step:1378/1390 train_time:205161ms step_avg:149.97ms
step:1379/1390 train_time:205320ms step_avg:149.98ms
step:1380/1390 train_time:205476ms step_avg:149.98ms
step:1381/1390 train_time:205637ms step_avg:149.99ms
step:1382/1390 train_time:205797ms step_avg:150.00ms
step:1383/1390 train_time:205955ms step_avg:150.00ms
step:1384/1390 train_time:206118ms step_avg:150.01ms
step:1385/1390 train_time:206273ms step_avg:150.02ms
step:1386/1390 train_time:206433ms step_avg:150.02ms
step:1387/1390 train_time:206596ms step_avg:150.03ms
step:1388/1390 train_time:206751ms step_avg:150.04ms
step:1389/1390 train_time:206914ms step_avg:150.05ms
step:1390/1390 train_time:207074ms step_avg:150.05ms
step:1390/1390 val_loss:3.5065 train_time:207146ms step_avg:150.11ms
peak memory consumption: 31565 MiB
