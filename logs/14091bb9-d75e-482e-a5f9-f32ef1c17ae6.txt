====================================================================================================
import os
import sys
with open(sys.argv[0]) as f:
    code = f.read() # read the code of this file ASAP, for logging
import uuid
import glob
import time
from dataclasses import dataclass

import numpy as np
import torch
from torch import nn
import torch.nn.functional as F
import torch.distributed as dist
import torch._inductor.config as config
from torch.nn.parallel import DistributedDataParallel as DDP
# Use of FlexAttention contributed by @KoszarskyB
from torch.nn.attention.flex_attention import flex_attention, create_block_mask, BlockMask, _score_mod_signature
from torch._inductor.lowering import make_pointwise, register_lowering
# Some internal torch.compile details
from torch._inductor.virtualized import ops
from functools import partial
flex_attention = torch.compile(flex_attention, dynamic=False)
create_block_mask = torch.compile(create_block_mask, dynamic=False)

# -----------------------------------------------------------------------------
# Muon optimizer

def zeropower_via_svd(G, steps=None):
    U, S, V = G.svd()
    return U @ V.T

@torch.compile
def zeropower_via_newtonschulz5(G, steps=10, eps=1e-7):
    """
    Newton-Schulz iteration to compute the zeroth power / orthogonalization of G. We opt to use a
    quintic iteration whose coefficients are selected to maximize the slope at zero. For the purpose
    of minimizing steps, it turns out to be empirically effective to keep increasing the slope at
    zero even beyond the point where the iteration no longer converges all the way to one everywhere
    on the interval. This iteration therefore does not produce UV^T but rather something like US'V^T
    where S' is diagonal with S_{ii}' ~ Uniform(0.5, 1.5), which turns out not to hurt model
    performance at all relative to UV^T, where USV^T = G is the SVD.
    """
    assert len(G.shape) == 2
    a, b, c = (3.4445, -4.7750,  2.0315)
    X = G.bfloat16()
    X /= (X.norm() + eps) # ensure top singular value <= 1
    if G.size(0) > G.size(1):
        X = X.T
    for _ in range(steps):
        A = X @ X.T
        B = b * A + c * A @ A # adapted from suggestion by @jxbz, @leloykun, and @YouJiacheng
        X = a * X + B @ X
    if G.size(0) > G.size(1):
        X = X.T
    return X

zeropower_backends = dict(svd=zeropower_via_svd, newtonschulz5=zeropower_via_newtonschulz5)

class Muon(torch.optim.Optimizer):
    """
    Muon - MomentUm Orthogonalized by Newton-schulz

    Muon internally runs standard SGD-momentum, and then performs an orthogonalization post-
    processing step, in which each 2D parameter's update is replaced with the nearest orthogonal
    matrix. To efficiently orthogonalize each update, we use a Newton-Schulz iteration, which has
    the advantage that it can be stably run in bfloat16 on the GPU.

    Some warnings:
    - This optimizer assumes that all parameters passed in are 2D.
    - It should not be used for the embedding layer, the final fully connected layer, or any {0,1}-D
    parameters; those should all be optimized by a standard method (e.g., AdamW).
    - To use it with 4D convolutional filters, it works well to just flatten their last 3 dimensions.
    - We believe it is unlikely to work well for training with small batch size.
    - We believe it may not work well for finetuning pretrained models, but we haven't tested this.
    - We have not yet tried this optimizer for training scenarios larger than NanoGPT (124M).

    Arguments:
        lr: The learning rate used by the internal SGD.
        momentum: The momentum used by the internal SGD.
        nesterov: Whether to use Nesterov-style momentum in the internal SGD. (recommended)
        backend: The chosen backend for the orthogonalization step. (recommended: 'newtonschulz5')
        backend_steps: The number of iteration steps to use in the backend, if it is iterative.
    """
    def __init__(self, params, lr=0.02, momentum=0.95, nesterov=True,
                 backend='newtonschulz5', backend_steps=5):
        defaults = dict(lr=lr, momentum=momentum, nesterov=nesterov, backend=backend, backend_steps=backend_steps)
        super().__init__(params, defaults)

    def step(self):

        for group in self.param_groups:

            lr = group['lr']
            momentum = group['momentum']
            zeropower_backend = zeropower_backends[group['backend']]

            # generate weight updates in distributed fashion
            total_params = sum(p.numel() for p in group['params'])
            updates_flat = torch.zeros(total_params, device='cuda', dtype=torch.bfloat16)
            curr_idx = 0
            for i, p in enumerate(group['params']):
                # luckily this will perfectly distribute a transformer with multiple of 4 layers to 8 GPUs
                if i % int(os.environ['WORLD_SIZE']) == int(os.environ['RANK']):
                    g = p.grad
                    assert g is not None
                    state = self.state[p]
                    if 'momentum_buffer' not in state:
                        state['momentum_buffer'] = torch.zeros_like(g)
                    buf = state['momentum_buffer']
                    buf.mul_(momentum).add_(g)
                    if group['nesterov']:
                        g = g.add(buf, alpha=momentum)
                    g = zeropower_backend(g, steps=group['backend_steps'])
                    g *= max(1, g.size(0)/g.size(1))**0.5
                    updates_flat[curr_idx:curr_idx+p.numel()] = g.flatten()
                curr_idx += p.numel()

            # sync updates across devices. we are not memory-constrained so can do this simple deserialization
            dist.all_reduce(updates_flat, op=dist.ReduceOp.SUM)

            # deserialize and apply updates
            curr_idx = 0
            for p in group['params']:
                g = updates_flat[curr_idx:curr_idx+p.numel()].view_as(p.data).type_as(p.data)
                p.data.add_(g, alpha=-lr)
                curr_idx += p.numel()

# -----------------------------------------------------------------------------
# Attention Tanh softcapping

@torch.library.custom_op("approx::tanh", mutates_args=())
def _tanh_approx(inp: torch.Tensor) -> torch.Tensor:
    return torch.tanh(inp)

@_tanh_approx.register_fake
def _(inp: torch.Tensor) -> torch.Tensor:
    return torch.tanh(inp)

def _tanh_approx_lowering(inp):
    fn = partial(ops.inline_asm_elementwise, asm="tanh.approx.f32 $0, $1;")
    return make_pointwise(fn)(inp)

register_lowering(torch.ops.approx.tanh)(_tanh_approx_lowering)

class _TanhApprox(torch.autograd.Function):
    @staticmethod
    def forward(x):
        return torch.ops.approx.tanh(x)

    @staticmethod
    def setup_context(ctx, inputs, output):
        (x,) = inputs
        result = output
        ctx.save_for_backward(result)

    @staticmethod
    def backward(ctx, grad_output):
        (result,) = ctx.saved_tensors
        return grad_output * (1 - result * result)

    @staticmethod
    def vmap(info, in_dims, x):
        return torch.tanh(x), 0

_tanh_approx = _TanhApprox.apply

def generate_tanh_softcap(soft_cap: int, approx: bool=True) -> _score_mod_signature:
    tanh = _tanh_approx if approx else torch.tanh

    def tanh_softcap(score, b, h, q_idx, kv_idx):
        return soft_cap * tanh(score / soft_cap)

    prefix = "tanh_softcap_approx" if approx else "tanh_softcap"
    tanh_softcap.__name__ = f"{prefix}_{soft_cap}"

    return tanh_softcap

# -----------------------------------------------------------------------------
# PyTorch nn.Module definitions for the GPT-2 model

class Rotary(torch.nn.Module):

    def __init__(self, dim, base=10000):
        super().__init__()
        self.dim = dim
        self.base = base
        self.inv_freq = None
        self.seq_len_cached = None
        self.cos_cached = None
        self.sin_cached = None

    def forward(self, x):
        seq_len = x.shape[1]
        if seq_len != self.seq_len_cached:
            self.inv_freq = 1.0 / (self.base ** (torch.arange(0, self.dim, 2, device=x.device).float() / self.dim))
            self.seq_len_cached = seq_len
            t = torch.arange(seq_len, device=x.device).type_as(self.inv_freq)
            freqs = torch.outer(t, self.inv_freq)
            self.cos_cached = freqs.cos().bfloat16()
            self.sin_cached = freqs.sin().bfloat16()
        return self.cos_cached[None, :, None, :], self.sin_cached[None, :, None, :]

def apply_rotary_emb(x, cos, sin):
    assert x.ndim == 4 # multihead attention
    d = x.shape[3]//2
    x1 = x[..., :d]
    x2 = x[..., d:]
    y1 = x1 * cos + x2 * sin
    y2 = x1 * (-sin) + x2 * cos
    return torch.cat([y1, y2], 3).type_as(x)

class CastedLinear(nn.Linear):
    def forward(self, x):
        return F.linear(x, self.weight.to(x.dtype))

class CausalSelfAttention(nn.Module):

    def __init__(self, config):
        super().__init__()
        self.n_head = config.n_head
        self.n_embd = config.n_embd
        self.head_dim = self.n_embd // self.n_head
        assert self.n_embd % self.n_head == 0
        self.c_q = CastedLinear(self.n_embd, self.n_embd, bias=False)
        self.c_k = CastedLinear(self.n_embd, self.n_embd, bias=False)
        self.c_v = CastedLinear(self.n_embd, self.n_embd, bias=False)
        # output projection
        self.c_proj = CastedLinear(self.n_embd, self.n_embd, bias=False)
        self.c_proj.weight.data.zero_() # zero init suggested by @Grad62304977
        self.rotary = Rotary(self.head_dim)
        self.lamb = nn.Parameter(torch.tensor(0.5)) # @Grad62304977

    def forward(self, x, v1, block_mask: BlockMask, score_mod: _score_mod_signature):
        B, T, C = x.size() # batch size, sequence length, embedding dimensionality (n_embd)
        q = self.c_q(x).view(B, T, self.n_head, self.head_dim)
        k = self.c_k(x).view(B, T, self.n_head, self.head_dim)
        v = self.c_v(x).view(B, T, self.n_head, self.head_dim)
        if v1 is None:
            v1 = v # This happens if we are in the first block. v needs to be accessed by subsequent blocks
        v = (1 - self.lamb) * v + self.lamb * v1.view_as(v) # @Grad62304977
        cos, sin = self.rotary(q)
        q, k = F.rms_norm(q, (q.size(-1),)), F.rms_norm(k, (k.size(-1),)) # QK norm suggested by @Grad62304977
        q, k = apply_rotary_emb(q, cos, sin), apply_rotary_emb(k, cos, sin)
        y = flex_attention(q.transpose(1, 2), k.transpose(1, 2), v.transpose(1, 2), score_mod=score_mod, block_mask=block_mask)
        y = y.transpose(1, 2).contiguous().view_as(x) # re-assemble all head outputs side by side
        y = self.c_proj(y)
        return y, v1

class MLP(nn.Module):

    def __init__(self, config):
        super().__init__()
        self.c_fc    = CastedLinear(config.n_embd, 4 * config.n_embd, bias=False)
        self.c_proj  = CastedLinear(4 * config.n_embd, config.n_embd, bias=False)
        self.c_proj.weight.data.zero_() # zero init suggested by @Grad62304977

    def forward(self, x):
        x = self.c_fc(x)
        x = F.relu(x).square() # https://arxiv.org/abs/2109.08668v2; ~1-2% better than GELU; suggested by @SKYLINEZ007 and @Grad62304977
        x = self.c_proj(x)
        return x

class Block(nn.Module):

    def __init__(self, config):
        super().__init__()
        self.attn = CausalSelfAttention(config)
        self.mlp = MLP(config)
        self.lambdas = nn.Parameter(torch.tensor([1., 0.]))

    def forward(self, x, v1, x0, block_mask: BlockMask, score_mod: _score_mod_signature):
        x = self.lambdas[0] * x + self.lambdas[1] * x0
        x1, v1 = self.attn(F.rms_norm(x, (x.size(-1),)), v1, block_mask, score_mod)
        x = x + x1
        x = x + self.mlp(F.rms_norm(x, (x.size(-1),)))
        return x, v1

# -----------------------------------------------------------------------------
# The main GPT-2 model

@dataclass
class GPTConfig:
    vocab_size : int = 50304
    n_layer : int = 12
    n_head : int = 6 # head dim 128 suggested by @Grad62304977
    n_embd : int = 768
    attention_soft_cap : int = 50
    lm_head_soft_cap : int = 30

class GPT(nn.Module):

    def __init__(self, config: GPTConfig):
        super().__init__()
        self.attention_soft_cap = config.attention_soft_cap
        self.lm_head_soft_cap = config.lm_head_soft_cap

        # U-net design by @brendanh0gan
        self.num_encoder_layers = config.n_layer // 2 # Half of the layers for encoder
        self.num_decoder_layers = config.n_layer - self.num_encoder_layers # Remaining for decoder
        # Add learnable skip connection weights for decoder layers
        self.skip_weights = nn.Parameter(torch.ones(self.num_decoder_layers))

        self.transformer = nn.ModuleDict(dict(
            wte = nn.Embedding(config.vocab_size, config.n_embd),
            h = nn.ModuleList([Block(config) for _ in range(config.n_layer)]),
        ))
        self.lm_head = CastedLinear(config.n_embd, config.vocab_size, bias=False)
        self.lm_head.weight.data.zero_() # @Grad62304977

    def forward(self, idx, target):

        docs = (idx == 50256).cumsum(0)
        def document_causal_mask(b, h, q_idx, kv_idx):
            causal_mask = q_idx >= kv_idx
            document_mask = docs[q_idx] == docs[kv_idx]
            window_mask = q_idx - kv_idx < 1024
            return causal_mask & document_mask & window_mask

        softcap_mod = generate_tanh_softcap(self.attention_soft_cap, approx=True)  # @leloykun

        S = len(idx)
        block_mask = create_block_mask(document_causal_mask, None, None, S, S, device="cuda", _compile=True)

        # forward the GPT model itself
        x = self.transformer.wte(idx[None]) # token embeddings of shape (b, t, n_embd)
        x = F.rms_norm(x, (x.size(-1),)) # @Grad62304977
        x0 = x
        v1 = None

        # Store outputs for U-Net skip connections
        skip_connections = []
        # Encoder pass - process only the first half of the blocks
        for i in range(self.num_encoder_layers):
            x, v1 = self.transformer.h[i](x, v1, x0, block_mask, softcap_mod)
            skip_connections.append(x)
        # Decoder pass - process the remaining blocks with weighted skip connections
        for i in range(self.num_decoder_layers):
            x = x + self.skip_weights[i] * skip_connections.pop()
            x, v1 = self.transformer.h[self.num_encoder_layers + i](x, v1, x0, block_mask, softcap_mod)

        x = F.rms_norm(x, (x.size(-1),))
        logits = self.lm_head(x)
        logits = self.lm_head_soft_cap * torch.tanh(logits / self.lm_head_soft_cap) # @Grad62304977
        logits = logits.float()
        loss = F.cross_entropy(logits.view(-1, logits.size(-1)), target.view(-1))
        return loss

# -----------------------------------------------------------------------------
# Our own simple Distributed Data Loader

def _peek_data_shard(filename):
    # only reads the header, returns header data
    with open(filename, "rb") as f:
        # first read the header, which is 256 int32 integers (4 bytes each)
        header = np.frombuffer(f.read(256*4), dtype=np.int32)
    if header[0] != 20240520:
        print("ERROR: magic number mismatch in the data .bin file!")
        print("---> HINT: Are you passing in a correct file with --input_bin?")
        print("---> HINT: Dataset encoding changed recently, re-run data prepro or refer again to README")
        print("---> HINT: For example re-run: `python dev/data/tinyshakespeare.py`, then re-try")
        exit(1)
    assert header[1] == 1, "unsupported version"
    ntok = header[2] # number of tokens (claimed)
    return ntok # for now just return the number of tokens

def _load_data_shard(filename):
    with open(filename, "rb") as f:
        # first read the header, which is 256 int32 integers (4 bytes each)
        header = np.frombuffer(f.read(256*4), dtype=np.int32)
        assert header[0] == 20240520, "magic number mismatch in the data .bin file"
        assert header[1] == 1, "unsupported version"
        ntok = header[2] # number of tokens (claimed)
        # the rest of it are tokens, stored as uint16
        tokens = np.frombuffer(f.read(), dtype=np.uint16)
    assert len(tokens) == ntok, "number of tokens read does not match header?"
    return tokens

class DistributedDataLoader:
    def __init__(self, filename_pattern, B, T, process_rank, num_processes):
        self.process_rank = process_rank
        self.num_processes = num_processes
        self.B = B
        self.T = T

        # glob files that match the pattern
        self.files = sorted(glob.glob(filename_pattern))
        assert len(self.files) > 0, f"did not find any files that match the pattern {filename_pattern}"

        # load and validate all data shards, count number of tokens in total
        ntok_total = 0
        for fname in self.files:
            shard_ntok = _peek_data_shard(fname)
            assert shard_ntok >= num_processes * B * T + 1
            ntok_total += int(shard_ntok)
        self.ntok_total = ntok_total

        self.reset()

    def reset(self):
        self.current_shard = -1
        self.advance()

    def advance(self): # advance to next data shard
        self.current_shard = (self.current_shard + 1) % len(self.files)
        self.current_position = self.process_rank * self.B * self.T
        self.tokens = _load_data_shard(self.files[self.current_shard])

    def next_batch(self):
        batch_size = self.B * self.T * self.num_processes
        buf = self.tokens[self.current_position:self.current_position+self.B*self.T+1]
        buf = torch.tensor(buf.astype(np.int32), dtype=torch.long)
        x = buf[:-1] # inputs
        y = buf[1:] # targets
        # advance current position and load next shard if necessary
        self.current_position += batch_size
        if self.current_position + batch_size >= len(self.tokens):
            self.advance()
        return x.cuda(), y.cuda()

# -----------------------------------------------------------------------------
# int main

@dataclass
class Hyperparameters:
    # data hyperparams
    input_bin : str = 'data/fineweb10B/fineweb_train_*.bin' # input .bin to train on
    input_val_bin : str = 'data/fineweb10B/fineweb_val_*.bin' # input .bin to eval validation loss on
    # optimization hyperparams
    batch_size : int = 8 # batch size, in sequences, across all devices
    device_batch_size : int = 1 # batch size, in sequences, per device
    sequence_length : int = 64*1024 # sequence length, in tokens
    num_iterations : int = 1875 # number of iterations to run
    warmup_iters : int = 0
    warmdown_iters : int = 562 # number of iterations of linear warmup/warmdown for triangular or trapezoidal schedule
    weight_decay : float = 0
    # evaluation and logging hyperparams
    val_loss_every : int = 125 # every how many steps to evaluate val loss? 0 for only at the end
    val_tokens : int = 10485760 # how many tokens of validation data? it's important to keep this fixed for consistent comparisons
    save_every : int = 0 # every how many steps to save the checkpoint? 0 for only at the end
args = Hyperparameters()

# set up DDP (distributed data parallel). torchrun sets this env variable
assert torch.cuda.is_available()
dist.init_process_group(backend='nccl')
ddp_rank = int(os.environ['RANK'])
ddp_local_rank = int(os.environ['LOCAL_RANK'])
ddp_world_size = int(os.environ['WORLD_SIZE'])
device = f'cuda:{ddp_local_rank}'
torch.cuda.set_device(device)
print(f"using device: {device}")
master_process = (ddp_rank == 0) # this process will do logging, checkpointing etc.

# begin logging
logfile = None
if master_process:
    run_id = str(uuid.uuid4())
    logdir = 'logs/%s/' % run_id
    os.makedirs(logdir, exist_ok=True)
    logfile = 'logs/%s.txt' % run_id
    # create the log file
    with open(logfile, "w") as f:
        # begin the log by printing this file (the Python code)
        f.write('='*100 + '\n')
        f.write(code)
        f.write('='*100 + '\n')
def print0(s, logonly=False):
    if master_process:
        with open(logfile, "a") as f:
            if not logonly:
                print(s)
            f.write(s+'\n')
# log information about the hardware/software environment this is running on
# and print the full `nvidia-smi` to file
print0(f"Running pytorch {torch.version.__version__} compiled for CUDA {torch.version.cuda}\nnvidia-smi:")
import subprocess
result = subprocess.run(['nvidia-smi'], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
print0(f'{result.stdout}', logonly=True)
print0('='*100, logonly=True)

# convenience variables
B, T = args.device_batch_size, args.sequence_length
# calculate the number of steps to take in the val loop.
assert args.val_tokens % (B * T * ddp_world_size) == 0
val_steps = args.val_tokens // (B * T * ddp_world_size)
# calculate the steps of gradient accumulation required to attain the desired global batch size.
assert args.batch_size % (B * ddp_world_size) == 0
train_accumulation_steps = args.batch_size // (B * ddp_world_size)

# load tokens
train_loader = DistributedDataLoader(args.input_bin, B, T, ddp_rank, ddp_world_size)
val_loader = DistributedDataLoader(args.input_val_bin, B, T, ddp_rank, ddp_world_size)
print0(f"Training DataLoader: total number of tokens: {train_loader.ntok_total} across {len(train_loader.files)} files")
print0(f"Validation DataLoader: total number of tokens: {val_loader.ntok_total} across {len(val_loader.files)} files")
print0('='*100, logonly=True)
x, y = train_loader.next_batch()

# there are only 50257 unique GPT-2 tokens; we extend to nearest multiple of 128 for efficiency. suggested to me by @Grad62304977.
# this originates from Karpathy's experiments.
num_vocab = 50304
model = GPT(GPTConfig(vocab_size=num_vocab, n_layer=12, n_head=6, n_embd=768))
model = model.cuda().bfloat16()
for m in model.modules():
    if isinstance(m, CastedLinear):
        m.float()
if hasattr(config, "coordinate_descent_tuning"):
    config.coordinate_descent_tuning = True # suggested by @Chillee
model = torch.compile(model)
# here we wrap model into DDP container
model = DDP(model, device_ids=[ddp_local_rank])
raw_model = model.module # always contains the "raw" unwrapped model

# CUDNN attention is ~4ms faster than Flash, but doesn't get selected by default in PyTorch 2.5.1
from torch.backends.cuda import enable_cudnn_sdp, enable_flash_sdp, enable_math_sdp, enable_mem_efficient_sdp
enable_cudnn_sdp(True)
enable_flash_sdp(False)
enable_mem_efficient_sdp(False)
enable_math_sdp(False)

# init the optimizer(s)
optimizer1 = torch.optim.Adam([raw_model.transformer.wte.weight], lr=0.6,   betas=(0.9, 0.95), fused=True)
optimizer2 = torch.optim.Adam([raw_model.lm_head.weight],         lr=0.008, betas=(0.9, 0.95), fused=True)
params = list(raw_model.transformer.h.parameters())
matrix_params = [p for p in params if p.ndim == 2]
scalar_params = [p for p in params if p.ndim < 2] + [raw_model.skip_weights]
optimizer3 = Muon(matrix_params, lr=0.04, momentum=0.95)
optimizer4 = torch.optim.Adam(scalar_params, lr=0.04, betas=(0.9, 0.95), fused=True) # note that this learning rate is neither sensitive nor tuned
optimizers = [optimizer1, optimizer2, optimizer3, optimizer4]
# learning rate decay scheduler (linear warmup and warmdown)
def get_lr(it):
    assert it <= args.num_iterations
    # 1) linear warmup for warmup_iters steps
    if it < args.warmup_iters:
        return (it+1) / args.warmup_iters
    # 2) constant lr for a while
    elif it < args.num_iterations - args.warmdown_iters:
        return 1.0
    # 3) linear warmdown
    else:
        decay_ratio = (args.num_iterations - it) / args.warmdown_iters
        return decay_ratio
schedulers = [torch.optim.lr_scheduler.LambdaLR(opt, get_lr) for opt in optimizers]

# Start training loop
training_time_ms = 0
# start the clock
torch.cuda.synchronize()
t0 = time.time()
# begin training
for step in range(args.num_iterations + 1):
    last_step = (step == args.num_iterations)
    # This effectively ignores timing first 10 steps, which are slower for weird reasons.
    # Alternately, and slightly more correctly in terms of benchmarking, we could do 10
    # steps with dummy data first, and then re-initialize the model and reset the loader.
    if step == 10:
        training_time_ms = 0
        t0 = time.time()
    timed_steps = float('nan') if step <= 11 else (step - 10) + 1 # <= 11 to avoid bug in val

    # once in a while evaluate the validation dataset
    if (last_step or (args.val_loss_every > 0 and step % args.val_loss_every == 0)):
        # stop the clock
        torch.cuda.synchronize()
        training_time_ms += 1000 * (time.time() - t0)
        # run validation batches
        model.eval()
        val_loader.reset()
        val_loss = 0.0
        for _ in range(val_steps):
            with torch.no_grad():
                x_val, y_val = val_loader.next_batch()
                val_loss += model(x_val, y_val)
        dist.all_reduce(val_loss, op=dist.ReduceOp.AVG)
        val_loss /= val_steps
        # log val loss to console and to logfile
        print0(f'step:{step}/{args.num_iterations} val_loss:{val_loss:.4f} train_time:{training_time_ms:.0f}ms step_avg:{training_time_ms/(timed_steps-1):.2f}ms')
        if master_process:
            with open(logfile, "a") as f:
                print("============== Weight norms: ==============")
                f.write("============== Weight norms: ==============\n")
                for name, p in model.named_parameters():
                    if p.ndim != 2:
                        continue
                    if "c_q" not in name and "c_k" not in name:
                        continue
                    fro_norm = torch.linalg.norm(p.data.float(), ord="fro").item()
                    spectral_norm = torch.linalg.matrix_norm(p.data.float(), ord=2).item()
                    nuclear_norm = torch.linalg.matrix_norm(p.data.float(), ord="nuc").item()
                    print(f"{name = } | {fro_norm = :.5f} | {spectral_norm = :.5f} | {nuclear_norm = :.5f}")
                    f.write(f"{name = } | {fro_norm = :.5f} | {spectral_norm = :.5f} | {nuclear_norm = :.5f}\n")
                f.write("===========================================\n")
                print("===========================================")
        # start the clock again
        torch.cuda.synchronize()
        t0 = time.time()

    if master_process and (last_step or (args.save_every > 0 and step % args.save_every == 0)):
        # stop the clock
        torch.cuda.synchronize()
        training_time_ms += 1000 * (time.time() - t0)
        # save the state of the training process
        log = dict(step=step, code=code, model=raw_model.state_dict(), optimizers=[opt.state_dict() for opt in optimizers])
        torch.save(log, 'logs/%s/state_step%06d.pt' % (run_id, step))
        # start the clock again
        torch.cuda.synchronize()
        t0 = time.time()

    # bit confusing: we want to make sure to eval on 0th iteration
    # but also after the very last iteration. so we loop for step <= num_iterations
    # instead of just < num_iterations (one extra due to <=), only to do
    # the validation/sampling one last time, and then we break right here as we're done.
    if last_step:
        break

    # --------------- TRAINING SECTION BEGIN -----------------
    model.train()
    for i in range(1, train_accumulation_steps+1):
        # forward pass
        loss = model(x, y)
        train_loss = loss.detach()
        # advance the dataset for the next batch
        x, y = train_loader.next_batch()
        # backward pass
        if i < train_accumulation_steps:
            with model.no_sync(): # there's no need to sync gradients every accumulation step
                loss.backward()
        else:
            loss.backward() # just sync on the last step
    for p in model.parameters():
        p.grad /= train_accumulation_steps
    # momentum warmup for Muon
    frac = min(step/500, 1)
    optimizer3.param_groups[0]['momentum'] = (1 - frac) * 0.85 + frac * 0.95
    # step the optimizers and schedulers
    for opt, sched in zip(optimizers, schedulers):
        opt.step()
        sched.step()
    # null the gradients
    model.zero_grad(set_to_none=True)
    # --------------- TRAINING SECTION END -------------------
    # everything that follows now is just diagnostics, prints, logging, etc.

    #dist.all_reduce(train_loss, op=dist.ReduceOp.AVG) # all-reducing the training loss would be more correct in terms of logging, but slower
    approx_time = training_time_ms + 1000 * (time.time() - t0)
    print0(f"step:{step+1}/{args.num_iterations} train_loss:{train_loss.item():.4f} train_time:{approx_time:.0f}ms step_avg:{approx_time/timed_steps:.2f}ms")

if master_process:
    print(f"peak memory consumption: {torch.cuda.max_memory_allocated() // 1024 // 1024} MiB")

# -------------------------------------------------------------------------
# clean up nice
dist.destroy_process_group()
====================================================================================================
Running pytorch 2.6.0.dev20241122+cu124 compiled for CUDA 12.4
nvidia-smi:
Fri Nov 22 13:34:39 2024       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A100-SXM4-80GB          On  |   00000000:48:00.0 Off |                    0 |
| N/A   36C    P0             66W /  400W |       3MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA A100-SXM4-80GB          On  |   00000000:4E:00.0 Off |                    0 |
| N/A   33C    P0             68W /  400W |      20MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA A100-SXM4-80GB          On  |   00000000:9B:00.0 Off |                    0 |
| N/A   33C    P0             70W /  400W |      20MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA A100-SXM4-80GB          On  |   00000000:A1:00.0 Off |                    0 |
| N/A   38C    P0             72W /  400W |      20MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
+-----------------------------------------------------------------------------------------+

====================================================================================================
Training DataLoader: total number of tokens: 1100000000 across 11 files
Validation DataLoader: total number of tokens: 100000000 across 1 files
====================================================================================================
step:0/1875 val_loss:10.8258 train_time:0ms step_avg:nanms
============== Weight norms: ==============
name = 'module._orig_mod.transformer.h.0.attn.c_q.weight' | fro_norm = 15.99643 | spectral_norm = 1.15958 | nuclear_norm = 376.35370
name = 'module._orig_mod.transformer.h.0.attn.c_k.weight' | fro_norm = 15.97878 | spectral_norm = 1.14000 | nuclear_norm = 375.90851
name = 'module._orig_mod.transformer.h.1.attn.c_q.weight' | fro_norm = 16.01406 | spectral_norm = 1.15635 | nuclear_norm = 376.78134
name = 'module._orig_mod.transformer.h.1.attn.c_k.weight' | fro_norm = 16.00851 | spectral_norm = 1.14089 | nuclear_norm = 376.63831
name = 'module._orig_mod.transformer.h.2.attn.c_q.weight' | fro_norm = 15.98544 | spectral_norm = 1.15277 | nuclear_norm = 376.08023
name = 'module._orig_mod.transformer.h.2.attn.c_k.weight' | fro_norm = 15.98659 | spectral_norm = 1.15070 | nuclear_norm = 375.97876
name = 'module._orig_mod.transformer.h.3.attn.c_q.weight' | fro_norm = 15.99817 | spectral_norm = 1.15798 | nuclear_norm = 376.42072
name = 'module._orig_mod.transformer.h.3.attn.c_k.weight' | fro_norm = 16.00122 | spectral_norm = 1.13594 | nuclear_norm = 376.54800
name = 'module._orig_mod.transformer.h.4.attn.c_q.weight' | fro_norm = 16.00977 | spectral_norm = 1.14558 | nuclear_norm = 376.63916
name = 'module._orig_mod.transformer.h.4.attn.c_k.weight' | fro_norm = 15.99860 | spectral_norm = 1.15021 | nuclear_norm = 376.36115
name = 'module._orig_mod.transformer.h.5.attn.c_q.weight' | fro_norm = 15.99845 | spectral_norm = 1.15507 | nuclear_norm = 376.39444
name = 'module._orig_mod.transformer.h.5.attn.c_k.weight' | fro_norm = 16.01130 | spectral_norm = 1.14741 | nuclear_norm = 376.88077
name = 'module._orig_mod.transformer.h.6.attn.c_q.weight' | fro_norm = 16.01600 | spectral_norm = 1.14215 | nuclear_norm = 376.72073
name = 'module._orig_mod.transformer.h.6.attn.c_k.weight' | fro_norm = 15.99523 | spectral_norm = 1.15142 | nuclear_norm = 376.05579
name = 'module._orig_mod.transformer.h.7.attn.c_q.weight' | fro_norm = 15.98434 | spectral_norm = 1.15139 | nuclear_norm = 376.18967
name = 'module._orig_mod.transformer.h.7.attn.c_k.weight' | fro_norm = 15.99546 | spectral_norm = 1.14508 | nuclear_norm = 376.31540
name = 'module._orig_mod.transformer.h.8.attn.c_q.weight' | fro_norm = 16.01124 | spectral_norm = 1.14584 | nuclear_norm = 376.49463
name = 'module._orig_mod.transformer.h.8.attn.c_k.weight' | fro_norm = 15.99873 | spectral_norm = 1.15466 | nuclear_norm = 376.22675
name = 'module._orig_mod.transformer.h.9.attn.c_q.weight' | fro_norm = 16.01651 | spectral_norm = 1.14726 | nuclear_norm = 376.79242
name = 'module._orig_mod.transformer.h.9.attn.c_k.weight' | fro_norm = 15.98819 | spectral_norm = 1.15051 | nuclear_norm = 376.03442
name = 'module._orig_mod.transformer.h.10.attn.c_q.weight' | fro_norm = 16.00163 | spectral_norm = 1.15496 | nuclear_norm = 376.61026
name = 'module._orig_mod.transformer.h.10.attn.c_k.weight' | fro_norm = 16.00033 | spectral_norm = 1.15781 | nuclear_norm = 376.30899
name = 'module._orig_mod.transformer.h.11.attn.c_q.weight' | fro_norm = 16.00681 | spectral_norm = 1.14643 | nuclear_norm = 376.52832
name = 'module._orig_mod.transformer.h.11.attn.c_k.weight' | fro_norm = 16.01167 | spectral_norm = 1.14223 | nuclear_norm = 376.81610
===========================================
step:1/1875 train_loss:10.8258 train_time:23000ms step_avg:nanms
step:2/1875 train_loss:10.1150 train_time:24214ms step_avg:nanms
step:3/1875 train_loss:8.4646 train_time:24940ms step_avg:nanms
step:4/1875 train_loss:7.5280 train_time:25673ms step_avg:nanms
step:5/1875 train_loss:7.4052 train_time:26400ms step_avg:nanms
step:6/1875 train_loss:7.0688 train_time:27126ms step_avg:nanms
step:7/1875 train_loss:7.0562 train_time:27867ms step_avg:nanms
step:8/1875 train_loss:6.5880 train_time:28612ms step_avg:nanms
step:9/1875 train_loss:6.8284 train_time:29351ms step_avg:nanms
step:10/1875 train_loss:6.5924 train_time:30089ms step_avg:nanms
step:11/1875 train_loss:6.5161 train_time:718ms step_avg:nanms
step:12/1875 train_loss:6.3699 train_time:1460ms step_avg:nanms
step:13/1875 train_loss:6.3957 train_time:2197ms step_avg:732.20ms
step:14/1875 train_loss:6.3209 train_time:2936ms step_avg:733.98ms
step:15/1875 train_loss:6.3161 train_time:3667ms step_avg:733.45ms
step:16/1875 train_loss:6.1404 train_time:4406ms step_avg:734.32ms
step:17/1875 train_loss:6.0851 train_time:5146ms step_avg:735.10ms
step:18/1875 train_loss:6.6574 train_time:5904ms step_avg:737.99ms
step:19/1875 train_loss:6.0980 train_time:6644ms step_avg:738.23ms
step:20/1875 train_loss:6.2227 train_time:7377ms step_avg:737.72ms
step:21/1875 train_loss:6.1412 train_time:8107ms step_avg:737.04ms
step:22/1875 train_loss:5.9129 train_time:8853ms step_avg:737.78ms
step:23/1875 train_loss:5.9792 train_time:9599ms step_avg:738.36ms
step:24/1875 train_loss:6.0066 train_time:10331ms step_avg:737.90ms
step:25/1875 train_loss:5.8016 train_time:11067ms step_avg:737.79ms
step:26/1875 train_loss:5.9353 train_time:11813ms step_avg:738.33ms
step:27/1875 train_loss:5.8745 train_time:12547ms step_avg:738.06ms
step:28/1875 train_loss:5.8764 train_time:13286ms step_avg:738.11ms
step:29/1875 train_loss:5.8823 train_time:14021ms step_avg:737.96ms
step:30/1875 train_loss:5.9295 train_time:14762ms step_avg:738.08ms
step:31/1875 train_loss:6.3199 train_time:15505ms step_avg:738.32ms
step:32/1875 train_loss:5.7704 train_time:16235ms step_avg:737.97ms
step:33/1875 train_loss:5.6319 train_time:16979ms step_avg:738.22ms
step:34/1875 train_loss:5.6509 train_time:17717ms step_avg:738.22ms
step:35/1875 train_loss:5.8805 train_time:18462ms step_avg:738.47ms
step:36/1875 train_loss:5.7475 train_time:19203ms step_avg:738.57ms
step:37/1875 train_loss:5.7679 train_time:19943ms step_avg:738.63ms
step:38/1875 train_loss:5.5954 train_time:20697ms step_avg:739.16ms
step:39/1875 train_loss:5.6850 train_time:21437ms step_avg:739.20ms
step:40/1875 train_loss:5.4673 train_time:22187ms step_avg:739.58ms
step:41/1875 train_loss:5.6733 train_time:22922ms step_avg:739.41ms
step:42/1875 train_loss:5.5265 train_time:23651ms step_avg:739.09ms
step:43/1875 train_loss:5.5312 train_time:24379ms step_avg:738.76ms
step:44/1875 train_loss:5.4164 train_time:25128ms step_avg:739.07ms
step:45/1875 train_loss:5.3045 train_time:25876ms step_avg:739.32ms
step:46/1875 train_loss:5.4075 train_time:26622ms step_avg:739.49ms
step:47/1875 train_loss:5.3128 train_time:27356ms step_avg:739.35ms
step:48/1875 train_loss:5.4330 train_time:28108ms step_avg:739.69ms
step:49/1875 train_loss:5.2862 train_time:28849ms step_avg:739.73ms
step:50/1875 train_loss:5.3473 train_time:29586ms step_avg:739.64ms
step:51/1875 train_loss:5.3359 train_time:30338ms step_avg:739.95ms
step:52/1875 train_loss:5.4384 train_time:31079ms step_avg:739.98ms
step:53/1875 train_loss:5.2890 train_time:31814ms step_avg:739.86ms
step:54/1875 train_loss:5.3189 train_time:32540ms step_avg:739.56ms
step:55/1875 train_loss:5.2103 train_time:33299ms step_avg:739.97ms
step:56/1875 train_loss:5.2342 train_time:34028ms step_avg:739.74ms
step:57/1875 train_loss:5.2579 train_time:34765ms step_avg:739.68ms
step:58/1875 train_loss:5.2730 train_time:35498ms step_avg:739.53ms
step:59/1875 train_loss:5.2921 train_time:36241ms step_avg:739.62ms
step:60/1875 train_loss:5.1430 train_time:36985ms step_avg:739.70ms
step:61/1875 train_loss:5.2461 train_time:37728ms step_avg:739.76ms
step:62/1875 train_loss:5.2509 train_time:38460ms step_avg:739.62ms
step:63/1875 train_loss:5.1830 train_time:39204ms step_avg:739.70ms
step:64/1875 train_loss:5.1441 train_time:39958ms step_avg:739.96ms
step:65/1875 train_loss:5.0108 train_time:40693ms step_avg:739.86ms
step:66/1875 train_loss:5.0167 train_time:41432ms step_avg:739.86ms
step:67/1875 train_loss:5.1470 train_time:42170ms step_avg:739.82ms
step:68/1875 train_loss:5.1355 train_time:42920ms step_avg:740.01ms
step:69/1875 train_loss:5.1549 train_time:43659ms step_avg:739.99ms
step:70/1875 train_loss:5.0267 train_time:44401ms step_avg:740.01ms
step:71/1875 train_loss:5.0969 train_time:45146ms step_avg:740.10ms
step:72/1875 train_loss:5.0844 train_time:45907ms step_avg:740.44ms
step:73/1875 train_loss:5.0747 train_time:46643ms step_avg:740.37ms
step:74/1875 train_loss:4.9020 train_time:47383ms step_avg:740.36ms
step:75/1875 train_loss:4.9567 train_time:48120ms step_avg:740.31ms
step:76/1875 train_loss:4.8591 train_time:48871ms step_avg:740.48ms
step:77/1875 train_loss:5.0624 train_time:49612ms step_avg:740.47ms
step:78/1875 train_loss:4.9871 train_time:50347ms step_avg:740.39ms
step:79/1875 train_loss:4.6955 train_time:51112ms step_avg:740.76ms
step:80/1875 train_loss:4.9845 train_time:51842ms step_avg:740.59ms
step:81/1875 train_loss:4.9355 train_time:52577ms step_avg:740.52ms
step:82/1875 train_loss:4.9717 train_time:53322ms step_avg:740.59ms
step:83/1875 train_loss:4.9889 train_time:54059ms step_avg:740.54ms
step:84/1875 train_loss:4.8438 train_time:54792ms step_avg:740.44ms
step:85/1875 train_loss:4.8843 train_time:55532ms step_avg:740.43ms
step:86/1875 train_loss:4.9540 train_time:56273ms step_avg:740.44ms
step:87/1875 train_loss:4.9656 train_time:57008ms step_avg:740.36ms
step:88/1875 train_loss:4.8002 train_time:57750ms step_avg:740.38ms
step:89/1875 train_loss:4.7957 train_time:58491ms step_avg:740.39ms
step:90/1875 train_loss:4.7524 train_time:59239ms step_avg:740.49ms
step:91/1875 train_loss:4.8847 train_time:59972ms step_avg:740.40ms
step:92/1875 train_loss:4.8381 train_time:60709ms step_avg:740.35ms
step:93/1875 train_loss:4.9802 train_time:61445ms step_avg:740.30ms
step:94/1875 train_loss:5.0583 train_time:62186ms step_avg:740.31ms
step:95/1875 train_loss:4.7723 train_time:62920ms step_avg:740.23ms
step:96/1875 train_loss:4.6902 train_time:63656ms step_avg:740.19ms
step:97/1875 train_loss:4.8526 train_time:64395ms step_avg:740.17ms
step:98/1875 train_loss:4.6946 train_time:65127ms step_avg:740.09ms
step:99/1875 train_loss:4.6688 train_time:65866ms step_avg:740.07ms
step:100/1875 train_loss:4.6973 train_time:66625ms step_avg:740.28ms
step:101/1875 train_loss:4.5636 train_time:67380ms step_avg:740.44ms
step:102/1875 train_loss:4.7319 train_time:68109ms step_avg:740.31ms
step:103/1875 train_loss:4.6278 train_time:68859ms step_avg:740.42ms
step:104/1875 train_loss:4.7266 train_time:69603ms step_avg:740.45ms
step:105/1875 train_loss:4.7108 train_time:70332ms step_avg:740.34ms
step:106/1875 train_loss:4.8711 train_time:71078ms step_avg:740.39ms
step:107/1875 train_loss:4.6513 train_time:71820ms step_avg:740.41ms
step:108/1875 train_loss:4.5068 train_time:72551ms step_avg:740.31ms
step:109/1875 train_loss:4.8872 train_time:73281ms step_avg:740.21ms
step:110/1875 train_loss:4.6689 train_time:74025ms step_avg:740.25ms
step:111/1875 train_loss:4.5759 train_time:74759ms step_avg:740.19ms
step:112/1875 train_loss:4.7799 train_time:75505ms step_avg:740.24ms
step:113/1875 train_loss:4.4462 train_time:76239ms step_avg:740.19ms
step:114/1875 train_loss:4.6512 train_time:76971ms step_avg:740.10ms
step:115/1875 train_loss:4.5614 train_time:77711ms step_avg:740.10ms
step:116/1875 train_loss:4.6194 train_time:78446ms step_avg:740.06ms
step:117/1875 train_loss:4.4056 train_time:79177ms step_avg:739.97ms
step:118/1875 train_loss:4.6207 train_time:79913ms step_avg:739.93ms
step:119/1875 train_loss:4.4424 train_time:80641ms step_avg:739.83ms
step:120/1875 train_loss:4.5509 train_time:81376ms step_avg:739.78ms
step:121/1875 train_loss:4.5090 train_time:82109ms step_avg:739.72ms
step:122/1875 train_loss:4.3977 train_time:82851ms step_avg:739.74ms
step:123/1875 train_loss:4.4924 train_time:83585ms step_avg:739.69ms
step:124/1875 train_loss:4.3528 train_time:84314ms step_avg:739.60ms
step:125/1875 train_loss:4.3657 train_time:85045ms step_avg:739.52ms
step:125/1875 val_loss:4.4463 train_time:85056ms step_avg:739.62ms
============== Weight norms: ==============
name = 'module._orig_mod.transformer.h.0.attn.c_q.weight' | fro_norm = 25.82758 | spectral_norm = 3.00442 | nuclear_norm = 600.00977
name = 'module._orig_mod.transformer.h.0.attn.c_k.weight' | fro_norm = 25.59469 | spectral_norm = 3.31849 | nuclear_norm = 590.08191
name = 'module._orig_mod.transformer.h.1.attn.c_q.weight' | fro_norm = 24.48591 | spectral_norm = 2.59079 | nuclear_norm = 566.44263
name = 'module._orig_mod.transformer.h.1.attn.c_k.weight' | fro_norm = 24.56660 | spectral_norm = 2.59573 | nuclear_norm = 566.51172
name = 'module._orig_mod.transformer.h.2.attn.c_q.weight' | fro_norm = 23.13718 | spectral_norm = 2.44509 | nuclear_norm = 523.27771
name = 'module._orig_mod.transformer.h.2.attn.c_k.weight' | fro_norm = 24.00407 | spectral_norm = 2.44887 | nuclear_norm = 543.26349
name = 'module._orig_mod.transformer.h.3.attn.c_q.weight' | fro_norm = 23.53870 | spectral_norm = 2.35004 | nuclear_norm = 530.36053
name = 'module._orig_mod.transformer.h.3.attn.c_k.weight' | fro_norm = 24.29379 | spectral_norm = 2.31569 | nuclear_norm = 547.38416
name = 'module._orig_mod.transformer.h.4.attn.c_q.weight' | fro_norm = 23.28555 | spectral_norm = 2.50624 | nuclear_norm = 526.71820
name = 'module._orig_mod.transformer.h.4.attn.c_k.weight' | fro_norm = 24.10600 | spectral_norm = 2.50474 | nuclear_norm = 547.77258
name = 'module._orig_mod.transformer.h.5.attn.c_q.weight' | fro_norm = 23.47664 | spectral_norm = 2.45291 | nuclear_norm = 528.62183
name = 'module._orig_mod.transformer.h.5.attn.c_k.weight' | fro_norm = 24.40919 | spectral_norm = 2.44443 | nuclear_norm = 550.67139
name = 'module._orig_mod.transformer.h.6.attn.c_q.weight' | fro_norm = 23.57937 | spectral_norm = 2.50947 | nuclear_norm = 531.68005
name = 'module._orig_mod.transformer.h.6.attn.c_k.weight' | fro_norm = 24.45374 | spectral_norm = 2.42247 | nuclear_norm = 550.81622
name = 'module._orig_mod.transformer.h.7.attn.c_q.weight' | fro_norm = 23.34725 | spectral_norm = 2.47741 | nuclear_norm = 525.60223
name = 'module._orig_mod.transformer.h.7.attn.c_k.weight' | fro_norm = 24.40515 | spectral_norm = 2.33229 | nuclear_norm = 550.22571
name = 'module._orig_mod.transformer.h.8.attn.c_q.weight' | fro_norm = 23.58324 | spectral_norm = 2.34940 | nuclear_norm = 527.70209
name = 'module._orig_mod.transformer.h.8.attn.c_k.weight' | fro_norm = 24.72444 | spectral_norm = 2.36444 | nuclear_norm = 553.99225
name = 'module._orig_mod.transformer.h.9.attn.c_q.weight' | fro_norm = 23.58512 | spectral_norm = 2.35787 | nuclear_norm = 527.30353
name = 'module._orig_mod.transformer.h.9.attn.c_k.weight' | fro_norm = 24.59541 | spectral_norm = 2.31502 | nuclear_norm = 550.52606
name = 'module._orig_mod.transformer.h.10.attn.c_q.weight' | fro_norm = 23.54766 | spectral_norm = 2.39562 | nuclear_norm = 529.15979
name = 'module._orig_mod.transformer.h.10.attn.c_k.weight' | fro_norm = 24.52193 | spectral_norm = 2.34527 | nuclear_norm = 551.07562
name = 'module._orig_mod.transformer.h.11.attn.c_q.weight' | fro_norm = 23.13320 | spectral_norm = 2.32923 | nuclear_norm = 514.28601
name = 'module._orig_mod.transformer.h.11.attn.c_k.weight' | fro_norm = 24.04764 | spectral_norm = 2.46280 | nuclear_norm = 532.84375
===========================================
step:126/1875 train_loss:4.2797 train_time:85776ms step_avg:739.45ms
step:127/1875 train_loss:4.4999 train_time:86510ms step_avg:739.40ms
step:128/1875 train_loss:4.4902 train_time:87245ms step_avg:739.36ms
step:129/1875 train_loss:4.5091 train_time:87975ms step_avg:739.28ms
step:130/1875 train_loss:4.4425 train_time:88731ms step_avg:739.43ms
step:131/1875 train_loss:4.5703 train_time:89474ms step_avg:739.45ms
step:132/1875 train_loss:4.3365 train_time:90206ms step_avg:739.39ms
step:133/1875 train_loss:4.3107 train_time:90931ms step_avg:739.27ms
step:134/1875 train_loss:4.4774 train_time:91665ms step_avg:739.24ms
step:135/1875 train_loss:4.3147 train_time:92399ms step_avg:739.19ms
step:136/1875 train_loss:4.3282 train_time:93138ms step_avg:739.19ms
step:137/1875 train_loss:4.3463 train_time:93877ms step_avg:739.19ms
step:138/1875 train_loss:4.3915 train_time:94601ms step_avg:739.07ms
step:139/1875 train_loss:4.4816 train_time:95337ms step_avg:739.04ms
step:140/1875 train_loss:4.3851 train_time:96071ms step_avg:739.01ms
step:141/1875 train_loss:4.2544 train_time:96814ms step_avg:739.04ms
step:142/1875 train_loss:4.3883 train_time:97548ms step_avg:739.00ms
step:143/1875 train_loss:4.4167 train_time:98288ms step_avg:739.01ms
step:144/1875 train_loss:4.4848 train_time:99023ms step_avg:738.98ms
step:145/1875 train_loss:4.3112 train_time:99758ms step_avg:738.95ms
step:146/1875 train_loss:4.3438 train_time:100493ms step_avg:738.92ms
step:147/1875 train_loss:4.3568 train_time:101221ms step_avg:738.84ms
step:148/1875 train_loss:4.1643 train_time:101967ms step_avg:738.89ms
step:149/1875 train_loss:4.3054 train_time:102702ms step_avg:738.87ms
step:150/1875 train_loss:4.2645 train_time:103442ms step_avg:738.87ms
step:151/1875 train_loss:4.2697 train_time:104181ms step_avg:738.87ms
step:152/1875 train_loss:4.0891 train_time:104936ms step_avg:738.98ms
step:153/1875 train_loss:4.3662 train_time:105674ms step_avg:738.98ms
step:154/1875 train_loss:4.1414 train_time:106404ms step_avg:738.92ms
step:155/1875 train_loss:4.1449 train_time:107143ms step_avg:738.92ms
step:156/1875 train_loss:4.2753 train_time:107889ms step_avg:738.96ms
step:157/1875 train_loss:4.3713 train_time:108624ms step_avg:738.94ms
step:158/1875 train_loss:4.2549 train_time:109352ms step_avg:738.87ms
step:159/1875 train_loss:4.1963 train_time:110085ms step_avg:738.82ms
step:160/1875 train_loss:4.1119 train_time:110822ms step_avg:738.81ms
step:161/1875 train_loss:4.2164 train_time:111553ms step_avg:738.76ms
step:162/1875 train_loss:4.2237 train_time:112284ms step_avg:738.71ms
step:163/1875 train_loss:4.1838 train_time:113015ms step_avg:738.66ms
step:164/1875 train_loss:4.1299 train_time:113753ms step_avg:738.65ms
step:165/1875 train_loss:4.2182 train_time:114483ms step_avg:738.60ms
step:166/1875 train_loss:4.3516 train_time:115224ms step_avg:738.62ms
step:167/1875 train_loss:4.2302 train_time:115962ms step_avg:738.61ms
step:168/1875 train_loss:4.1929 train_time:116698ms step_avg:738.59ms
step:169/1875 train_loss:4.2441 train_time:117434ms step_avg:738.58ms
step:170/1875 train_loss:4.2775 train_time:118196ms step_avg:738.72ms
step:171/1875 train_loss:3.7652 train_time:118959ms step_avg:738.88ms
step:172/1875 train_loss:4.1270 train_time:119694ms step_avg:738.85ms
step:173/1875 train_loss:4.1104 train_time:120429ms step_avg:738.83ms
step:174/1875 train_loss:4.3161 train_time:121156ms step_avg:738.76ms
step:175/1875 train_loss:4.1206 train_time:121892ms step_avg:738.74ms
step:176/1875 train_loss:4.1969 train_time:122633ms step_avg:738.75ms
step:177/1875 train_loss:4.3241 train_time:123364ms step_avg:738.71ms
step:178/1875 train_loss:4.2067 train_time:124095ms step_avg:738.66ms
step:179/1875 train_loss:4.1376 train_time:124837ms step_avg:738.68ms
step:180/1875 train_loss:4.2115 train_time:125565ms step_avg:738.62ms
step:181/1875 train_loss:4.0980 train_time:126297ms step_avg:738.58ms
step:182/1875 train_loss:4.1619 train_time:127029ms step_avg:738.54ms
step:183/1875 train_loss:4.1139 train_time:127764ms step_avg:738.52ms
step:184/1875 train_loss:4.2703 train_time:128500ms step_avg:738.51ms
step:185/1875 train_loss:4.1884 train_time:129233ms step_avg:738.47ms
step:186/1875 train_loss:4.2475 train_time:129975ms step_avg:738.49ms
step:187/1875 train_loss:4.1751 train_time:130720ms step_avg:738.53ms
step:188/1875 train_loss:4.1492 train_time:131454ms step_avg:738.51ms
step:189/1875 train_loss:3.9691 train_time:132197ms step_avg:738.53ms
step:190/1875 train_loss:4.0963 train_time:133136ms step_avg:739.65ms
step:191/1875 train_loss:4.0732 train_time:133893ms step_avg:739.74ms
step:192/1875 train_loss:4.0244 train_time:134626ms step_avg:739.71ms
step:193/1875 train_loss:4.2230 train_time:135392ms step_avg:739.85ms
step:194/1875 train_loss:4.1605 train_time:136121ms step_avg:739.79ms
step:195/1875 train_loss:4.3487 train_time:136849ms step_avg:739.73ms
step:196/1875 train_loss:4.1654 train_time:137590ms step_avg:739.73ms
step:197/1875 train_loss:4.0091 train_time:138335ms step_avg:739.76ms
step:198/1875 train_loss:4.1832 train_time:139070ms step_avg:739.73ms
step:199/1875 train_loss:4.0389 train_time:139796ms step_avg:739.66ms
step:200/1875 train_loss:4.1186 train_time:140535ms step_avg:739.66ms
step:201/1875 train_loss:3.9705 train_time:141282ms step_avg:739.69ms
step:202/1875 train_loss:4.2184 train_time:142019ms step_avg:739.68ms
step:203/1875 train_loss:4.0426 train_time:142753ms step_avg:739.65ms
step:204/1875 train_loss:4.2009 train_time:143486ms step_avg:739.62ms
step:205/1875 train_loss:4.2330 train_time:144226ms step_avg:739.62ms
step:206/1875 train_loss:3.9495 train_time:144967ms step_avg:739.63ms
step:207/1875 train_loss:4.0873 train_time:145696ms step_avg:739.58ms
step:208/1875 train_loss:4.0783 train_time:146429ms step_avg:739.54ms
step:209/1875 train_loss:4.2469 train_time:147173ms step_avg:739.56ms
step:210/1875 train_loss:4.1662 train_time:147917ms step_avg:739.59ms
step:211/1875 train_loss:4.0448 train_time:148648ms step_avg:739.54ms
step:212/1875 train_loss:3.9869 train_time:149388ms step_avg:739.54ms
step:213/1875 train_loss:4.0418 train_time:150130ms step_avg:739.56ms
step:214/1875 train_loss:4.1110 train_time:150870ms step_avg:739.56ms
step:215/1875 train_loss:3.8853 train_time:151607ms step_avg:739.55ms
step:216/1875 train_loss:3.9688 train_time:152335ms step_avg:739.49ms
step:217/1875 train_loss:3.9825 train_time:153068ms step_avg:739.46ms
step:218/1875 train_loss:4.0751 train_time:153801ms step_avg:739.43ms
step:219/1875 train_loss:4.0653 train_time:154528ms step_avg:739.37ms
step:220/1875 train_loss:4.0654 train_time:155264ms step_avg:739.35ms
step:221/1875 train_loss:4.0890 train_time:156000ms step_avg:739.34ms
step:222/1875 train_loss:3.9814 train_time:156740ms step_avg:739.34ms
step:223/1875 train_loss:3.9189 train_time:157481ms step_avg:739.35ms
step:224/1875 train_loss:4.2782 train_time:158216ms step_avg:739.33ms
step:225/1875 train_loss:3.8874 train_time:158952ms step_avg:739.31ms
step:226/1875 train_loss:3.9818 train_time:159683ms step_avg:739.27ms
step:227/1875 train_loss:3.9662 train_time:160413ms step_avg:739.23ms
step:228/1875 train_loss:4.1315 train_time:161142ms step_avg:739.18ms
step:229/1875 train_loss:3.9125 train_time:161885ms step_avg:739.20ms
step:230/1875 train_loss:4.0393 train_time:162624ms step_avg:739.20ms
step:231/1875 train_loss:3.8729 train_time:163355ms step_avg:739.16ms
step:232/1875 train_loss:3.9621 train_time:164090ms step_avg:739.15ms
step:233/1875 train_loss:4.0657 train_time:164820ms step_avg:739.10ms
step:234/1875 train_loss:4.0202 train_time:165570ms step_avg:739.15ms
step:235/1875 train_loss:3.8429 train_time:166321ms step_avg:739.20ms
step:236/1875 train_loss:4.0346 train_time:167048ms step_avg:739.15ms
step:237/1875 train_loss:4.0690 train_time:167795ms step_avg:739.19ms
step:238/1875 train_loss:3.9176 train_time:168534ms step_avg:739.18ms
step:239/1875 train_loss:4.0355 train_time:169266ms step_avg:739.15ms
step:240/1875 train_loss:4.0933 train_time:170011ms step_avg:739.18ms
step:241/1875 train_loss:3.9428 train_time:170756ms step_avg:739.20ms
step:242/1875 train_loss:4.1157 train_time:171495ms step_avg:739.20ms
step:243/1875 train_loss:4.0020 train_time:172228ms step_avg:739.18ms
step:244/1875 train_loss:4.0643 train_time:172963ms step_avg:739.16ms
step:245/1875 train_loss:4.1395 train_time:173694ms step_avg:739.12ms
step:246/1875 train_loss:4.0503 train_time:174435ms step_avg:739.13ms
step:247/1875 train_loss:3.9969 train_time:175170ms step_avg:739.11ms
step:248/1875 train_loss:4.0769 train_time:175906ms step_avg:739.10ms
step:249/1875 train_loss:3.9104 train_time:176639ms step_avg:739.08ms
step:250/1875 train_loss:3.9667 train_time:177367ms step_avg:739.03ms
step:250/1875 val_loss:3.9868 train_time:177379ms step_avg:739.08ms
============== Weight norms: ==============
name = 'module._orig_mod.transformer.h.0.attn.c_q.weight' | fro_norm = 39.16703 | spectral_norm = 5.10350 | nuclear_norm = 910.57739
name = 'module._orig_mod.transformer.h.0.attn.c_k.weight' | fro_norm = 38.51181 | spectral_norm = 6.18199 | nuclear_norm = 887.86035
name = 'module._orig_mod.transformer.h.1.attn.c_q.weight' | fro_norm = 38.44759 | spectral_norm = 3.85048 | nuclear_norm = 892.35767
name = 'module._orig_mod.transformer.h.1.attn.c_k.weight' | fro_norm = 37.68877 | spectral_norm = 3.92962 | nuclear_norm = 873.14600
name = 'module._orig_mod.transformer.h.2.attn.c_q.weight' | fro_norm = 36.57086 | spectral_norm = 3.53195 | nuclear_norm = 822.88049
name = 'module._orig_mod.transformer.h.2.attn.c_k.weight' | fro_norm = 37.09521 | spectral_norm = 3.49516 | nuclear_norm = 838.28503
name = 'module._orig_mod.transformer.h.3.attn.c_q.weight' | fro_norm = 37.70015 | spectral_norm = 3.68189 | nuclear_norm = 851.77429
name = 'module._orig_mod.transformer.h.3.attn.c_k.weight' | fro_norm = 37.97063 | spectral_norm = 3.41953 | nuclear_norm = 860.18878
name = 'module._orig_mod.transformer.h.4.attn.c_q.weight' | fro_norm = 36.86354 | spectral_norm = 3.80265 | nuclear_norm = 843.16479
name = 'module._orig_mod.transformer.h.4.attn.c_k.weight' | fro_norm = 36.61638 | spectral_norm = 3.84260 | nuclear_norm = 841.65686
name = 'module._orig_mod.transformer.h.5.attn.c_q.weight' | fro_norm = 37.20341 | spectral_norm = 3.77357 | nuclear_norm = 847.39349
name = 'module._orig_mod.transformer.h.5.attn.c_k.weight' | fro_norm = 37.60596 | spectral_norm = 3.68584 | nuclear_norm = 858.89880
name = 'module._orig_mod.transformer.h.6.attn.c_q.weight' | fro_norm = 37.11844 | spectral_norm = 3.81942 | nuclear_norm = 843.83655
name = 'module._orig_mod.transformer.h.6.attn.c_k.weight' | fro_norm = 37.51606 | spectral_norm = 3.59574 | nuclear_norm = 855.30249
name = 'module._orig_mod.transformer.h.7.attn.c_q.weight' | fro_norm = 36.90905 | spectral_norm = 3.81729 | nuclear_norm = 837.61078
name = 'module._orig_mod.transformer.h.7.attn.c_k.weight' | fro_norm = 37.37771 | spectral_norm = 3.74582 | nuclear_norm = 852.31995
name = 'module._orig_mod.transformer.h.8.attn.c_q.weight' | fro_norm = 37.54844 | spectral_norm = 3.69355 | nuclear_norm = 849.00531
name = 'module._orig_mod.transformer.h.8.attn.c_k.weight' | fro_norm = 38.25180 | spectral_norm = 3.57973 | nuclear_norm = 863.37891
name = 'module._orig_mod.transformer.h.9.attn.c_q.weight' | fro_norm = 37.17089 | spectral_norm = 3.68019 | nuclear_norm = 834.03723
name = 'module._orig_mod.transformer.h.9.attn.c_k.weight' | fro_norm = 37.81402 | spectral_norm = 3.44027 | nuclear_norm = 847.09302
name = 'module._orig_mod.transformer.h.10.attn.c_q.weight' | fro_norm = 37.94463 | spectral_norm = 3.63885 | nuclear_norm = 864.61646
name = 'module._orig_mod.transformer.h.10.attn.c_k.weight' | fro_norm = 38.09067 | spectral_norm = 3.46324 | nuclear_norm = 868.04358
name = 'module._orig_mod.transformer.h.11.attn.c_q.weight' | fro_norm = 36.44312 | spectral_norm = 3.80205 | nuclear_norm = 805.33691
name = 'module._orig_mod.transformer.h.11.attn.c_k.weight' | fro_norm = 37.35020 | spectral_norm = 3.67307 | nuclear_norm = 821.40240
===========================================
step:251/1875 train_loss:4.0537 train_time:178088ms step_avg:738.95ms
step:252/1875 train_loss:4.1414 train_time:178823ms step_avg:738.94ms
step:253/1875 train_loss:3.9240 train_time:179561ms step_avg:738.93ms
step:254/1875 train_loss:3.8602 train_time:180291ms step_avg:738.90ms
step:255/1875 train_loss:4.0444 train_time:181019ms step_avg:738.85ms
step:256/1875 train_loss:3.9545 train_time:181756ms step_avg:738.84ms
step:257/1875 train_loss:3.9750 train_time:182488ms step_avg:738.82ms
step:258/1875 train_loss:3.9701 train_time:183227ms step_avg:738.82ms
step:259/1875 train_loss:4.0269 train_time:183963ms step_avg:738.81ms
step:260/1875 train_loss:4.0545 train_time:184702ms step_avg:738.81ms
step:261/1875 train_loss:4.0017 train_time:185456ms step_avg:738.87ms
step:262/1875 train_loss:3.9788 train_time:186186ms step_avg:738.83ms
step:263/1875 train_loss:3.8903 train_time:186931ms step_avg:738.86ms
step:264/1875 train_loss:3.9700 train_time:187665ms step_avg:738.84ms
step:265/1875 train_loss:3.8617 train_time:188401ms step_avg:738.83ms
step:266/1875 train_loss:3.9183 train_time:189136ms step_avg:738.81ms
step:267/1875 train_loss:3.9034 train_time:189893ms step_avg:738.88ms
step:268/1875 train_loss:3.9463 train_time:190624ms step_avg:738.85ms
step:269/1875 train_loss:3.8478 train_time:191358ms step_avg:738.83ms
step:270/1875 train_loss:4.0847 train_time:192084ms step_avg:738.78ms
step:271/1875 train_loss:3.9596 train_time:192821ms step_avg:738.78ms
step:272/1875 train_loss:3.9104 train_time:193556ms step_avg:738.76ms
step:273/1875 train_loss:3.9483 train_time:194285ms step_avg:738.73ms
step:274/1875 train_loss:4.0297 train_time:195019ms step_avg:738.71ms
step:275/1875 train_loss:4.0454 train_time:195760ms step_avg:738.72ms
step:276/1875 train_loss:4.1806 train_time:196503ms step_avg:738.73ms
step:277/1875 train_loss:4.0172 train_time:197229ms step_avg:738.69ms
step:278/1875 train_loss:4.0561 train_time:197963ms step_avg:738.67ms
step:279/1875 train_loss:3.9778 train_time:198696ms step_avg:738.65ms
step:280/1875 train_loss:4.1326 train_time:199452ms step_avg:738.71ms
step:281/1875 train_loss:3.9349 train_time:200211ms step_avg:738.79ms
step:282/1875 train_loss:3.9203 train_time:200953ms step_avg:738.80ms
step:283/1875 train_loss:3.8972 train_time:201686ms step_avg:738.78ms
step:284/1875 train_loss:4.0241 train_time:202423ms step_avg:738.77ms
step:285/1875 train_loss:4.0397 train_time:203163ms step_avg:738.77ms
step:286/1875 train_loss:4.0738 train_time:203904ms step_avg:738.78ms
step:287/1875 train_loss:3.8898 train_time:204638ms step_avg:738.76ms
step:288/1875 train_loss:4.0078 train_time:205380ms step_avg:738.78ms
step:289/1875 train_loss:3.8440 train_time:206123ms step_avg:738.79ms
step:290/1875 train_loss:3.8370 train_time:206857ms step_avg:738.78ms
step:291/1875 train_loss:3.9046 train_time:207595ms step_avg:738.77ms
step:292/1875 train_loss:3.8478 train_time:208323ms step_avg:738.73ms
step:293/1875 train_loss:3.8899 train_time:209051ms step_avg:738.70ms
step:294/1875 train_loss:3.9322 train_time:209784ms step_avg:738.68ms
step:295/1875 train_loss:3.8300 train_time:210530ms step_avg:738.70ms
step:296/1875 train_loss:3.8573 train_time:211271ms step_avg:738.71ms
step:297/1875 train_loss:3.8450 train_time:212009ms step_avg:738.71ms
step:298/1875 train_loss:3.9647 train_time:212747ms step_avg:738.71ms
step:299/1875 train_loss:3.8129 train_time:213488ms step_avg:738.71ms
step:300/1875 train_loss:3.9284 train_time:214230ms step_avg:738.73ms
step:301/1875 train_loss:3.9496 train_time:214964ms step_avg:738.71ms
step:302/1875 train_loss:3.9262 train_time:215693ms step_avg:738.67ms
step:303/1875 train_loss:3.9600 train_time:216420ms step_avg:738.63ms
step:304/1875 train_loss:3.9460 train_time:217148ms step_avg:738.60ms
step:305/1875 train_loss:4.4428 train_time:217879ms step_avg:738.57ms
step:306/1875 train_loss:3.9359 train_time:218615ms step_avg:738.56ms
step:307/1875 train_loss:3.8278 train_time:219353ms step_avg:738.56ms
step:308/1875 train_loss:3.9621 train_time:220090ms step_avg:738.56ms
step:309/1875 train_loss:3.8528 train_time:220821ms step_avg:738.53ms
step:310/1875 train_loss:4.0792 train_time:221556ms step_avg:738.52ms
step:311/1875 train_loss:3.9028 train_time:222294ms step_avg:738.52ms
step:312/1875 train_loss:3.8445 train_time:223027ms step_avg:738.50ms
step:313/1875 train_loss:3.9215 train_time:223776ms step_avg:738.54ms
step:314/1875 train_loss:4.0424 train_time:224517ms step_avg:738.54ms
step:315/1875 train_loss:3.9304 train_time:225243ms step_avg:738.50ms
step:316/1875 train_loss:3.7611 train_time:225976ms step_avg:738.48ms
step:317/1875 train_loss:3.8575 train_time:226721ms step_avg:738.50ms
step:318/1875 train_loss:3.9196 train_time:227463ms step_avg:738.52ms
step:319/1875 train_loss:3.9013 train_time:228194ms step_avg:738.49ms
step:320/1875 train_loss:4.0041 train_time:228934ms step_avg:738.50ms
step:321/1875 train_loss:3.9492 train_time:229671ms step_avg:738.49ms
step:322/1875 train_loss:3.9170 train_time:230407ms step_avg:738.49ms
step:323/1875 train_loss:3.9841 train_time:231138ms step_avg:738.46ms
step:324/1875 train_loss:3.9406 train_time:231876ms step_avg:738.46ms
step:325/1875 train_loss:4.0081 train_time:232611ms step_avg:738.45ms
step:326/1875 train_loss:3.8745 train_time:233346ms step_avg:738.44ms
step:327/1875 train_loss:4.3686 train_time:234086ms step_avg:738.44ms
step:328/1875 train_loss:4.0592 train_time:234850ms step_avg:738.52ms
step:329/1875 train_loss:3.7895 train_time:235605ms step_avg:738.57ms
step:330/1875 train_loss:3.7142 train_time:236342ms step_avg:738.57ms
step:331/1875 train_loss:3.9635 train_time:237076ms step_avg:738.55ms
step:332/1875 train_loss:3.8899 train_time:237810ms step_avg:738.54ms
step:333/1875 train_loss:3.8614 train_time:238544ms step_avg:738.53ms
step:334/1875 train_loss:3.8361 train_time:239287ms step_avg:738.54ms
step:335/1875 train_loss:4.0031 train_time:240018ms step_avg:738.52ms
step:336/1875 train_loss:3.9526 train_time:240747ms step_avg:738.49ms
step:337/1875 train_loss:4.3701 train_time:241502ms step_avg:738.54ms
step:338/1875 train_loss:3.9505 train_time:242243ms step_avg:738.54ms
step:339/1875 train_loss:3.8381 train_time:242985ms step_avg:738.56ms
step:340/1875 train_loss:3.9217 train_time:243722ms step_avg:738.55ms
step:341/1875 train_loss:3.8523 train_time:244456ms step_avg:738.54ms
step:342/1875 train_loss:3.8067 train_time:245185ms step_avg:738.51ms
step:343/1875 train_loss:3.8241 train_time:245930ms step_avg:738.53ms
step:344/1875 train_loss:4.0062 train_time:246663ms step_avg:738.51ms
step:345/1875 train_loss:3.8157 train_time:247411ms step_avg:738.54ms
step:346/1875 train_loss:3.7536 train_time:248146ms step_avg:738.53ms
step:347/1875 train_loss:3.7791 train_time:248890ms step_avg:738.55ms
step:348/1875 train_loss:3.8474 train_time:249623ms step_avg:738.53ms
step:349/1875 train_loss:3.8201 train_time:250361ms step_avg:738.53ms
step:350/1875 train_loss:3.5610 train_time:251102ms step_avg:738.54ms
step:351/1875 train_loss:3.8182 train_time:251836ms step_avg:738.52ms
step:352/1875 train_loss:4.1814 train_time:252573ms step_avg:738.52ms
step:353/1875 train_loss:3.6483 train_time:253311ms step_avg:738.52ms
step:354/1875 train_loss:3.9410 train_time:254052ms step_avg:738.52ms
step:355/1875 train_loss:3.7755 train_time:254787ms step_avg:738.51ms
step:356/1875 train_loss:3.8724 train_time:255516ms step_avg:738.49ms
step:357/1875 train_loss:3.7441 train_time:256254ms step_avg:738.48ms
step:358/1875 train_loss:3.8484 train_time:257001ms step_avg:738.51ms
step:359/1875 train_loss:3.7415 train_time:257747ms step_avg:738.53ms
step:360/1875 train_loss:3.4132 train_time:258499ms step_avg:738.57ms
step:361/1875 train_loss:3.9972 train_time:259243ms step_avg:738.58ms
step:362/1875 train_loss:3.8836 train_time:259980ms step_avg:738.58ms
step:363/1875 train_loss:3.8263 train_time:260706ms step_avg:738.55ms
step:364/1875 train_loss:3.7299 train_time:261457ms step_avg:738.58ms
step:365/1875 train_loss:3.8969 train_time:262201ms step_avg:738.60ms
step:366/1875 train_loss:3.8673 train_time:262941ms step_avg:738.60ms
step:367/1875 train_loss:3.8506 train_time:263678ms step_avg:738.59ms
step:368/1875 train_loss:3.8499 train_time:264422ms step_avg:738.61ms
step:369/1875 train_loss:3.7424 train_time:265150ms step_avg:738.58ms
step:370/1875 train_loss:3.8927 train_time:265883ms step_avg:738.56ms
step:371/1875 train_loss:3.7361 train_time:266612ms step_avg:738.54ms
step:372/1875 train_loss:3.6872 train_time:267343ms step_avg:738.52ms
step:373/1875 train_loss:3.9170 train_time:268070ms step_avg:738.48ms
step:374/1875 train_loss:3.8334 train_time:268801ms step_avg:738.46ms
step:375/1875 train_loss:3.7994 train_time:269534ms step_avg:738.45ms
step:375/1875 val_loss:3.8214 train_time:269546ms step_avg:738.48ms
============== Weight norms: ==============
name = 'module._orig_mod.transformer.h.0.attn.c_q.weight' | fro_norm = 51.57101 | spectral_norm = 7.42942 | nuclear_norm = 1195.68213
name = 'module._orig_mod.transformer.h.0.attn.c_k.weight' | fro_norm = 50.95134 | spectral_norm = 9.03754 | nuclear_norm = 1170.44275
name = 'module._orig_mod.transformer.h.1.attn.c_q.weight' | fro_norm = 51.42809 | spectral_norm = 5.23662 | nuclear_norm = 1192.62549
name = 'module._orig_mod.transformer.h.1.attn.c_k.weight' | fro_norm = 50.14072 | spectral_norm = 5.32737 | nuclear_norm = 1161.76331
name = 'module._orig_mod.transformer.h.2.attn.c_q.weight' | fro_norm = 48.85139 | spectral_norm = 4.66362 | nuclear_norm = 1097.01501
name = 'module._orig_mod.transformer.h.2.attn.c_k.weight' | fro_norm = 49.38590 | spectral_norm = 4.56026 | nuclear_norm = 1113.99316
name = 'module._orig_mod.transformer.h.3.attn.c_q.weight' | fro_norm = 50.60640 | spectral_norm = 5.03115 | nuclear_norm = 1145.62146
name = 'module._orig_mod.transformer.h.3.attn.c_k.weight' | fro_norm = 50.61697 | spectral_norm = 4.66860 | nuclear_norm = 1147.42798
name = 'module._orig_mod.transformer.h.4.attn.c_q.weight' | fro_norm = 49.53150 | spectral_norm = 5.14673 | nuclear_norm = 1133.13110
name = 'module._orig_mod.transformer.h.4.attn.c_k.weight' | fro_norm = 48.88577 | spectral_norm = 5.27088 | nuclear_norm = 1124.88782
name = 'module._orig_mod.transformer.h.5.attn.c_q.weight' | fro_norm = 50.30264 | spectral_norm = 5.19439 | nuclear_norm = 1150.97534
name = 'module._orig_mod.transformer.h.5.attn.c_k.weight' | fro_norm = 50.46702 | spectral_norm = 5.02137 | nuclear_norm = 1157.43823
name = 'module._orig_mod.transformer.h.6.attn.c_q.weight' | fro_norm = 50.39856 | spectral_norm = 5.02332 | nuclear_norm = 1149.41516
name = 'module._orig_mod.transformer.h.6.attn.c_k.weight' | fro_norm = 50.36266 | spectral_norm = 4.82617 | nuclear_norm = 1151.32019
name = 'module._orig_mod.transformer.h.7.attn.c_q.weight' | fro_norm = 50.45666 | spectral_norm = 5.16313 | nuclear_norm = 1151.14575
name = 'module._orig_mod.transformer.h.7.attn.c_k.weight' | fro_norm = 50.50468 | spectral_norm = 5.07005 | nuclear_norm = 1158.57861
name = 'module._orig_mod.transformer.h.8.attn.c_q.weight' | fro_norm = 51.44597 | spectral_norm = 5.22741 | nuclear_norm = 1168.05273
name = 'module._orig_mod.transformer.h.8.attn.c_k.weight' | fro_norm = 52.06924 | spectral_norm = 4.90607 | nuclear_norm = 1178.35938
name = 'module._orig_mod.transformer.h.9.attn.c_q.weight' | fro_norm = 50.69396 | spectral_norm = 5.04873 | nuclear_norm = 1139.76489
name = 'module._orig_mod.transformer.h.9.attn.c_k.weight' | fro_norm = 51.21614 | spectral_norm = 4.66208 | nuclear_norm = 1147.41821
name = 'module._orig_mod.transformer.h.10.attn.c_q.weight' | fro_norm = 52.03480 | spectral_norm = 4.94510 | nuclear_norm = 1190.86865
name = 'module._orig_mod.transformer.h.10.attn.c_k.weight' | fro_norm = 51.56811 | spectral_norm = 4.77763 | nuclear_norm = 1179.93335
name = 'module._orig_mod.transformer.h.11.attn.c_q.weight' | fro_norm = 49.75402 | spectral_norm = 5.50046 | nuclear_norm = 1099.11230
name = 'module._orig_mod.transformer.h.11.attn.c_k.weight' | fro_norm = 50.44242 | spectral_norm = 5.04586 | nuclear_norm = 1107.81396
===========================================
step:376/1875 train_loss:3.8789 train_time:270259ms step_avg:738.41ms
step:377/1875 train_loss:3.7743 train_time:271008ms step_avg:738.44ms
step:378/1875 train_loss:3.8429 train_time:271762ms step_avg:738.48ms
step:379/1875 train_loss:3.8665 train_time:272503ms step_avg:738.49ms
step:380/1875 train_loss:3.9366 train_time:273448ms step_avg:739.05ms
step:381/1875 train_loss:3.6860 train_time:274386ms step_avg:739.58ms
step:382/1875 train_loss:3.7635 train_time:275139ms step_avg:739.62ms
step:383/1875 train_loss:3.7761 train_time:275877ms step_avg:739.62ms
step:384/1875 train_loss:3.8895 train_time:276614ms step_avg:739.61ms
step:385/1875 train_loss:3.6639 train_time:277345ms step_avg:739.59ms
step:386/1875 train_loss:3.8674 train_time:278084ms step_avg:739.59ms
step:387/1875 train_loss:3.7919 train_time:278823ms step_avg:739.58ms
step:388/1875 train_loss:3.9539 train_time:279560ms step_avg:739.58ms
step:389/1875 train_loss:3.8143 train_time:280285ms step_avg:739.54ms
step:390/1875 train_loss:3.8522 train_time:281040ms step_avg:739.58ms
step:391/1875 train_loss:3.6963 train_time:281775ms step_avg:739.57ms
step:392/1875 train_loss:3.7697 train_time:282507ms step_avg:739.55ms
step:393/1875 train_loss:3.8222 train_time:283236ms step_avg:739.52ms
step:394/1875 train_loss:3.8037 train_time:283967ms step_avg:739.50ms
step:395/1875 train_loss:3.8143 train_time:284703ms step_avg:739.49ms
step:396/1875 train_loss:3.7155 train_time:285457ms step_avg:739.53ms
step:397/1875 train_loss:3.5799 train_time:286194ms step_avg:739.52ms
step:398/1875 train_loss:3.8313 train_time:286926ms step_avg:739.50ms
step:399/1875 train_loss:3.7770 train_time:287659ms step_avg:739.48ms
step:400/1875 train_loss:3.7102 train_time:288388ms step_avg:739.46ms
step:401/1875 train_loss:3.8112 train_time:289125ms step_avg:739.45ms
step:402/1875 train_loss:3.6831 train_time:289857ms step_avg:739.43ms
step:403/1875 train_loss:3.9736 train_time:290603ms step_avg:739.45ms
step:404/1875 train_loss:3.8458 train_time:291341ms step_avg:739.44ms
step:405/1875 train_loss:3.8508 train_time:292075ms step_avg:739.43ms
step:406/1875 train_loss:3.8629 train_time:292807ms step_avg:739.41ms
step:407/1875 train_loss:3.8355 train_time:293539ms step_avg:739.39ms
step:408/1875 train_loss:3.7398 train_time:294281ms step_avg:739.40ms
step:409/1875 train_loss:3.8094 train_time:295005ms step_avg:739.36ms
step:410/1875 train_loss:3.7607 train_time:295745ms step_avg:739.36ms
step:411/1875 train_loss:3.7613 train_time:296474ms step_avg:739.34ms
step:412/1875 train_loss:3.7837 train_time:297208ms step_avg:739.32ms
step:413/1875 train_loss:3.7825 train_time:297942ms step_avg:739.31ms
step:414/1875 train_loss:3.8755 train_time:298679ms step_avg:739.30ms
step:415/1875 train_loss:3.7334 train_time:299407ms step_avg:739.28ms
step:416/1875 train_loss:3.8035 train_time:300147ms step_avg:739.28ms
step:417/1875 train_loss:3.8742 train_time:300881ms step_avg:739.27ms
step:418/1875 train_loss:3.6829 train_time:301614ms step_avg:739.25ms
step:419/1875 train_loss:3.9289 train_time:302345ms step_avg:739.23ms
step:420/1875 train_loss:4.0019 train_time:303082ms step_avg:739.22ms
step:421/1875 train_loss:3.7653 train_time:303809ms step_avg:739.20ms
step:422/1875 train_loss:3.9170 train_time:304542ms step_avg:739.18ms
step:423/1875 train_loss:3.5749 train_time:305280ms step_avg:739.18ms
step:424/1875 train_loss:3.7889 train_time:306010ms step_avg:739.15ms
step:425/1875 train_loss:3.6503 train_time:306746ms step_avg:739.15ms
step:426/1875 train_loss:3.8563 train_time:307486ms step_avg:739.15ms
step:427/1875 train_loss:3.8412 train_time:308224ms step_avg:739.15ms
step:428/1875 train_loss:3.7748 train_time:308964ms step_avg:739.15ms
step:429/1875 train_loss:3.8880 train_time:309707ms step_avg:739.16ms
step:430/1875 train_loss:3.7132 train_time:310443ms step_avg:739.15ms
step:431/1875 train_loss:3.6375 train_time:311187ms step_avg:739.16ms
step:432/1875 train_loss:3.8380 train_time:311916ms step_avg:739.14ms
step:433/1875 train_loss:3.8689 train_time:312646ms step_avg:739.12ms
step:434/1875 train_loss:3.8566 train_time:313377ms step_avg:739.10ms
step:435/1875 train_loss:3.7649 train_time:314109ms step_avg:739.08ms
step:436/1875 train_loss:3.8411 train_time:314841ms step_avg:739.06ms
step:437/1875 train_loss:3.8359 train_time:315577ms step_avg:739.06ms
step:438/1875 train_loss:3.7966 train_time:316313ms step_avg:739.05ms
step:439/1875 train_loss:3.8761 train_time:317049ms step_avg:739.04ms
step:440/1875 train_loss:3.7146 train_time:317784ms step_avg:739.03ms
step:441/1875 train_loss:3.8045 train_time:318520ms step_avg:739.03ms
step:442/1875 train_loss:3.7289 train_time:319259ms step_avg:739.03ms
step:443/1875 train_loss:3.6249 train_time:319989ms step_avg:739.00ms
step:444/1875 train_loss:3.7661 train_time:320714ms step_avg:738.97ms
step:445/1875 train_loss:4.0263 train_time:321454ms step_avg:738.98ms
step:446/1875 train_loss:3.6597 train_time:322185ms step_avg:738.96ms
step:447/1875 train_loss:3.8473 train_time:322920ms step_avg:738.95ms
step:448/1875 train_loss:3.8770 train_time:323662ms step_avg:738.96ms
step:449/1875 train_loss:3.7290 train_time:324407ms step_avg:738.97ms
step:450/1875 train_loss:3.6822 train_time:325145ms step_avg:738.97ms
step:451/1875 train_loss:3.7158 train_time:325887ms step_avg:738.97ms
step:452/1875 train_loss:4.0561 train_time:326627ms step_avg:738.97ms
step:453/1875 train_loss:3.9539 train_time:327365ms step_avg:738.97ms
step:454/1875 train_loss:3.8163 train_time:328107ms step_avg:738.98ms
step:455/1875 train_loss:3.7159 train_time:328844ms step_avg:738.98ms
step:456/1875 train_loss:3.8374 train_time:329576ms step_avg:738.96ms
step:457/1875 train_loss:3.7548 train_time:330305ms step_avg:738.94ms
step:458/1875 train_loss:3.7755 train_time:331035ms step_avg:738.92ms
step:459/1875 train_loss:3.8765 train_time:331765ms step_avg:738.90ms
step:460/1875 train_loss:3.6834 train_time:332517ms step_avg:738.93ms
step:461/1875 train_loss:3.7972 train_time:333254ms step_avg:738.92ms
step:462/1875 train_loss:3.7466 train_time:333993ms step_avg:738.92ms
step:463/1875 train_loss:3.6085 train_time:334724ms step_avg:738.91ms
step:464/1875 train_loss:3.7558 train_time:335458ms step_avg:738.89ms
step:465/1875 train_loss:3.8370 train_time:336185ms step_avg:738.87ms
step:466/1875 train_loss:3.7175 train_time:336924ms step_avg:738.87ms
step:467/1875 train_loss:3.7334 train_time:337656ms step_avg:738.85ms
step:468/1875 train_loss:3.7146 train_time:338398ms step_avg:738.86ms
step:469/1875 train_loss:3.9095 train_time:339126ms step_avg:738.84ms
step:470/1875 train_loss:3.7619 train_time:339853ms step_avg:738.81ms
step:471/1875 train_loss:3.6237 train_time:340607ms step_avg:738.84ms
step:472/1875 train_loss:3.8380 train_time:341336ms step_avg:738.82ms
step:473/1875 train_loss:3.6992 train_time:342061ms step_avg:738.79ms
step:474/1875 train_loss:3.8186 train_time:342797ms step_avg:738.79ms
step:475/1875 train_loss:3.8814 train_time:343527ms step_avg:738.77ms
step:476/1875 train_loss:4.0407 train_time:344263ms step_avg:738.76ms
step:477/1875 train_loss:3.8294 train_time:344991ms step_avg:738.74ms
step:478/1875 train_loss:3.7967 train_time:345733ms step_avg:738.75ms
step:479/1875 train_loss:3.7454 train_time:346468ms step_avg:738.74ms
step:480/1875 train_loss:3.6929 train_time:347217ms step_avg:738.76ms
step:481/1875 train_loss:3.7443 train_time:347949ms step_avg:738.75ms
step:482/1875 train_loss:3.8426 train_time:348680ms step_avg:738.73ms
step:483/1875 train_loss:3.7779 train_time:349413ms step_avg:738.72ms
step:484/1875 train_loss:3.8505 train_time:350153ms step_avg:738.72ms
step:485/1875 train_loss:3.7894 train_time:350895ms step_avg:738.73ms
step:486/1875 train_loss:3.6177 train_time:351626ms step_avg:738.71ms
step:487/1875 train_loss:3.7470 train_time:352360ms step_avg:738.70ms
step:488/1875 train_loss:3.7562 train_time:353098ms step_avg:738.70ms
step:489/1875 train_loss:3.7769 train_time:353821ms step_avg:738.67ms
step:490/1875 train_loss:3.9825 train_time:354560ms step_avg:738.67ms
step:491/1875 train_loss:3.7101 train_time:355292ms step_avg:738.65ms
step:492/1875 train_loss:3.6760 train_time:356022ms step_avg:738.63ms
step:493/1875 train_loss:3.8064 train_time:356751ms step_avg:738.62ms
step:494/1875 train_loss:3.5688 train_time:357501ms step_avg:738.64ms
step:495/1875 train_loss:3.7376 train_time:358242ms step_avg:738.64ms
step:496/1875 train_loss:3.9105 train_time:358991ms step_avg:738.66ms
step:497/1875 train_loss:3.7651 train_time:359740ms step_avg:738.69ms
step:498/1875 train_loss:3.7357 train_time:360478ms step_avg:738.69ms
step:499/1875 train_loss:3.7195 train_time:361203ms step_avg:738.66ms
step:500/1875 train_loss:3.8223 train_time:361941ms step_avg:738.65ms
step:500/1875 val_loss:3.7277 train_time:361952ms step_avg:738.68ms
============== Weight norms: ==============
name = 'module._orig_mod.transformer.h.0.attn.c_q.weight' | fro_norm = 66.34776 | spectral_norm = 10.16394 | nuclear_norm = 1537.38550
name = 'module._orig_mod.transformer.h.0.attn.c_k.weight' | fro_norm = 65.34513 | spectral_norm = 12.07479 | nuclear_norm = 1500.68079
name = 'module._orig_mod.transformer.h.1.attn.c_q.weight' | fro_norm = 66.27924 | spectral_norm = 6.83541 | nuclear_norm = 1536.30859
name = 'module._orig_mod.transformer.h.1.attn.c_k.weight' | fro_norm = 64.51797 | spectral_norm = 6.93025 | nuclear_norm = 1494.12500
name = 'module._orig_mod.transformer.h.2.attn.c_q.weight' | fro_norm = 63.20016 | spectral_norm = 5.93054 | nuclear_norm = 1420.64758
name = 'module._orig_mod.transformer.h.2.attn.c_k.weight' | fro_norm = 63.65154 | spectral_norm = 5.80796 | nuclear_norm = 1436.30676
name = 'module._orig_mod.transformer.h.3.attn.c_q.weight' | fro_norm = 65.33085 | spectral_norm = 6.39292 | nuclear_norm = 1480.89722
name = 'module._orig_mod.transformer.h.3.attn.c_k.weight' | fro_norm = 64.97323 | spectral_norm = 5.98160 | nuclear_norm = 1472.74829
name = 'module._orig_mod.transformer.h.4.attn.c_q.weight' | fro_norm = 64.10612 | spectral_norm = 6.79298 | nuclear_norm = 1464.88892
name = 'module._orig_mod.transformer.h.4.attn.c_k.weight' | fro_norm = 63.02876 | spectral_norm = 6.87401 | nuclear_norm = 1451.16797
name = 'module._orig_mod.transformer.h.5.attn.c_q.weight' | fro_norm = 65.34796 | spectral_norm = 6.78687 | nuclear_norm = 1499.37927
name = 'module._orig_mod.transformer.h.5.attn.c_k.weight' | fro_norm = 65.12651 | spectral_norm = 6.47878 | nuclear_norm = 1497.66028
name = 'module._orig_mod.transformer.h.6.attn.c_q.weight' | fro_norm = 65.16985 | spectral_norm = 6.55772 | nuclear_norm = 1488.83301
name = 'module._orig_mod.transformer.h.6.attn.c_k.weight' | fro_norm = 64.74966 | spectral_norm = 6.20095 | nuclear_norm = 1482.35217
name = 'module._orig_mod.transformer.h.7.attn.c_q.weight' | fro_norm = 65.55161 | spectral_norm = 6.75434 | nuclear_norm = 1499.00000
name = 'module._orig_mod.transformer.h.7.attn.c_k.weight' | fro_norm = 65.33364 | spectral_norm = 6.59909 | nuclear_norm = 1502.49438
name = 'module._orig_mod.transformer.h.8.attn.c_q.weight' | fro_norm = 67.08466 | spectral_norm = 6.90726 | nuclear_norm = 1527.12817
name = 'module._orig_mod.transformer.h.8.attn.c_k.weight' | fro_norm = 67.60777 | spectral_norm = 6.60761 | nuclear_norm = 1531.29175
name = 'module._orig_mod.transformer.h.9.attn.c_q.weight' | fro_norm = 65.90509 | spectral_norm = 6.62332 | nuclear_norm = 1483.05103
name = 'module._orig_mod.transformer.h.9.attn.c_k.weight' | fro_norm = 66.30538 | spectral_norm = 6.10968 | nuclear_norm = 1483.84937
name = 'module._orig_mod.transformer.h.10.attn.c_q.weight' | fro_norm = 67.81461 | spectral_norm = 6.42186 | nuclear_norm = 1554.46021
name = 'module._orig_mod.transformer.h.10.attn.c_k.weight' | fro_norm = 66.83460 | spectral_norm = 6.38685 | nuclear_norm = 1529.74365
name = 'module._orig_mod.transformer.h.11.attn.c_q.weight' | fro_norm = 64.82333 | spectral_norm = 7.39163 | nuclear_norm = 1432.51709
name = 'module._orig_mod.transformer.h.11.attn.c_k.weight' | fro_norm = 65.14719 | spectral_norm = 6.65971 | nuclear_norm = 1429.36255
===========================================
step:501/1875 train_loss:3.7318 train_time:362675ms step_avg:738.65ms
step:502/1875 train_loss:3.6608 train_time:363418ms step_avg:738.65ms
step:503/1875 train_loss:3.7736 train_time:364149ms step_avg:738.64ms
step:504/1875 train_loss:3.6268 train_time:364883ms step_avg:738.63ms
step:505/1875 train_loss:4.0526 train_time:365609ms step_avg:738.60ms
step:506/1875 train_loss:3.7022 train_time:366342ms step_avg:738.59ms
step:507/1875 train_loss:3.7893 train_time:367083ms step_avg:738.60ms
step:508/1875 train_loss:3.9508 train_time:367819ms step_avg:738.59ms
step:509/1875 train_loss:3.6641 train_time:368555ms step_avg:738.59ms
step:510/1875 train_loss:3.7706 train_time:369286ms step_avg:738.57ms
step:511/1875 train_loss:3.7633 train_time:370033ms step_avg:738.59ms
step:512/1875 train_loss:3.5837 train_time:370772ms step_avg:738.59ms
step:513/1875 train_loss:3.5694 train_time:371530ms step_avg:738.63ms
step:514/1875 train_loss:3.8169 train_time:372254ms step_avg:738.60ms
step:515/1875 train_loss:3.9179 train_time:372998ms step_avg:738.61ms
step:516/1875 train_loss:3.8171 train_time:373730ms step_avg:738.60ms
step:517/1875 train_loss:3.6433 train_time:374473ms step_avg:738.61ms
step:518/1875 train_loss:3.8084 train_time:375208ms step_avg:738.60ms
step:519/1875 train_loss:3.5575 train_time:375935ms step_avg:738.57ms
step:520/1875 train_loss:3.8039 train_time:376674ms step_avg:738.58ms
step:521/1875 train_loss:3.6908 train_time:377416ms step_avg:738.58ms
step:522/1875 train_loss:3.5841 train_time:378148ms step_avg:738.57ms
step:523/1875 train_loss:3.8358 train_time:378890ms step_avg:738.58ms
step:524/1875 train_loss:3.6321 train_time:379627ms step_avg:738.57ms
step:525/1875 train_loss:3.6902 train_time:380361ms step_avg:738.57ms
step:526/1875 train_loss:3.7429 train_time:381107ms step_avg:738.58ms
step:527/1875 train_loss:3.9960 train_time:381838ms step_avg:738.57ms
step:528/1875 train_loss:3.7017 train_time:382567ms step_avg:738.55ms
step:529/1875 train_loss:3.6904 train_time:383301ms step_avg:738.54ms
step:530/1875 train_loss:3.6983 train_time:384038ms step_avg:738.53ms
step:531/1875 train_loss:3.8024 train_time:384774ms step_avg:738.53ms
step:532/1875 train_loss:3.7690 train_time:385522ms step_avg:738.55ms
step:533/1875 train_loss:3.7654 train_time:386263ms step_avg:738.55ms
step:534/1875 train_loss:3.8402 train_time:386995ms step_avg:738.54ms
step:535/1875 train_loss:3.7920 train_time:387748ms step_avg:738.57ms
step:536/1875 train_loss:3.6418 train_time:388481ms step_avg:738.56ms
step:537/1875 train_loss:3.7271 train_time:389221ms step_avg:738.56ms
step:538/1875 train_loss:3.6675 train_time:389959ms step_avg:738.56ms
step:539/1875 train_loss:3.6598 train_time:390710ms step_avg:738.58ms
step:540/1875 train_loss:3.7352 train_time:391467ms step_avg:738.62ms
step:541/1875 train_loss:3.6451 train_time:392198ms step_avg:738.60ms
step:542/1875 train_loss:3.6898 train_time:392942ms step_avg:738.61ms
step:543/1875 train_loss:3.7477 train_time:393674ms step_avg:738.60ms
step:544/1875 train_loss:3.7227 train_time:394415ms step_avg:738.60ms
step:545/1875 train_loss:3.7591 train_time:395151ms step_avg:738.60ms
step:546/1875 train_loss:3.7841 train_time:395886ms step_avg:738.59ms
step:547/1875 train_loss:3.6303 train_time:396629ms step_avg:738.60ms
step:548/1875 train_loss:3.8881 train_time:397370ms step_avg:738.61ms
step:549/1875 train_loss:3.3166 train_time:398112ms step_avg:738.61ms
step:550/1875 train_loss:3.7560 train_time:398859ms step_avg:738.63ms
step:551/1875 train_loss:3.7627 train_time:399593ms step_avg:738.62ms
step:552/1875 train_loss:3.6898 train_time:400321ms step_avg:738.60ms
step:553/1875 train_loss:3.7838 train_time:401064ms step_avg:738.61ms
step:554/1875 train_loss:3.7112 train_time:401800ms step_avg:738.60ms
step:555/1875 train_loss:3.6954 train_time:402534ms step_avg:738.59ms
step:556/1875 train_loss:3.8301 train_time:403263ms step_avg:738.58ms
step:557/1875 train_loss:3.7310 train_time:403993ms step_avg:738.56ms
step:558/1875 train_loss:3.6523 train_time:404727ms step_avg:738.55ms
step:559/1875 train_loss:3.7556 train_time:405462ms step_avg:738.55ms
step:560/1875 train_loss:3.6530 train_time:406188ms step_avg:738.52ms
step:561/1875 train_loss:3.7092 train_time:406923ms step_avg:738.52ms
step:562/1875 train_loss:3.7070 train_time:407653ms step_avg:738.50ms
step:563/1875 train_loss:3.5090 train_time:408383ms step_avg:738.49ms
step:564/1875 train_loss:3.7762 train_time:409109ms step_avg:738.46ms
step:565/1875 train_loss:3.6341 train_time:409854ms step_avg:738.48ms
step:566/1875 train_loss:3.6776 train_time:410592ms step_avg:738.47ms
step:567/1875 train_loss:3.7558 train_time:411327ms step_avg:738.47ms
step:568/1875 train_loss:3.6725 train_time:412058ms step_avg:738.46ms
step:569/1875 train_loss:4.0186 train_time:412787ms step_avg:738.44ms
step:570/1875 train_loss:3.7242 train_time:413723ms step_avg:738.79ms
step:571/1875 train_loss:3.6852 train_time:414466ms step_avg:738.80ms
step:572/1875 train_loss:3.7868 train_time:415205ms step_avg:738.80ms
step:573/1875 train_loss:3.7527 train_time:415940ms step_avg:738.79ms
step:574/1875 train_loss:3.7581 train_time:416674ms step_avg:738.78ms
step:575/1875 train_loss:3.8081 train_time:417430ms step_avg:738.81ms
step:576/1875 train_loss:3.7645 train_time:418161ms step_avg:738.80ms
step:577/1875 train_loss:3.7928 train_time:418891ms step_avg:738.78ms
step:578/1875 train_loss:3.7005 train_time:419618ms step_avg:738.76ms
step:579/1875 train_loss:3.7011 train_time:420357ms step_avg:738.76ms
step:580/1875 train_loss:3.6963 train_time:421097ms step_avg:738.77ms
step:581/1875 train_loss:3.6236 train_time:421832ms step_avg:738.76ms
step:582/1875 train_loss:3.6724 train_time:422562ms step_avg:738.74ms
step:583/1875 train_loss:3.8790 train_time:423307ms step_avg:738.76ms
step:584/1875 train_loss:3.6648 train_time:424039ms step_avg:738.74ms
step:585/1875 train_loss:3.6142 train_time:424777ms step_avg:738.74ms
step:586/1875 train_loss:3.8230 train_time:425508ms step_avg:738.73ms
step:587/1875 train_loss:3.5360 train_time:426247ms step_avg:738.73ms
step:588/1875 train_loss:3.7030 train_time:426979ms step_avg:738.72ms
step:589/1875 train_loss:3.6803 train_time:427714ms step_avg:738.71ms
step:590/1875 train_loss:4.0332 train_time:428451ms step_avg:738.71ms
step:591/1875 train_loss:3.8005 train_time:429191ms step_avg:738.71ms
step:592/1875 train_loss:3.5486 train_time:429917ms step_avg:738.69ms
step:593/1875 train_loss:3.5700 train_time:430656ms step_avg:738.69ms
step:594/1875 train_loss:3.5299 train_time:431397ms step_avg:738.69ms
step:595/1875 train_loss:3.5833 train_time:432139ms step_avg:738.70ms
step:596/1875 train_loss:3.9611 train_time:432886ms step_avg:738.71ms
step:597/1875 train_loss:3.6745 train_time:433624ms step_avg:738.71ms
step:598/1875 train_loss:3.6168 train_time:434355ms step_avg:738.70ms
step:599/1875 train_loss:3.6975 train_time:435087ms step_avg:738.69ms
step:600/1875 train_loss:3.5102 train_time:435816ms step_avg:738.67ms
step:601/1875 train_loss:3.6349 train_time:436549ms step_avg:738.66ms
step:602/1875 train_loss:3.6795 train_time:437279ms step_avg:738.65ms
step:603/1875 train_loss:3.7025 train_time:438020ms step_avg:738.65ms
step:604/1875 train_loss:3.8140 train_time:438767ms step_avg:738.67ms
step:605/1875 train_loss:3.6366 train_time:439496ms step_avg:738.65ms
step:606/1875 train_loss:3.6548 train_time:440234ms step_avg:738.65ms
step:607/1875 train_loss:3.6082 train_time:440984ms step_avg:738.67ms
step:608/1875 train_loss:3.8667 train_time:441709ms step_avg:738.64ms
step:609/1875 train_loss:3.6774 train_time:442440ms step_avg:738.63ms
step:610/1875 train_loss:3.6387 train_time:443164ms step_avg:738.61ms
step:611/1875 train_loss:3.7325 train_time:443901ms step_avg:738.60ms
step:612/1875 train_loss:3.6328 train_time:444633ms step_avg:738.59ms
step:613/1875 train_loss:3.5978 train_time:445362ms step_avg:738.58ms
step:614/1875 train_loss:3.7810 train_time:446102ms step_avg:738.58ms
step:615/1875 train_loss:3.7288 train_time:446832ms step_avg:738.57ms
step:616/1875 train_loss:3.7351 train_time:447568ms step_avg:738.56ms
step:617/1875 train_loss:3.6618 train_time:448297ms step_avg:738.55ms
step:618/1875 train_loss:3.5834 train_time:449030ms step_avg:738.54ms
step:619/1875 train_loss:3.7217 train_time:449765ms step_avg:738.53ms
step:620/1875 train_loss:3.5874 train_time:450502ms step_avg:738.53ms
step:621/1875 train_loss:3.6171 train_time:451242ms step_avg:738.53ms
step:622/1875 train_loss:3.9541 train_time:451971ms step_avg:738.51ms
step:623/1875 train_loss:3.6035 train_time:452722ms step_avg:738.54ms
step:624/1875 train_loss:3.6383 train_time:453455ms step_avg:738.53ms
step:625/1875 train_loss:3.7301 train_time:454202ms step_avg:738.54ms
step:625/1875 val_loss:3.6535 train_time:454214ms step_avg:738.56ms
============== Weight norms: ==============
name = 'module._orig_mod.transformer.h.0.attn.c_q.weight' | fro_norm = 82.48032 | spectral_norm = 13.22453 | nuclear_norm = 1908.56091
name = 'module._orig_mod.transformer.h.0.attn.c_k.weight' | fro_norm = 80.81403 | spectral_norm = 15.24134 | nuclear_norm = 1854.70312
name = 'module._orig_mod.transformer.h.1.attn.c_q.weight' | fro_norm = 82.51744 | spectral_norm = 8.58787 | nuclear_norm = 1911.98779
name = 'module._orig_mod.transformer.h.1.attn.c_k.weight' | fro_norm = 80.22729 | spectral_norm = 8.75990 | nuclear_norm = 1857.14990
name = 'module._orig_mod.transformer.h.2.attn.c_q.weight' | fro_norm = 78.83432 | spectral_norm = 7.54070 | nuclear_norm = 1766.17261
name = 'module._orig_mod.transformer.h.2.attn.c_k.weight' | fro_norm = 79.14960 | spectral_norm = 7.11400 | nuclear_norm = 1781.03003
name = 'module._orig_mod.transformer.h.3.attn.c_q.weight' | fro_norm = 81.34376 | spectral_norm = 7.88593 | nuclear_norm = 1842.71130
name = 'module._orig_mod.transformer.h.3.attn.c_k.weight' | fro_norm = 80.58711 | spectral_norm = 7.55667 | nuclear_norm = 1824.64417
name = 'module._orig_mod.transformer.h.4.attn.c_q.weight' | fro_norm = 79.84304 | spectral_norm = 8.69035 | nuclear_norm = 1821.64795
name = 'module._orig_mod.transformer.h.4.attn.c_k.weight' | fro_norm = 78.47887 | spectral_norm = 8.66535 | nuclear_norm = 1806.42651
name = 'module._orig_mod.transformer.h.5.attn.c_q.weight' | fro_norm = 81.60433 | spectral_norm = 8.54601 | nuclear_norm = 1874.06763
name = 'module._orig_mod.transformer.h.5.attn.c_k.weight' | fro_norm = 81.07555 | spectral_norm = 8.11054 | nuclear_norm = 1867.04980
name = 'module._orig_mod.transformer.h.6.attn.c_q.weight' | fro_norm = 80.86732 | spectral_norm = 8.13213 | nuclear_norm = 1846.75110
name = 'module._orig_mod.transformer.h.6.attn.c_k.weight' | fro_norm = 80.30076 | spectral_norm = 7.77315 | nuclear_norm = 1836.17090
name = 'module._orig_mod.transformer.h.7.attn.c_q.weight' | fro_norm = 81.80755 | spectral_norm = 8.38487 | nuclear_norm = 1871.85547
name = 'module._orig_mod.transformer.h.7.attn.c_k.weight' | fro_norm = 81.44216 | spectral_norm = 8.35176 | nuclear_norm = 1874.05481
name = 'module._orig_mod.transformer.h.8.attn.c_q.weight' | fro_norm = 83.90716 | spectral_norm = 8.78882 | nuclear_norm = 1908.53137
name = 'module._orig_mod.transformer.h.8.attn.c_k.weight' | fro_norm = 84.33699 | spectral_norm = 8.42410 | nuclear_norm = 1906.86670
name = 'module._orig_mod.transformer.h.9.attn.c_q.weight' | fro_norm = 82.19926 | spectral_norm = 8.38636 | nuclear_norm = 1846.39124
name = 'module._orig_mod.transformer.h.9.attn.c_k.weight' | fro_norm = 82.45802 | spectral_norm = 7.83219 | nuclear_norm = 1838.82788
name = 'module._orig_mod.transformer.h.10.attn.c_q.weight' | fro_norm = 84.61731 | spectral_norm = 8.06908 | nuclear_norm = 1937.02808
name = 'module._orig_mod.transformer.h.10.attn.c_k.weight' | fro_norm = 83.26082 | spectral_norm = 8.17089 | nuclear_norm = 1901.68970
name = 'module._orig_mod.transformer.h.11.attn.c_q.weight' | fro_norm = 80.82825 | spectral_norm = 9.52255 | nuclear_norm = 1781.75854
name = 'module._orig_mod.transformer.h.11.attn.c_k.weight' | fro_norm = 80.84105 | spectral_norm = 8.46324 | nuclear_norm = 1765.94434
===========================================
step:626/1875 train_loss:3.7355 train_time:454927ms step_avg:738.52ms
step:627/1875 train_loss:3.7747 train_time:455663ms step_avg:738.51ms
step:628/1875 train_loss:3.7541 train_time:456403ms step_avg:738.52ms
step:629/1875 train_loss:3.8013 train_time:457133ms step_avg:738.50ms
step:630/1875 train_loss:3.6225 train_time:457866ms step_avg:738.49ms
step:631/1875 train_loss:3.7499 train_time:458592ms step_avg:738.47ms
step:632/1875 train_loss:3.7798 train_time:459329ms step_avg:738.47ms
step:633/1875 train_loss:3.6818 train_time:460066ms step_avg:738.47ms
step:634/1875 train_loss:3.6378 train_time:460803ms step_avg:738.47ms
step:635/1875 train_loss:3.7265 train_time:461549ms step_avg:738.48ms
step:636/1875 train_loss:3.9802 train_time:462282ms step_avg:738.47ms
step:637/1875 train_loss:3.5707 train_time:463014ms step_avg:738.46ms
step:638/1875 train_loss:3.3766 train_time:463750ms step_avg:738.45ms
step:639/1875 train_loss:3.6215 train_time:464492ms step_avg:738.46ms
step:640/1875 train_loss:3.6633 train_time:465222ms step_avg:738.45ms
step:641/1875 train_loss:3.6076 train_time:465955ms step_avg:738.44ms
step:642/1875 train_loss:3.6023 train_time:466687ms step_avg:738.43ms
step:643/1875 train_loss:3.6617 train_time:467424ms step_avg:738.43ms
step:644/1875 train_loss:3.6422 train_time:468162ms step_avg:738.43ms
step:645/1875 train_loss:3.5915 train_time:468892ms step_avg:738.41ms
step:646/1875 train_loss:3.8057 train_time:469627ms step_avg:738.41ms
step:647/1875 train_loss:3.7102 train_time:470370ms step_avg:738.42ms
step:648/1875 train_loss:3.6911 train_time:471104ms step_avg:738.41ms
step:649/1875 train_loss:3.7413 train_time:471860ms step_avg:738.43ms
step:650/1875 train_loss:3.7981 train_time:472591ms step_avg:738.42ms
step:651/1875 train_loss:3.6575 train_time:473334ms step_avg:738.43ms
step:652/1875 train_loss:3.8024 train_time:474074ms step_avg:738.43ms
step:653/1875 train_loss:3.6148 train_time:474809ms step_avg:738.43ms
step:654/1875 train_loss:3.6907 train_time:475541ms step_avg:738.42ms
step:655/1875 train_loss:3.4582 train_time:476275ms step_avg:738.41ms
step:656/1875 train_loss:3.6010 train_time:476999ms step_avg:738.39ms
step:657/1875 train_loss:3.6055 train_time:477737ms step_avg:738.39ms
step:658/1875 train_loss:3.5251 train_time:478473ms step_avg:738.38ms
step:659/1875 train_loss:3.7167 train_time:479212ms step_avg:738.39ms
step:660/1875 train_loss:3.6234 train_time:479953ms step_avg:738.39ms
step:661/1875 train_loss:3.7080 train_time:480683ms step_avg:738.38ms
step:662/1875 train_loss:3.7775 train_time:481422ms step_avg:738.38ms
step:663/1875 train_loss:3.7052 train_time:482158ms step_avg:738.37ms
step:664/1875 train_loss:3.5895 train_time:482892ms step_avg:738.37ms
step:665/1875 train_loss:3.6410 train_time:483628ms step_avg:738.36ms
step:666/1875 train_loss:3.5292 train_time:484364ms step_avg:738.36ms
step:667/1875 train_loss:3.8149 train_time:485090ms step_avg:738.34ms
step:668/1875 train_loss:3.6414 train_time:485834ms step_avg:738.35ms
step:669/1875 train_loss:3.6806 train_time:486574ms step_avg:738.35ms
step:670/1875 train_loss:3.5122 train_time:487313ms step_avg:738.35ms
step:671/1875 train_loss:3.6358 train_time:488056ms step_avg:738.36ms
step:672/1875 train_loss:3.5924 train_time:488784ms step_avg:738.35ms
step:673/1875 train_loss:3.5929 train_time:489521ms step_avg:738.34ms
step:674/1875 train_loss:3.8787 train_time:490259ms step_avg:738.34ms
step:675/1875 train_loss:3.6543 train_time:490994ms step_avg:738.34ms
step:676/1875 train_loss:3.7417 train_time:491733ms step_avg:738.34ms
step:677/1875 train_loss:3.5160 train_time:492469ms step_avg:738.33ms
step:678/1875 train_loss:3.6326 train_time:493197ms step_avg:738.32ms
step:679/1875 train_loss:3.5814 train_time:493933ms step_avg:738.32ms
step:680/1875 train_loss:3.7075 train_time:494675ms step_avg:738.32ms
step:681/1875 train_loss:3.6217 train_time:495420ms step_avg:738.33ms
step:682/1875 train_loss:3.6486 train_time:496149ms step_avg:738.32ms
step:683/1875 train_loss:3.6840 train_time:496884ms step_avg:738.31ms
step:684/1875 train_loss:3.7679 train_time:497628ms step_avg:738.32ms
step:685/1875 train_loss:3.6743 train_time:498373ms step_avg:738.33ms
step:686/1875 train_loss:3.7239 train_time:499104ms step_avg:738.32ms
step:687/1875 train_loss:3.6570 train_time:499839ms step_avg:738.31ms
step:688/1875 train_loss:3.6938 train_time:500584ms step_avg:738.32ms
step:689/1875 train_loss:3.2101 train_time:501347ms step_avg:738.36ms
step:690/1875 train_loss:3.4371 train_time:502077ms step_avg:738.35ms
step:691/1875 train_loss:3.5776 train_time:502811ms step_avg:738.34ms
step:692/1875 train_loss:3.4440 train_time:503540ms step_avg:738.33ms
step:693/1875 train_loss:3.6542 train_time:504272ms step_avg:738.32ms
step:694/1875 train_loss:3.6784 train_time:505002ms step_avg:738.31ms
step:695/1875 train_loss:3.5850 train_time:505732ms step_avg:738.29ms
step:696/1875 train_loss:3.5661 train_time:506463ms step_avg:738.28ms
step:697/1875 train_loss:3.8911 train_time:507206ms step_avg:738.29ms
step:698/1875 train_loss:3.6135 train_time:507937ms step_avg:738.28ms
step:699/1875 train_loss:3.6724 train_time:508670ms step_avg:738.27ms
step:700/1875 train_loss:3.7911 train_time:509406ms step_avg:738.27ms
step:701/1875 train_loss:3.5937 train_time:510134ms step_avg:738.26ms
step:702/1875 train_loss:3.5751 train_time:510864ms step_avg:738.24ms
step:703/1875 train_loss:3.5397 train_time:511606ms step_avg:738.25ms
step:704/1875 train_loss:3.5273 train_time:512340ms step_avg:738.24ms
step:705/1875 train_loss:3.6038 train_time:513097ms step_avg:738.27ms
step:706/1875 train_loss:3.5889 train_time:513829ms step_avg:738.26ms
step:707/1875 train_loss:3.6116 train_time:514577ms step_avg:738.27ms
step:708/1875 train_loss:3.6756 train_time:515316ms step_avg:738.28ms
step:709/1875 train_loss:3.6312 train_time:516064ms step_avg:738.29ms
step:710/1875 train_loss:3.6133 train_time:516801ms step_avg:738.29ms
step:711/1875 train_loss:3.5782 train_time:517539ms step_avg:738.29ms
step:712/1875 train_loss:3.6259 train_time:518286ms step_avg:738.30ms
step:713/1875 train_loss:3.6838 train_time:519018ms step_avg:738.29ms
step:714/1875 train_loss:3.6737 train_time:519765ms step_avg:738.30ms
step:715/1875 train_loss:3.5905 train_time:520502ms step_avg:738.30ms
step:716/1875 train_loss:3.6043 train_time:521233ms step_avg:738.29ms
step:717/1875 train_loss:3.6191 train_time:521967ms step_avg:738.28ms
step:718/1875 train_loss:3.7245 train_time:522697ms step_avg:738.27ms
step:719/1875 train_loss:3.6233 train_time:523430ms step_avg:738.26ms
step:720/1875 train_loss:3.7076 train_time:524162ms step_avg:738.26ms
step:721/1875 train_loss:3.8732 train_time:524907ms step_avg:738.27ms
step:722/1875 train_loss:3.4910 train_time:525638ms step_avg:738.26ms
step:723/1875 train_loss:3.7659 train_time:526379ms step_avg:738.26ms
step:724/1875 train_loss:3.8031 train_time:527103ms step_avg:738.24ms
step:725/1875 train_loss:3.5987 train_time:527840ms step_avg:738.24ms
step:726/1875 train_loss:3.6803 train_time:528592ms step_avg:738.26ms
step:727/1875 train_loss:3.5745 train_time:529329ms step_avg:738.26ms
step:728/1875 train_loss:3.6052 train_time:530058ms step_avg:738.24ms
step:729/1875 train_loss:3.7688 train_time:530790ms step_avg:738.23ms
step:730/1875 train_loss:3.6975 train_time:531528ms step_avg:738.23ms
step:731/1875 train_loss:3.6902 train_time:532272ms step_avg:738.24ms
step:732/1875 train_loss:3.5957 train_time:533009ms step_avg:738.24ms
step:733/1875 train_loss:3.6301 train_time:533734ms step_avg:738.22ms
step:734/1875 train_loss:3.8646 train_time:534469ms step_avg:738.22ms
step:735/1875 train_loss:3.5956 train_time:535202ms step_avg:738.21ms
step:736/1875 train_loss:3.6413 train_time:535949ms step_avg:738.22ms
step:737/1875 train_loss:3.7660 train_time:536679ms step_avg:738.21ms
step:738/1875 train_loss:3.7057 train_time:537412ms step_avg:738.20ms
step:739/1875 train_loss:3.6279 train_time:538137ms step_avg:738.18ms
step:740/1875 train_loss:3.5315 train_time:538866ms step_avg:738.17ms
step:741/1875 train_loss:4.1395 train_time:539624ms step_avg:738.20ms
step:742/1875 train_loss:3.5282 train_time:540362ms step_avg:738.20ms
step:743/1875 train_loss:3.5960 train_time:541101ms step_avg:738.20ms
step:744/1875 train_loss:3.6080 train_time:541855ms step_avg:738.22ms
step:745/1875 train_loss:3.6833 train_time:542596ms step_avg:738.23ms
step:746/1875 train_loss:3.6268 train_time:543327ms step_avg:738.22ms
step:747/1875 train_loss:3.6282 train_time:544052ms step_avg:738.20ms
step:748/1875 train_loss:3.6868 train_time:544786ms step_avg:738.19ms
step:749/1875 train_loss:3.5965 train_time:545531ms step_avg:738.20ms
step:750/1875 train_loss:3.5946 train_time:546284ms step_avg:738.22ms
step:750/1875 val_loss:3.5981 train_time:546295ms step_avg:738.24ms
============== Weight norms: ==============
name = 'module._orig_mod.transformer.h.0.attn.c_q.weight' | fro_norm = 96.16044 | spectral_norm = 16.00842 | nuclear_norm = 2220.00610
name = 'module._orig_mod.transformer.h.0.attn.c_k.weight' | fro_norm = 93.81631 | spectral_norm = 18.44818 | nuclear_norm = 2146.62256
name = 'module._orig_mod.transformer.h.1.attn.c_q.weight' | fro_norm = 96.19691 | spectral_norm = 10.13845 | nuclear_norm = 2225.33252
name = 'module._orig_mod.transformer.h.1.attn.c_k.weight' | fro_norm = 93.43539 | spectral_norm = 10.24634 | nuclear_norm = 2160.08276
name = 'module._orig_mod.transformer.h.2.attn.c_q.weight' | fro_norm = 91.75828 | spectral_norm = 8.82109 | nuclear_norm = 2045.29395
name = 'module._orig_mod.transformer.h.2.attn.c_k.weight' | fro_norm = 92.09209 | spectral_norm = 8.31567 | nuclear_norm = 2063.91162
name = 'module._orig_mod.transformer.h.3.attn.c_q.weight' | fro_norm = 94.76659 | spectral_norm = 9.26853 | nuclear_norm = 2140.31714
name = 'module._orig_mod.transformer.h.3.attn.c_k.weight' | fro_norm = 93.71979 | spectral_norm = 8.95228 | nuclear_norm = 2115.49536
name = 'module._orig_mod.transformer.h.4.attn.c_q.weight' | fro_norm = 93.21466 | spectral_norm = 10.32772 | nuclear_norm = 2118.49194
name = 'module._orig_mod.transformer.h.4.attn.c_k.weight' | fro_norm = 91.56493 | spectral_norm = 10.15392 | nuclear_norm = 2102.89697
name = 'module._orig_mod.transformer.h.5.attn.c_q.weight' | fro_norm = 95.32528 | spectral_norm = 10.15681 | nuclear_norm = 2184.42822
name = 'module._orig_mod.transformer.h.5.attn.c_k.weight' | fro_norm = 94.46593 | spectral_norm = 9.45672 | nuclear_norm = 2171.92334
name = 'module._orig_mod.transformer.h.6.attn.c_q.weight' | fro_norm = 94.01949 | spectral_norm = 9.62726 | nuclear_norm = 2139.54883
name = 'module._orig_mod.transformer.h.6.attn.c_k.weight' | fro_norm = 93.33051 | spectral_norm = 9.10827 | nuclear_norm = 2129.16406
name = 'module._orig_mod.transformer.h.7.attn.c_q.weight' | fro_norm = 95.44527 | spectral_norm = 9.88997 | nuclear_norm = 2179.05005
name = 'module._orig_mod.transformer.h.7.attn.c_k.weight' | fro_norm = 95.09302 | spectral_norm = 9.85038 | nuclear_norm = 2184.84717
name = 'module._orig_mod.transformer.h.8.attn.c_q.weight' | fro_norm = 97.92340 | spectral_norm = 10.33367 | nuclear_norm = 2218.71021
name = 'module._orig_mod.transformer.h.8.attn.c_k.weight' | fro_norm = 98.38579 | spectral_norm = 10.05748 | nuclear_norm = 2215.71167
name = 'module._orig_mod.transformer.h.9.attn.c_q.weight' | fro_norm = 95.91849 | spectral_norm = 9.94279 | nuclear_norm = 2144.72119
name = 'module._orig_mod.transformer.h.9.attn.c_k.weight' | fro_norm = 96.15837 | spectral_norm = 9.30751 | nuclear_norm = 2132.63257
name = 'module._orig_mod.transformer.h.10.attn.c_q.weight' | fro_norm = 98.76183 | spectral_norm = 9.67508 | nuclear_norm = 2253.17578
name = 'module._orig_mod.transformer.h.10.attn.c_k.weight' | fro_norm = 97.02054 | spectral_norm = 9.77758 | nuclear_norm = 2209.15186
name = 'module._orig_mod.transformer.h.11.attn.c_q.weight' | fro_norm = 94.04012 | spectral_norm = 11.51142 | nuclear_norm = 2059.40771
name = 'module._orig_mod.transformer.h.11.attn.c_k.weight' | fro_norm = 93.71764 | spectral_norm = 10.11998 | nuclear_norm = 2033.59766
===========================================
step:751/1875 train_loss:3.6406 train_time:547009ms step_avg:738.20ms
step:752/1875 train_loss:3.6030 train_time:547745ms step_avg:738.20ms
step:753/1875 train_loss:3.6466 train_time:548478ms step_avg:738.19ms
step:754/1875 train_loss:3.6487 train_time:549215ms step_avg:738.19ms
step:755/1875 train_loss:3.6203 train_time:549937ms step_avg:738.17ms
step:756/1875 train_loss:3.7113 train_time:550678ms step_avg:738.17ms
step:757/1875 train_loss:3.4979 train_time:551419ms step_avg:738.18ms
step:758/1875 train_loss:3.7476 train_time:552172ms step_avg:738.20ms
step:759/1875 train_loss:3.6807 train_time:552896ms step_avg:738.18ms
step:760/1875 train_loss:3.6156 train_time:553836ms step_avg:738.45ms
step:761/1875 train_loss:3.7384 train_time:554564ms step_avg:738.43ms
step:762/1875 train_loss:3.6407 train_time:555492ms step_avg:738.69ms
step:763/1875 train_loss:3.4714 train_time:556237ms step_avg:738.69ms
step:764/1875 train_loss:3.4618 train_time:556970ms step_avg:738.69ms
step:765/1875 train_loss:3.5736 train_time:557707ms step_avg:738.68ms
step:766/1875 train_loss:3.5730 train_time:558441ms step_avg:738.68ms
step:767/1875 train_loss:4.6026 train_time:559192ms step_avg:738.69ms
step:768/1875 train_loss:3.5791 train_time:559935ms step_avg:738.70ms
step:769/1875 train_loss:3.6154 train_time:560670ms step_avg:738.70ms
step:770/1875 train_loss:3.7065 train_time:561403ms step_avg:738.69ms
step:771/1875 train_loss:4.2131 train_time:562134ms step_avg:738.68ms
step:772/1875 train_loss:3.6274 train_time:562883ms step_avg:738.69ms
step:773/1875 train_loss:3.6334 train_time:563616ms step_avg:738.68ms
step:774/1875 train_loss:3.5908 train_time:564350ms step_avg:738.68ms
step:775/1875 train_loss:3.7256 train_time:565076ms step_avg:738.66ms
step:776/1875 train_loss:3.5086 train_time:565810ms step_avg:738.66ms
step:777/1875 train_loss:3.6532 train_time:566541ms step_avg:738.65ms
step:778/1875 train_loss:3.6464 train_time:567283ms step_avg:738.65ms
step:779/1875 train_loss:3.6149 train_time:568026ms step_avg:738.65ms
step:780/1875 train_loss:3.6109 train_time:568763ms step_avg:738.65ms
step:781/1875 train_loss:3.4983 train_time:569503ms step_avg:738.66ms
step:782/1875 train_loss:3.6573 train_time:570238ms step_avg:738.65ms
step:783/1875 train_loss:3.6064 train_time:570977ms step_avg:738.65ms
step:784/1875 train_loss:3.5675 train_time:571711ms step_avg:738.65ms
step:785/1875 train_loss:3.5781 train_time:572449ms step_avg:738.64ms
step:786/1875 train_loss:3.5940 train_time:573185ms step_avg:738.64ms
step:787/1875 train_loss:3.5582 train_time:573921ms step_avg:738.64ms
step:788/1875 train_loss:3.6119 train_time:574652ms step_avg:738.63ms
step:789/1875 train_loss:3.5717 train_time:575385ms step_avg:738.62ms
step:790/1875 train_loss:3.5054 train_time:576117ms step_avg:738.61ms
step:791/1875 train_loss:3.5594 train_time:576865ms step_avg:738.62ms
step:792/1875 train_loss:3.6311 train_time:577593ms step_avg:738.61ms
step:793/1875 train_loss:3.6408 train_time:578325ms step_avg:738.60ms
step:794/1875 train_loss:3.6657 train_time:579074ms step_avg:738.61ms
step:795/1875 train_loss:3.5972 train_time:579809ms step_avg:738.61ms
step:796/1875 train_loss:3.7152 train_time:580551ms step_avg:738.61ms
step:797/1875 train_loss:3.6122 train_time:581288ms step_avg:738.61ms
step:798/1875 train_loss:3.4237 train_time:582028ms step_avg:738.61ms
step:799/1875 train_loss:3.4994 train_time:582767ms step_avg:738.62ms
step:800/1875 train_loss:4.2479 train_time:583521ms step_avg:738.63ms
step:801/1875 train_loss:3.7306 train_time:584254ms step_avg:738.63ms
step:802/1875 train_loss:3.5820 train_time:584981ms step_avg:738.61ms
step:803/1875 train_loss:3.6290 train_time:585722ms step_avg:738.61ms
step:804/1875 train_loss:3.6139 train_time:586468ms step_avg:738.63ms
step:805/1875 train_loss:3.5602 train_time:587197ms step_avg:738.61ms
step:806/1875 train_loss:3.5636 train_time:587942ms step_avg:738.62ms
step:807/1875 train_loss:3.5889 train_time:588676ms step_avg:738.61ms
step:808/1875 train_loss:3.6597 train_time:589407ms step_avg:738.61ms
step:809/1875 train_loss:3.8633 train_time:590142ms step_avg:738.60ms
step:810/1875 train_loss:3.7156 train_time:590868ms step_avg:738.59ms
step:811/1875 train_loss:3.5136 train_time:591604ms step_avg:738.58ms
step:812/1875 train_loss:3.6359 train_time:592333ms step_avg:738.57ms
step:813/1875 train_loss:3.6482 train_time:593068ms step_avg:738.57ms
step:814/1875 train_loss:3.5954 train_time:593798ms step_avg:738.56ms
step:815/1875 train_loss:3.4397 train_time:594538ms step_avg:738.56ms
step:816/1875 train_loss:3.7866 train_time:595267ms step_avg:738.55ms
step:817/1875 train_loss:3.6075 train_time:595996ms step_avg:738.53ms
step:818/1875 train_loss:3.5701 train_time:596737ms step_avg:738.54ms
step:819/1875 train_loss:3.5809 train_time:597470ms step_avg:738.53ms
step:820/1875 train_loss:3.5600 train_time:598202ms step_avg:738.52ms
step:821/1875 train_loss:3.4475 train_time:598943ms step_avg:738.52ms
step:822/1875 train_loss:3.5715 train_time:599675ms step_avg:738.52ms
step:823/1875 train_loss:3.6689 train_time:600404ms step_avg:738.50ms
step:824/1875 train_loss:3.4110 train_time:601138ms step_avg:738.50ms
step:825/1875 train_loss:3.6163 train_time:601877ms step_avg:738.50ms
step:826/1875 train_loss:3.7123 train_time:602612ms step_avg:738.50ms
step:827/1875 train_loss:3.4623 train_time:603363ms step_avg:738.51ms
step:828/1875 train_loss:3.5320 train_time:604105ms step_avg:738.51ms
step:829/1875 train_loss:3.5424 train_time:604835ms step_avg:738.50ms
step:830/1875 train_loss:3.6357 train_time:605565ms step_avg:738.49ms
step:831/1875 train_loss:3.4813 train_time:606303ms step_avg:738.49ms
step:832/1875 train_loss:3.6043 train_time:607042ms step_avg:738.49ms
step:833/1875 train_loss:3.6302 train_time:607777ms step_avg:738.49ms
step:834/1875 train_loss:3.6386 train_time:608510ms step_avg:738.48ms
step:835/1875 train_loss:3.4868 train_time:609265ms step_avg:738.50ms
step:836/1875 train_loss:3.7096 train_time:609996ms step_avg:738.49ms
step:837/1875 train_loss:3.4893 train_time:610726ms step_avg:738.48ms
step:838/1875 train_loss:3.4100 train_time:611458ms step_avg:738.48ms
step:839/1875 train_loss:3.6503 train_time:612195ms step_avg:738.47ms
step:840/1875 train_loss:3.5774 train_time:612934ms step_avg:738.47ms
step:841/1875 train_loss:3.6510 train_time:613662ms step_avg:738.46ms
step:842/1875 train_loss:3.5391 train_time:614393ms step_avg:738.45ms
step:843/1875 train_loss:3.5932 train_time:615135ms step_avg:738.46ms
step:844/1875 train_loss:3.5508 train_time:615865ms step_avg:738.45ms
step:845/1875 train_loss:3.5696 train_time:616605ms step_avg:738.45ms
step:846/1875 train_loss:3.5829 train_time:617342ms step_avg:738.45ms
step:847/1875 train_loss:3.6232 train_time:618080ms step_avg:738.45ms
step:848/1875 train_loss:3.5704 train_time:618818ms step_avg:738.45ms
step:849/1875 train_loss:3.4005 train_time:619550ms step_avg:738.44ms
step:850/1875 train_loss:3.6206 train_time:620289ms step_avg:738.44ms
step:851/1875 train_loss:3.5056 train_time:621024ms step_avg:738.44ms
step:852/1875 train_loss:3.6183 train_time:621766ms step_avg:738.44ms
step:853/1875 train_loss:3.3911 train_time:622493ms step_avg:738.43ms
step:854/1875 train_loss:3.6853 train_time:623222ms step_avg:738.42ms
step:855/1875 train_loss:3.6151 train_time:623947ms step_avg:738.40ms
step:856/1875 train_loss:3.3972 train_time:624679ms step_avg:738.39ms
step:857/1875 train_loss:3.6916 train_time:625430ms step_avg:738.41ms
step:858/1875 train_loss:3.6846 train_time:626165ms step_avg:738.40ms
step:859/1875 train_loss:3.4025 train_time:626909ms step_avg:738.41ms
step:860/1875 train_loss:3.5892 train_time:627650ms step_avg:738.41ms
step:861/1875 train_loss:3.6437 train_time:628387ms step_avg:738.41ms
step:862/1875 train_loss:3.4481 train_time:629116ms step_avg:738.40ms
step:863/1875 train_loss:3.5263 train_time:629863ms step_avg:738.41ms
step:864/1875 train_loss:3.8247 train_time:630607ms step_avg:738.42ms
step:865/1875 train_loss:3.7676 train_time:631365ms step_avg:738.44ms
step:866/1875 train_loss:3.5899 train_time:632103ms step_avg:738.44ms
step:867/1875 train_loss:3.5469 train_time:632830ms step_avg:738.43ms
step:868/1875 train_loss:3.7308 train_time:633573ms step_avg:738.43ms
step:869/1875 train_loss:3.4715 train_time:634316ms step_avg:738.44ms
step:870/1875 train_loss:3.4184 train_time:635052ms step_avg:738.43ms
step:871/1875 train_loss:3.5947 train_time:635787ms step_avg:738.43ms
step:872/1875 train_loss:3.5499 train_time:636524ms step_avg:738.43ms
step:873/1875 train_loss:3.5011 train_time:637256ms step_avg:738.42ms
step:874/1875 train_loss:3.6432 train_time:637986ms step_avg:738.41ms
step:875/1875 train_loss:3.5457 train_time:638725ms step_avg:738.41ms
step:875/1875 val_loss:3.5514 train_time:638737ms step_avg:738.42ms
============== Weight norms: ==============
name = 'module._orig_mod.transformer.h.0.attn.c_q.weight' | fro_norm = 108.34432 | spectral_norm = 18.57036 | nuclear_norm = 2496.35596
name = 'module._orig_mod.transformer.h.0.attn.c_k.weight' | fro_norm = 105.67573 | spectral_norm = 21.63367 | nuclear_norm = 2415.21411
name = 'module._orig_mod.transformer.h.1.attn.c_q.weight' | fro_norm = 108.48046 | spectral_norm = 11.32599 | nuclear_norm = 2507.30054
name = 'module._orig_mod.transformer.h.1.attn.c_k.weight' | fro_norm = 105.24325 | spectral_norm = 11.52160 | nuclear_norm = 2429.13330
name = 'module._orig_mod.transformer.h.2.attn.c_q.weight' | fro_norm = 103.19887 | spectral_norm = 10.09958 | nuclear_norm = 2291.47900
name = 'module._orig_mod.transformer.h.2.attn.c_k.weight' | fro_norm = 103.60886 | spectral_norm = 9.47806 | nuclear_norm = 2312.52930
name = 'module._orig_mod.transformer.h.3.attn.c_q.weight' | fro_norm = 106.73598 | spectral_norm = 10.43532 | nuclear_norm = 2405.32251
name = 'module._orig_mod.transformer.h.3.attn.c_k.weight' | fro_norm = 105.47977 | spectral_norm = 10.15685 | nuclear_norm = 2374.09741
name = 'module._orig_mod.transformer.h.4.attn.c_q.weight' | fro_norm = 104.89301 | spectral_norm = 11.83992 | nuclear_norm = 2376.82129
name = 'module._orig_mod.transformer.h.4.attn.c_k.weight' | fro_norm = 103.18382 | spectral_norm = 11.50531 | nuclear_norm = 2364.74292
name = 'module._orig_mod.transformer.h.5.attn.c_q.weight' | fro_norm = 107.44172 | spectral_norm = 11.55686 | nuclear_norm = 2457.30396
name = 'module._orig_mod.transformer.h.5.attn.c_k.weight' | fro_norm = 106.33810 | spectral_norm = 10.69368 | nuclear_norm = 2441.43945
name = 'module._orig_mod.transformer.h.6.attn.c_q.weight' | fro_norm = 105.73052 | spectral_norm = 10.81838 | nuclear_norm = 2400.42139
name = 'module._orig_mod.transformer.h.6.attn.c_k.weight' | fro_norm = 104.97031 | spectral_norm = 10.34264 | nuclear_norm = 2388.08838
name = 'module._orig_mod.transformer.h.7.attn.c_q.weight' | fro_norm = 107.36285 | spectral_norm = 11.14142 | nuclear_norm = 2444.82861
name = 'module._orig_mod.transformer.h.7.attn.c_k.weight' | fro_norm = 107.07538 | spectral_norm = 11.28119 | nuclear_norm = 2455.78101
name = 'module._orig_mod.transformer.h.8.attn.c_q.weight' | fro_norm = 110.45428 | spectral_norm = 11.75951 | nuclear_norm = 2493.96289
name = 'module._orig_mod.transformer.h.8.attn.c_k.weight' | fro_norm = 110.83945 | spectral_norm = 11.55088 | nuclear_norm = 2486.96606
name = 'module._orig_mod.transformer.h.9.attn.c_q.weight' | fro_norm = 108.02770 | spectral_norm = 11.41446 | nuclear_norm = 2405.31421
name = 'module._orig_mod.transformer.h.9.attn.c_k.weight' | fro_norm = 108.25214 | spectral_norm = 10.76561 | nuclear_norm = 2389.19800
name = 'module._orig_mod.transformer.h.10.attn.c_q.weight' | fro_norm = 111.27647 | spectral_norm = 11.06883 | nuclear_norm = 2531.54736
name = 'module._orig_mod.transformer.h.10.attn.c_k.weight' | fro_norm = 109.16439 | spectral_norm = 11.26491 | nuclear_norm = 2477.38232
name = 'module._orig_mod.transformer.h.11.attn.c_q.weight' | fro_norm = 105.64531 | spectral_norm = 13.28541 | nuclear_norm = 2299.47974
name = 'module._orig_mod.transformer.h.11.attn.c_k.weight' | fro_norm = 105.00746 | spectral_norm = 11.68724 | nuclear_norm = 2265.28467
===========================================
step:876/1875 train_loss:3.6528 train_time:639465ms step_avg:738.41ms
step:877/1875 train_loss:3.4439 train_time:640198ms step_avg:738.41ms
step:878/1875 train_loss:3.6604 train_time:640935ms step_avg:738.40ms
step:879/1875 train_loss:3.5215 train_time:641666ms step_avg:738.40ms
step:880/1875 train_loss:3.8800 train_time:642398ms step_avg:738.39ms
step:881/1875 train_loss:3.5871 train_time:643128ms step_avg:738.38ms
step:882/1875 train_loss:3.4132 train_time:643854ms step_avg:738.37ms
step:883/1875 train_loss:3.7331 train_time:644589ms step_avg:738.36ms
step:884/1875 train_loss:3.4408 train_time:645321ms step_avg:738.35ms
step:885/1875 train_loss:3.6960 train_time:646049ms step_avg:738.34ms
step:886/1875 train_loss:3.5647 train_time:646793ms step_avg:738.35ms
step:887/1875 train_loss:3.6272 train_time:647534ms step_avg:738.35ms
step:888/1875 train_loss:3.6099 train_time:648262ms step_avg:738.34ms
step:889/1875 train_loss:3.6378 train_time:648999ms step_avg:738.34ms
step:890/1875 train_loss:3.6011 train_time:649748ms step_avg:738.35ms
step:891/1875 train_loss:3.4414 train_time:650479ms step_avg:738.34ms
step:892/1875 train_loss:3.6190 train_time:651214ms step_avg:738.34ms
step:893/1875 train_loss:3.5250 train_time:651950ms step_avg:738.33ms
step:894/1875 train_loss:3.5926 train_time:652681ms step_avg:738.33ms
step:895/1875 train_loss:3.4170 train_time:653408ms step_avg:738.31ms
step:896/1875 train_loss:3.3512 train_time:654155ms step_avg:738.32ms
step:897/1875 train_loss:3.4935 train_time:654895ms step_avg:738.33ms
step:898/1875 train_loss:3.6726 train_time:655639ms step_avg:738.33ms
step:899/1875 train_loss:3.5414 train_time:656369ms step_avg:738.32ms
step:900/1875 train_loss:3.6028 train_time:657112ms step_avg:738.33ms
step:901/1875 train_loss:3.7566 train_time:657837ms step_avg:738.31ms
step:902/1875 train_loss:3.5250 train_time:658572ms step_avg:738.31ms
step:903/1875 train_loss:3.4777 train_time:659308ms step_avg:738.31ms
step:904/1875 train_loss:3.7033 train_time:660054ms step_avg:738.32ms
step:905/1875 train_loss:3.6533 train_time:660783ms step_avg:738.30ms
step:906/1875 train_loss:3.4946 train_time:661518ms step_avg:738.30ms
step:907/1875 train_loss:3.5059 train_time:662252ms step_avg:738.30ms
step:908/1875 train_loss:3.7971 train_time:663002ms step_avg:738.31ms
step:909/1875 train_loss:3.5135 train_time:663741ms step_avg:738.31ms
step:910/1875 train_loss:3.6929 train_time:664476ms step_avg:738.31ms
step:911/1875 train_loss:3.8805 train_time:665225ms step_avg:738.32ms
step:912/1875 train_loss:3.3303 train_time:665952ms step_avg:738.31ms
step:913/1875 train_loss:3.6657 train_time:666682ms step_avg:738.30ms
step:914/1875 train_loss:3.5183 train_time:667425ms step_avg:738.30ms
step:915/1875 train_loss:3.6010 train_time:668169ms step_avg:738.31ms
step:916/1875 train_loss:3.7459 train_time:668911ms step_avg:738.31ms
step:917/1875 train_loss:3.5111 train_time:669641ms step_avg:738.30ms
step:918/1875 train_loss:3.4977 train_time:670388ms step_avg:738.31ms
step:919/1875 train_loss:3.5815 train_time:671121ms step_avg:738.31ms
step:920/1875 train_loss:3.4784 train_time:671862ms step_avg:738.31ms
step:921/1875 train_loss:3.5314 train_time:672613ms step_avg:738.32ms
step:922/1875 train_loss:3.4819 train_time:673341ms step_avg:738.31ms
step:923/1875 train_loss:3.6447 train_time:674079ms step_avg:738.31ms
step:924/1875 train_loss:3.5086 train_time:674807ms step_avg:738.30ms
step:925/1875 train_loss:3.5016 train_time:675538ms step_avg:738.29ms
step:926/1875 train_loss:3.6247 train_time:676278ms step_avg:738.29ms
step:927/1875 train_loss:3.4975 train_time:677011ms step_avg:738.29ms
step:928/1875 train_loss:3.6834 train_time:677751ms step_avg:738.29ms
step:929/1875 train_loss:3.5545 train_time:678477ms step_avg:738.28ms
step:930/1875 train_loss:3.3945 train_time:679217ms step_avg:738.28ms
step:931/1875 train_loss:3.7206 train_time:679946ms step_avg:738.27ms
step:932/1875 train_loss:3.4075 train_time:680680ms step_avg:738.26ms
step:933/1875 train_loss:3.3978 train_time:681416ms step_avg:738.26ms
step:934/1875 train_loss:3.6091 train_time:682155ms step_avg:738.26ms
step:935/1875 train_loss:3.5684 train_time:682887ms step_avg:738.26ms
step:936/1875 train_loss:3.4128 train_time:683643ms step_avg:738.28ms
step:937/1875 train_loss:3.3676 train_time:684380ms step_avg:738.27ms
step:938/1875 train_loss:3.5319 train_time:685112ms step_avg:738.27ms
step:939/1875 train_loss:3.3368 train_time:685846ms step_avg:738.26ms
step:940/1875 train_loss:3.6156 train_time:686576ms step_avg:738.25ms
step:941/1875 train_loss:3.4535 train_time:687321ms step_avg:738.26ms
step:942/1875 train_loss:3.4525 train_time:688061ms step_avg:738.26ms
step:943/1875 train_loss:3.5790 train_time:688805ms step_avg:738.27ms
step:944/1875 train_loss:3.4728 train_time:689539ms step_avg:738.26ms
step:945/1875 train_loss:3.4731 train_time:690272ms step_avg:738.26ms
step:946/1875 train_loss:3.6406 train_time:691016ms step_avg:738.26ms
step:947/1875 train_loss:3.5447 train_time:691752ms step_avg:738.26ms
step:948/1875 train_loss:3.6167 train_time:692501ms step_avg:738.27ms
step:949/1875 train_loss:3.7832 train_time:693237ms step_avg:738.27ms
step:950/1875 train_loss:3.4050 train_time:694175ms step_avg:738.48ms
step:951/1875 train_loss:3.4810 train_time:694907ms step_avg:738.48ms
step:952/1875 train_loss:3.7309 train_time:695645ms step_avg:738.48ms
step:953/1875 train_loss:3.4341 train_time:696376ms step_avg:738.47ms
step:954/1875 train_loss:3.5022 train_time:697117ms step_avg:738.47ms
step:955/1875 train_loss:3.6041 train_time:697867ms step_avg:738.48ms
step:956/1875 train_loss:3.4746 train_time:698603ms step_avg:738.48ms
step:957/1875 train_loss:3.5165 train_time:699330ms step_avg:738.47ms
step:958/1875 train_loss:3.4758 train_time:700081ms step_avg:738.48ms
step:959/1875 train_loss:3.5347 train_time:700820ms step_avg:738.48ms
step:960/1875 train_loss:3.5340 train_time:701555ms step_avg:738.48ms
step:961/1875 train_loss:3.5468 train_time:702292ms step_avg:738.48ms
step:962/1875 train_loss:3.4324 train_time:703046ms step_avg:738.49ms
step:963/1875 train_loss:3.6805 train_time:703781ms step_avg:738.49ms
step:964/1875 train_loss:3.6421 train_time:704512ms step_avg:738.48ms
step:965/1875 train_loss:3.4600 train_time:705248ms step_avg:738.48ms
step:966/1875 train_loss:3.4612 train_time:705988ms step_avg:738.48ms
step:967/1875 train_loss:3.5106 train_time:706716ms step_avg:738.47ms
step:968/1875 train_loss:3.7529 train_time:707452ms step_avg:738.47ms
step:969/1875 train_loss:3.5566 train_time:708183ms step_avg:738.46ms
step:970/1875 train_loss:3.5575 train_time:708909ms step_avg:738.45ms
step:971/1875 train_loss:3.6176 train_time:709649ms step_avg:738.45ms
step:972/1875 train_loss:3.4063 train_time:710384ms step_avg:738.45ms
step:973/1875 train_loss:3.5706 train_time:711119ms step_avg:738.44ms
step:974/1875 train_loss:3.5176 train_time:711852ms step_avg:738.44ms
step:975/1875 train_loss:3.5767 train_time:712587ms step_avg:738.43ms
step:976/1875 train_loss:3.6282 train_time:713318ms step_avg:738.42ms
step:977/1875 train_loss:3.5055 train_time:714054ms step_avg:738.42ms
step:978/1875 train_loss:3.7050 train_time:714784ms step_avg:738.41ms
step:979/1875 train_loss:3.6132 train_time:715514ms step_avg:738.40ms
step:980/1875 train_loss:3.3897 train_time:716249ms step_avg:738.40ms
step:981/1875 train_loss:3.6684 train_time:716983ms step_avg:738.40ms
step:982/1875 train_loss:3.4555 train_time:717713ms step_avg:738.39ms
step:983/1875 train_loss:3.6123 train_time:718438ms step_avg:738.37ms
step:984/1875 train_loss:3.5812 train_time:719177ms step_avg:738.37ms
step:985/1875 train_loss:3.5520 train_time:719924ms step_avg:738.38ms
step:986/1875 train_loss:3.5373 train_time:720658ms step_avg:738.38ms
step:987/1875 train_loss:3.6175 train_time:721396ms step_avg:738.38ms
step:988/1875 train_loss:3.4610 train_time:722127ms step_avg:738.37ms
step:989/1875 train_loss:3.5295 train_time:722861ms step_avg:738.37ms
step:990/1875 train_loss:3.5143 train_time:723595ms step_avg:738.36ms
step:991/1875 train_loss:3.4586 train_time:724343ms step_avg:738.37ms
step:992/1875 train_loss:3.6956 train_time:725096ms step_avg:738.39ms
step:993/1875 train_loss:3.5104 train_time:725827ms step_avg:738.38ms
step:994/1875 train_loss:3.4745 train_time:726561ms step_avg:738.38ms
step:995/1875 train_loss:3.5483 train_time:727316ms step_avg:738.39ms
step:996/1875 train_loss:3.6375 train_time:728049ms step_avg:738.39ms
step:997/1875 train_loss:3.5764 train_time:728775ms step_avg:738.37ms
step:998/1875 train_loss:3.4974 train_time:729511ms step_avg:738.37ms
step:999/1875 train_loss:3.8180 train_time:730241ms step_avg:738.36ms
step:1000/1875 train_loss:3.4896 train_time:730971ms step_avg:738.35ms
step:1000/1875 val_loss:3.5132 train_time:730982ms step_avg:738.37ms
============== Weight norms: ==============
name = 'module._orig_mod.transformer.h.0.attn.c_q.weight' | fro_norm = 119.23460 | spectral_norm = 20.93274 | nuclear_norm = 2744.30615
name = 'module._orig_mod.transformer.h.0.attn.c_k.weight' | fro_norm = 116.41225 | spectral_norm = 24.55640 | nuclear_norm = 2655.42017
name = 'module._orig_mod.transformer.h.1.attn.c_q.weight' | fro_norm = 119.65724 | spectral_norm = 12.46455 | nuclear_norm = 2763.81177
name = 'module._orig_mod.transformer.h.1.attn.c_k.weight' | fro_norm = 116.06882 | spectral_norm = 12.67469 | nuclear_norm = 2677.67285
name = 'module._orig_mod.transformer.h.2.attn.c_q.weight' | fro_norm = 113.65463 | spectral_norm = 11.11173 | nuclear_norm = 2513.56934
name = 'module._orig_mod.transformer.h.2.attn.c_k.weight' | fro_norm = 114.30165 | spectral_norm = 10.51593 | nuclear_norm = 2543.13965
name = 'module._orig_mod.transformer.h.3.attn.c_q.weight' | fro_norm = 117.45989 | spectral_norm = 11.60033 | nuclear_norm = 2641.35278
name = 'module._orig_mod.transformer.h.3.attn.c_k.weight' | fro_norm = 116.13272 | spectral_norm = 11.30114 | nuclear_norm = 2609.25439
name = 'module._orig_mod.transformer.h.4.attn.c_q.weight' | fro_norm = 115.64513 | spectral_norm = 13.22698 | nuclear_norm = 2614.46704
name = 'module._orig_mod.transformer.h.4.attn.c_k.weight' | fro_norm = 113.66171 | spectral_norm = 12.76888 | nuclear_norm = 2602.29053
name = 'module._orig_mod.transformer.h.5.attn.c_q.weight' | fro_norm = 118.35369 | spectral_norm = 12.84563 | nuclear_norm = 2702.01709
name = 'module._orig_mod.transformer.h.5.attn.c_k.weight' | fro_norm = 117.09425 | spectral_norm = 11.80332 | nuclear_norm = 2685.84814
name = 'module._orig_mod.transformer.h.6.attn.c_q.weight' | fro_norm = 116.21144 | spectral_norm = 11.99435 | nuclear_norm = 2632.67480
name = 'module._orig_mod.transformer.h.6.attn.c_k.weight' | fro_norm = 115.46066 | spectral_norm = 11.43827 | nuclear_norm = 2620.41284
name = 'module._orig_mod.transformer.h.7.attn.c_q.weight' | fro_norm = 118.14373 | spectral_norm = 12.50856 | nuclear_norm = 2685.32959
name = 'module._orig_mod.transformer.h.7.attn.c_k.weight' | fro_norm = 117.94480 | spectral_norm = 12.61160 | nuclear_norm = 2699.25928
name = 'module._orig_mod.transformer.h.8.attn.c_q.weight' | fro_norm = 121.78137 | spectral_norm = 12.99173 | nuclear_norm = 2742.08252
name = 'module._orig_mod.transformer.h.8.attn.c_k.weight' | fro_norm = 122.10231 | spectral_norm = 12.93100 | nuclear_norm = 2733.29053
name = 'module._orig_mod.transformer.h.9.attn.c_q.weight' | fro_norm = 118.95168 | spectral_norm = 12.73944 | nuclear_norm = 2639.34082
name = 'module._orig_mod.transformer.h.9.attn.c_k.weight' | fro_norm = 119.33336 | spectral_norm = 12.06578 | nuclear_norm = 2625.74658
name = 'module._orig_mod.transformer.h.10.attn.c_q.weight' | fro_norm = 122.56846 | spectral_norm = 12.45801 | nuclear_norm = 2779.15820
name = 'module._orig_mod.transformer.h.10.attn.c_k.weight' | fro_norm = 120.17203 | spectral_norm = 12.66063 | nuclear_norm = 2719.80225
name = 'module._orig_mod.transformer.h.11.attn.c_q.weight' | fro_norm = 116.16792 | spectral_norm = 14.95406 | nuclear_norm = 2515.76318
name = 'module._orig_mod.transformer.h.11.attn.c_k.weight' | fro_norm = 115.04472 | spectral_norm = 13.08135 | nuclear_norm = 2468.76074
===========================================
step:1001/1875 train_loss:3.6322 train_time:731695ms step_avg:738.34ms
step:1002/1875 train_loss:3.4796 train_time:732423ms step_avg:738.33ms
step:1003/1875 train_loss:3.5470 train_time:733149ms step_avg:738.32ms
step:1004/1875 train_loss:3.4202 train_time:733892ms step_avg:738.32ms
step:1005/1875 train_loss:3.6059 train_time:734634ms step_avg:738.33ms
step:1006/1875 train_loss:3.6544 train_time:735376ms step_avg:738.33ms
step:1007/1875 train_loss:3.4312 train_time:736109ms step_avg:738.32ms
step:1008/1875 train_loss:3.5042 train_time:736845ms step_avg:738.32ms
step:1009/1875 train_loss:3.4878 train_time:737579ms step_avg:738.32ms
step:1010/1875 train_loss:3.6092 train_time:738325ms step_avg:738.32ms
step:1011/1875 train_loss:3.7168 train_time:739079ms step_avg:738.34ms
step:1012/1875 train_loss:3.6033 train_time:739816ms step_avg:738.34ms
step:1013/1875 train_loss:3.5812 train_time:740550ms step_avg:738.33ms
step:1014/1875 train_loss:3.4376 train_time:741294ms step_avg:738.34ms
step:1015/1875 train_loss:3.5817 train_time:742021ms step_avg:738.33ms
step:1016/1875 train_loss:3.6731 train_time:742749ms step_avg:738.32ms
step:1017/1875 train_loss:3.3730 train_time:743480ms step_avg:738.31ms
step:1018/1875 train_loss:3.4578 train_time:744230ms step_avg:738.32ms
step:1019/1875 train_loss:3.4492 train_time:744977ms step_avg:738.33ms
step:1020/1875 train_loss:3.4410 train_time:745703ms step_avg:738.32ms
step:1021/1875 train_loss:3.5716 train_time:746437ms step_avg:738.32ms
step:1022/1875 train_loss:3.4406 train_time:747176ms step_avg:738.32ms
step:1023/1875 train_loss:3.3930 train_time:747912ms step_avg:738.31ms
step:1024/1875 train_loss:3.5286 train_time:748650ms step_avg:738.31ms
step:1025/1875 train_loss:3.5506 train_time:749391ms step_avg:738.32ms
step:1026/1875 train_loss:3.5213 train_time:750132ms step_avg:738.32ms
step:1027/1875 train_loss:3.5332 train_time:750873ms step_avg:738.32ms
step:1028/1875 train_loss:3.6821 train_time:751604ms step_avg:738.31ms
step:1029/1875 train_loss:3.3713 train_time:752346ms step_avg:738.32ms
step:1030/1875 train_loss:3.4409 train_time:753101ms step_avg:738.33ms
step:1031/1875 train_loss:3.3653 train_time:753838ms step_avg:738.33ms
step:1032/1875 train_loss:3.5846 train_time:754566ms step_avg:738.32ms
step:1033/1875 train_loss:3.5685 train_time:755298ms step_avg:738.32ms
step:1034/1875 train_loss:3.7405 train_time:756037ms step_avg:738.32ms
step:1035/1875 train_loss:3.5470 train_time:756773ms step_avg:738.31ms
step:1036/1875 train_loss:3.4556 train_time:757519ms step_avg:738.32ms
step:1037/1875 train_loss:3.4929 train_time:758255ms step_avg:738.32ms
step:1038/1875 train_loss:3.5383 train_time:758989ms step_avg:738.32ms
step:1039/1875 train_loss:3.8457 train_time:759723ms step_avg:738.31ms
step:1040/1875 train_loss:3.6723 train_time:760455ms step_avg:738.31ms
step:1041/1875 train_loss:3.5647 train_time:761184ms step_avg:738.30ms
step:1042/1875 train_loss:3.4700 train_time:761917ms step_avg:738.29ms
step:1043/1875 train_loss:3.5394 train_time:762657ms step_avg:738.29ms
step:1044/1875 train_loss:3.5726 train_time:763401ms step_avg:738.30ms
step:1045/1875 train_loss:3.4920 train_time:764126ms step_avg:738.29ms
step:1046/1875 train_loss:3.5049 train_time:764856ms step_avg:738.28ms
step:1047/1875 train_loss:3.5703 train_time:765594ms step_avg:738.28ms
step:1048/1875 train_loss:3.4781 train_time:766330ms step_avg:738.28ms
step:1049/1875 train_loss:3.7011 train_time:767072ms step_avg:738.28ms
step:1050/1875 train_loss:3.5545 train_time:767817ms step_avg:738.29ms
step:1051/1875 train_loss:3.4599 train_time:768552ms step_avg:738.28ms
step:1052/1875 train_loss:3.4494 train_time:769289ms step_avg:738.28ms
step:1053/1875 train_loss:3.5565 train_time:770021ms step_avg:738.28ms
step:1054/1875 train_loss:3.4151 train_time:770757ms step_avg:738.27ms
step:1055/1875 train_loss:3.7520 train_time:771484ms step_avg:738.26ms
step:1056/1875 train_loss:3.5959 train_time:772222ms step_avg:738.26ms
step:1057/1875 train_loss:3.4402 train_time:772959ms step_avg:738.26ms
step:1058/1875 train_loss:3.5586 train_time:773696ms step_avg:738.26ms
step:1059/1875 train_loss:3.6398 train_time:774423ms step_avg:738.25ms
step:1060/1875 train_loss:3.3597 train_time:775162ms step_avg:738.25ms
step:1061/1875 train_loss:3.4219 train_time:775908ms step_avg:738.26ms
step:1062/1875 train_loss:3.4911 train_time:776639ms step_avg:738.25ms
step:1063/1875 train_loss:3.4729 train_time:777373ms step_avg:738.25ms
step:1064/1875 train_loss:3.4429 train_time:778107ms step_avg:738.24ms
step:1065/1875 train_loss:3.5260 train_time:778840ms step_avg:738.24ms
step:1066/1875 train_loss:3.4437 train_time:779571ms step_avg:738.23ms
step:1067/1875 train_loss:3.4177 train_time:780303ms step_avg:738.22ms
step:1068/1875 train_loss:3.4676 train_time:781042ms step_avg:738.22ms
step:1069/1875 train_loss:3.3437 train_time:781781ms step_avg:738.23ms
step:1070/1875 train_loss:3.4878 train_time:782510ms step_avg:738.22ms
step:1071/1875 train_loss:3.3608 train_time:783255ms step_avg:738.22ms
step:1072/1875 train_loss:3.6273 train_time:783984ms step_avg:738.21ms
step:1073/1875 train_loss:3.5678 train_time:784730ms step_avg:738.22ms
step:1074/1875 train_loss:3.4961 train_time:785461ms step_avg:738.22ms
step:1075/1875 train_loss:3.5817 train_time:786193ms step_avg:738.21ms
step:1076/1875 train_loss:3.5010 train_time:786932ms step_avg:738.21ms
step:1077/1875 train_loss:3.4621 train_time:787662ms step_avg:738.20ms
step:1078/1875 train_loss:3.8538 train_time:788390ms step_avg:738.19ms
step:1079/1875 train_loss:3.4911 train_time:789125ms step_avg:738.19ms
step:1080/1875 train_loss:3.1560 train_time:789883ms step_avg:738.21ms
step:1081/1875 train_loss:3.5899 train_time:790615ms step_avg:738.20ms
step:1082/1875 train_loss:3.4904 train_time:791351ms step_avg:738.20ms
step:1083/1875 train_loss:3.5757 train_time:792104ms step_avg:738.21ms
step:1084/1875 train_loss:3.6590 train_time:792836ms step_avg:738.21ms
step:1085/1875 train_loss:3.5641 train_time:793566ms step_avg:738.20ms
step:1086/1875 train_loss:3.5306 train_time:794297ms step_avg:738.19ms
step:1087/1875 train_loss:3.4941 train_time:795030ms step_avg:738.19ms
step:1088/1875 train_loss:3.6977 train_time:795778ms step_avg:738.20ms
step:1089/1875 train_loss:3.5780 train_time:796529ms step_avg:738.21ms
step:1090/1875 train_loss:3.4233 train_time:797257ms step_avg:738.20ms
step:1091/1875 train_loss:3.4398 train_time:797995ms step_avg:738.20ms
step:1092/1875 train_loss:3.5486 train_time:798734ms step_avg:738.20ms
step:1093/1875 train_loss:3.3479 train_time:799470ms step_avg:738.20ms
step:1094/1875 train_loss:3.5586 train_time:800195ms step_avg:738.19ms
step:1095/1875 train_loss:3.6725 train_time:800928ms step_avg:738.18ms
step:1096/1875 train_loss:3.5112 train_time:801670ms step_avg:738.19ms
step:1097/1875 train_loss:3.4771 train_time:802406ms step_avg:738.18ms
step:1098/1875 train_loss:3.4908 train_time:803145ms step_avg:738.18ms
step:1099/1875 train_loss:3.5547 train_time:803877ms step_avg:738.18ms
step:1100/1875 train_loss:3.6244 train_time:804618ms step_avg:738.18ms
step:1101/1875 train_loss:3.6015 train_time:805365ms step_avg:738.19ms
step:1102/1875 train_loss:3.5029 train_time:806103ms step_avg:738.19ms
step:1103/1875 train_loss:3.3570 train_time:806838ms step_avg:738.19ms
step:1104/1875 train_loss:3.3991 train_time:807576ms step_avg:738.19ms
step:1105/1875 train_loss:3.5133 train_time:808317ms step_avg:738.19ms
step:1106/1875 train_loss:3.3793 train_time:809052ms step_avg:738.19ms
step:1107/1875 train_loss:4.1366 train_time:809800ms step_avg:738.20ms
step:1108/1875 train_loss:3.2956 train_time:810531ms step_avg:738.19ms
step:1109/1875 train_loss:3.6353 train_time:811263ms step_avg:738.18ms
step:1110/1875 train_loss:3.4106 train_time:811993ms step_avg:738.18ms
step:1111/1875 train_loss:3.5675 train_time:812721ms step_avg:738.17ms
step:1112/1875 train_loss:3.5019 train_time:813451ms step_avg:738.16ms
step:1113/1875 train_loss:3.5519 train_time:814192ms step_avg:738.16ms
step:1114/1875 train_loss:3.6320 train_time:814924ms step_avg:738.16ms
step:1115/1875 train_loss:3.5090 train_time:815650ms step_avg:738.14ms
step:1116/1875 train_loss:3.4337 train_time:816389ms step_avg:738.15ms
step:1117/1875 train_loss:3.3209 train_time:817151ms step_avg:738.17ms
step:1118/1875 train_loss:3.4951 train_time:817876ms step_avg:738.15ms
step:1119/1875 train_loss:3.6727 train_time:818625ms step_avg:738.16ms
step:1120/1875 train_loss:3.7010 train_time:819353ms step_avg:738.16ms
step:1121/1875 train_loss:3.5525 train_time:820085ms step_avg:738.15ms
step:1122/1875 train_loss:3.5671 train_time:820819ms step_avg:738.15ms
step:1123/1875 train_loss:3.4591 train_time:821546ms step_avg:738.14ms
step:1124/1875 train_loss:3.5267 train_time:822270ms step_avg:738.12ms
step:1125/1875 train_loss:3.6611 train_time:823017ms step_avg:738.13ms
step:1125/1875 val_loss:3.4867 train_time:823028ms step_avg:738.14ms
============== Weight norms: ==============
name = 'module._orig_mod.transformer.h.0.attn.c_q.weight' | fro_norm = 129.34061 | spectral_norm = 23.08943 | nuclear_norm = 2973.91675
name = 'module._orig_mod.transformer.h.0.attn.c_k.weight' | fro_norm = 126.28912 | spectral_norm = 27.29212 | nuclear_norm = 2876.43750
name = 'module._orig_mod.transformer.h.1.attn.c_q.weight' | fro_norm = 129.91716 | spectral_norm = 13.45332 | nuclear_norm = 2998.34180
name = 'module._orig_mod.transformer.h.1.attn.c_k.weight' | fro_norm = 125.87225 | spectral_norm = 13.71637 | nuclear_norm = 2903.17285
name = 'module._orig_mod.transformer.h.2.attn.c_q.weight' | fro_norm = 123.17705 | spectral_norm = 12.16630 | nuclear_norm = 2715.31177
name = 'module._orig_mod.transformer.h.2.attn.c_k.weight' | fro_norm = 124.05196 | spectral_norm = 11.59691 | nuclear_norm = 2754.09863
name = 'module._orig_mod.transformer.h.3.attn.c_q.weight' | fro_norm = 127.36559 | spectral_norm = 12.64693 | nuclear_norm = 2860.03857
name = 'module._orig_mod.transformer.h.3.attn.c_k.weight' | fro_norm = 125.86440 | spectral_norm = 12.22631 | nuclear_norm = 2822.00391
name = 'module._orig_mod.transformer.h.4.attn.c_q.weight' | fro_norm = 125.47692 | spectral_norm = 14.53347 | nuclear_norm = 2830.78638
name = 'module._orig_mod.transformer.h.4.attn.c_k.weight' | fro_norm = 123.51345 | spectral_norm = 13.86104 | nuclear_norm = 2825.81543
name = 'module._orig_mod.transformer.h.5.attn.c_q.weight' | fro_norm = 128.34576 | spectral_norm = 14.00896 | nuclear_norm = 2925.05127
name = 'module._orig_mod.transformer.h.5.attn.c_k.weight' | fro_norm = 126.90040 | spectral_norm = 12.83874 | nuclear_norm = 2906.14551
name = 'module._orig_mod.transformer.h.6.attn.c_q.weight' | fro_norm = 125.90211 | spectral_norm = 13.03724 | nuclear_norm = 2846.71997
name = 'module._orig_mod.transformer.h.6.attn.c_k.weight' | fro_norm = 125.12277 | spectral_norm = 12.46771 | nuclear_norm = 2834.40674
name = 'module._orig_mod.transformer.h.7.attn.c_q.weight' | fro_norm = 128.17616 | spectral_norm = 13.68073 | nuclear_norm = 2908.01318
name = 'module._orig_mod.transformer.h.7.attn.c_k.weight' | fro_norm = 127.93000 | spectral_norm = 13.75717 | nuclear_norm = 2925.40820
name = 'module._orig_mod.transformer.h.8.attn.c_q.weight' | fro_norm = 132.07733 | spectral_norm = 14.08603 | nuclear_norm = 2965.22266
name = 'module._orig_mod.transformer.h.8.attn.c_k.weight' | fro_norm = 132.41461 | spectral_norm = 14.15452 | nuclear_norm = 2957.35083
name = 'module._orig_mod.transformer.h.9.attn.c_q.weight' | fro_norm = 129.07533 | spectral_norm = 13.99699 | nuclear_norm = 2856.04639
name = 'module._orig_mod.transformer.h.9.attn.c_k.weight' | fro_norm = 129.43614 | spectral_norm = 13.29523 | nuclear_norm = 2837.81934
name = 'module._orig_mod.transformer.h.10.attn.c_q.weight' | fro_norm = 133.06122 | spectral_norm = 13.80386 | nuclear_norm = 3010.34717
name = 'module._orig_mod.transformer.h.10.attn.c_k.weight' | fro_norm = 130.33038 | spectral_norm = 13.94735 | nuclear_norm = 2943.05322
name = 'module._orig_mod.transformer.h.11.attn.c_q.weight' | fro_norm = 125.70592 | spectral_norm = 16.41949 | nuclear_norm = 2709.43945
name = 'module._orig_mod.transformer.h.11.attn.c_k.weight' | fro_norm = 124.31028 | spectral_norm = 14.38571 | nuclear_norm = 2657.25708
===========================================
step:1126/1875 train_loss:3.4206 train_time:823753ms step_avg:738.13ms
step:1127/1875 train_loss:3.2787 train_time:824493ms step_avg:738.13ms
step:1128/1875 train_loss:3.5529 train_time:825239ms step_avg:738.14ms
step:1129/1875 train_loss:3.7575 train_time:825971ms step_avg:738.13ms
step:1130/1875 train_loss:3.3039 train_time:826711ms step_avg:738.13ms
step:1131/1875 train_loss:3.6361 train_time:827444ms step_avg:738.13ms
step:1132/1875 train_loss:3.4600 train_time:828174ms step_avg:738.12ms
step:1133/1875 train_loss:3.4790 train_time:828907ms step_avg:738.12ms
step:1134/1875 train_loss:3.4331 train_time:829640ms step_avg:738.11ms
step:1135/1875 train_loss:3.5771 train_time:830387ms step_avg:738.12ms
step:1136/1875 train_loss:3.5294 train_time:831121ms step_avg:738.12ms
step:1137/1875 train_loss:3.5952 train_time:831856ms step_avg:738.12ms
step:1138/1875 train_loss:3.6319 train_time:832598ms step_avg:738.12ms
step:1139/1875 train_loss:3.5310 train_time:833341ms step_avg:738.12ms
step:1140/1875 train_loss:3.4282 train_time:834284ms step_avg:738.30ms
step:1141/1875 train_loss:3.7288 train_time:835022ms step_avg:738.30ms
step:1142/1875 train_loss:3.5400 train_time:835754ms step_avg:738.30ms
step:1143/1875 train_loss:3.6022 train_time:836670ms step_avg:738.46ms
step:1144/1875 train_loss:3.6485 train_time:837401ms step_avg:738.45ms
step:1145/1875 train_loss:3.2587 train_time:838146ms step_avg:738.45ms
step:1146/1875 train_loss:3.5733 train_time:838889ms step_avg:738.46ms
step:1147/1875 train_loss:3.4264 train_time:839623ms step_avg:738.45ms
step:1148/1875 train_loss:3.4754 train_time:840354ms step_avg:738.45ms
step:1149/1875 train_loss:3.5388 train_time:841088ms step_avg:738.44ms
step:1150/1875 train_loss:3.6155 train_time:841817ms step_avg:738.44ms
step:1151/1875 train_loss:3.5740 train_time:842548ms step_avg:738.43ms
step:1152/1875 train_loss:3.4718 train_time:843292ms step_avg:738.43ms
step:1153/1875 train_loss:3.4401 train_time:844036ms step_avg:738.44ms
step:1154/1875 train_loss:3.6604 train_time:844768ms step_avg:738.43ms
step:1155/1875 train_loss:3.6599 train_time:845506ms step_avg:738.43ms
step:1156/1875 train_loss:3.3777 train_time:846240ms step_avg:738.43ms
step:1157/1875 train_loss:3.3743 train_time:846967ms step_avg:738.42ms
step:1158/1875 train_loss:3.5198 train_time:847714ms step_avg:738.43ms
step:1159/1875 train_loss:3.5476 train_time:848454ms step_avg:738.43ms
step:1160/1875 train_loss:3.2999 train_time:849186ms step_avg:738.42ms
step:1161/1875 train_loss:3.3776 train_time:849920ms step_avg:738.42ms
step:1162/1875 train_loss:3.3663 train_time:850654ms step_avg:738.42ms
step:1163/1875 train_loss:3.5876 train_time:851385ms step_avg:738.41ms
step:1164/1875 train_loss:3.3893 train_time:852128ms step_avg:738.41ms
step:1165/1875 train_loss:3.5138 train_time:852864ms step_avg:738.41ms
step:1166/1875 train_loss:3.4829 train_time:853599ms step_avg:738.41ms
step:1167/1875 train_loss:3.4956 train_time:854338ms step_avg:738.41ms
step:1168/1875 train_loss:3.4748 train_time:855070ms step_avg:738.40ms
step:1169/1875 train_loss:3.4684 train_time:855801ms step_avg:738.40ms
step:1170/1875 train_loss:3.6840 train_time:856534ms step_avg:738.39ms
step:1171/1875 train_loss:3.4459 train_time:857271ms step_avg:738.39ms
step:1172/1875 train_loss:3.5345 train_time:858007ms step_avg:738.39ms
step:1173/1875 train_loss:3.4980 train_time:858744ms step_avg:738.39ms
step:1174/1875 train_loss:3.4028 train_time:859475ms step_avg:738.38ms
step:1175/1875 train_loss:3.4968 train_time:860208ms step_avg:738.38ms
step:1176/1875 train_loss:3.8579 train_time:860981ms step_avg:738.41ms
step:1177/1875 train_loss:3.4682 train_time:861720ms step_avg:738.41ms
step:1178/1875 train_loss:3.4677 train_time:862458ms step_avg:738.41ms
step:1179/1875 train_loss:3.3606 train_time:863217ms step_avg:738.42ms
step:1180/1875 train_loss:3.5019 train_time:863948ms step_avg:738.42ms
step:1181/1875 train_loss:3.5157 train_time:864681ms step_avg:738.41ms
step:1182/1875 train_loss:3.4545 train_time:865416ms step_avg:738.41ms
step:1183/1875 train_loss:3.3619 train_time:866156ms step_avg:738.41ms
step:1184/1875 train_loss:3.5006 train_time:866895ms step_avg:738.41ms
step:1185/1875 train_loss:3.6080 train_time:867630ms step_avg:738.41ms
step:1186/1875 train_loss:3.7858 train_time:868364ms step_avg:738.40ms
step:1187/1875 train_loss:3.6297 train_time:869103ms step_avg:738.41ms
step:1188/1875 train_loss:3.4676 train_time:869845ms step_avg:738.41ms
step:1189/1875 train_loss:3.3231 train_time:870598ms step_avg:738.42ms
step:1190/1875 train_loss:3.4573 train_time:871338ms step_avg:738.42ms
step:1191/1875 train_loss:3.4544 train_time:872067ms step_avg:738.41ms
step:1192/1875 train_loss:3.5072 train_time:872806ms step_avg:738.41ms
step:1193/1875 train_loss:3.4248 train_time:873540ms step_avg:738.41ms
step:1194/1875 train_loss:3.5825 train_time:874275ms step_avg:738.41ms
step:1195/1875 train_loss:3.4364 train_time:875003ms step_avg:738.40ms
step:1196/1875 train_loss:3.4354 train_time:875750ms step_avg:738.41ms
step:1197/1875 train_loss:3.4249 train_time:876494ms step_avg:738.41ms
step:1198/1875 train_loss:3.5019 train_time:877227ms step_avg:738.41ms
step:1199/1875 train_loss:3.4774 train_time:877962ms step_avg:738.40ms
step:1200/1875 train_loss:3.4345 train_time:878709ms step_avg:738.41ms
step:1201/1875 train_loss:3.8540 train_time:879473ms step_avg:738.43ms
step:1202/1875 train_loss:3.3871 train_time:880209ms step_avg:738.43ms
step:1203/1875 train_loss:3.4775 train_time:880942ms step_avg:738.43ms
step:1204/1875 train_loss:3.4752 train_time:881681ms step_avg:738.43ms
step:1205/1875 train_loss:3.5461 train_time:882440ms step_avg:738.44ms
step:1206/1875 train_loss:3.5404 train_time:883175ms step_avg:738.44ms
step:1207/1875 train_loss:3.5059 train_time:883923ms step_avg:738.45ms
step:1208/1875 train_loss:3.4287 train_time:884655ms step_avg:738.44ms
step:1209/1875 train_loss:3.4871 train_time:885385ms step_avg:738.44ms
step:1210/1875 train_loss:3.4285 train_time:886126ms step_avg:738.44ms
step:1211/1875 train_loss:3.4898 train_time:886862ms step_avg:738.44ms
step:1212/1875 train_loss:3.7440 train_time:887613ms step_avg:738.45ms
step:1213/1875 train_loss:3.4097 train_time:888348ms step_avg:738.44ms
step:1214/1875 train_loss:3.6631 train_time:889080ms step_avg:738.44ms
step:1215/1875 train_loss:3.4744 train_time:889810ms step_avg:738.43ms
step:1216/1875 train_loss:3.5519 train_time:890550ms step_avg:738.43ms
step:1217/1875 train_loss:3.5010 train_time:891288ms step_avg:738.43ms
step:1218/1875 train_loss:3.5130 train_time:892013ms step_avg:738.42ms
step:1219/1875 train_loss:3.5443 train_time:892753ms step_avg:738.42ms
step:1220/1875 train_loss:3.4701 train_time:893487ms step_avg:738.42ms
step:1221/1875 train_loss:3.5153 train_time:894221ms step_avg:738.42ms
step:1222/1875 train_loss:3.5343 train_time:894960ms step_avg:738.42ms
step:1223/1875 train_loss:3.5454 train_time:895696ms step_avg:738.41ms
step:1224/1875 train_loss:3.4959 train_time:896444ms step_avg:738.42ms
step:1225/1875 train_loss:3.4830 train_time:897183ms step_avg:738.42ms
step:1226/1875 train_loss:3.3808 train_time:897922ms step_avg:738.42ms
step:1227/1875 train_loss:3.5337 train_time:898666ms step_avg:738.43ms
step:1228/1875 train_loss:3.3266 train_time:899395ms step_avg:738.42ms
step:1229/1875 train_loss:3.6261 train_time:900135ms step_avg:738.42ms
step:1230/1875 train_loss:3.4456 train_time:900870ms step_avg:738.42ms
step:1231/1875 train_loss:3.4467 train_time:901622ms step_avg:738.43ms
step:1232/1875 train_loss:3.6250 train_time:902368ms step_avg:738.44ms
step:1233/1875 train_loss:3.3369 train_time:903107ms step_avg:738.44ms
step:1234/1875 train_loss:3.4208 train_time:903842ms step_avg:738.43ms
step:1235/1875 train_loss:3.4651 train_time:904575ms step_avg:738.43ms
step:1236/1875 train_loss:3.4799 train_time:905306ms step_avg:738.42ms
step:1237/1875 train_loss:3.4687 train_time:906048ms step_avg:738.43ms
step:1238/1875 train_loss:3.4413 train_time:906781ms step_avg:738.42ms
step:1239/1875 train_loss:3.6697 train_time:907513ms step_avg:738.42ms
step:1240/1875 train_loss:3.4252 train_time:908266ms step_avg:738.43ms
step:1241/1875 train_loss:3.3130 train_time:908997ms step_avg:738.42ms
step:1242/1875 train_loss:3.5895 train_time:909742ms step_avg:738.43ms
step:1243/1875 train_loss:3.2962 train_time:910487ms step_avg:738.43ms
step:1244/1875 train_loss:3.4820 train_time:911218ms step_avg:738.43ms
step:1245/1875 train_loss:3.7274 train_time:911951ms step_avg:738.42ms
step:1246/1875 train_loss:3.4013 train_time:912685ms step_avg:738.42ms
step:1247/1875 train_loss:3.4830 train_time:913412ms step_avg:738.41ms
step:1248/1875 train_loss:3.5759 train_time:914139ms step_avg:738.40ms
step:1249/1875 train_loss:3.3067 train_time:914873ms step_avg:738.40ms
step:1250/1875 train_loss:3.4040 train_time:915609ms step_avg:738.39ms
step:1250/1875 val_loss:3.4584 train_time:915621ms step_avg:738.40ms
============== Weight norms: ==============
name = 'module._orig_mod.transformer.h.0.attn.c_q.weight' | fro_norm = 138.64999 | spectral_norm = 25.10348 | nuclear_norm = 3183.84619
name = 'module._orig_mod.transformer.h.0.attn.c_k.weight' | fro_norm = 135.51251 | spectral_norm = 29.79707 | nuclear_norm = 3083.55908
name = 'module._orig_mod.transformer.h.1.attn.c_q.weight' | fro_norm = 139.45401 | spectral_norm = 14.45647 | nuclear_norm = 3216.18213
name = 'module._orig_mod.transformer.h.1.attn.c_k.weight' | fro_norm = 135.17175 | spectral_norm = 14.64455 | nuclear_norm = 3116.16406
name = 'module._orig_mod.transformer.h.2.attn.c_q.weight' | fro_norm = 131.99048 | spectral_norm = 13.13894 | nuclear_norm = 2900.84961
name = 'module._orig_mod.transformer.h.2.attn.c_k.weight' | fro_norm = 133.10316 | spectral_norm = 12.48657 | nuclear_norm = 2948.12036
name = 'module._orig_mod.transformer.h.3.attn.c_q.weight' | fro_norm = 136.57870 | spectral_norm = 13.64056 | nuclear_norm = 3063.18555
name = 'module._orig_mod.transformer.h.3.attn.c_k.weight' | fro_norm = 135.03836 | spectral_norm = 13.09292 | nuclear_norm = 3023.05493
name = 'module._orig_mod.transformer.h.4.attn.c_q.weight' | fro_norm = 134.74463 | spectral_norm = 15.75238 | nuclear_norm = 3035.32568
name = 'module._orig_mod.transformer.h.4.attn.c_k.weight' | fro_norm = 132.67415 | spectral_norm = 14.99073 | nuclear_norm = 3032.84717
name = 'module._orig_mod.transformer.h.5.attn.c_q.weight' | fro_norm = 137.69293 | spectral_norm = 15.15796 | nuclear_norm = 3132.37280
name = 'module._orig_mod.transformer.h.5.attn.c_k.weight' | fro_norm = 136.08862 | spectral_norm = 13.78394 | nuclear_norm = 3114.68604
name = 'module._orig_mod.transformer.h.6.attn.c_q.weight' | fro_norm = 134.88104 | spectral_norm = 13.88068 | nuclear_norm = 3043.61377
name = 'module._orig_mod.transformer.h.6.attn.c_k.weight' | fro_norm = 134.07809 | spectral_norm = 13.47803 | nuclear_norm = 3031.48633
name = 'module._orig_mod.transformer.h.7.attn.c_q.weight' | fro_norm = 137.60661 | spectral_norm = 14.82221 | nuclear_norm = 3117.58643
name = 'module._orig_mod.transformer.h.7.attn.c_k.weight' | fro_norm = 137.34000 | spectral_norm = 14.92983 | nuclear_norm = 3136.52686
name = 'module._orig_mod.transformer.h.8.attn.c_q.weight' | fro_norm = 141.69742 | spectral_norm = 15.09591 | nuclear_norm = 3173.43359
name = 'module._orig_mod.transformer.h.8.attn.c_k.weight' | fro_norm = 142.03394 | spectral_norm = 15.28417 | nuclear_norm = 3165.13525
name = 'module._orig_mod.transformer.h.9.attn.c_q.weight' | fro_norm = 138.40555 | spectral_norm = 15.09529 | nuclear_norm = 3053.58398
name = 'module._orig_mod.transformer.h.9.attn.c_k.weight' | fro_norm = 138.80273 | spectral_norm = 14.51411 | nuclear_norm = 3033.21875
name = 'module._orig_mod.transformer.h.10.attn.c_q.weight' | fro_norm = 142.75235 | spectral_norm = 14.98244 | nuclear_norm = 3222.03857
name = 'module._orig_mod.transformer.h.10.attn.c_k.weight' | fro_norm = 139.68794 | spectral_norm = 15.06887 | nuclear_norm = 3147.63672
name = 'module._orig_mod.transformer.h.11.attn.c_q.weight' | fro_norm = 134.55246 | spectral_norm = 17.86309 | nuclear_norm = 2886.47754
name = 'module._orig_mod.transformer.h.11.attn.c_k.weight' | fro_norm = 132.84901 | spectral_norm = 15.64062 | nuclear_norm = 2826.80835
===========================================
step:1251/1875 train_loss:3.4152 train_time:916336ms step_avg:738.39ms
step:1252/1875 train_loss:3.2883 train_time:917066ms step_avg:738.38ms
step:1253/1875 train_loss:3.5444 train_time:917798ms step_avg:738.37ms
step:1254/1875 train_loss:3.6407 train_time:918550ms step_avg:738.38ms
step:1255/1875 train_loss:3.3776 train_time:919280ms step_avg:738.38ms
step:1256/1875 train_loss:3.5855 train_time:920006ms step_avg:738.37ms
step:1257/1875 train_loss:3.3303 train_time:920747ms step_avg:738.37ms
step:1258/1875 train_loss:3.5117 train_time:921483ms step_avg:738.37ms
step:1259/1875 train_loss:3.5961 train_time:922213ms step_avg:738.36ms
step:1260/1875 train_loss:3.4472 train_time:922941ms step_avg:738.35ms
step:1261/1875 train_loss:3.5015 train_time:923693ms step_avg:738.36ms
step:1262/1875 train_loss:3.6226 train_time:924427ms step_avg:738.36ms
step:1263/1875 train_loss:3.2953 train_time:925160ms step_avg:738.36ms
step:1264/1875 train_loss:3.5458 train_time:925898ms step_avg:738.36ms
step:1265/1875 train_loss:3.4704 train_time:926634ms step_avg:738.35ms
step:1266/1875 train_loss:3.4565 train_time:927365ms step_avg:738.35ms
step:1267/1875 train_loss:3.3888 train_time:928097ms step_avg:738.34ms
step:1268/1875 train_loss:3.3802 train_time:928844ms step_avg:738.35ms
step:1269/1875 train_loss:3.5023 train_time:929579ms step_avg:738.35ms
step:1270/1875 train_loss:3.3918 train_time:930318ms step_avg:738.35ms
step:1271/1875 train_loss:3.5061 train_time:931048ms step_avg:738.34ms
step:1272/1875 train_loss:3.4532 train_time:931790ms step_avg:738.34ms
step:1273/1875 train_loss:3.4905 train_time:932520ms step_avg:738.34ms
step:1274/1875 train_loss:3.3939 train_time:933254ms step_avg:738.33ms
step:1275/1875 train_loss:3.5199 train_time:933979ms step_avg:738.32ms
step:1276/1875 train_loss:3.4590 train_time:934708ms step_avg:738.32ms
step:1277/1875 train_loss:3.5522 train_time:935435ms step_avg:738.31ms
step:1278/1875 train_loss:3.4930 train_time:936169ms step_avg:738.30ms
step:1279/1875 train_loss:3.4112 train_time:936926ms step_avg:738.32ms
step:1280/1875 train_loss:3.3584 train_time:937662ms step_avg:738.32ms
step:1281/1875 train_loss:3.4463 train_time:938390ms step_avg:738.31ms
step:1282/1875 train_loss:3.4150 train_time:939127ms step_avg:738.31ms
step:1283/1875 train_loss:3.5994 train_time:939860ms step_avg:738.30ms
step:1284/1875 train_loss:3.4208 train_time:940588ms step_avg:738.30ms
step:1285/1875 train_loss:3.5656 train_time:941327ms step_avg:738.30ms
step:1286/1875 train_loss:3.4399 train_time:942070ms step_avg:738.30ms
step:1287/1875 train_loss:3.5229 train_time:942797ms step_avg:738.29ms
step:1288/1875 train_loss:3.4875 train_time:943525ms step_avg:738.28ms
step:1289/1875 train_loss:3.4774 train_time:944264ms step_avg:738.28ms
step:1290/1875 train_loss:3.4937 train_time:945008ms step_avg:738.29ms
step:1291/1875 train_loss:3.6329 train_time:945754ms step_avg:738.29ms
step:1292/1875 train_loss:3.4439 train_time:946500ms step_avg:738.30ms
step:1293/1875 train_loss:3.2491 train_time:947239ms step_avg:738.30ms
step:1294/1875 train_loss:3.4758 train_time:947971ms step_avg:738.30ms
step:1295/1875 train_loss:3.4641 train_time:948725ms step_avg:738.31ms
step:1296/1875 train_loss:3.5070 train_time:949462ms step_avg:738.31ms
step:1297/1875 train_loss:3.5398 train_time:950201ms step_avg:738.31ms
step:1298/1875 train_loss:3.5435 train_time:950929ms step_avg:738.30ms
step:1299/1875 train_loss:3.5256 train_time:951665ms step_avg:738.30ms
step:1300/1875 train_loss:3.4858 train_time:952396ms step_avg:738.29ms
step:1301/1875 train_loss:3.6181 train_time:953129ms step_avg:738.29ms
step:1302/1875 train_loss:3.4760 train_time:953860ms step_avg:738.28ms
step:1303/1875 train_loss:3.5625 train_time:954592ms step_avg:738.28ms
step:1304/1875 train_loss:3.4825 train_time:955319ms step_avg:738.27ms
step:1305/1875 train_loss:3.5659 train_time:956063ms step_avg:738.27ms
step:1306/1875 train_loss:3.6508 train_time:956810ms step_avg:738.28ms
step:1307/1875 train_loss:3.4383 train_time:957554ms step_avg:738.28ms
step:1308/1875 train_loss:3.4000 train_time:958284ms step_avg:738.28ms
step:1309/1875 train_loss:3.4163 train_time:959022ms step_avg:738.28ms
step:1310/1875 train_loss:3.4698 train_time:959752ms step_avg:738.27ms
step:1311/1875 train_loss:3.3952 train_time:960485ms step_avg:738.27ms
step:1312/1875 train_loss:3.5780 train_time:961215ms step_avg:738.26ms
step:1313/1875 train_loss:3.4687 train_time:961945ms step_avg:738.25ms
step:1314/1875 train_loss:3.5256 train_time:962682ms step_avg:738.25ms
step:1315/1875 train_loss:3.4958 train_time:963417ms step_avg:738.25ms
step:1316/1875 train_loss:3.5216 train_time:964143ms step_avg:738.24ms
step:1317/1875 train_loss:3.3661 train_time:964893ms step_avg:738.25ms
step:1318/1875 train_loss:3.6359 train_time:965623ms step_avg:738.24ms
step:1319/1875 train_loss:3.5494 train_time:966359ms step_avg:738.24ms
step:1320/1875 train_loss:3.4341 train_time:967088ms step_avg:738.23ms
step:1321/1875 train_loss:3.5453 train_time:967830ms step_avg:738.24ms
step:1322/1875 train_loss:3.5157 train_time:968558ms step_avg:738.23ms
step:1323/1875 train_loss:3.4945 train_time:969292ms step_avg:738.23ms
step:1324/1875 train_loss:3.6809 train_time:970038ms step_avg:738.23ms
step:1325/1875 train_loss:3.5434 train_time:970789ms step_avg:738.24ms
step:1326/1875 train_loss:3.5890 train_time:971521ms step_avg:738.24ms
step:1327/1875 train_loss:3.6115 train_time:972250ms step_avg:738.23ms
step:1328/1875 train_loss:3.3529 train_time:972998ms step_avg:738.24ms
step:1329/1875 train_loss:3.4345 train_time:973730ms step_avg:738.23ms
step:1330/1875 train_loss:3.4925 train_time:974691ms step_avg:738.40ms
step:1331/1875 train_loss:2.6261 train_time:975443ms step_avg:738.41ms
step:1332/1875 train_loss:3.4962 train_time:976182ms step_avg:738.41ms
step:1333/1875 train_loss:3.4691 train_time:976918ms step_avg:738.41ms
step:1334/1875 train_loss:3.4480 train_time:977652ms step_avg:738.41ms
step:1335/1875 train_loss:3.8658 train_time:978409ms step_avg:738.42ms
step:1336/1875 train_loss:3.5808 train_time:979135ms step_avg:738.41ms
step:1337/1875 train_loss:3.4784 train_time:979867ms step_avg:738.41ms
step:1338/1875 train_loss:3.4145 train_time:980613ms step_avg:738.41ms
step:1339/1875 train_loss:3.4060 train_time:981352ms step_avg:738.41ms
step:1340/1875 train_loss:3.6638 train_time:982094ms step_avg:738.42ms
step:1341/1875 train_loss:3.6327 train_time:982833ms step_avg:738.42ms
step:1342/1875 train_loss:3.4526 train_time:983570ms step_avg:738.42ms
step:1343/1875 train_loss:3.3999 train_time:984296ms step_avg:738.41ms
step:1344/1875 train_loss:3.7120 train_time:985037ms step_avg:738.41ms
step:1345/1875 train_loss:3.4665 train_time:985771ms step_avg:738.41ms
step:1346/1875 train_loss:3.4755 train_time:986509ms step_avg:738.41ms
step:1347/1875 train_loss:3.5328 train_time:987239ms step_avg:738.40ms
step:1348/1875 train_loss:3.4942 train_time:987976ms step_avg:738.40ms
step:1349/1875 train_loss:3.4114 train_time:988703ms step_avg:738.39ms
step:1350/1875 train_loss:3.3708 train_time:989436ms step_avg:738.38ms
step:1351/1875 train_loss:3.4545 train_time:990180ms step_avg:738.39ms
step:1352/1875 train_loss:3.3840 train_time:990920ms step_avg:738.39ms
step:1353/1875 train_loss:3.5020 train_time:991654ms step_avg:738.39ms
step:1354/1875 train_loss:3.3550 train_time:992383ms step_avg:738.38ms
step:1355/1875 train_loss:3.4182 train_time:993111ms step_avg:738.37ms
step:1356/1875 train_loss:3.5269 train_time:993851ms step_avg:738.37ms
step:1357/1875 train_loss:3.3673 train_time:994594ms step_avg:738.38ms
step:1358/1875 train_loss:3.3004 train_time:995324ms step_avg:738.37ms
step:1359/1875 train_loss:3.6303 train_time:996064ms step_avg:738.37ms
step:1360/1875 train_loss:3.5445 train_time:996803ms step_avg:738.37ms
step:1361/1875 train_loss:3.2954 train_time:997537ms step_avg:738.37ms
step:1362/1875 train_loss:3.5577 train_time:998284ms step_avg:738.38ms
step:1363/1875 train_loss:3.4662 train_time:999020ms step_avg:738.37ms
step:1364/1875 train_loss:3.2694 train_time:999764ms step_avg:738.38ms
step:1365/1875 train_loss:3.5023 train_time:1000502ms step_avg:738.38ms
step:1366/1875 train_loss:3.3865 train_time:1001245ms step_avg:738.38ms
step:1367/1875 train_loss:3.4179 train_time:1001976ms step_avg:738.38ms
step:1368/1875 train_loss:3.4233 train_time:1002725ms step_avg:738.38ms
step:1369/1875 train_loss:3.5365 train_time:1003449ms step_avg:738.37ms
step:1370/1875 train_loss:3.5047 train_time:1004184ms step_avg:738.37ms
step:1371/1875 train_loss:3.4593 train_time:1004927ms step_avg:738.37ms
step:1372/1875 train_loss:3.3738 train_time:1005669ms step_avg:738.38ms
step:1373/1875 train_loss:3.7155 train_time:1006406ms step_avg:738.38ms
step:1374/1875 train_loss:3.4284 train_time:1007130ms step_avg:738.37ms
step:1375/1875 train_loss:3.4722 train_time:1007869ms step_avg:738.37ms
step:1375/1875 val_loss:3.4257 train_time:1007881ms step_avg:738.37ms
============== Weight norms: ==============
name = 'module._orig_mod.transformer.h.0.attn.c_q.weight' | fro_norm = 146.88126 | spectral_norm = 27.06297 | nuclear_norm = 3369.26855
name = 'module._orig_mod.transformer.h.0.attn.c_k.weight' | fro_norm = 143.75700 | spectral_norm = 32.13345 | nuclear_norm = 3267.91455
name = 'module._orig_mod.transformer.h.1.attn.c_q.weight' | fro_norm = 148.12129 | spectral_norm = 15.32845 | nuclear_norm = 3414.47485
name = 'module._orig_mod.transformer.h.1.attn.c_k.weight' | fro_norm = 143.42085 | spectral_norm = 15.55456 | nuclear_norm = 3303.71021
name = 'module._orig_mod.transformer.h.2.attn.c_q.weight' | fro_norm = 140.06636 | spectral_norm = 14.08453 | nuclear_norm = 3071.36499
name = 'module._orig_mod.transformer.h.2.attn.c_k.weight' | fro_norm = 141.27281 | spectral_norm = 13.29750 | nuclear_norm = 3123.15381
name = 'module._orig_mod.transformer.h.3.attn.c_q.weight' | fro_norm = 144.89726 | spectral_norm = 14.52660 | nuclear_norm = 3245.74854
name = 'module._orig_mod.transformer.h.3.attn.c_k.weight' | fro_norm = 143.35815 | spectral_norm = 13.95953 | nuclear_norm = 3207.42798
name = 'module._orig_mod.transformer.h.4.attn.c_q.weight' | fro_norm = 143.18835 | spectral_norm = 16.89585 | nuclear_norm = 3221.12646
name = 'module._orig_mod.transformer.h.4.attn.c_k.weight' | fro_norm = 141.06429 | spectral_norm = 16.00071 | nuclear_norm = 3222.40527
name = 'module._orig_mod.transformer.h.5.attn.c_q.weight' | fro_norm = 146.18568 | spectral_norm = 16.23202 | nuclear_norm = 3320.68140
name = 'module._orig_mod.transformer.h.5.attn.c_k.weight' | fro_norm = 144.42271 | spectral_norm = 14.67226 | nuclear_norm = 3302.39844
name = 'module._orig_mod.transformer.h.6.attn.c_q.weight' | fro_norm = 142.98969 | spectral_norm = 14.79659 | nuclear_norm = 3221.92041
name = 'module._orig_mod.transformer.h.6.attn.c_k.weight' | fro_norm = 142.16565 | spectral_norm = 14.37209 | nuclear_norm = 3210.02832
name = 'module._orig_mod.transformer.h.7.attn.c_q.weight' | fro_norm = 146.23608 | spectral_norm = 15.88345 | nuclear_norm = 3307.40039
name = 'module._orig_mod.transformer.h.7.attn.c_k.weight' | fro_norm = 145.87480 | spectral_norm = 15.96215 | nuclear_norm = 3328.37085
name = 'module._orig_mod.transformer.h.8.attn.c_q.weight' | fro_norm = 150.52425 | spectral_norm = 16.10932 | nuclear_norm = 3364.86108
name = 'module._orig_mod.transformer.h.8.attn.c_k.weight' | fro_norm = 150.67688 | spectral_norm = 16.21568 | nuclear_norm = 3352.29443
name = 'module._orig_mod.transformer.h.9.attn.c_q.weight' | fro_norm = 146.93294 | spectral_norm = 16.19667 | nuclear_norm = 3234.57617
name = 'module._orig_mod.transformer.h.9.attn.c_k.weight' | fro_norm = 147.43474 | spectral_norm = 15.62035 | nuclear_norm = 3213.15747
name = 'module._orig_mod.transformer.h.10.attn.c_q.weight' | fro_norm = 151.63960 | spectral_norm = 16.24727 | nuclear_norm = 3415.76196
name = 'module._orig_mod.transformer.h.10.attn.c_k.weight' | fro_norm = 148.27534 | spectral_norm = 16.13999 | nuclear_norm = 3333.93384
name = 'module._orig_mod.transformer.h.11.attn.c_q.weight' | fro_norm = 142.53958 | spectral_norm = 19.26449 | nuclear_norm = 3044.94824
name = 'module._orig_mod.transformer.h.11.attn.c_k.weight' | fro_norm = 140.46819 | spectral_norm = 16.83653 | nuclear_norm = 2974.86646
===========================================
step:1376/1875 train_loss:3.4742 train_time:1008597ms step_avg:738.36ms
step:1377/1875 train_loss:3.2739 train_time:1009340ms step_avg:738.36ms
step:1378/1875 train_loss:3.6635 train_time:1010079ms step_avg:738.36ms
step:1379/1875 train_loss:3.4503 train_time:1010803ms step_avg:738.35ms
step:1380/1875 train_loss:3.5937 train_time:1011544ms step_avg:738.35ms
step:1381/1875 train_loss:3.6119 train_time:1012274ms step_avg:738.35ms
step:1382/1875 train_loss:3.2879 train_time:1013010ms step_avg:738.35ms
step:1383/1875 train_loss:3.4293 train_time:1013758ms step_avg:738.35ms
step:1384/1875 train_loss:3.8375 train_time:1014495ms step_avg:738.35ms
step:1385/1875 train_loss:3.3348 train_time:1015226ms step_avg:738.35ms
step:1386/1875 train_loss:3.5067 train_time:1015957ms step_avg:738.34ms
step:1387/1875 train_loss:3.5897 train_time:1016691ms step_avg:738.34ms
step:1388/1875 train_loss:3.5127 train_time:1017419ms step_avg:738.33ms
step:1389/1875 train_loss:3.4570 train_time:1018151ms step_avg:738.33ms
step:1390/1875 train_loss:3.3047 train_time:1018887ms step_avg:738.32ms
step:1391/1875 train_loss:3.4580 train_time:1019627ms step_avg:738.32ms
step:1392/1875 train_loss:3.4283 train_time:1020360ms step_avg:738.32ms
step:1393/1875 train_loss:3.6880 train_time:1021086ms step_avg:738.31ms
step:1394/1875 train_loss:3.4048 train_time:1021818ms step_avg:738.31ms
step:1395/1875 train_loss:3.4030 train_time:1022551ms step_avg:738.30ms
step:1396/1875 train_loss:3.3639 train_time:1023282ms step_avg:738.30ms
step:1397/1875 train_loss:3.6236 train_time:1024014ms step_avg:738.29ms
step:1398/1875 train_loss:3.5119 train_time:1024748ms step_avg:738.29ms
step:1399/1875 train_loss:3.5203 train_time:1025483ms step_avg:738.29ms
step:1400/1875 train_loss:3.4175 train_time:1026204ms step_avg:738.28ms
step:1401/1875 train_loss:3.3658 train_time:1026936ms step_avg:738.27ms
step:1402/1875 train_loss:3.4429 train_time:1027674ms step_avg:738.27ms
step:1403/1875 train_loss:3.4285 train_time:1028411ms step_avg:738.27ms
step:1404/1875 train_loss:3.4533 train_time:1029138ms step_avg:738.26ms
step:1405/1875 train_loss:3.4029 train_time:1029873ms step_avg:738.26ms
step:1406/1875 train_loss:3.6133 train_time:1030616ms step_avg:738.26ms
step:1407/1875 train_loss:3.3870 train_time:1031342ms step_avg:738.26ms
step:1408/1875 train_loss:3.4251 train_time:1032084ms step_avg:738.26ms
step:1409/1875 train_loss:3.4209 train_time:1032814ms step_avg:738.25ms
step:1410/1875 train_loss:3.2844 train_time:1033547ms step_avg:738.25ms
step:1411/1875 train_loss:3.4189 train_time:1034269ms step_avg:738.24ms
step:1412/1875 train_loss:3.4013 train_time:1035017ms step_avg:738.24ms
step:1413/1875 train_loss:3.3913 train_time:1035748ms step_avg:738.24ms
step:1414/1875 train_loss:3.4743 train_time:1036477ms step_avg:738.23ms
step:1415/1875 train_loss:3.4327 train_time:1037211ms step_avg:738.23ms
step:1416/1875 train_loss:3.4665 train_time:1037943ms step_avg:738.22ms
step:1417/1875 train_loss:3.4459 train_time:1038673ms step_avg:738.22ms
step:1418/1875 train_loss:3.5154 train_time:1039406ms step_avg:738.21ms
step:1419/1875 train_loss:3.3278 train_time:1040162ms step_avg:738.23ms
step:1420/1875 train_loss:3.3910 train_time:1040909ms step_avg:738.23ms
step:1421/1875 train_loss:3.4917 train_time:1041641ms step_avg:738.23ms
step:1422/1875 train_loss:3.4602 train_time:1042376ms step_avg:738.23ms
step:1423/1875 train_loss:3.4678 train_time:1043117ms step_avg:738.23ms
step:1424/1875 train_loss:3.4798 train_time:1043852ms step_avg:738.23ms
step:1425/1875 train_loss:3.4496 train_time:1044588ms step_avg:738.22ms
step:1426/1875 train_loss:3.4267 train_time:1045318ms step_avg:738.22ms
step:1427/1875 train_loss:3.4345 train_time:1046053ms step_avg:738.22ms
step:1428/1875 train_loss:3.2889 train_time:1046804ms step_avg:738.23ms
step:1429/1875 train_loss:3.4305 train_time:1047532ms step_avg:738.22ms
step:1430/1875 train_loss:3.3817 train_time:1048265ms step_avg:738.21ms
step:1431/1875 train_loss:3.4792 train_time:1048995ms step_avg:738.21ms
step:1432/1875 train_loss:3.4598 train_time:1049720ms step_avg:738.20ms
step:1433/1875 train_loss:3.3671 train_time:1050458ms step_avg:738.20ms
step:1434/1875 train_loss:3.4268 train_time:1051196ms step_avg:738.20ms
step:1435/1875 train_loss:3.4492 train_time:1051929ms step_avg:738.20ms
step:1436/1875 train_loss:3.2782 train_time:1052676ms step_avg:738.20ms
step:1437/1875 train_loss:3.3973 train_time:1053420ms step_avg:738.21ms
step:1438/1875 train_loss:3.2233 train_time:1054153ms step_avg:738.20ms
step:1439/1875 train_loss:3.3268 train_time:1054884ms step_avg:738.20ms
step:1440/1875 train_loss:3.5151 train_time:1055630ms step_avg:738.20ms
step:1441/1875 train_loss:3.4803 train_time:1056361ms step_avg:738.20ms
step:1442/1875 train_loss:3.4192 train_time:1057100ms step_avg:738.20ms
step:1443/1875 train_loss:3.2871 train_time:1057829ms step_avg:738.19ms
step:1444/1875 train_loss:3.4553 train_time:1058568ms step_avg:738.19ms
step:1445/1875 train_loss:3.5015 train_time:1059313ms step_avg:738.20ms
step:1446/1875 train_loss:3.5791 train_time:1060061ms step_avg:738.20ms
step:1447/1875 train_loss:3.5530 train_time:1060789ms step_avg:738.20ms
step:1448/1875 train_loss:3.4362 train_time:1061523ms step_avg:738.19ms
step:1449/1875 train_loss:3.3086 train_time:1062264ms step_avg:738.20ms
step:1450/1875 train_loss:3.3940 train_time:1062995ms step_avg:738.19ms
step:1451/1875 train_loss:3.4047 train_time:1063731ms step_avg:738.19ms
step:1452/1875 train_loss:3.5148 train_time:1064459ms step_avg:738.18ms
step:1453/1875 train_loss:3.4975 train_time:1065189ms step_avg:738.18ms
step:1454/1875 train_loss:3.3184 train_time:1065924ms step_avg:738.17ms
step:1455/1875 train_loss:3.4322 train_time:1066661ms step_avg:738.17ms
step:1456/1875 train_loss:3.3616 train_time:1067398ms step_avg:738.17ms
step:1457/1875 train_loss:3.3875 train_time:1068128ms step_avg:738.17ms
step:1458/1875 train_loss:3.4306 train_time:1068870ms step_avg:738.17ms
step:1459/1875 train_loss:3.3776 train_time:1069601ms step_avg:738.16ms
step:1460/1875 train_loss:3.2630 train_time:1070331ms step_avg:738.16ms
step:1461/1875 train_loss:3.5190 train_time:1071067ms step_avg:738.16ms
step:1462/1875 train_loss:3.3748 train_time:1071800ms step_avg:738.15ms
step:1463/1875 train_loss:3.4186 train_time:1072542ms step_avg:738.16ms
step:1464/1875 train_loss:3.5371 train_time:1073268ms step_avg:738.15ms
step:1465/1875 train_loss:3.3697 train_time:1074002ms step_avg:738.15ms
step:1466/1875 train_loss:3.5689 train_time:1074735ms step_avg:738.14ms
step:1467/1875 train_loss:3.4616 train_time:1075461ms step_avg:738.13ms
step:1468/1875 train_loss:3.4572 train_time:1076191ms step_avg:738.13ms
step:1469/1875 train_loss:3.3850 train_time:1076935ms step_avg:738.13ms
step:1470/1875 train_loss:3.5039 train_time:1077667ms step_avg:738.13ms
step:1471/1875 train_loss:3.3867 train_time:1078401ms step_avg:738.13ms
step:1472/1875 train_loss:3.3664 train_time:1079141ms step_avg:738.13ms
step:1473/1875 train_loss:3.4318 train_time:1079889ms step_avg:738.13ms
step:1474/1875 train_loss:3.3484 train_time:1080629ms step_avg:738.13ms
step:1475/1875 train_loss:3.3619 train_time:1081376ms step_avg:738.14ms
step:1476/1875 train_loss:3.5339 train_time:1082104ms step_avg:738.13ms
step:1477/1875 train_loss:3.4092 train_time:1082835ms step_avg:738.13ms
step:1478/1875 train_loss:3.2471 train_time:1083566ms step_avg:738.12ms
step:1479/1875 train_loss:3.3626 train_time:1084306ms step_avg:738.13ms
step:1480/1875 train_loss:3.3406 train_time:1085049ms step_avg:738.13ms
step:1481/1875 train_loss:3.4126 train_time:1085796ms step_avg:738.13ms
step:1482/1875 train_loss:3.4939 train_time:1086528ms step_avg:738.13ms
step:1483/1875 train_loss:3.3733 train_time:1087258ms step_avg:738.12ms
step:1484/1875 train_loss:3.5508 train_time:1087997ms step_avg:738.13ms
step:1485/1875 train_loss:3.4679 train_time:1088733ms step_avg:738.12ms
step:1486/1875 train_loss:3.3769 train_time:1089481ms step_avg:738.13ms
step:1487/1875 train_loss:3.3644 train_time:1090211ms step_avg:738.13ms
step:1488/1875 train_loss:3.3760 train_time:1090942ms step_avg:738.12ms
step:1489/1875 train_loss:3.3240 train_time:1091689ms step_avg:738.13ms
step:1490/1875 train_loss:3.4319 train_time:1092434ms step_avg:738.13ms
step:1491/1875 train_loss:3.3321 train_time:1093179ms step_avg:738.14ms
step:1492/1875 train_loss:3.4212 train_time:1093910ms step_avg:738.13ms
step:1493/1875 train_loss:3.3474 train_time:1094656ms step_avg:738.14ms
step:1494/1875 train_loss:3.2654 train_time:1095384ms step_avg:738.13ms
step:1495/1875 train_loss:3.3536 train_time:1096120ms step_avg:738.13ms
step:1496/1875 train_loss:3.5327 train_time:1096853ms step_avg:738.12ms
step:1497/1875 train_loss:3.3954 train_time:1097593ms step_avg:738.13ms
step:1498/1875 train_loss:3.1352 train_time:1098329ms step_avg:738.12ms
step:1499/1875 train_loss:3.4483 train_time:1099063ms step_avg:738.12ms
step:1500/1875 train_loss:3.4027 train_time:1099802ms step_avg:738.12ms
step:1500/1875 val_loss:3.3762 train_time:1099814ms step_avg:738.13ms
============== Weight norms: ==============
name = 'module._orig_mod.transformer.h.0.attn.c_q.weight' | fro_norm = 152.35135 | spectral_norm = 28.36042 | nuclear_norm = 3492.66479
name = 'module._orig_mod.transformer.h.0.attn.c_k.weight' | fro_norm = 149.20026 | spectral_norm = 33.79072 | nuclear_norm = 3390.24146
name = 'module._orig_mod.transformer.h.1.attn.c_q.weight' | fro_norm = 153.93816 | spectral_norm = 15.87981 | nuclear_norm = 3547.54785
name = 'module._orig_mod.transformer.h.1.attn.c_k.weight' | fro_norm = 148.93848 | spectral_norm = 16.21652 | nuclear_norm = 3429.50391
name = 'module._orig_mod.transformer.h.2.attn.c_q.weight' | fro_norm = 145.14690 | spectral_norm = 14.66641 | nuclear_norm = 3174.93555
name = 'module._orig_mod.transformer.h.2.attn.c_k.weight' | fro_norm = 146.55188 | spectral_norm = 13.92172 | nuclear_norm = 3231.68652
name = 'module._orig_mod.transformer.h.3.attn.c_q.weight' | fro_norm = 150.20804 | spectral_norm = 15.08621 | nuclear_norm = 3357.84668
name = 'module._orig_mod.transformer.h.3.attn.c_k.weight' | fro_norm = 148.76781 | spectral_norm = 14.59170 | nuclear_norm = 3322.04028
name = 'module._orig_mod.transformer.h.4.attn.c_q.weight' | fro_norm = 148.72424 | spectral_norm = 17.70658 | nuclear_norm = 3340.92236
name = 'module._orig_mod.transformer.h.4.attn.c_k.weight' | fro_norm = 146.58597 | spectral_norm = 16.66160 | nuclear_norm = 3346.40869
name = 'module._orig_mod.transformer.h.5.attn.c_q.weight' | fro_norm = 151.69812 | spectral_norm = 16.91163 | nuclear_norm = 3439.18652
name = 'module._orig_mod.transformer.h.5.attn.c_k.weight' | fro_norm = 149.80847 | spectral_norm = 15.35261 | nuclear_norm = 3422.16895
name = 'module._orig_mod.transformer.h.6.attn.c_q.weight' | fro_norm = 148.41034 | spectral_norm = 15.33750 | nuclear_norm = 3337.47412
name = 'module._orig_mod.transformer.h.6.attn.c_k.weight' | fro_norm = 147.58801 | spectral_norm = 14.97642 | nuclear_norm = 3328.24707
name = 'module._orig_mod.transformer.h.7.attn.c_q.weight' | fro_norm = 151.75752 | spectral_norm = 16.62215 | nuclear_norm = 3427.63330
name = 'module._orig_mod.transformer.h.7.attn.c_k.weight' | fro_norm = 151.47823 | spectral_norm = 16.58867 | nuclear_norm = 3453.39990
name = 'module._orig_mod.transformer.h.8.attn.c_q.weight' | fro_norm = 156.21700 | spectral_norm = 16.85806 | nuclear_norm = 3485.55078
name = 'module._orig_mod.transformer.h.8.attn.c_k.weight' | fro_norm = 156.37315 | spectral_norm = 16.91719 | nuclear_norm = 3470.08203
name = 'module._orig_mod.transformer.h.9.attn.c_q.weight' | fro_norm = 152.33337 | spectral_norm = 16.89651 | nuclear_norm = 3342.55884
name = 'module._orig_mod.transformer.h.9.attn.c_k.weight' | fro_norm = 152.90828 | spectral_norm = 16.32549 | nuclear_norm = 3321.07812
name = 'module._orig_mod.transformer.h.10.attn.c_q.weight' | fro_norm = 157.33939 | spectral_norm = 17.15221 | nuclear_norm = 3536.54272
name = 'module._orig_mod.transformer.h.10.attn.c_k.weight' | fro_norm = 153.82567 | spectral_norm = 16.94244 | nuclear_norm = 3450.43530
name = 'module._orig_mod.transformer.h.11.attn.c_q.weight' | fro_norm = 147.55110 | spectral_norm = 20.23787 | nuclear_norm = 3135.72949
name = 'module._orig_mod.transformer.h.11.attn.c_k.weight' | fro_norm = 145.29744 | spectral_norm = 17.74365 | nuclear_norm = 3059.35498
===========================================
step:1501/1875 train_loss:3.4358 train_time:1100522ms step_avg:738.11ms
step:1502/1875 train_loss:3.4091 train_time:1101267ms step_avg:738.11ms
step:1503/1875 train_loss:3.3841 train_time:1102006ms step_avg:738.12ms
step:1504/1875 train_loss:3.1720 train_time:1102760ms step_avg:738.13ms
step:1505/1875 train_loss:3.4517 train_time:1103504ms step_avg:738.13ms
step:1506/1875 train_loss:3.3351 train_time:1104253ms step_avg:738.14ms
step:1507/1875 train_loss:3.3409 train_time:1104996ms step_avg:738.14ms
step:1508/1875 train_loss:3.3044 train_time:1105727ms step_avg:738.14ms
step:1509/1875 train_loss:3.3717 train_time:1106460ms step_avg:738.13ms
step:1510/1875 train_loss:3.2721 train_time:1107195ms step_avg:738.13ms
step:1511/1875 train_loss:3.5887 train_time:1107933ms step_avg:738.13ms
step:1512/1875 train_loss:3.3632 train_time:1108657ms step_avg:738.12ms
step:1513/1875 train_loss:3.3647 train_time:1109397ms step_avg:738.12ms
step:1514/1875 train_loss:3.5051 train_time:1110121ms step_avg:738.11ms
step:1515/1875 train_loss:3.5192 train_time:1110869ms step_avg:738.12ms
step:1516/1875 train_loss:3.3615 train_time:1111604ms step_avg:738.12ms
step:1517/1875 train_loss:3.1852 train_time:1112350ms step_avg:738.12ms
step:1518/1875 train_loss:3.3267 train_time:1113078ms step_avg:738.12ms
step:1519/1875 train_loss:3.3389 train_time:1113823ms step_avg:738.12ms
step:1520/1875 train_loss:3.3957 train_time:1114763ms step_avg:738.25ms
step:1521/1875 train_loss:3.3032 train_time:1115492ms step_avg:738.25ms
step:1522/1875 train_loss:3.6029 train_time:1116222ms step_avg:738.24ms
step:1523/1875 train_loss:3.2253 train_time:1116953ms step_avg:738.24ms
step:1524/1875 train_loss:3.3336 train_time:1117894ms step_avg:738.37ms
step:1525/1875 train_loss:3.3947 train_time:1118634ms step_avg:738.37ms
step:1526/1875 train_loss:3.3783 train_time:1119375ms step_avg:738.37ms
step:1527/1875 train_loss:3.4405 train_time:1120118ms step_avg:738.38ms
step:1528/1875 train_loss:3.3348 train_time:1120849ms step_avg:738.37ms
step:1529/1875 train_loss:3.3008 train_time:1121580ms step_avg:738.37ms
step:1530/1875 train_loss:3.3500 train_time:1122308ms step_avg:738.36ms
step:1531/1875 train_loss:3.3702 train_time:1123044ms step_avg:738.36ms
step:1532/1875 train_loss:3.3691 train_time:1123780ms step_avg:738.36ms
step:1533/1875 train_loss:3.3292 train_time:1124550ms step_avg:738.38ms
step:1534/1875 train_loss:3.5009 train_time:1125285ms step_avg:738.38ms
step:1535/1875 train_loss:3.2727 train_time:1126020ms step_avg:738.37ms
step:1536/1875 train_loss:3.4245 train_time:1126752ms step_avg:738.37ms
step:1537/1875 train_loss:3.3325 train_time:1127492ms step_avg:738.37ms
step:1538/1875 train_loss:3.2193 train_time:1128237ms step_avg:738.37ms
step:1539/1875 train_loss:3.1814 train_time:1128976ms step_avg:738.38ms
step:1540/1875 train_loss:3.2752 train_time:1129705ms step_avg:738.37ms
step:1541/1875 train_loss:3.2914 train_time:1130449ms step_avg:738.37ms
step:1542/1875 train_loss:3.2101 train_time:1131183ms step_avg:738.37ms
step:1543/1875 train_loss:3.4782 train_time:1131916ms step_avg:738.37ms
step:1544/1875 train_loss:3.2992 train_time:1132648ms step_avg:738.36ms
step:1545/1875 train_loss:3.1726 train_time:1133408ms step_avg:738.38ms
step:1546/1875 train_loss:3.3643 train_time:1134147ms step_avg:738.38ms
step:1547/1875 train_loss:3.3743 train_time:1134881ms step_avg:738.37ms
step:1548/1875 train_loss:3.1552 train_time:1135616ms step_avg:738.37ms
step:1549/1875 train_loss:3.5335 train_time:1136351ms step_avg:738.37ms
step:1550/1875 train_loss:3.4839 train_time:1137092ms step_avg:738.37ms
step:1551/1875 train_loss:3.3527 train_time:1137843ms step_avg:738.38ms
step:1552/1875 train_loss:3.5030 train_time:1138576ms step_avg:738.38ms
step:1553/1875 train_loss:3.4030 train_time:1139312ms step_avg:738.37ms
step:1554/1875 train_loss:3.3287 train_time:1140050ms step_avg:738.37ms
step:1555/1875 train_loss:3.4905 train_time:1140785ms step_avg:738.37ms
step:1556/1875 train_loss:3.4465 train_time:1141512ms step_avg:738.37ms
step:1557/1875 train_loss:3.3303 train_time:1142239ms step_avg:738.36ms
step:1558/1875 train_loss:3.2753 train_time:1142974ms step_avg:738.36ms
step:1559/1875 train_loss:3.2924 train_time:1143706ms step_avg:738.35ms
step:1560/1875 train_loss:3.3210 train_time:1144440ms step_avg:738.35ms
step:1561/1875 train_loss:3.3510 train_time:1145174ms step_avg:738.35ms
step:1562/1875 train_loss:3.3526 train_time:1145914ms step_avg:738.35ms
step:1563/1875 train_loss:3.4135 train_time:1146658ms step_avg:738.35ms
step:1564/1875 train_loss:3.3176 train_time:1147383ms step_avg:738.34ms
step:1565/1875 train_loss:3.4238 train_time:1148122ms step_avg:738.34ms
step:1566/1875 train_loss:3.2969 train_time:1148860ms step_avg:738.34ms
step:1567/1875 train_loss:3.4434 train_time:1149592ms step_avg:738.34ms
step:1568/1875 train_loss:3.2519 train_time:1150330ms step_avg:738.34ms
step:1569/1875 train_loss:3.2802 train_time:1151066ms step_avg:738.34ms
step:1570/1875 train_loss:3.2132 train_time:1151795ms step_avg:738.33ms
step:1571/1875 train_loss:3.2210 train_time:1152536ms step_avg:738.33ms
step:1572/1875 train_loss:3.2649 train_time:1153275ms step_avg:738.33ms
step:1573/1875 train_loss:3.3405 train_time:1154007ms step_avg:738.33ms
step:1574/1875 train_loss:3.1225 train_time:1154747ms step_avg:738.33ms
step:1575/1875 train_loss:3.3396 train_time:1155479ms step_avg:738.33ms
step:1576/1875 train_loss:3.3367 train_time:1156228ms step_avg:738.33ms
step:1577/1875 train_loss:3.3275 train_time:1156966ms step_avg:738.33ms
step:1578/1875 train_loss:3.3568 train_time:1157721ms step_avg:738.34ms
step:1579/1875 train_loss:3.3395 train_time:1158453ms step_avg:738.34ms
step:1580/1875 train_loss:3.2920 train_time:1159183ms step_avg:738.33ms
step:1581/1875 train_loss:3.5196 train_time:1159916ms step_avg:738.33ms
step:1582/1875 train_loss:3.3860 train_time:1160657ms step_avg:738.33ms
step:1583/1875 train_loss:3.4351 train_time:1161386ms step_avg:738.33ms
step:1584/1875 train_loss:3.1625 train_time:1162135ms step_avg:738.33ms
step:1585/1875 train_loss:3.3136 train_time:1162877ms step_avg:738.33ms
step:1586/1875 train_loss:3.2458 train_time:1163612ms step_avg:738.33ms
step:1587/1875 train_loss:3.4025 train_time:1164341ms step_avg:738.33ms
step:1588/1875 train_loss:3.3134 train_time:1165072ms step_avg:738.32ms
step:1589/1875 train_loss:3.2795 train_time:1165803ms step_avg:738.32ms
step:1590/1875 train_loss:3.2895 train_time:1166547ms step_avg:738.32ms
step:1591/1875 train_loss:3.3252 train_time:1167280ms step_avg:738.32ms
step:1592/1875 train_loss:3.1674 train_time:1168023ms step_avg:738.32ms
step:1593/1875 train_loss:3.2648 train_time:1168753ms step_avg:738.32ms
step:1594/1875 train_loss:3.6196 train_time:1169488ms step_avg:738.31ms
step:1595/1875 train_loss:3.2401 train_time:1170224ms step_avg:738.31ms
step:1596/1875 train_loss:3.2175 train_time:1170977ms step_avg:738.32ms
step:1597/1875 train_loss:3.3826 train_time:1171708ms step_avg:738.32ms
step:1598/1875 train_loss:3.2985 train_time:1172460ms step_avg:738.33ms
step:1599/1875 train_loss:3.1608 train_time:1173200ms step_avg:738.33ms
step:1600/1875 train_loss:3.3124 train_time:1173942ms step_avg:738.33ms
step:1601/1875 train_loss:3.3101 train_time:1174673ms step_avg:738.32ms
step:1602/1875 train_loss:3.3741 train_time:1175404ms step_avg:738.32ms
step:1603/1875 train_loss:3.2784 train_time:1176134ms step_avg:738.31ms
step:1604/1875 train_loss:3.1953 train_time:1176886ms step_avg:738.32ms
step:1605/1875 train_loss:3.3504 train_time:1177629ms step_avg:738.33ms
step:1606/1875 train_loss:3.1504 train_time:1178377ms step_avg:738.33ms
step:1607/1875 train_loss:3.3547 train_time:1179106ms step_avg:738.33ms
step:1608/1875 train_loss:3.2208 train_time:1179845ms step_avg:738.33ms
step:1609/1875 train_loss:3.3135 train_time:1180579ms step_avg:738.32ms
step:1610/1875 train_loss:3.3366 train_time:1181331ms step_avg:738.33ms
step:1611/1875 train_loss:3.1930 train_time:1182062ms step_avg:738.33ms
step:1612/1875 train_loss:3.3277 train_time:1182822ms step_avg:738.34ms
step:1613/1875 train_loss:3.3115 train_time:1183558ms step_avg:738.34ms
step:1614/1875 train_loss:3.1472 train_time:1184328ms step_avg:738.36ms
step:1615/1875 train_loss:3.4083 train_time:1185081ms step_avg:738.37ms
step:1616/1875 train_loss:3.3741 train_time:1185820ms step_avg:738.37ms
step:1617/1875 train_loss:3.3368 train_time:1186551ms step_avg:738.36ms
step:1618/1875 train_loss:3.2633 train_time:1187296ms step_avg:738.37ms
step:1619/1875 train_loss:3.4420 train_time:1188031ms step_avg:738.37ms
step:1620/1875 train_loss:3.3937 train_time:1188763ms step_avg:738.36ms
step:1621/1875 train_loss:3.3143 train_time:1189500ms step_avg:738.36ms
step:1622/1875 train_loss:3.5721 train_time:1190235ms step_avg:738.36ms
step:1623/1875 train_loss:3.2604 train_time:1190974ms step_avg:738.36ms
step:1624/1875 train_loss:3.5603 train_time:1191725ms step_avg:738.37ms
step:1625/1875 train_loss:3.3043 train_time:1192455ms step_avg:738.36ms
step:1625/1875 val_loss:3.3333 train_time:1192466ms step_avg:738.37ms
============== Weight norms: ==============
name = 'module._orig_mod.transformer.h.0.attn.c_q.weight' | fro_norm = 155.04219 | spectral_norm = 29.19511 | nuclear_norm = 3550.88916
name = 'module._orig_mod.transformer.h.0.attn.c_k.weight' | fro_norm = 151.97841 | spectral_norm = 34.74351 | nuclear_norm = 3452.21655
name = 'module._orig_mod.transformer.h.1.attn.c_q.weight' | fro_norm = 157.04253 | spectral_norm = 16.17532 | nuclear_norm = 3617.19727
name = 'module._orig_mod.transformer.h.1.attn.c_k.weight' | fro_norm = 151.82632 | spectral_norm = 16.55142 | nuclear_norm = 3494.68555
name = 'module._orig_mod.transformer.h.2.attn.c_q.weight' | fro_norm = 147.82211 | spectral_norm = 15.03438 | nuclear_norm = 3226.61865
name = 'module._orig_mod.transformer.h.2.attn.c_k.weight' | fro_norm = 149.30237 | spectral_norm = 14.21624 | nuclear_norm = 3286.48486
name = 'module._orig_mod.transformer.h.3.attn.c_q.weight' | fro_norm = 152.99295 | spectral_norm = 15.33458 | nuclear_norm = 3415.04858
name = 'module._orig_mod.transformer.h.3.attn.c_k.weight' | fro_norm = 151.53935 | spectral_norm = 14.89817 | nuclear_norm = 3378.98486
name = 'module._orig_mod.transformer.h.4.attn.c_q.weight' | fro_norm = 151.71143 | spectral_norm = 18.12795 | nuclear_norm = 3403.38232
name = 'module._orig_mod.transformer.h.4.attn.c_k.weight' | fro_norm = 149.50964 | spectral_norm = 17.05692 | nuclear_norm = 3410.34375
name = 'module._orig_mod.transformer.h.5.attn.c_q.weight' | fro_norm = 154.65425 | spectral_norm = 17.30211 | nuclear_norm = 3502.18066
name = 'module._orig_mod.transformer.h.5.attn.c_k.weight' | fro_norm = 152.60632 | spectral_norm = 15.66099 | nuclear_norm = 3482.82080
name = 'module._orig_mod.transformer.h.6.attn.c_q.weight' | fro_norm = 151.20901 | spectral_norm = 15.67184 | nuclear_norm = 3395.14746
name = 'module._orig_mod.transformer.h.6.attn.c_k.weight' | fro_norm = 150.41876 | spectral_norm = 15.38792 | nuclear_norm = 3388.23267
name = 'module._orig_mod.transformer.h.7.attn.c_q.weight' | fro_norm = 154.67538 | spectral_norm = 17.03930 | nuclear_norm = 3488.13843
name = 'module._orig_mod.transformer.h.7.attn.c_k.weight' | fro_norm = 154.36900 | spectral_norm = 16.95783 | nuclear_norm = 3516.44824
name = 'module._orig_mod.transformer.h.8.attn.c_q.weight' | fro_norm = 159.23640 | spectral_norm = 17.22813 | nuclear_norm = 3545.81689
name = 'module._orig_mod.transformer.h.8.attn.c_k.weight' | fro_norm = 159.29008 | spectral_norm = 17.32897 | nuclear_norm = 3527.28711
name = 'module._orig_mod.transformer.h.9.attn.c_q.weight' | fro_norm = 155.14073 | spectral_norm = 17.34666 | nuclear_norm = 3394.79785
name = 'module._orig_mod.transformer.h.9.attn.c_k.weight' | fro_norm = 155.67133 | spectral_norm = 16.78733 | nuclear_norm = 3370.86108
name = 'module._orig_mod.transformer.h.10.attn.c_q.weight' | fro_norm = 160.28500 | spectral_norm = 17.73218 | nuclear_norm = 3596.31299
name = 'module._orig_mod.transformer.h.10.attn.c_k.weight' | fro_norm = 156.61037 | spectral_norm = 17.33466 | nuclear_norm = 3505.52319
name = 'module._orig_mod.transformer.h.11.attn.c_q.weight' | fro_norm = 150.07944 | spectral_norm = 20.87437 | nuclear_norm = 3174.07544
name = 'module._orig_mod.transformer.h.11.attn.c_k.weight' | fro_norm = 147.58963 | spectral_norm = 18.31326 | nuclear_norm = 3091.12988
===========================================
step:1626/1875 train_loss:3.3831 train_time:1193177ms step_avg:738.35ms
step:1627/1875 train_loss:3.4108 train_time:1193908ms step_avg:738.35ms
step:1628/1875 train_loss:3.4343 train_time:1194634ms step_avg:738.34ms
step:1629/1875 train_loss:3.2776 train_time:1195372ms step_avg:738.34ms
step:1630/1875 train_loss:3.3374 train_time:1196107ms step_avg:738.34ms
step:1631/1875 train_loss:3.3098 train_time:1196838ms step_avg:738.33ms
step:1632/1875 train_loss:3.2006 train_time:1197571ms step_avg:738.33ms
step:1633/1875 train_loss:3.3146 train_time:1198303ms step_avg:738.33ms
step:1634/1875 train_loss:3.3218 train_time:1199036ms step_avg:738.32ms
step:1635/1875 train_loss:3.3137 train_time:1199778ms step_avg:738.33ms
step:1636/1875 train_loss:3.3956 train_time:1200511ms step_avg:738.32ms
step:1637/1875 train_loss:3.6664 train_time:1201252ms step_avg:738.32ms
step:1638/1875 train_loss:3.2874 train_time:1202013ms step_avg:738.34ms
step:1639/1875 train_loss:3.2622 train_time:1202753ms step_avg:738.34ms
step:1640/1875 train_loss:3.2802 train_time:1203493ms step_avg:738.34ms
step:1641/1875 train_loss:3.3920 train_time:1204215ms step_avg:738.33ms
step:1642/1875 train_loss:3.3471 train_time:1204952ms step_avg:738.33ms
step:1643/1875 train_loss:3.3362 train_time:1205693ms step_avg:738.33ms
step:1644/1875 train_loss:3.2471 train_time:1206424ms step_avg:738.33ms
step:1645/1875 train_loss:3.2404 train_time:1207161ms step_avg:738.33ms
step:1646/1875 train_loss:3.3262 train_time:1207899ms step_avg:738.32ms
step:1647/1875 train_loss:3.2001 train_time:1208650ms step_avg:738.33ms
step:1648/1875 train_loss:3.3485 train_time:1209386ms step_avg:738.33ms
step:1649/1875 train_loss:3.3902 train_time:1210117ms step_avg:738.33ms
step:1650/1875 train_loss:3.2822 train_time:1210857ms step_avg:738.33ms
step:1651/1875 train_loss:3.3640 train_time:1211595ms step_avg:738.33ms
step:1652/1875 train_loss:3.3223 train_time:1212338ms step_avg:738.33ms
step:1653/1875 train_loss:3.2921 train_time:1213068ms step_avg:738.33ms
step:1654/1875 train_loss:3.3898 train_time:1213803ms step_avg:738.32ms
step:1655/1875 train_loss:3.2303 train_time:1214536ms step_avg:738.32ms
step:1656/1875 train_loss:3.0190 train_time:1215279ms step_avg:738.32ms
step:1657/1875 train_loss:3.3418 train_time:1216015ms step_avg:738.32ms
step:1658/1875 train_loss:3.3619 train_time:1216744ms step_avg:738.32ms
step:1659/1875 train_loss:3.3041 train_time:1217480ms step_avg:738.31ms
step:1660/1875 train_loss:3.5606 train_time:1218229ms step_avg:738.32ms
step:1661/1875 train_loss:3.3942 train_time:1218969ms step_avg:738.32ms
step:1662/1875 train_loss:3.3710 train_time:1219710ms step_avg:738.32ms
step:1663/1875 train_loss:3.3387 train_time:1220449ms step_avg:738.32ms
step:1664/1875 train_loss:3.3716 train_time:1221183ms step_avg:738.32ms
step:1665/1875 train_loss:3.1898 train_time:1221919ms step_avg:738.32ms
step:1666/1875 train_loss:3.3497 train_time:1222653ms step_avg:738.32ms
step:1667/1875 train_loss:3.1443 train_time:1223393ms step_avg:738.32ms
step:1668/1875 train_loss:3.3007 train_time:1224128ms step_avg:738.32ms
step:1669/1875 train_loss:3.3335 train_time:1224865ms step_avg:738.31ms
step:1670/1875 train_loss:3.1554 train_time:1225604ms step_avg:738.32ms
step:1671/1875 train_loss:3.3107 train_time:1226370ms step_avg:738.33ms
step:1672/1875 train_loss:3.1949 train_time:1227115ms step_avg:738.34ms
step:1673/1875 train_loss:3.4804 train_time:1227855ms step_avg:738.34ms
step:1674/1875 train_loss:3.3521 train_time:1228590ms step_avg:738.34ms
step:1675/1875 train_loss:3.3150 train_time:1229323ms step_avg:738.33ms
step:1676/1875 train_loss:3.1983 train_time:1230063ms step_avg:738.33ms
step:1677/1875 train_loss:3.2635 train_time:1230807ms step_avg:738.34ms
step:1678/1875 train_loss:3.5902 train_time:1231540ms step_avg:738.33ms
step:1679/1875 train_loss:3.3217 train_time:1232279ms step_avg:738.33ms
step:1680/1875 train_loss:3.3033 train_time:1233016ms step_avg:738.33ms
step:1681/1875 train_loss:3.4431 train_time:1233754ms step_avg:738.33ms
step:1682/1875 train_loss:3.3530 train_time:1234493ms step_avg:738.33ms
step:1683/1875 train_loss:3.2727 train_time:1235243ms step_avg:738.34ms
step:1684/1875 train_loss:3.3642 train_time:1235976ms step_avg:738.34ms
step:1685/1875 train_loss:3.1997 train_time:1236713ms step_avg:738.34ms
step:1686/1875 train_loss:3.3591 train_time:1237449ms step_avg:738.33ms
step:1687/1875 train_loss:3.2538 train_time:1238200ms step_avg:738.34ms
step:1688/1875 train_loss:3.0708 train_time:1238936ms step_avg:738.34ms
step:1689/1875 train_loss:3.3757 train_time:1239685ms step_avg:738.35ms
step:1690/1875 train_loss:3.3468 train_time:1240420ms step_avg:738.35ms
step:1691/1875 train_loss:3.3405 train_time:1241156ms step_avg:738.34ms
step:1692/1875 train_loss:3.2514 train_time:1241914ms step_avg:738.36ms
step:1693/1875 train_loss:3.2359 train_time:1242648ms step_avg:738.35ms
step:1694/1875 train_loss:3.3323 train_time:1243381ms step_avg:738.35ms
step:1695/1875 train_loss:3.2524 train_time:1244114ms step_avg:738.35ms
step:1696/1875 train_loss:3.3477 train_time:1244851ms step_avg:738.35ms
step:1697/1875 train_loss:3.2974 train_time:1245589ms step_avg:738.35ms
step:1698/1875 train_loss:3.4046 train_time:1246323ms step_avg:738.34ms
step:1699/1875 train_loss:3.2364 train_time:1247065ms step_avg:738.35ms
step:1700/1875 train_loss:3.2857 train_time:1247799ms step_avg:738.34ms
step:1701/1875 train_loss:3.2126 train_time:1248529ms step_avg:738.34ms
step:1702/1875 train_loss:3.2262 train_time:1249267ms step_avg:738.34ms
step:1703/1875 train_loss:3.3134 train_time:1249995ms step_avg:738.33ms
step:1704/1875 train_loss:3.3305 train_time:1250725ms step_avg:738.33ms
step:1705/1875 train_loss:3.3008 train_time:1251452ms step_avg:738.32ms
step:1706/1875 train_loss:3.3430 train_time:1252188ms step_avg:738.32ms
step:1707/1875 train_loss:3.2928 train_time:1252930ms step_avg:738.32ms
step:1708/1875 train_loss:3.4491 train_time:1253665ms step_avg:738.32ms
step:1709/1875 train_loss:3.1503 train_time:1254396ms step_avg:738.31ms
step:1710/1875 train_loss:3.2627 train_time:1255334ms step_avg:738.43ms
step:1711/1875 train_loss:3.2500 train_time:1256075ms step_avg:738.43ms
step:1712/1875 train_loss:3.2551 train_time:1256810ms step_avg:738.43ms
step:1713/1875 train_loss:3.7425 train_time:1257557ms step_avg:738.44ms
step:1714/1875 train_loss:3.3050 train_time:1258303ms step_avg:738.44ms
step:1715/1875 train_loss:3.3059 train_time:1259033ms step_avg:738.44ms
step:1716/1875 train_loss:3.3435 train_time:1259763ms step_avg:738.43ms
step:1717/1875 train_loss:3.3646 train_time:1260495ms step_avg:738.43ms
step:1718/1875 train_loss:3.2604 train_time:1261239ms step_avg:738.43ms
step:1719/1875 train_loss:3.3084 train_time:1261983ms step_avg:738.43ms
step:1720/1875 train_loss:3.1196 train_time:1262717ms step_avg:738.43ms
step:1721/1875 train_loss:3.2650 train_time:1263444ms step_avg:738.42ms
step:1722/1875 train_loss:3.2836 train_time:1264174ms step_avg:738.42ms
step:1723/1875 train_loss:3.2354 train_time:1264903ms step_avg:738.41ms
step:1724/1875 train_loss:3.3923 train_time:1265636ms step_avg:738.41ms
step:1725/1875 train_loss:3.1821 train_time:1266391ms step_avg:738.42ms
step:1726/1875 train_loss:3.3385 train_time:1267134ms step_avg:738.42ms
step:1727/1875 train_loss:3.4275 train_time:1267865ms step_avg:738.42ms
step:1728/1875 train_loss:3.2793 train_time:1268600ms step_avg:738.42ms
step:1729/1875 train_loss:3.5083 train_time:1269344ms step_avg:738.42ms
step:1730/1875 train_loss:3.2769 train_time:1270084ms step_avg:738.42ms
step:1731/1875 train_loss:3.3538 train_time:1270812ms step_avg:738.41ms
step:1732/1875 train_loss:3.3176 train_time:1271546ms step_avg:738.41ms
step:1733/1875 train_loss:3.2983 train_time:1272281ms step_avg:738.41ms
step:1734/1875 train_loss:3.6816 train_time:1273026ms step_avg:738.41ms
step:1735/1875 train_loss:3.3114 train_time:1273764ms step_avg:738.41ms
step:1736/1875 train_loss:3.4464 train_time:1274500ms step_avg:738.41ms
step:1737/1875 train_loss:3.2223 train_time:1275241ms step_avg:738.41ms
step:1738/1875 train_loss:3.2608 train_time:1275981ms step_avg:738.41ms
step:1739/1875 train_loss:3.2931 train_time:1276708ms step_avg:738.41ms
step:1740/1875 train_loss:3.2713 train_time:1277444ms step_avg:738.41ms
step:1741/1875 train_loss:3.3984 train_time:1278172ms step_avg:738.40ms
step:1742/1875 train_loss:3.2474 train_time:1278909ms step_avg:738.40ms
step:1743/1875 train_loss:3.3048 train_time:1279650ms step_avg:738.40ms
step:1744/1875 train_loss:3.3906 train_time:1280379ms step_avg:738.40ms
step:1745/1875 train_loss:3.1842 train_time:1281117ms step_avg:738.40ms
step:1746/1875 train_loss:3.0804 train_time:1281852ms step_avg:738.39ms
step:1747/1875 train_loss:2.9678 train_time:1282604ms step_avg:738.40ms
step:1748/1875 train_loss:3.3080 train_time:1283336ms step_avg:738.40ms
step:1749/1875 train_loss:3.3274 train_time:1284067ms step_avg:738.39ms
step:1750/1875 train_loss:3.2831 train_time:1284805ms step_avg:738.39ms
step:1750/1875 val_loss:3.2938 train_time:1284817ms step_avg:738.40ms
============== Weight norms: ==============
name = 'module._orig_mod.transformer.h.0.attn.c_q.weight' | fro_norm = 155.97295 | spectral_norm = 29.64072 | nuclear_norm = 3570.06689
name = 'module._orig_mod.transformer.h.0.attn.c_k.weight' | fro_norm = 152.98935 | spectral_norm = 35.16484 | nuclear_norm = 3474.03320
name = 'module._orig_mod.transformer.h.1.attn.c_q.weight' | fro_norm = 158.30940 | spectral_norm = 16.34418 | nuclear_norm = 3645.83789
name = 'module._orig_mod.transformer.h.1.attn.c_k.weight' | fro_norm = 153.06871 | spectral_norm = 16.71150 | nuclear_norm = 3522.41455
name = 'module._orig_mod.transformer.h.2.attn.c_q.weight' | fro_norm = 148.85213 | spectral_norm = 15.18032 | nuclear_norm = 3242.93262
name = 'module._orig_mod.transformer.h.2.attn.c_k.weight' | fro_norm = 150.32362 | spectral_norm = 14.33729 | nuclear_norm = 3304.02368
name = 'module._orig_mod.transformer.h.3.attn.c_q.weight' | fro_norm = 154.11867 | spectral_norm = 15.47385 | nuclear_norm = 3436.06152
name = 'module._orig_mod.transformer.h.3.attn.c_k.weight' | fro_norm = 152.68291 | spectral_norm = 14.99871 | nuclear_norm = 3400.70117
name = 'module._orig_mod.transformer.h.4.attn.c_q.weight' | fro_norm = 152.94617 | spectral_norm = 18.33515 | nuclear_norm = 3428.59033
name = 'module._orig_mod.transformer.h.4.attn.c_k.weight' | fro_norm = 150.69667 | spectral_norm = 17.22065 | nuclear_norm = 3436.06030
name = 'module._orig_mod.transformer.h.5.attn.c_q.weight' | fro_norm = 155.83923 | spectral_norm = 17.45963 | nuclear_norm = 3525.25439
name = 'module._orig_mod.transformer.h.5.attn.c_k.weight' | fro_norm = 153.72026 | spectral_norm = 15.75479 | nuclear_norm = 3505.69873
name = 'module._orig_mod.transformer.h.6.attn.c_q.weight' | fro_norm = 152.30838 | spectral_norm = 15.84099 | nuclear_norm = 3415.92603
name = 'module._orig_mod.transformer.h.6.attn.c_k.weight' | fro_norm = 151.57709 | spectral_norm = 15.56443 | nuclear_norm = 3411.18066
name = 'module._orig_mod.transformer.h.7.attn.c_q.weight' | fro_norm = 155.88399 | spectral_norm = 17.25468 | nuclear_norm = 3511.72021
name = 'module._orig_mod.transformer.h.7.attn.c_k.weight' | fro_norm = 155.59581 | spectral_norm = 17.15506 | nuclear_norm = 3541.81274
name = 'module._orig_mod.transformer.h.8.attn.c_q.weight' | fro_norm = 160.44540 | spectral_norm = 17.39807 | nuclear_norm = 3567.58447
name = 'module._orig_mod.transformer.h.8.attn.c_k.weight' | fro_norm = 160.44266 | spectral_norm = 17.47541 | nuclear_norm = 3546.73535
name = 'module._orig_mod.transformer.h.9.attn.c_q.weight' | fro_norm = 156.24478 | spectral_norm = 17.55292 | nuclear_norm = 3411.71533
name = 'module._orig_mod.transformer.h.9.attn.c_k.weight' | fro_norm = 156.78990 | spectral_norm = 16.97360 | nuclear_norm = 3386.46777
name = 'module._orig_mod.transformer.h.10.attn.c_q.weight' | fro_norm = 161.43051 | spectral_norm = 18.01942 | nuclear_norm = 3616.39551
name = 'module._orig_mod.transformer.h.10.attn.c_k.weight' | fro_norm = 157.71663 | spectral_norm = 17.56420 | nuclear_norm = 3524.34302
name = 'module._orig_mod.transformer.h.11.attn.c_q.weight' | fro_norm = 150.95326 | spectral_norm = 21.24968 | nuclear_norm = 3181.65381
name = 'module._orig_mod.transformer.h.11.attn.c_k.weight' | fro_norm = 148.39543 | spectral_norm = 18.66101 | nuclear_norm = 3094.50977
===========================================
step:1751/1875 train_loss:3.3114 train_time:1285530ms step_avg:738.39ms
step:1752/1875 train_loss:3.5155 train_time:1286283ms step_avg:738.39ms
step:1753/1875 train_loss:3.2513 train_time:1287017ms step_avg:738.39ms
step:1754/1875 train_loss:3.3061 train_time:1287761ms step_avg:738.39ms
step:1755/1875 train_loss:3.3176 train_time:1288483ms step_avg:738.39ms
step:1756/1875 train_loss:2.9130 train_time:1289239ms step_avg:738.40ms
step:1757/1875 train_loss:3.0388 train_time:1289970ms step_avg:738.39ms
step:1758/1875 train_loss:3.0950 train_time:1290721ms step_avg:738.40ms
step:1759/1875 train_loss:3.0967 train_time:1291450ms step_avg:738.39ms
step:1760/1875 train_loss:3.2797 train_time:1292190ms step_avg:738.39ms
step:1761/1875 train_loss:3.1598 train_time:1292921ms step_avg:738.39ms
step:1762/1875 train_loss:3.1362 train_time:1293650ms step_avg:738.38ms
step:1763/1875 train_loss:4.2264 train_time:1294390ms step_avg:738.39ms
step:1764/1875 train_loss:3.2787 train_time:1295123ms step_avg:738.38ms
step:1765/1875 train_loss:3.3270 train_time:1295853ms step_avg:738.38ms
step:1766/1875 train_loss:3.3234 train_time:1296583ms step_avg:738.37ms
step:1767/1875 train_loss:3.3328 train_time:1297313ms step_avg:738.37ms
step:1768/1875 train_loss:3.2455 train_time:1298058ms step_avg:738.37ms
step:1769/1875 train_loss:3.3099 train_time:1298822ms step_avg:738.39ms
step:1770/1875 train_loss:3.3026 train_time:1299553ms step_avg:738.38ms
step:1771/1875 train_loss:3.5282 train_time:1300289ms step_avg:738.38ms
step:1772/1875 train_loss:3.2909 train_time:1301022ms step_avg:738.38ms
step:1773/1875 train_loss:3.3600 train_time:1301755ms step_avg:738.37ms
step:1774/1875 train_loss:3.5827 train_time:1302509ms step_avg:738.38ms
step:1775/1875 train_loss:3.2638 train_time:1303246ms step_avg:738.38ms
step:1776/1875 train_loss:3.1767 train_time:1303985ms step_avg:738.38ms
step:1777/1875 train_loss:3.4196 train_time:1304723ms step_avg:738.38ms
step:1778/1875 train_loss:3.1836 train_time:1305473ms step_avg:738.39ms
step:1779/1875 train_loss:3.3440 train_time:1306214ms step_avg:738.39ms
step:1780/1875 train_loss:3.3702 train_time:1306951ms step_avg:738.39ms
step:1781/1875 train_loss:3.4948 train_time:1307682ms step_avg:738.39ms
step:1782/1875 train_loss:3.2890 train_time:1308410ms step_avg:738.38ms
step:1783/1875 train_loss:3.5752 train_time:1309145ms step_avg:738.38ms
step:1784/1875 train_loss:3.3455 train_time:1309879ms step_avg:738.38ms
step:1785/1875 train_loss:3.3532 train_time:1310616ms step_avg:738.38ms
step:1786/1875 train_loss:3.1356 train_time:1311350ms step_avg:738.37ms
step:1787/1875 train_loss:3.2462 train_time:1312086ms step_avg:738.37ms
step:1788/1875 train_loss:3.3827 train_time:1312816ms step_avg:738.37ms
step:1789/1875 train_loss:3.2830 train_time:1313557ms step_avg:738.37ms
step:1790/1875 train_loss:3.4519 train_time:1314284ms step_avg:738.36ms
step:1791/1875 train_loss:3.2488 train_time:1315032ms step_avg:738.37ms
step:1792/1875 train_loss:3.2289 train_time:1315762ms step_avg:738.36ms
step:1793/1875 train_loss:3.3671 train_time:1316492ms step_avg:738.36ms
step:1794/1875 train_loss:3.2923 train_time:1317228ms step_avg:738.36ms
step:1795/1875 train_loss:3.2286 train_time:1317958ms step_avg:738.35ms
step:1796/1875 train_loss:3.3590 train_time:1318686ms step_avg:738.35ms
step:1797/1875 train_loss:3.2402 train_time:1319433ms step_avg:738.35ms
step:1798/1875 train_loss:3.2307 train_time:1320159ms step_avg:738.34ms
step:1799/1875 train_loss:3.2843 train_time:1320901ms step_avg:738.35ms
step:1800/1875 train_loss:3.2088 train_time:1321645ms step_avg:738.35ms
step:1801/1875 train_loss:3.3886 train_time:1322377ms step_avg:738.35ms
step:1802/1875 train_loss:3.2786 train_time:1323118ms step_avg:738.35ms
step:1803/1875 train_loss:3.3546 train_time:1323857ms step_avg:738.35ms
step:1804/1875 train_loss:3.2638 train_time:1324594ms step_avg:738.35ms
step:1805/1875 train_loss:3.3272 train_time:1325324ms step_avg:738.34ms
step:1806/1875 train_loss:3.1849 train_time:1326063ms step_avg:738.34ms
step:1807/1875 train_loss:3.1344 train_time:1326803ms step_avg:738.34ms
step:1808/1875 train_loss:3.4046 train_time:1327533ms step_avg:738.34ms
step:1809/1875 train_loss:3.3209 train_time:1328268ms step_avg:738.34ms
step:1810/1875 train_loss:3.3239 train_time:1329013ms step_avg:738.34ms
step:1811/1875 train_loss:3.4419 train_time:1329756ms step_avg:738.34ms
step:1812/1875 train_loss:3.2394 train_time:1330493ms step_avg:738.34ms
step:1813/1875 train_loss:3.3364 train_time:1331227ms step_avg:738.34ms
step:1814/1875 train_loss:3.4846 train_time:1331962ms step_avg:738.34ms
step:1815/1875 train_loss:3.3343 train_time:1332685ms step_avg:738.33ms
step:1816/1875 train_loss:3.3701 train_time:1333426ms step_avg:738.33ms
step:1817/1875 train_loss:3.3882 train_time:1334172ms step_avg:738.34ms
step:1818/1875 train_loss:3.3377 train_time:1334913ms step_avg:738.34ms
step:1819/1875 train_loss:3.3517 train_time:1335650ms step_avg:738.34ms
step:1820/1875 train_loss:3.3273 train_time:1336397ms step_avg:738.34ms
step:1821/1875 train_loss:3.3794 train_time:1337149ms step_avg:738.35ms
step:1822/1875 train_loss:3.3022 train_time:1337877ms step_avg:738.34ms
step:1823/1875 train_loss:3.3017 train_time:1338625ms step_avg:738.35ms
step:1824/1875 train_loss:3.2599 train_time:1339370ms step_avg:738.35ms
step:1825/1875 train_loss:3.2029 train_time:1340112ms step_avg:738.35ms
step:1826/1875 train_loss:3.1658 train_time:1340847ms step_avg:738.35ms
step:1827/1875 train_loss:3.3240 train_time:1341577ms step_avg:738.35ms
step:1828/1875 train_loss:3.4033 train_time:1342314ms step_avg:738.35ms
step:1829/1875 train_loss:3.3825 train_time:1343061ms step_avg:738.35ms
step:1830/1875 train_loss:3.3618 train_time:1343810ms step_avg:738.36ms
step:1831/1875 train_loss:3.2399 train_time:1344548ms step_avg:738.36ms
step:1832/1875 train_loss:3.1957 train_time:1345305ms step_avg:738.37ms
step:1833/1875 train_loss:3.4101 train_time:1346045ms step_avg:738.37ms
step:1834/1875 train_loss:3.1564 train_time:1346782ms step_avg:738.37ms
step:1835/1875 train_loss:3.3079 train_time:1347515ms step_avg:738.36ms
step:1836/1875 train_loss:3.1880 train_time:1348246ms step_avg:738.36ms
step:1837/1875 train_loss:3.5266 train_time:1348979ms step_avg:738.36ms
step:1838/1875 train_loss:3.3488 train_time:1349713ms step_avg:738.35ms
step:1839/1875 train_loss:3.3314 train_time:1350457ms step_avg:738.36ms
step:1840/1875 train_loss:3.4523 train_time:1351195ms step_avg:738.36ms
step:1841/1875 train_loss:3.3201 train_time:1351935ms step_avg:738.36ms
step:1842/1875 train_loss:3.2144 train_time:1352690ms step_avg:738.37ms
step:1843/1875 train_loss:3.3083 train_time:1353421ms step_avg:738.36ms
step:1844/1875 train_loss:3.1909 train_time:1354161ms step_avg:738.36ms
step:1845/1875 train_loss:3.3129 train_time:1354903ms step_avg:738.37ms
step:1846/1875 train_loss:3.3611 train_time:1355643ms step_avg:738.37ms
step:1847/1875 train_loss:3.1098 train_time:1356379ms step_avg:738.37ms
step:1848/1875 train_loss:3.2447 train_time:1357113ms step_avg:738.36ms
step:1849/1875 train_loss:3.3203 train_time:1357858ms step_avg:738.37ms
step:1850/1875 train_loss:3.2525 train_time:1358596ms step_avg:738.37ms
step:1851/1875 train_loss:3.1504 train_time:1359337ms step_avg:738.37ms
step:1852/1875 train_loss:3.3912 train_time:1360081ms step_avg:738.37ms
step:1853/1875 train_loss:3.1747 train_time:1360810ms step_avg:738.37ms
step:1854/1875 train_loss:3.2687 train_time:1361543ms step_avg:738.36ms
step:1855/1875 train_loss:3.2187 train_time:1362276ms step_avg:738.36ms
step:1856/1875 train_loss:3.4155 train_time:1363009ms step_avg:738.36ms
step:1857/1875 train_loss:3.3933 train_time:1363756ms step_avg:738.36ms
step:1858/1875 train_loss:3.2631 train_time:1364489ms step_avg:738.36ms
step:1859/1875 train_loss:3.2300 train_time:1365222ms step_avg:738.36ms
step:1860/1875 train_loss:3.2512 train_time:1365966ms step_avg:738.36ms
step:1861/1875 train_loss:3.4916 train_time:1366710ms step_avg:738.36ms
step:1862/1875 train_loss:3.2936 train_time:1367449ms step_avg:738.36ms
step:1863/1875 train_loss:3.2670 train_time:1368179ms step_avg:738.36ms
step:1864/1875 train_loss:3.3309 train_time:1368915ms step_avg:738.36ms
step:1865/1875 train_loss:3.1786 train_time:1369644ms step_avg:738.35ms
step:1866/1875 train_loss:3.1846 train_time:1370382ms step_avg:738.35ms
step:1867/1875 train_loss:3.2798 train_time:1371117ms step_avg:738.35ms
step:1868/1875 train_loss:3.3227 train_time:1371856ms step_avg:738.35ms
step:1869/1875 train_loss:3.0686 train_time:1372601ms step_avg:738.35ms
step:1870/1875 train_loss:3.2208 train_time:1373328ms step_avg:738.35ms
step:1871/1875 train_loss:3.1718 train_time:1374070ms step_avg:738.35ms
step:1872/1875 train_loss:3.1594 train_time:1374806ms step_avg:738.35ms
step:1873/1875 train_loss:3.3354 train_time:1375538ms step_avg:738.35ms
step:1874/1875 train_loss:3.3162 train_time:1376273ms step_avg:738.34ms
step:1875/1875 train_loss:3.2576 train_time:1377006ms step_avg:738.34ms
step:1875/1875 val_loss:3.2716 train_time:1377017ms step_avg:738.35ms
============== Weight norms: ==============
name = 'module._orig_mod.transformer.h.0.attn.c_q.weight' | fro_norm = 156.09431 | spectral_norm = 29.77592 | nuclear_norm = 3571.91504
name = 'module._orig_mod.transformer.h.0.attn.c_k.weight' | fro_norm = 153.14925 | spectral_norm = 35.26419 | nuclear_norm = 3477.02393
name = 'module._orig_mod.transformer.h.1.attn.c_q.weight' | fro_norm = 158.56943 | spectral_norm = 16.39483 | nuclear_norm = 3651.40576
name = 'module._orig_mod.transformer.h.1.attn.c_k.weight' | fro_norm = 153.31424 | spectral_norm = 16.74323 | nuclear_norm = 3527.63330
name = 'module._orig_mod.transformer.h.2.attn.c_q.weight' | fro_norm = 149.00722 | spectral_norm = 15.23660 | nuclear_norm = 3243.96680
name = 'module._orig_mod.transformer.h.2.attn.c_k.weight' | fro_norm = 150.48688 | spectral_norm = 14.38413 | nuclear_norm = 3305.30688
name = 'module._orig_mod.transformer.h.3.attn.c_q.weight' | fro_norm = 154.30211 | spectral_norm = 15.50711 | nuclear_norm = 3438.51025
name = 'module._orig_mod.transformer.h.3.attn.c_k.weight' | fro_norm = 152.88766 | spectral_norm = 15.02859 | nuclear_norm = 3403.68286
name = 'module._orig_mod.transformer.h.4.attn.c_q.weight' | fro_norm = 153.19446 | spectral_norm = 18.39149 | nuclear_norm = 3432.84375
name = 'module._orig_mod.transformer.h.4.attn.c_k.weight' | fro_norm = 150.93677 | spectral_norm = 17.25525 | nuclear_norm = 3441.14404
name = 'module._orig_mod.transformer.h.5.attn.c_q.weight' | fro_norm = 156.05867 | spectral_norm = 17.50525 | nuclear_norm = 3528.88428
name = 'module._orig_mod.transformer.h.5.attn.c_k.weight' | fro_norm = 153.91724 | spectral_norm = 15.79282 | nuclear_norm = 3509.23853
name = 'module._orig_mod.transformer.h.6.attn.c_q.weight' | fro_norm = 152.51715 | spectral_norm = 15.87473 | nuclear_norm = 3418.84375
name = 'module._orig_mod.transformer.h.6.attn.c_k.weight' | fro_norm = 151.78856 | spectral_norm = 15.60095 | nuclear_norm = 3414.82520
name = 'module._orig_mod.transformer.h.7.attn.c_q.weight' | fro_norm = 156.10995 | spectral_norm = 17.31974 | nuclear_norm = 3515.32300
name = 'module._orig_mod.transformer.h.7.attn.c_k.weight' | fro_norm = 155.82008 | spectral_norm = 17.18901 | nuclear_norm = 3546.06836
name = 'module._orig_mod.transformer.h.8.attn.c_q.weight' | fro_norm = 160.66235 | spectral_norm = 17.42255 | nuclear_norm = 3570.23071
name = 'module._orig_mod.transformer.h.8.attn.c_k.weight' | fro_norm = 160.65814 | spectral_norm = 17.51931 | nuclear_norm = 3549.34937
name = 'module._orig_mod.transformer.h.9.attn.c_q.weight' | fro_norm = 156.42972 | spectral_norm = 17.59908 | nuclear_norm = 3412.52588
name = 'module._orig_mod.transformer.h.9.attn.c_k.weight' | fro_norm = 156.97545 | spectral_norm = 17.01849 | nuclear_norm = 3386.88281
name = 'module._orig_mod.transformer.h.10.attn.c_q.weight' | fro_norm = 161.61189 | spectral_norm = 18.13159 | nuclear_norm = 3618.40674
name = 'module._orig_mod.transformer.h.10.attn.c_k.weight' | fro_norm = 157.88666 | spectral_norm = 17.61961 | nuclear_norm = 3525.83154
name = 'module._orig_mod.transformer.h.11.attn.c_q.weight' | fro_norm = 151.05318 | spectral_norm = 21.36236 | nuclear_norm = 3178.53003
name = 'module._orig_mod.transformer.h.11.attn.c_k.weight' | fro_norm = 148.48590 | spectral_norm = 18.73831 | nuclear_norm = 3090.87500
===========================================
