import os
import sys
with open(sys.argv[0]) as f:
    code = f.read() # read the code of this file ASAP, for logging
import uuid
import time
import glob
import subprocess
import contextlib
from dataclasses import dataclass

import torch
torch.empty(1, device='cuda', requires_grad=True).backward()
from torch import nn
import torch.nn.functional as F
import torch.distributed as dist
from torch.nn.parallel import DistributedDataParallel as DDP
# use of FlexAttention contributed by @KoszarskyB
from torch.nn.attention.flex_attention import BlockMask, flex_attention

# -----------------------------------------------------------------------------
# Muon optimizer

@torch.compile
def zeropower_via_newtonschulz5(G, steps):
    """
    Newton-Schulz iteration to compute the zeroth power / orthogonalization of G. We opt to use a
    quintic iteration whose coefficients are selected to maximize the slope at zero. For the purpose
    of minimizing steps, it turns out to be empirically effective to keep increasing the slope at
    zero even beyond the point where the iteration no longer converges all the way to one everywhere
    on the interval. This iteration therefore does not produce UV^T but rather something like US'V^T
    where S' is diagonal with S_{ii}' ~ Uniform(0.5, 1.5), which turns out not to hurt model
    performance at all relative to UV^T, where USV^T = G is the SVD.
    """
    assert len(G.shape) == 2
    a, b, c = (3.4445, -4.7750,  2.0315)
    X = G.bfloat16()
    if G.size(0) > G.size(1):
        X = X.T

    # Ensure spectral norm is at most 1
    X = X / (X.norm() + 1e-7)
    # Perform the NS iterations
    for _ in range(steps):
        A = X @ X.T
        B = b * A + c * A @ A # adapted from suggestion by @jxbz, @leloykun, and @YouJiacheng
        X = a * X + B @ X
    
    if G.size(0) > G.size(1):
        X = X.T
    X = torch.einsum("ij,ij,ab->ab", G.type_as(X), X, X)
    return X

class Muon(torch.optim.Optimizer):
    """
    Muon - MomentUm Orthogonalized by Newton-schulz

    Muon internally runs standard SGD-momentum, and then performs an orthogonalization post-
    processing step, in which each 2D parameter's update is replaced with the nearest orthogonal
    matrix. To efficiently orthogonalize each update, we use a Newton-Schulz iteration, which has
    the advantage that it can be stably run in bfloat16 on the GPU.

    Some warnings:
    - This optimizer assumes that all parameters passed in are 2D.
    - It should not be used for the embedding layer, the final fully connected layer, or any {0,1}-D
    parameters; those should all be optimized by a standard method (e.g., AdamW).
    - To use it with 4D convolutional filters, it works well to just flatten their last 3 dimensions.
    - We believe it is unlikely to work well for training with small batch size.
    - We believe it may not work well for finetuning pretrained models, but we haven't tested this.
    - We have not yet tried this optimizer for training scenarios larger than NanoGPT (124M).

    Arguments:
        lr: The learning rate used by the internal SGD.
        momentum: The momentum used by the internal SGD.
        nesterov: Whether to use Nesterov-style momentum in the internal SGD. (recommended)
        ns_steps: The number of Newton-Schulz iteration steps to use.
    """
    def __init__(self, params, lr=0.02, momentum=0.95, nesterov=True, ns_steps=5):
        self.world_size = int(os.environ['WORLD_SIZE'])
        self.rank = int(os.environ['RANK'])
        defaults = dict(lr=lr, momentum=momentum, nesterov=nesterov, ns_steps=ns_steps)
        assert all(isinstance(p, torch.Tensor) for p in params)
        sizes = {p.numel() for p in params}
        param_groups = [dict(params=[p for p in params if p.numel() == size],
                             update_buffer=[torch.empty(size, device='cuda', dtype=torch.bfloat16) for _ in range(self.world_size)])
                        for size in sizes]
        super().__init__(param_groups, defaults)

    def step(self):

        for group in self.param_groups:

            lr = group['lr']
            momentum = group['momentum']
            nesterov = group['nesterov']
            ns_steps = group['ns_steps']
            update_buffers = group['update_buffer']
            # generate weight updates in distributed fashion
            params = group['params']
            handle = None
            params_world = None
            def update_prev():
                if params_world is None:
                    return
                assert handle is not None
                handle.wait()
                for p_world, g_world in zip(params_world, update_buffers):
                    p_world.data.add_(
                        g_world.view_as(p_world),
                        alpha=-lr * max(1, p_world.size(0) / p_world.size(1)) ** 0.5,
                    )
            for base_i in range(len(params))[::self.world_size]:
                if base_i + rank < len(params):
                    p = params[base_i + self.rank]
                    g = p.grad
                    assert g is not None
                    state = self.state[p]
                    if 'momentum_buffer' not in state:
                        state['momentum_buffer'] = torch.zeros_like(g)
                    buf = state['momentum_buffer']
                    buf.lerp_(g, 1 - momentum)
                    g = g.lerp_(buf, momentum) if nesterov else buf
                    g = zeropower_via_newtonschulz5(g, steps=ns_steps).flatten()
                else:
                    g = update_buffers[rank]
                update_prev() # async all_gather instead of sync all_reduce by @YouJiacheng
                handle = dist.all_gather(update_buffers, g, async_op=True)
                params_world = params[base_i : base_i + self.world_size]
            update_prev()

# -----------------------------------------------------------------------------
# PyTorch nn.Module definitions for the GPT-2 model

def norm(x):
    return F.rms_norm(x, (x.size(-1),))

class CastedLinear(nn.Linear):

    def __init__(self, in_features, out_features):
        super().__init__(in_features, out_features, bias=False)

    def forward(self, x):
        return F.linear(x, self.weight.type_as(x))

class Rotary(nn.Module):

    def __init__(self, dim, max_seq_len=65536):
        super().__init__()
        # half-truncate RoPE by @YouJiacheng
        angular_freq = (1 / 1024) ** torch.linspace(0, 1, steps=dim//4, dtype=torch.float32)
        angular_freq = torch.cat([angular_freq, angular_freq.new_zeros(dim//4)])
        t = torch.arange(max_seq_len, dtype=torch.float32)
        theta = torch.einsum('i,j -> ij', t, angular_freq)
        self.cos = nn.Buffer(theta.cos(), persistent=False)
        self.sin = nn.Buffer(theta.sin(), persistent=False)

    def forward(self, x):
        cos, sin = self.cos[None, :x.size(-3), None, :], self.sin[None, :x.size(-3), None, :]
        x1, x2 = x.float().chunk(2, dim=-1)
        y1 = x1 * cos + x2 * sin
        y2 = x1 * (-sin) + x2 * cos
        return torch.cat((y1, y2), 3).type_as(x)

class CausalSelfAttention(nn.Module):

    def __init__(self, dim, num_heads):
        super().__init__()
        assert dim % num_heads == 0
        self.num_heads = num_heads
        self.c_q = CastedLinear(dim, dim)
        self.c_k = CastedLinear(dim, dim)
        self.c_v = CastedLinear(dim, dim)
        self.lambdas = nn.Parameter(torch.tensor([0.5, 0.5]))
        self.rotary = Rotary(dim // num_heads) # dim // num_heads = head_dim
        self.c_proj = CastedLinear(dim, dim)
        self.c_proj.weight.data.zero_() # zero init suggested by @Grad62304977

    def forward(self, x, ve, block_mask):
        B, T = x.size(0), x.size(1) # batch size, sequence length
        assert B == 1, 'Must use batch size = 1 for FlexAttention'
        q = self.c_q(x).view(B, T, self.num_heads, -1)
        k = self.c_k(x).view(B, T, self.num_heads, -1)
        v = self.c_v(x).view(B, T, self.num_heads, -1)
        if ve is not None:
            v = self.lambdas[0] * v + self.lambdas[1] * ve.view_as(v) # @KoszarskyB & @Grad62304977
        else: # skip mid-layers token value embeddings by @YouJiacheng
            v = self.lambdas[0] * v
        q, k = norm(q), norm(k) # QK norm @Grad62304977
        q, k = self.rotary(q), self.rotary(k)
        y = flex_attention(q.transpose(1, 2), k.transpose(1, 2), v.transpose(1, 2), block_mask=block_mask)
        y = y.transpose(1, 2).contiguous().view_as(x) # re-assemble all head outputs side by side
        y = self.c_proj(y)
        return y

class MLP(nn.Module):

    def __init__(self, dim):
        super().__init__()
        self.c_fc = CastedLinear(dim, 4 * dim)
        self.c_proj = CastedLinear(4 * dim, dim)
        self.c_proj.weight.data.zero_() # zero init suggested by @Grad62304977

    def forward(self, x):
        x = self.c_fc(x)
        x = F.relu(x).square() # https://arxiv.org/abs/2109.08668v2; ~1-2% better than GELU; suggested by @SKYLINEZ007 and @Grad62304977
        x = self.c_proj(x)
        return x

class Block(nn.Module):

    def __init__(self, model_dim, num_heads, use_attn=True):
        super().__init__()
        self.attn = CausalSelfAttention(model_dim, num_heads) if use_attn else None
        self.mlp = MLP(model_dim)
        self.lambdas = nn.Parameter(torch.tensor([1., 0.]))

    def forward(self, x, ve, x0, block_mask):
        x = self.lambdas[0] * x + self.lambdas[1] * x0
        if self.attn is not None:
            x = x + self.attn(norm(x), ve, block_mask)
        x = x + self.mlp(norm(x))
        return x

class ValueEmbedding(nn.Module):
    def __init__(self, vocab_size, model_dim):
        super().__init__()
        self.embed = nn.ModuleList([nn.Embedding(vocab_size, model_dim) for _ in range(3)])

    def forward(self, inputs):
        ve = [emb(inputs).bfloat16() for emb in self.embed]
        # 012 ... 012 structure on token value embeddings by @YouJiacheng, improved on @leloykun's U-net structure
        ve = [ve[0], ve[1], ve[2], None, None, None, None, None, None, ve[0], ve[1], ve[2]]
        return ve

# -----------------------------------------------------------------------------
# The main GPT-2 model

class GPT(nn.Module):

    def __init__(self, vocab_size, num_layers, num_heads, model_dim):
        super().__init__()
        self.embed = nn.Embedding(vocab_size, model_dim)
        # skip attention of blocks.7 (the 8th layer) by @YouJiacheng
        self.blocks = nn.ModuleList([Block(model_dim, num_heads, use_attn=(i != 7))
                                     for i in range(num_layers)])
        # token value embeddings by @KoszarskyB - inspired by @Grad62304977's value residual learning
        # U-net structure on token value embeddings by @leloykun
        self.value_embeds = ValueEmbedding(vocab_size, model_dim)
        self.lm_head = CastedLinear(model_dim, vocab_size)
        self.lm_head.weight.data.zero_() # @Grad62304977
        # U-net design by @brendanh0gan
        self.num_encoder_layers = num_layers // 2 # Half of the layers for encoder
        self.num_decoder_layers = num_layers - self.num_encoder_layers # Remaining for decoder
        # Add learnable skip connection weights for decoder layers
        self.skip_weights = nn.Parameter(torch.ones(self.num_decoder_layers))

    def forward(self, inputs, targets, sliding_window_num_blocks):
        BLOCK_SIZE = 128
        seq_len = len(inputs)
        assert seq_len % BLOCK_SIZE == 0
        total_num_blocks = seq_len // BLOCK_SIZE
        assert inputs.ndim == 1
        docs = (inputs == 50256).cumsum(0)
        docs_low = docs.view(-1, BLOCK_SIZE)[:, 0].contiguous()
        docs_high = docs.view(-1, BLOCK_SIZE)[:, -1].contiguous()

        def document_causal(b, h, q_idx, kv_idx):
            causal_mask = q_idx >= kv_idx
            document_mask = docs[q_idx] == docs[kv_idx]
            return causal_mask & document_mask

        def dense_to_ordered(dense_mask):
            num_blocks = dense_mask.sum(dim=-1, dtype=torch.int32)
            indices = dense_mask.argsort(dim=-1, descending=True, stable=True).to(torch.int32)
            return num_blocks[None, None].contiguous(), indices[None, None].contiguous()

        def create_doc_swc_block_mask(sliding_window_num_blocks):
            kv_idx = block_idx = torch.arange(total_num_blocks, dtype=torch.int32, device='cuda')
            q_idx = block_idx[:, None]
            causal_bm = q_idx >= kv_idx
            causal_full_bm = q_idx > kv_idx
            window_bm = q_idx - kv_idx < sliding_window_num_blocks
            window_full_bm = window_bm # block-wise sliding window by @YouJiacheng
            # document_bm = (docs_low[q_idx] <= docs_high[kv_idx]) & (docs_low[kv_idx] <= docs_high[q_idx])
            document_bm = (docs_low[:, None] <= docs_high) & (docs_low <= docs_high[:, None])
            document_full_bm = (docs_low[:, None] == docs_high) & (docs_low == docs_high[:, None])
            nonzero_bm = causal_bm & window_bm & document_bm
            full_bm  = causal_full_bm & window_full_bm & document_full_bm
            kv_num_blocks, kv_indices = dense_to_ordered(nonzero_bm & ~full_bm)
            full_kv_num_blocks, full_kv_indices = dense_to_ordered(full_bm)
            return BlockMask.from_kv_blocks(
                kv_num_blocks,
                kv_indices,
                full_kv_num_blocks,
                full_kv_indices,
                BLOCK_SIZE=BLOCK_SIZE,
                mask_mod=document_causal,
            )

        block_mask = create_doc_swc_block_mask(sliding_window_num_blocks)

        x0 = norm(self.embed(inputs[None]).bfloat16()) # use of norm here by @Grad62304977
        x = x0
        ve = self.value_embeds(inputs)
        assert len(ve) == len(self.blocks)
        ve_enc, ve_dec = ve[:self.num_encoder_layers], ve[self.num_encoder_layers:]

        # Store outputs for U-Net skip connections
        skip_connections = []
        # Encoder pass - process only the first half of the blocks
        for i in range(self.num_encoder_layers):
            x = self.blocks[i](x, ve_enc[i], x0, block_mask)
            skip_connections.append(x)
        # Decoder pass - process the remaining blocks with weighted skip connections
        for i in range(self.num_decoder_layers):
            x = x + self.skip_weights[i] * skip_connections.pop()
            # U-net structure on token value embeddings by @leloykun
            x = self.blocks[self.num_encoder_layers + i](x, ve_dec[i], x0, block_mask)

        x = norm(x)
        logits = self.lm_head(x)
        logits = 15 * torch.tanh(logits / 15) # @Grad62304977 added tanh softcapping, @KoszarskyB reduced it from 30 to 15
        logits = logits.float()
        loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets)
        return loss

# -----------------------------------------------------------------------------
# Our own simple Distributed Data Loader

def _load_data_shard(path):
    # only reads the header, returns header data
    # header is 256 int32
    header = torch.from_file(path, False, 256, dtype=torch.int32)
    assert header[0] == 20240520, 'magic number mismatch in the data .bin file'
    assert header[1] == 1, 'unsupported version'
    num_tokens = int(header[2]) # number of tokens (claimed)
    with open(path, 'rb', buffering=0) as f:
        tokens = torch.empty(num_tokens, dtype=torch.uint16, pin_memory=True) # avoid pin_memory copy by @YouJiacheng
        f.seek(256 * 4)
        nbytes = f.readinto(tokens.numpy()) # avoid bytes->array copy by @YouJiacheng
        assert nbytes == 2 * num_tokens, 'number of tokens read does not match header'
    return tokens

class DistributedDataLoader:

    def __init__(self, filename_pattern):
        self.rank = int(os.environ['RANK'])
        self.world_size = int(os.environ['WORLD_SIZE'])
        self.files = sorted(glob.glob(filename_pattern))
        self.reset()

    def reset(self):
        self.current_shard = -1
        self.advance()

    def advance(self):
        self.current_shard = (self.current_shard + 1) % len(self.files)
        self.current_position = 0
        self.tokens = _load_data_shard(self.files[self.current_shard])

    def next_batch(self, batch_size):
        assert batch_size % self.world_size == 0
        device_batch_size = batch_size // self.world_size
        # load next shard if necessary
        if self.current_position + batch_size + 1 >= len(self.tokens):
            self.advance()
        pos = self.current_position + self.rank * device_batch_size
        device_batch_tokens = self.tokens[pos:pos+device_batch_size+1]
        # advance current position
        self.current_position += batch_size
        inputs = device_batch_tokens[:-1].to(device='cuda', dtype=torch.int32, non_blocking=True)
        targets = device_batch_tokens[1:].to(device='cuda', dtype=torch.int64, non_blocking=True)
        return inputs, targets

# -----------------------------------------------------------------------------
# int main

@dataclass
class Hyperparameters:
    # data
    train_files = 'data/fineweb10B/fineweb_train_*.bin' # input .bin to train on
    val_files = 'data/fineweb10B/fineweb_val_*.bin' # input .bin to eval validation loss on
    val_tokens = 10485760 # how many tokens of validation data? it's important to keep this fixed for consistent comparisons
    # optimization
    batch_size = 8*64*1024 # batch size in tokens
    num_iterations = 1390 # number of iterations to run
    cooldown_frac = 0.4 # fraction of training spent cooling down the learning rate
    bf16_embeds = True
    # evaluation and logging
    val_loss_every = 125 # every how many steps to evaluate val loss? 0 for only at the end
    # implementation
    max_device_batch_size = 64*1024 # batch size per device in tokens
    save_checkpoint = False
args = Hyperparameters()

micro_bs = args.max_device_batch_size

# set up DDP (distributed data parallel). torchrun sets this env variable
rank = int(os.environ['RANK'])
local_rank = int(os.environ['LOCAL_RANK'])
world_size = int(os.environ['WORLD_SIZE'])
assert torch.cuda.is_available()
torch.cuda.set_device(local_rank)
dist.init_process_group(backend='nccl', device_id=torch.device(local_rank))
dist.barrier()
master_process = (rank == 0) # this process will do logging, checkpointing etc.

# begin logging
logfile = None
if master_process:
    run_id = uuid.uuid4()
    os.makedirs('logs', exist_ok=True)
    logfile = f'logs/{run_id}.txt'
    print(logfile)

def print0(s, console=False):
    if master_process:
        with open(logfile, 'a') as f:
            if console:
                print(s)
            print(s, file=f)

# begin by printing this file (the Python code)
print0(code)
print0('='*100)
# log information about the hardware/software environment this is running on
print0(f'Running Python {sys.version}')
print0(f'Running PyTorch {torch.version.__version__} compiled for CUDA {torch.version.cuda}')
print0(subprocess.run(['nvidia-smi'], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True).stdout)
print0('='*100)

# load data
train_loader = DistributedDataLoader(args.train_files)
val_loader = DistributedDataLoader(args.val_files)
print0(f'Training dataloader files: {train_loader.files}')
print0(f'Validation dataloader files: {val_loader.files}')
print0('='*100)

# there are only 50257 unique GPT-2 tokens; we extend to nearest multiple of 128 for efficiency. suggested to me by @Grad62304977.
# this originates from Karpathy's experiments.
model = GPT(vocab_size=50304, num_layers=12, num_heads=6, model_dim=768)
model = model.cuda()
if args.bf16_embeds:
    for m in model.modules():
        if isinstance(m, nn.Embedding):
            m.bfloat16()
model = torch.compile(model)
ddp_model = DDP(model, device_ids=[local_rank], broadcast_buffers=False, gradient_as_bucket_view=True)

# collect the parameters to optimize
hidden_matrix_params = [p for p in model.blocks.parameters() if p.ndim == 2]
embed_params = [model.embed.weight, *model.value_embeds.parameters()]
scalar_params = [p for p in model.parameters() if p.ndim < 2]
head_params = [model.lm_head.weight]

# init the optimizer(s)
optimizer1 = torch.optim.Adam([dict(params=embed_params, lr=0.6),
                               dict(params=head_params, lr=0.008),
                               dict(params=scalar_params, lr=0.04)],
                              betas=(0.8, 0.95), fused=True)
# optimizer2 = Muon(hidden_matrix_params, lr=0.5, momentum=0.95)
# optimizer2 = Muon(hidden_matrix_params, lr=0.25, momentum=0.95)
optimizer2 = Muon(hidden_matrix_params, lr=0.1, momentum=0.95)
# optimizer2 = Muon(hidden_matrix_params, lr=0.05, momentum=0.95)  # done
# optimizer2 = Muon(hidden_matrix_params, lr=0.01, momentum=0.95)
# optimizer2 = Muon(hidden_matrix_params, lr=0.025, momentum=0.95)
# optimizer2 = Muon(hidden_matrix_params, lr=0.005, momentum=0.95)
optimizers = [optimizer1, optimizer2]

# learning rate schedule: stable then decay
def get_lr(it):
    t = 1 - it / args.num_iterations # time remaining in training
    assert 1 >= t > 0
    # 1) constant lr for first part of training
    if t >= args.cooldown_frac:
        return 1.0
    # 2) then linear cooldown
    else:
        return t / args.cooldown_frac
schedulers = [torch.optim.lr_scheduler.LambdaLR(opt, get_lr) for opt in optimizers]

# sliding window size schedule: linear increase over training in chunks of 128 from 128 -> 1792. By @fernbear.bsky.social
def get_sliding_window_blocks(it):
    x = it / args.num_iterations # training progress
    assert 0 <= x <= 1
    return int(((1 - x) * 128 + x * 1856) // 128)
sliding_window_num_blocks = torch.tensor(1, dtype=torch.int32, device='cuda')

# Start training loop
training_time_ms = 0
# start the clock
torch.cuda.synchronize()
t0 = time.perf_counter()
# begin training
train_steps = args.num_iterations
for step in range(train_steps + 1):
    last_step = (step == train_steps)
    # This effectively ignores timing first 10 steps, which are slower for weird reasons.
    # Alternately, and slightly more correctly in terms of benchmarking, we could do 10
    # steps with dummy data first, and then re-initialize the model and reset the loader.
    if step == 10:
        training_time_ms = 0
        t0 = time.perf_counter()
    timed_steps = float('nan') if step <= 11 else (step - 10) + 1 # <= 11 to avoid bug in val

    sliding_window_num_blocks.copy_(get_sliding_window_blocks(step))

    # --------------- VALIDATION SECTION -----------------
    if last_step or (args.val_loss_every > 0 and step % args.val_loss_every == 0):
        # stop the clock
        torch.cuda.synchronize()
        training_time_ms += 1000 * (time.perf_counter() - t0)
        # run validation batches
        model.eval()
        val_loader.reset()
        val_loss = 0.0
        # calculate the number of steps to take in the val loop.
        val_batch_size = world_size * micro_bs
        assert args.val_tokens % val_batch_size == 0
        val_steps = args.val_tokens // val_batch_size
        for _ in range(val_steps):
            with torch.no_grad():
                inputs_val, targets_val = val_loader.next_batch(val_batch_size)
                val_loss += ddp_model(inputs_val, targets_val, sliding_window_num_blocks)
        dist.all_reduce(val_loss, op=dist.ReduceOp.AVG)
        val_loss /= val_steps
        # logging
        print0(f'step:{step}/{train_steps} val_loss:{val_loss:.4f} train_time:{training_time_ms:.0f}ms step_avg:{training_time_ms/(timed_steps-1):.2f}ms', console=True)
        # start the clock again
        torch.cuda.synchronize()
        t0 = time.perf_counter()

    if last_step:
        if master_process and args.save_checkpoint:
            log = dict(step=step, code=code, model=model.state_dict(), optimizers=[opt.state_dict() for opt in optimizers])
            os.makedirs(f'logs/{run_id}', exist_ok=True)
            torch.save(log, f'logs/{run_id}/state_step{step:06d}.pt')
        # the last step only has the validation loop, so break to avoid training
        break

    # --------------- TRAINING SECTION -----------------
    model.train()
    batch_size = args.batch_size
    assert batch_size % world_size == 0
    inputs_train, targets_train = train_loader.next_batch(batch_size)
    assert len(inputs_train) <= micro_bs or len(inputs_train) % micro_bs == 0
    for micro_inputs_train, micro_targets_train in zip(inputs_train.split(micro_bs), targets_train.split(micro_bs)):
        ddp_model(micro_inputs_train, micro_targets_train, sliding_window_num_blocks).backward()
    # momentum warmup for Muon
    frac = min(step/300, 1)
    for group in optimizer2.param_groups:
        group['momentum'] = (1 - frac) * 0.85 + frac * 0.95
    # step the optimizers and schedulers
    for opt, sched in zip(optimizers, schedulers):
        opt.step()
        if step != train_steps-1:
            sched.step()
    # null the gradients
    model.zero_grad(set_to_none=True)
    # logging
    approx_time = training_time_ms + 1000 * (time.perf_counter() - t0)
    print0(f'step:{step+1}/{train_steps} train_time:{approx_time:.0f}ms step_avg:{approx_time/timed_steps:.2f}ms', console=True)

print0(f'peak memory consumption: {torch.cuda.max_memory_allocated() // 1024 // 1024} MiB')
dist.destroy_process_group()

====================================================================================================
Running Python 3.10.12 (main, Sep 11 2024, 15:47:36) [GCC 11.4.0]
Running PyTorch 2.6.0.dev20241231+cu126 compiled for CUDA 12.6
Tue Jan 14 17:27:08 2025       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.183.06             Driver Version: 535.183.06   CUDA Version: 12.4     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA H100 80GB HBM3          On  | 00000000:19:00.0 Off |                    0 |
| N/A   28C    P0             118W / 700W |   7713MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   1  NVIDIA H100 80GB HBM3          On  | 00000000:3B:00.0 Off |                    0 |
| N/A   29C    P0             113W / 700W |   3451MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   2  NVIDIA H100 80GB HBM3          On  | 00000000:4C:00.0 Off |                    0 |
| N/A   25C    P0             116W / 700W |   3451MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   3  NVIDIA H100 80GB HBM3          On  | 00000000:5D:00.0 Off |                    0 |
| N/A   28C    P0             120W / 700W |   3451MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   4  NVIDIA H100 80GB HBM3          On  | 00000000:9B:00.0 Off |                    0 |
| N/A   29C    P0             117W / 700W |   3451MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   5  NVIDIA H100 80GB HBM3          On  | 00000000:BB:00.0 Off |                    0 |
| N/A   26C    P0             112W / 700W |   3451MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   6  NVIDIA H100 80GB HBM3          On  | 00000000:CB:00.0 Off |                    0 |
| N/A   27C    P0             109W / 700W |   3451MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   7  NVIDIA H100 80GB HBM3          On  | 00000000:DB:00.0 Off |                    0 |
| N/A   26C    P0             114W / 700W |   3211MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
+---------------------------------------------------------------------------------------+

====================================================================================================
Training dataloader files: ['data/fineweb10B/fineweb_train_000001.bin', 'data/fineweb10B/fineweb_train_000002.bin', 'data/fineweb10B/fineweb_train_000003.bin', 'data/fineweb10B/fineweb_train_000004.bin', 'data/fineweb10B/fineweb_train_000005.bin', 'data/fineweb10B/fineweb_train_000006.bin', 'data/fineweb10B/fineweb_train_000007.bin', 'data/fineweb10B/fineweb_train_000008.bin', 'data/fineweb10B/fineweb_train_000009.bin']
Validation dataloader files: ['data/fineweb10B/fineweb_val_000000.bin']
====================================================================================================
step:0/1390 val_loss:10.8258 train_time:0ms step_avg:nanms
step:1/1390 train_time:31209ms step_avg:nanms
step:2/1390 train_time:31309ms step_avg:nanms
step:3/1390 train_time:32402ms step_avg:nanms
step:4/1390 train_time:32537ms step_avg:nanms
step:5/1390 train_time:32671ms step_avg:nanms
step:6/1390 train_time:32806ms step_avg:nanms
step:7/1390 train_time:32941ms step_avg:nanms
step:8/1390 train_time:33076ms step_avg:nanms
step:9/1390 train_time:33211ms step_avg:nanms
step:10/1390 train_time:33350ms step_avg:nanms
step:11/1390 train_time:137ms step_avg:nanms
step:12/1390 train_time:273ms step_avg:nanms
step:13/1390 train_time:408ms step_avg:136.15ms
step:14/1390 train_time:544ms step_avg:136.08ms
step:15/1390 train_time:681ms step_avg:136.12ms
step:16/1390 train_time:817ms step_avg:136.13ms
step:17/1390 train_time:951ms step_avg:135.83ms
step:18/1390 train_time:1088ms step_avg:136.06ms
step:19/1390 train_time:1226ms step_avg:136.17ms
step:20/1390 train_time:1362ms step_avg:136.22ms
step:21/1390 train_time:1502ms step_avg:136.51ms
step:22/1390 train_time:1635ms step_avg:136.25ms
step:23/1390 train_time:1770ms step_avg:136.19ms
step:24/1390 train_time:1906ms step_avg:136.12ms
step:25/1390 train_time:2042ms step_avg:136.15ms
step:26/1390 train_time:2179ms step_avg:136.18ms
step:27/1390 train_time:2313ms step_avg:136.09ms
step:28/1390 train_time:2449ms step_avg:136.05ms
step:29/1390 train_time:2585ms step_avg:136.06ms
step:30/1390 train_time:2720ms step_avg:136.02ms
step:31/1390 train_time:2856ms step_avg:135.98ms
step:32/1390 train_time:2992ms step_avg:136.01ms
step:33/1390 train_time:3129ms step_avg:136.03ms
step:34/1390 train_time:3263ms step_avg:135.97ms
step:35/1390 train_time:3399ms step_avg:135.98ms
step:36/1390 train_time:3534ms step_avg:135.94ms
step:37/1390 train_time:3670ms step_avg:135.91ms
step:38/1390 train_time:3806ms step_avg:135.93ms
step:39/1390 train_time:3943ms step_avg:135.97ms
step:40/1390 train_time:4079ms step_avg:135.96ms
step:41/1390 train_time:4214ms step_avg:135.95ms
step:42/1390 train_time:4349ms step_avg:135.92ms
step:43/1390 train_time:4485ms step_avg:135.90ms
step:44/1390 train_time:4621ms step_avg:135.92ms
step:45/1390 train_time:4757ms step_avg:135.91ms
step:46/1390 train_time:4893ms step_avg:135.92ms
step:47/1390 train_time:5028ms step_avg:135.89ms
step:48/1390 train_time:5163ms step_avg:135.88ms
step:49/1390 train_time:5298ms step_avg:135.84ms
step:50/1390 train_time:5432ms step_avg:135.81ms
step:51/1390 train_time:5568ms step_avg:135.80ms
step:52/1390 train_time:5703ms step_avg:135.79ms
step:53/1390 train_time:5839ms step_avg:135.79ms
step:54/1390 train_time:5974ms step_avg:135.78ms
step:55/1390 train_time:6109ms step_avg:135.76ms
step:56/1390 train_time:6245ms step_avg:135.76ms
step:57/1390 train_time:6383ms step_avg:135.81ms
step:58/1390 train_time:6519ms step_avg:135.82ms
step:59/1390 train_time:6653ms step_avg:135.78ms
step:60/1390 train_time:6788ms step_avg:135.76ms
step:61/1390 train_time:6926ms step_avg:135.80ms
step:62/1390 train_time:7060ms step_avg:135.77ms
step:63/1390 train_time:7195ms step_avg:135.76ms
step:64/1390 train_time:7330ms step_avg:135.75ms
step:65/1390 train_time:7467ms step_avg:135.77ms
step:66/1390 train_time:7604ms step_avg:135.78ms
step:67/1390 train_time:7738ms step_avg:135.76ms
step:68/1390 train_time:7875ms step_avg:135.78ms
step:69/1390 train_time:8011ms step_avg:135.77ms
step:70/1390 train_time:8146ms step_avg:135.77ms
step:71/1390 train_time:8283ms step_avg:135.78ms
step:72/1390 train_time:8419ms step_avg:135.79ms
step:73/1390 train_time:8553ms step_avg:135.76ms
step:74/1390 train_time:8689ms step_avg:135.77ms
step:75/1390 train_time:8826ms step_avg:135.78ms
step:76/1390 train_time:8963ms step_avg:135.80ms
step:77/1390 train_time:9099ms step_avg:135.80ms
step:78/1390 train_time:9235ms step_avg:135.81ms
step:79/1390 train_time:9371ms step_avg:135.81ms
step:80/1390 train_time:9507ms step_avg:135.81ms
step:81/1390 train_time:9643ms step_avg:135.82ms
step:82/1390 train_time:9779ms step_avg:135.82ms
step:83/1390 train_time:9914ms step_avg:135.81ms
step:84/1390 train_time:10050ms step_avg:135.81ms
step:85/1390 train_time:10185ms step_avg:135.80ms
step:86/1390 train_time:10324ms step_avg:135.84ms
step:87/1390 train_time:10459ms step_avg:135.84ms
step:88/1390 train_time:10595ms step_avg:135.84ms
step:89/1390 train_time:10732ms step_avg:135.85ms
step:90/1390 train_time:10867ms step_avg:135.84ms
step:91/1390 train_time:11005ms step_avg:135.86ms
step:92/1390 train_time:11139ms step_avg:135.84ms
step:93/1390 train_time:11275ms step_avg:135.84ms
step:94/1390 train_time:11409ms step_avg:135.82ms
step:95/1390 train_time:11545ms step_avg:135.83ms
step:96/1390 train_time:11683ms step_avg:135.85ms
step:97/1390 train_time:11818ms step_avg:135.84ms
step:98/1390 train_time:11952ms step_avg:135.82ms
step:99/1390 train_time:12089ms step_avg:135.83ms
step:100/1390 train_time:12226ms step_avg:135.84ms
step:101/1390 train_time:12362ms step_avg:135.85ms
step:102/1390 train_time:12498ms step_avg:135.85ms
step:103/1390 train_time:12634ms step_avg:135.85ms
step:104/1390 train_time:12770ms step_avg:135.85ms
step:105/1390 train_time:12910ms step_avg:135.89ms
step:106/1390 train_time:13050ms step_avg:135.94ms
step:107/1390 train_time:13191ms step_avg:135.99ms
step:108/1390 train_time:13330ms step_avg:136.02ms
step:109/1390 train_time:13469ms step_avg:136.05ms
step:110/1390 train_time:13610ms step_avg:136.10ms
step:111/1390 train_time:13749ms step_avg:136.13ms
step:112/1390 train_time:13889ms step_avg:136.17ms
step:113/1390 train_time:14028ms step_avg:136.20ms
step:114/1390 train_time:14169ms step_avg:136.24ms
step:115/1390 train_time:14308ms step_avg:136.27ms
step:116/1390 train_time:14446ms step_avg:136.29ms
step:117/1390 train_time:14586ms step_avg:136.32ms
step:118/1390 train_time:14724ms step_avg:136.34ms
step:119/1390 train_time:14863ms step_avg:136.36ms
step:120/1390 train_time:15003ms step_avg:136.39ms
step:121/1390 train_time:15143ms step_avg:136.42ms
step:122/1390 train_time:15284ms step_avg:136.47ms
step:123/1390 train_time:15423ms step_avg:136.48ms
step:124/1390 train_time:15560ms step_avg:136.49ms
step:125/1390 train_time:15700ms step_avg:136.52ms
step:125/1390 val_loss:4.5507 train_time:15764ms step_avg:137.08ms
step:126/1390 train_time:15846ms step_avg:136.60ms
step:127/1390 train_time:15986ms step_avg:136.63ms
step:128/1390 train_time:16125ms step_avg:136.65ms
step:129/1390 train_time:16264ms step_avg:136.67ms
step:130/1390 train_time:16402ms step_avg:136.68ms
step:131/1390 train_time:16540ms step_avg:136.69ms
step:132/1390 train_time:16678ms step_avg:136.71ms
step:133/1390 train_time:16821ms step_avg:136.75ms
step:134/1390 train_time:16963ms step_avg:136.80ms
step:135/1390 train_time:17102ms step_avg:136.82ms
step:136/1390 train_time:17241ms step_avg:136.83ms
step:137/1390 train_time:17380ms step_avg:136.85ms
step:138/1390 train_time:17518ms step_avg:136.86ms
step:139/1390 train_time:17656ms step_avg:136.87ms
step:140/1390 train_time:17795ms step_avg:136.89ms
step:141/1390 train_time:17937ms step_avg:136.92ms
step:142/1390 train_time:18077ms step_avg:136.94ms
step:143/1390 train_time:18216ms step_avg:136.96ms
step:144/1390 train_time:18355ms step_avg:136.98ms
step:145/1390 train_time:18495ms step_avg:137.00ms
step:146/1390 train_time:18633ms step_avg:137.00ms
step:147/1390 train_time:18771ms step_avg:137.01ms
step:148/1390 train_time:18913ms step_avg:137.05ms
step:149/1390 train_time:19055ms step_avg:137.09ms
step:150/1390 train_time:19197ms step_avg:137.12ms
step:151/1390 train_time:19337ms step_avg:137.14ms
step:152/1390 train_time:19476ms step_avg:137.15ms
step:153/1390 train_time:19614ms step_avg:137.16ms
step:154/1390 train_time:19753ms step_avg:137.17ms
step:155/1390 train_time:19893ms step_avg:137.19ms
step:156/1390 train_time:20036ms step_avg:137.23ms
step:157/1390 train_time:20177ms step_avg:137.26ms
step:158/1390 train_time:20317ms step_avg:137.27ms
step:159/1390 train_time:20458ms step_avg:137.30ms
step:160/1390 train_time:20597ms step_avg:137.31ms
step:161/1390 train_time:20736ms step_avg:137.32ms
step:162/1390 train_time:20875ms step_avg:137.34ms
step:163/1390 train_time:21014ms step_avg:137.35ms
step:164/1390 train_time:21154ms step_avg:137.36ms
step:165/1390 train_time:21294ms step_avg:137.38ms
step:166/1390 train_time:21434ms step_avg:137.40ms
step:167/1390 train_time:21575ms step_avg:137.42ms
step:168/1390 train_time:21715ms step_avg:137.44ms
step:169/1390 train_time:21855ms step_avg:137.45ms
step:170/1390 train_time:21995ms step_avg:137.47ms
step:171/1390 train_time:22135ms step_avg:137.48ms
step:172/1390 train_time:22274ms step_avg:137.50ms
step:173/1390 train_time:22414ms step_avg:137.51ms
step:174/1390 train_time:22555ms step_avg:137.53ms
step:175/1390 train_time:22696ms step_avg:137.55ms
step:176/1390 train_time:22836ms step_avg:137.57ms
step:177/1390 train_time:22977ms step_avg:137.58ms
step:178/1390 train_time:23116ms step_avg:137.60ms
step:179/1390 train_time:23256ms step_avg:137.61ms
step:180/1390 train_time:23397ms step_avg:137.63ms
step:181/1390 train_time:23538ms step_avg:137.65ms
step:182/1390 train_time:23678ms step_avg:137.66ms
step:183/1390 train_time:23820ms step_avg:137.69ms
step:184/1390 train_time:23961ms step_avg:137.71ms
step:185/1390 train_time:24101ms step_avg:137.72ms
step:186/1390 train_time:24242ms step_avg:137.74ms
step:187/1390 train_time:24382ms step_avg:137.75ms
step:188/1390 train_time:24523ms step_avg:137.77ms
step:189/1390 train_time:24663ms step_avg:137.78ms
step:190/1390 train_time:24803ms step_avg:137.79ms
step:191/1390 train_time:24977ms step_avg:138.00ms
step:192/1390 train_time:25116ms step_avg:138.00ms
step:193/1390 train_time:25254ms step_avg:138.00ms
step:194/1390 train_time:25393ms step_avg:138.01ms
step:195/1390 train_time:25530ms step_avg:138.00ms
step:196/1390 train_time:25669ms step_avg:138.01ms
step:197/1390 train_time:25810ms step_avg:138.02ms
step:198/1390 train_time:25955ms step_avg:138.06ms
step:199/1390 train_time:26098ms step_avg:138.09ms
step:200/1390 train_time:26239ms step_avg:138.10ms
step:201/1390 train_time:26377ms step_avg:138.10ms
step:202/1390 train_time:26516ms step_avg:138.10ms
step:203/1390 train_time:26655ms step_avg:138.11ms
step:204/1390 train_time:26797ms step_avg:138.13ms
step:205/1390 train_time:26940ms step_avg:138.15ms
step:206/1390 train_time:27082ms step_avg:138.17ms
step:207/1390 train_time:27223ms step_avg:138.19ms
step:208/1390 train_time:27367ms step_avg:138.22ms
step:209/1390 train_time:27509ms step_avg:138.24ms
step:210/1390 train_time:27652ms step_avg:138.26ms
step:211/1390 train_time:27795ms step_avg:138.28ms
step:212/1390 train_time:27941ms step_avg:138.32ms
step:213/1390 train_time:28085ms step_avg:138.35ms
step:214/1390 train_time:28227ms step_avg:138.37ms
step:215/1390 train_time:28370ms step_avg:138.39ms
step:216/1390 train_time:28512ms step_avg:138.41ms
step:217/1390 train_time:28655ms step_avg:138.43ms
step:218/1390 train_time:28799ms step_avg:138.46ms
step:219/1390 train_time:28943ms step_avg:138.48ms
step:220/1390 train_time:29086ms step_avg:138.51ms
step:221/1390 train_time:29229ms step_avg:138.53ms
step:222/1390 train_time:29371ms step_avg:138.54ms
step:223/1390 train_time:29514ms step_avg:138.56ms
step:224/1390 train_time:29656ms step_avg:138.58ms
step:225/1390 train_time:29802ms step_avg:138.61ms
step:226/1390 train_time:29948ms step_avg:138.65ms
step:227/1390 train_time:30092ms step_avg:138.67ms
step:228/1390 train_time:30236ms step_avg:138.70ms
step:229/1390 train_time:30378ms step_avg:138.71ms
step:230/1390 train_time:30521ms step_avg:138.73ms
step:231/1390 train_time:30664ms step_avg:138.75ms
step:232/1390 train_time:30808ms step_avg:138.78ms
step:233/1390 train_time:30951ms step_avg:138.80ms
step:234/1390 train_time:31095ms step_avg:138.82ms
step:235/1390 train_time:31238ms step_avg:138.84ms
step:236/1390 train_time:31379ms step_avg:138.85ms
step:237/1390 train_time:31522ms step_avg:138.86ms
step:238/1390 train_time:31664ms step_avg:138.88ms
step:239/1390 train_time:31806ms step_avg:138.89ms
step:240/1390 train_time:31950ms step_avg:138.91ms
step:241/1390 train_time:32095ms step_avg:138.94ms
step:242/1390 train_time:32238ms step_avg:138.96ms
step:243/1390 train_time:32381ms step_avg:138.97ms
step:244/1390 train_time:32521ms step_avg:138.98ms
step:245/1390 train_time:32665ms step_avg:139.00ms
step:246/1390 train_time:32807ms step_avg:139.01ms
step:247/1390 train_time:32950ms step_avg:139.03ms
step:248/1390 train_time:33095ms step_avg:139.05ms
step:249/1390 train_time:33237ms step_avg:139.07ms
step:250/1390 train_time:33379ms step_avg:139.08ms
step:250/1390 val_loss:4.1088 train_time:33442ms step_avg:139.34ms
step:251/1390 train_time:33522ms step_avg:139.09ms
step:252/1390 train_time:33667ms step_avg:139.12ms
step:253/1390 train_time:33809ms step_avg:139.13ms
step:254/1390 train_time:33951ms step_avg:139.14ms
step:255/1390 train_time:34093ms step_avg:139.15ms
step:256/1390 train_time:34233ms step_avg:139.16ms
step:257/1390 train_time:34377ms step_avg:139.18ms
step:258/1390 train_time:34523ms step_avg:139.21ms
step:259/1390 train_time:34669ms step_avg:139.23ms
step:260/1390 train_time:34812ms step_avg:139.25ms
step:261/1390 train_time:34955ms step_avg:139.26ms
step:262/1390 train_time:35097ms step_avg:139.27ms
step:263/1390 train_time:35238ms step_avg:139.28ms
step:264/1390 train_time:35380ms step_avg:139.29ms
step:265/1390 train_time:35524ms step_avg:139.31ms
step:266/1390 train_time:35668ms step_avg:139.33ms
step:267/1390 train_time:35812ms step_avg:139.35ms
step:268/1390 train_time:35953ms step_avg:139.35ms
step:269/1390 train_time:36094ms step_avg:139.36ms
step:270/1390 train_time:36236ms step_avg:139.37ms
step:271/1390 train_time:36378ms step_avg:139.38ms
step:272/1390 train_time:36522ms step_avg:139.40ms
step:273/1390 train_time:36667ms step_avg:139.42ms
step:274/1390 train_time:36812ms step_avg:139.44ms
step:275/1390 train_time:36954ms step_avg:139.45ms
step:276/1390 train_time:37095ms step_avg:139.46ms
step:277/1390 train_time:37238ms step_avg:139.47ms
step:278/1390 train_time:37381ms step_avg:139.48ms
step:279/1390 train_time:37525ms step_avg:139.50ms
step:280/1390 train_time:37668ms step_avg:139.51ms
step:281/1390 train_time:37812ms step_avg:139.53ms
step:282/1390 train_time:37956ms step_avg:139.55ms
step:283/1390 train_time:38097ms step_avg:139.55ms
step:284/1390 train_time:38238ms step_avg:139.55ms
step:285/1390 train_time:38381ms step_avg:139.57ms
step:286/1390 train_time:38524ms step_avg:139.58ms
step:287/1390 train_time:38669ms step_avg:139.60ms
step:288/1390 train_time:38813ms step_avg:139.62ms
step:289/1390 train_time:38959ms step_avg:139.64ms
step:290/1390 train_time:39101ms step_avg:139.65ms
step:291/1390 train_time:39242ms step_avg:139.65ms
step:292/1390 train_time:39385ms step_avg:139.66ms
step:293/1390 train_time:39527ms step_avg:139.67ms
step:294/1390 train_time:39670ms step_avg:139.68ms
step:295/1390 train_time:39812ms step_avg:139.69ms
step:296/1390 train_time:39956ms step_avg:139.71ms
step:297/1390 train_time:40099ms step_avg:139.72ms
step:298/1390 train_time:40241ms step_avg:139.72ms
step:299/1390 train_time:40384ms step_avg:139.74ms
step:300/1390 train_time:40525ms step_avg:139.74ms
step:301/1390 train_time:40669ms step_avg:139.76ms
step:302/1390 train_time:40813ms step_avg:139.77ms
step:303/1390 train_time:40957ms step_avg:139.78ms
step:304/1390 train_time:41099ms step_avg:139.79ms
step:305/1390 train_time:41242ms step_avg:139.80ms
step:306/1390 train_time:41385ms step_avg:139.81ms
step:307/1390 train_time:41529ms step_avg:139.83ms
step:308/1390 train_time:41672ms step_avg:139.84ms
step:309/1390 train_time:41816ms step_avg:139.85ms
step:310/1390 train_time:41961ms step_avg:139.87ms
step:311/1390 train_time:42105ms step_avg:139.88ms
step:312/1390 train_time:42249ms step_avg:139.90ms
step:313/1390 train_time:42394ms step_avg:139.91ms
step:314/1390 train_time:42538ms step_avg:139.93ms
step:315/1390 train_time:42685ms step_avg:139.95ms
step:316/1390 train_time:42830ms step_avg:139.97ms
step:317/1390 train_time:42976ms step_avg:139.99ms
step:318/1390 train_time:43121ms step_avg:140.00ms
step:319/1390 train_time:43267ms step_avg:140.02ms
step:320/1390 train_time:43413ms step_avg:140.04ms
step:321/1390 train_time:43559ms step_avg:140.06ms
step:322/1390 train_time:43705ms step_avg:140.08ms
step:323/1390 train_time:43847ms step_avg:140.09ms
step:324/1390 train_time:43992ms step_avg:140.10ms
step:325/1390 train_time:44136ms step_avg:140.11ms
step:326/1390 train_time:44281ms step_avg:140.13ms
step:327/1390 train_time:44425ms step_avg:140.14ms
step:328/1390 train_time:44572ms step_avg:140.16ms
step:329/1390 train_time:44718ms step_avg:140.18ms
step:330/1390 train_time:44864ms step_avg:140.20ms
step:331/1390 train_time:45009ms step_avg:140.21ms
step:332/1390 train_time:45154ms step_avg:140.23ms
step:333/1390 train_time:45298ms step_avg:140.24ms
step:334/1390 train_time:45442ms step_avg:140.25ms
step:335/1390 train_time:45586ms step_avg:140.27ms
step:336/1390 train_time:45731ms step_avg:140.28ms
step:337/1390 train_time:45876ms step_avg:140.29ms
step:338/1390 train_time:46021ms step_avg:140.31ms
step:339/1390 train_time:46165ms step_avg:140.32ms
step:340/1390 train_time:46309ms step_avg:140.33ms
step:341/1390 train_time:46454ms step_avg:140.34ms
step:342/1390 train_time:46599ms step_avg:140.36ms
step:343/1390 train_time:46743ms step_avg:140.37ms
step:344/1390 train_time:46890ms step_avg:140.39ms
step:345/1390 train_time:47034ms step_avg:140.40ms
step:346/1390 train_time:47179ms step_avg:140.41ms
step:347/1390 train_time:47323ms step_avg:140.42ms
step:348/1390 train_time:47467ms step_avg:140.44ms
step:349/1390 train_time:47612ms step_avg:140.45ms
step:350/1390 train_time:47758ms step_avg:140.46ms
step:351/1390 train_time:47904ms step_avg:140.48ms
step:352/1390 train_time:48049ms step_avg:140.49ms
step:353/1390 train_time:48194ms step_avg:140.51ms
step:354/1390 train_time:48338ms step_avg:140.52ms
step:355/1390 train_time:48484ms step_avg:140.53ms
step:356/1390 train_time:48627ms step_avg:140.54ms
step:357/1390 train_time:48773ms step_avg:140.56ms
step:358/1390 train_time:48920ms step_avg:140.57ms
step:359/1390 train_time:49063ms step_avg:140.58ms
step:360/1390 train_time:49209ms step_avg:140.60ms
step:361/1390 train_time:49354ms step_avg:140.61ms
step:362/1390 train_time:49499ms step_avg:140.62ms
step:363/1390 train_time:49643ms step_avg:140.63ms
step:364/1390 train_time:49788ms step_avg:140.64ms
step:365/1390 train_time:49934ms step_avg:140.66ms
step:366/1390 train_time:50080ms step_avg:140.67ms
step:367/1390 train_time:50224ms step_avg:140.68ms
step:368/1390 train_time:50369ms step_avg:140.70ms
step:369/1390 train_time:50515ms step_avg:140.71ms
step:370/1390 train_time:50663ms step_avg:140.73ms
step:371/1390 train_time:50808ms step_avg:140.74ms
step:372/1390 train_time:50954ms step_avg:140.76ms
step:373/1390 train_time:51099ms step_avg:140.77ms
step:374/1390 train_time:51243ms step_avg:140.78ms
step:375/1390 train_time:51388ms step_avg:140.79ms
step:375/1390 val_loss:3.9421 train_time:51454ms step_avg:140.97ms
step:376/1390 train_time:51538ms step_avg:140.81ms
step:377/1390 train_time:51682ms step_avg:140.82ms
step:378/1390 train_time:51827ms step_avg:140.83ms
step:379/1390 train_time:51972ms step_avg:140.85ms
step:380/1390 train_time:52116ms step_avg:140.85ms
step:381/1390 train_time:52302ms step_avg:140.98ms
step:382/1390 train_time:52446ms step_avg:140.98ms
step:383/1390 train_time:52589ms step_avg:140.99ms
step:384/1390 train_time:52732ms step_avg:140.99ms
step:385/1390 train_time:52876ms step_avg:141.00ms
step:386/1390 train_time:53020ms step_avg:141.01ms
step:387/1390 train_time:53167ms step_avg:141.03ms
step:388/1390 train_time:53314ms step_avg:141.04ms
step:389/1390 train_time:53460ms step_avg:141.06ms
step:390/1390 train_time:53604ms step_avg:141.06ms
step:391/1390 train_time:53748ms step_avg:141.07ms
step:392/1390 train_time:53891ms step_avg:141.08ms
step:393/1390 train_time:54035ms step_avg:141.08ms
step:394/1390 train_time:54182ms step_avg:141.10ms
step:395/1390 train_time:54329ms step_avg:141.12ms
step:396/1390 train_time:54476ms step_avg:141.13ms
step:397/1390 train_time:54621ms step_avg:141.14ms
step:398/1390 train_time:54768ms step_avg:141.15ms
step:399/1390 train_time:54913ms step_avg:141.16ms
step:400/1390 train_time:55056ms step_avg:141.17ms
step:401/1390 train_time:55202ms step_avg:141.18ms
step:402/1390 train_time:55346ms step_avg:141.19ms
step:403/1390 train_time:55492ms step_avg:141.20ms
step:404/1390 train_time:55637ms step_avg:141.21ms
step:405/1390 train_time:55782ms step_avg:141.22ms
step:406/1390 train_time:55928ms step_avg:141.23ms
step:407/1390 train_time:56074ms step_avg:141.24ms
step:408/1390 train_time:56219ms step_avg:141.25ms
step:409/1390 train_time:56363ms step_avg:141.26ms
step:410/1390 train_time:56509ms step_avg:141.27ms
step:411/1390 train_time:56655ms step_avg:141.28ms
step:412/1390 train_time:56799ms step_avg:141.29ms
step:413/1390 train_time:56946ms step_avg:141.30ms
step:414/1390 train_time:57091ms step_avg:141.32ms
step:415/1390 train_time:57237ms step_avg:141.33ms
step:416/1390 train_time:57385ms step_avg:141.34ms
step:417/1390 train_time:57532ms step_avg:141.36ms
step:418/1390 train_time:57683ms step_avg:141.38ms
step:419/1390 train_time:57829ms step_avg:141.39ms
step:420/1390 train_time:57974ms step_avg:141.40ms
step:421/1390 train_time:58121ms step_avg:141.41ms
step:422/1390 train_time:58270ms step_avg:141.43ms
step:423/1390 train_time:58419ms step_avg:141.45ms
step:424/1390 train_time:58567ms step_avg:141.47ms
step:425/1390 train_time:58714ms step_avg:141.48ms
step:426/1390 train_time:58861ms step_avg:141.49ms
step:427/1390 train_time:59006ms step_avg:141.50ms
step:428/1390 train_time:59152ms step_avg:141.51ms
step:429/1390 train_time:59300ms step_avg:141.53ms
step:430/1390 train_time:59447ms step_avg:141.54ms
step:431/1390 train_time:59594ms step_avg:141.55ms
step:432/1390 train_time:59741ms step_avg:141.57ms
step:433/1390 train_time:59889ms step_avg:141.58ms
step:434/1390 train_time:60033ms step_avg:141.59ms
step:435/1390 train_time:60182ms step_avg:141.60ms
step:436/1390 train_time:60330ms step_avg:141.62ms
step:437/1390 train_time:60477ms step_avg:141.63ms
step:438/1390 train_time:60625ms step_avg:141.65ms
step:439/1390 train_time:60773ms step_avg:141.66ms
step:440/1390 train_time:60920ms step_avg:141.67ms
step:441/1390 train_time:61067ms step_avg:141.69ms
step:442/1390 train_time:61214ms step_avg:141.70ms
step:443/1390 train_time:61360ms step_avg:141.71ms
step:444/1390 train_time:61505ms step_avg:141.72ms
step:445/1390 train_time:61653ms step_avg:141.73ms
step:446/1390 train_time:61802ms step_avg:141.75ms
step:447/1390 train_time:61949ms step_avg:141.76ms
step:448/1390 train_time:62095ms step_avg:141.77ms
step:449/1390 train_time:62243ms step_avg:141.78ms
step:450/1390 train_time:62390ms step_avg:141.79ms
step:451/1390 train_time:62538ms step_avg:141.81ms
step:452/1390 train_time:62685ms step_avg:141.82ms
step:453/1390 train_time:62833ms step_avg:141.83ms
step:454/1390 train_time:62981ms step_avg:141.85ms
step:455/1390 train_time:63128ms step_avg:141.86ms
step:456/1390 train_time:63274ms step_avg:141.87ms
step:457/1390 train_time:63421ms step_avg:141.88ms
step:458/1390 train_time:63568ms step_avg:141.89ms
step:459/1390 train_time:63714ms step_avg:141.90ms
step:460/1390 train_time:63862ms step_avg:141.91ms
step:461/1390 train_time:64011ms step_avg:141.93ms
step:462/1390 train_time:64156ms step_avg:141.94ms
step:463/1390 train_time:64303ms step_avg:141.95ms
step:464/1390 train_time:64450ms step_avg:141.96ms
step:465/1390 train_time:64598ms step_avg:141.97ms
step:466/1390 train_time:64745ms step_avg:141.99ms
step:467/1390 train_time:64891ms step_avg:141.99ms
step:468/1390 train_time:65039ms step_avg:142.01ms
step:469/1390 train_time:65186ms step_avg:142.02ms
step:470/1390 train_time:65333ms step_avg:142.03ms
step:471/1390 train_time:65481ms step_avg:142.04ms
step:472/1390 train_time:65629ms step_avg:142.05ms
step:473/1390 train_time:65775ms step_avg:142.06ms
step:474/1390 train_time:65922ms step_avg:142.07ms
step:475/1390 train_time:66070ms step_avg:142.09ms
step:476/1390 train_time:66215ms step_avg:142.09ms
step:477/1390 train_time:66362ms step_avg:142.10ms
step:478/1390 train_time:66512ms step_avg:142.12ms
step:479/1390 train_time:66658ms step_avg:142.13ms
step:480/1390 train_time:66805ms step_avg:142.14ms
step:481/1390 train_time:66952ms step_avg:142.15ms
step:482/1390 train_time:67099ms step_avg:142.16ms
step:483/1390 train_time:67246ms step_avg:142.17ms
step:484/1390 train_time:67393ms step_avg:142.18ms
step:485/1390 train_time:67542ms step_avg:142.19ms
step:486/1390 train_time:67688ms step_avg:142.20ms
step:487/1390 train_time:67835ms step_avg:142.21ms
step:488/1390 train_time:67984ms step_avg:142.23ms
step:489/1390 train_time:68132ms step_avg:142.24ms
step:490/1390 train_time:68280ms step_avg:142.25ms
step:491/1390 train_time:68427ms step_avg:142.26ms
step:492/1390 train_time:68573ms step_avg:142.27ms
step:493/1390 train_time:68721ms step_avg:142.28ms
step:494/1390 train_time:68869ms step_avg:142.29ms
step:495/1390 train_time:69016ms step_avg:142.30ms
step:496/1390 train_time:69163ms step_avg:142.31ms
step:497/1390 train_time:69308ms step_avg:142.32ms
step:498/1390 train_time:69455ms step_avg:142.33ms
step:499/1390 train_time:69602ms step_avg:142.33ms
step:500/1390 train_time:69749ms step_avg:142.35ms
step:500/1390 val_loss:3.8438 train_time:69816ms step_avg:142.48ms
step:501/1390 train_time:69896ms step_avg:142.35ms
step:502/1390 train_time:70047ms step_avg:142.37ms
step:503/1390 train_time:70194ms step_avg:142.38ms
step:504/1390 train_time:70340ms step_avg:142.39ms
step:505/1390 train_time:70486ms step_avg:142.40ms
step:506/1390 train_time:70632ms step_avg:142.40ms
step:507/1390 train_time:70781ms step_avg:142.42ms
step:508/1390 train_time:70929ms step_avg:142.43ms
step:509/1390 train_time:71078ms step_avg:142.44ms
step:510/1390 train_time:71225ms step_avg:142.45ms
step:511/1390 train_time:71372ms step_avg:142.46ms
step:512/1390 train_time:71519ms step_avg:142.47ms
step:513/1390 train_time:71666ms step_avg:142.48ms
step:514/1390 train_time:71814ms step_avg:142.49ms
step:515/1390 train_time:71962ms step_avg:142.50ms
step:516/1390 train_time:72111ms step_avg:142.51ms
step:517/1390 train_time:72259ms step_avg:142.52ms
step:518/1390 train_time:72408ms step_avg:142.53ms
step:519/1390 train_time:72555ms step_avg:142.54ms
step:520/1390 train_time:72704ms step_avg:142.56ms
step:521/1390 train_time:72851ms step_avg:142.57ms
step:522/1390 train_time:73001ms step_avg:142.58ms
step:523/1390 train_time:73150ms step_avg:142.59ms
step:524/1390 train_time:73299ms step_avg:142.61ms
step:525/1390 train_time:73448ms step_avg:142.62ms
step:526/1390 train_time:73597ms step_avg:142.63ms
step:527/1390 train_time:73746ms step_avg:142.64ms
step:528/1390 train_time:73893ms step_avg:142.65ms
step:529/1390 train_time:74043ms step_avg:142.66ms
step:530/1390 train_time:74192ms step_avg:142.68ms
step:531/1390 train_time:74340ms step_avg:142.69ms
step:532/1390 train_time:74488ms step_avg:142.70ms
step:533/1390 train_time:74635ms step_avg:142.71ms
step:534/1390 train_time:74784ms step_avg:142.72ms
step:535/1390 train_time:74932ms step_avg:142.73ms
step:536/1390 train_time:75082ms step_avg:142.74ms
step:537/1390 train_time:75229ms step_avg:142.75ms
step:538/1390 train_time:75379ms step_avg:142.76ms
step:539/1390 train_time:75529ms step_avg:142.78ms
step:540/1390 train_time:75676ms step_avg:142.79ms
step:541/1390 train_time:75824ms step_avg:142.80ms
step:542/1390 train_time:75973ms step_avg:142.81ms
step:543/1390 train_time:76123ms step_avg:142.82ms
step:544/1390 train_time:76271ms step_avg:142.83ms
step:545/1390 train_time:76420ms step_avg:142.84ms
step:546/1390 train_time:76570ms step_avg:142.85ms
step:547/1390 train_time:76718ms step_avg:142.86ms
step:548/1390 train_time:76867ms step_avg:142.87ms
step:549/1390 train_time:77016ms step_avg:142.89ms
step:550/1390 train_time:77165ms step_avg:142.90ms
step:551/1390 train_time:77316ms step_avg:142.91ms
step:552/1390 train_time:77465ms step_avg:142.92ms
step:553/1390 train_time:77613ms step_avg:142.93ms
step:554/1390 train_time:77763ms step_avg:142.95ms
step:555/1390 train_time:77911ms step_avg:142.96ms
step:556/1390 train_time:78059ms step_avg:142.96ms
step:557/1390 train_time:78208ms step_avg:142.98ms
step:558/1390 train_time:78357ms step_avg:142.99ms
step:559/1390 train_time:78504ms step_avg:143.00ms
step:560/1390 train_time:78653ms step_avg:143.01ms
step:561/1390 train_time:78801ms step_avg:143.01ms
step:562/1390 train_time:78950ms step_avg:143.03ms
step:563/1390 train_time:79099ms step_avg:143.04ms
step:564/1390 train_time:79247ms step_avg:143.05ms
step:565/1390 train_time:79394ms step_avg:143.05ms
step:566/1390 train_time:79542ms step_avg:143.06ms
step:567/1390 train_time:79690ms step_avg:143.07ms
step:568/1390 train_time:79839ms step_avg:143.08ms
step:569/1390 train_time:79989ms step_avg:143.09ms
step:570/1390 train_time:80136ms step_avg:143.10ms
step:571/1390 train_time:80329ms step_avg:143.19ms
step:572/1390 train_time:80476ms step_avg:143.20ms
step:573/1390 train_time:80625ms step_avg:143.21ms
step:574/1390 train_time:80776ms step_avg:143.22ms
step:575/1390 train_time:80923ms step_avg:143.23ms
step:576/1390 train_time:81071ms step_avg:143.24ms
step:577/1390 train_time:81224ms step_avg:143.25ms
step:578/1390 train_time:81374ms step_avg:143.26ms
step:579/1390 train_time:81523ms step_avg:143.27ms
step:580/1390 train_time:81671ms step_avg:143.28ms
step:581/1390 train_time:81820ms step_avg:143.29ms
step:582/1390 train_time:81968ms step_avg:143.30ms
step:583/1390 train_time:82116ms step_avg:143.31ms
step:584/1390 train_time:82267ms step_avg:143.32ms
step:585/1390 train_time:82415ms step_avg:143.33ms
step:586/1390 train_time:82566ms step_avg:143.34ms
step:587/1390 train_time:82714ms step_avg:143.35ms
step:588/1390 train_time:82864ms step_avg:143.36ms
step:589/1390 train_time:83013ms step_avg:143.37ms
step:590/1390 train_time:83162ms step_avg:143.38ms
step:591/1390 train_time:83310ms step_avg:143.39ms
step:592/1390 train_time:83460ms step_avg:143.40ms
step:593/1390 train_time:83608ms step_avg:143.41ms
step:594/1390 train_time:83755ms step_avg:143.42ms
step:595/1390 train_time:83904ms step_avg:143.43ms
step:596/1390 train_time:84052ms step_avg:143.43ms
step:597/1390 train_time:84201ms step_avg:143.44ms
step:598/1390 train_time:84349ms step_avg:143.45ms
step:599/1390 train_time:84497ms step_avg:143.46ms
step:600/1390 train_time:84646ms step_avg:143.47ms
step:601/1390 train_time:84795ms step_avg:143.48ms
step:602/1390 train_time:84943ms step_avg:143.49ms
step:603/1390 train_time:85091ms step_avg:143.49ms
step:604/1390 train_time:85240ms step_avg:143.50ms
step:605/1390 train_time:85388ms step_avg:143.51ms
step:606/1390 train_time:85537ms step_avg:143.52ms
step:607/1390 train_time:85685ms step_avg:143.53ms
step:608/1390 train_time:85833ms step_avg:143.53ms
step:609/1390 train_time:85982ms step_avg:143.54ms
step:610/1390 train_time:86130ms step_avg:143.55ms
step:611/1390 train_time:86279ms step_avg:143.56ms
step:612/1390 train_time:86428ms step_avg:143.57ms
step:613/1390 train_time:86579ms step_avg:143.58ms
step:614/1390 train_time:86728ms step_avg:143.59ms
step:615/1390 train_time:86875ms step_avg:143.59ms
step:616/1390 train_time:87024ms step_avg:143.60ms
step:617/1390 train_time:87171ms step_avg:143.61ms
step:618/1390 train_time:87321ms step_avg:143.62ms
step:619/1390 train_time:87470ms step_avg:143.63ms
step:620/1390 train_time:87619ms step_avg:143.64ms
step:621/1390 train_time:87770ms step_avg:143.65ms
step:622/1390 train_time:87924ms step_avg:143.67ms
step:623/1390 train_time:88074ms step_avg:143.68ms
step:624/1390 train_time:88223ms step_avg:143.69ms
step:625/1390 train_time:88372ms step_avg:143.69ms
step:625/1390 val_loss:3.7650 train_time:88444ms step_avg:143.81ms
step:626/1390 train_time:88526ms step_avg:143.71ms
step:627/1390 train_time:88677ms step_avg:143.72ms
step:628/1390 train_time:88827ms step_avg:143.73ms
step:629/1390 train_time:88976ms step_avg:143.74ms
step:630/1390 train_time:89125ms step_avg:143.75ms
step:631/1390 train_time:89272ms step_avg:143.76ms
step:632/1390 train_time:89425ms step_avg:143.77ms
step:633/1390 train_time:89575ms step_avg:143.78ms
step:634/1390 train_time:89727ms step_avg:143.79ms
step:635/1390 train_time:89876ms step_avg:143.80ms
step:636/1390 train_time:90026ms step_avg:143.81ms
step:637/1390 train_time:90176ms step_avg:143.82ms
step:638/1390 train_time:90326ms step_avg:143.83ms
step:639/1390 train_time:90477ms step_avg:143.84ms
step:640/1390 train_time:90629ms step_avg:143.86ms
step:641/1390 train_time:90780ms step_avg:143.87ms
step:642/1390 train_time:90929ms step_avg:143.88ms
step:643/1390 train_time:91078ms step_avg:143.88ms
step:644/1390 train_time:91227ms step_avg:143.89ms
step:645/1390 train_time:91380ms step_avg:143.91ms
step:646/1390 train_time:91529ms step_avg:143.91ms
step:647/1390 train_time:91679ms step_avg:143.92ms
step:648/1390 train_time:91832ms step_avg:143.94ms
step:649/1390 train_time:91983ms step_avg:143.95ms
step:650/1390 train_time:92132ms step_avg:143.96ms
step:651/1390 train_time:92283ms step_avg:143.97ms
step:652/1390 train_time:92431ms step_avg:143.97ms
step:653/1390 train_time:92582ms step_avg:143.98ms
step:654/1390 train_time:92732ms step_avg:143.99ms
step:655/1390 train_time:92881ms step_avg:144.00ms
step:656/1390 train_time:93031ms step_avg:144.01ms
step:657/1390 train_time:93180ms step_avg:144.02ms
step:658/1390 train_time:93331ms step_avg:144.03ms
step:659/1390 train_time:93482ms step_avg:144.04ms
step:660/1390 train_time:93630ms step_avg:144.05ms
step:661/1390 train_time:93781ms step_avg:144.06ms
step:662/1390 train_time:93930ms step_avg:144.06ms
step:663/1390 train_time:94080ms step_avg:144.07ms
step:664/1390 train_time:94229ms step_avg:144.08ms
step:665/1390 train_time:94381ms step_avg:144.09ms
step:666/1390 train_time:94529ms step_avg:144.10ms
step:667/1390 train_time:94681ms step_avg:144.11ms
step:668/1390 train_time:94831ms step_avg:144.12ms
step:669/1390 train_time:94982ms step_avg:144.13ms
step:670/1390 train_time:95131ms step_avg:144.14ms
step:671/1390 train_time:95282ms step_avg:144.15ms
step:672/1390 train_time:95431ms step_avg:144.15ms
step:673/1390 train_time:95581ms step_avg:144.16ms
step:674/1390 train_time:95732ms step_avg:144.17ms
step:675/1390 train_time:95884ms step_avg:144.19ms
step:676/1390 train_time:96035ms step_avg:144.20ms
step:677/1390 train_time:96186ms step_avg:144.21ms
step:678/1390 train_time:96335ms step_avg:144.21ms
step:679/1390 train_time:96487ms step_avg:144.23ms
step:680/1390 train_time:96636ms step_avg:144.23ms
step:681/1390 train_time:96787ms step_avg:144.24ms
step:682/1390 train_time:96935ms step_avg:144.25ms
step:683/1390 train_time:97086ms step_avg:144.26ms
step:684/1390 train_time:97236ms step_avg:144.27ms
step:685/1390 train_time:97387ms step_avg:144.28ms
step:686/1390 train_time:97536ms step_avg:144.28ms
step:687/1390 train_time:97685ms step_avg:144.29ms
step:688/1390 train_time:97836ms step_avg:144.30ms
step:689/1390 train_time:97987ms step_avg:144.31ms
step:690/1390 train_time:98138ms step_avg:144.32ms
step:691/1390 train_time:98287ms step_avg:144.33ms
step:692/1390 train_time:98439ms step_avg:144.34ms
step:693/1390 train_time:98589ms step_avg:144.35ms
step:694/1390 train_time:98739ms step_avg:144.36ms
step:695/1390 train_time:98889ms step_avg:144.36ms
step:696/1390 train_time:99039ms step_avg:144.37ms
step:697/1390 train_time:99190ms step_avg:144.38ms
step:698/1390 train_time:99340ms step_avg:144.39ms
step:699/1390 train_time:99490ms step_avg:144.40ms
step:700/1390 train_time:99641ms step_avg:144.41ms
step:701/1390 train_time:99790ms step_avg:144.41ms
step:702/1390 train_time:99940ms step_avg:144.42ms
step:703/1390 train_time:100090ms step_avg:144.43ms
step:704/1390 train_time:100241ms step_avg:144.44ms
step:705/1390 train_time:100392ms step_avg:144.45ms
step:706/1390 train_time:100546ms step_avg:144.46ms
step:707/1390 train_time:100697ms step_avg:144.47ms
step:708/1390 train_time:100846ms step_avg:144.48ms
step:709/1390 train_time:100996ms step_avg:144.49ms
step:710/1390 train_time:101146ms step_avg:144.49ms
step:711/1390 train_time:101297ms step_avg:144.50ms
step:712/1390 train_time:101449ms step_avg:144.51ms
step:713/1390 train_time:101602ms step_avg:144.53ms
step:714/1390 train_time:101752ms step_avg:144.53ms
step:715/1390 train_time:101902ms step_avg:144.54ms
step:716/1390 train_time:102051ms step_avg:144.55ms
step:717/1390 train_time:102201ms step_avg:144.56ms
step:718/1390 train_time:102350ms step_avg:144.56ms
step:719/1390 train_time:102500ms step_avg:144.57ms
step:720/1390 train_time:102650ms step_avg:144.58ms
step:721/1390 train_time:102801ms step_avg:144.59ms
step:722/1390 train_time:102952ms step_avg:144.59ms
step:723/1390 train_time:103103ms step_avg:144.60ms
step:724/1390 train_time:103254ms step_avg:144.61ms
step:725/1390 train_time:103405ms step_avg:144.62ms
step:726/1390 train_time:103557ms step_avg:144.63ms
step:727/1390 train_time:103712ms step_avg:144.65ms
step:728/1390 train_time:103865ms step_avg:144.66ms
step:729/1390 train_time:104015ms step_avg:144.67ms
step:730/1390 train_time:104168ms step_avg:144.68ms
step:731/1390 train_time:104319ms step_avg:144.69ms
step:732/1390 train_time:104469ms step_avg:144.69ms
step:733/1390 train_time:104622ms step_avg:144.71ms
step:734/1390 train_time:104773ms step_avg:144.71ms
step:735/1390 train_time:104926ms step_avg:144.73ms
step:736/1390 train_time:105078ms step_avg:144.74ms
step:737/1390 train_time:105230ms step_avg:144.75ms
step:738/1390 train_time:105383ms step_avg:144.76ms
step:739/1390 train_time:105534ms step_avg:144.77ms
step:740/1390 train_time:105687ms step_avg:144.78ms
step:741/1390 train_time:105840ms step_avg:144.79ms
step:742/1390 train_time:105990ms step_avg:144.79ms
step:743/1390 train_time:106142ms step_avg:144.81ms
step:744/1390 train_time:106293ms step_avg:144.81ms
step:745/1390 train_time:106447ms step_avg:144.83ms
step:746/1390 train_time:106599ms step_avg:144.84ms
step:747/1390 train_time:106750ms step_avg:144.84ms
step:748/1390 train_time:106903ms step_avg:144.85ms
step:749/1390 train_time:107054ms step_avg:144.86ms
step:750/1390 train_time:107206ms step_avg:144.87ms
step:750/1390 val_loss:3.7154 train_time:107278ms step_avg:144.97ms
step:751/1390 train_time:107361ms step_avg:144.89ms
step:752/1390 train_time:107511ms step_avg:144.89ms
step:753/1390 train_time:107662ms step_avg:144.90ms
step:754/1390 train_time:107811ms step_avg:144.91ms
step:755/1390 train_time:107962ms step_avg:144.92ms
step:756/1390 train_time:108113ms step_avg:144.92ms
step:757/1390 train_time:108266ms step_avg:144.93ms
step:758/1390 train_time:108420ms step_avg:144.95ms
step:759/1390 train_time:108572ms step_avg:144.96ms
step:760/1390 train_time:108722ms step_avg:144.96ms
step:761/1390 train_time:108916ms step_avg:145.03ms
step:762/1390 train_time:109066ms step_avg:145.03ms
step:763/1390 train_time:109216ms step_avg:145.04ms
step:764/1390 train_time:109367ms step_avg:145.05ms
step:765/1390 train_time:109518ms step_avg:145.06ms
step:766/1390 train_time:109671ms step_avg:145.07ms
step:767/1390 train_time:109825ms step_avg:145.08ms
step:768/1390 train_time:109980ms step_avg:145.09ms
step:769/1390 train_time:110131ms step_avg:145.10ms
step:770/1390 train_time:110283ms step_avg:145.11ms
step:771/1390 train_time:110432ms step_avg:145.11ms
step:772/1390 train_time:110582ms step_avg:145.12ms
step:773/1390 train_time:110733ms step_avg:145.13ms
step:774/1390 train_time:110886ms step_avg:145.14ms
step:775/1390 train_time:111039ms step_avg:145.15ms
step:776/1390 train_time:111192ms step_avg:145.16ms
step:777/1390 train_time:111345ms step_avg:145.17ms
step:778/1390 train_time:111495ms step_avg:145.18ms
step:779/1390 train_time:111646ms step_avg:145.18ms
step:780/1390 train_time:111797ms step_avg:145.19ms
step:781/1390 train_time:111949ms step_avg:145.20ms
step:782/1390 train_time:112103ms step_avg:145.21ms
step:783/1390 train_time:112252ms step_avg:145.22ms
step:784/1390 train_time:112405ms step_avg:145.23ms
step:785/1390 train_time:112555ms step_avg:145.23ms
step:786/1390 train_time:112706ms step_avg:145.24ms
step:787/1390 train_time:112858ms step_avg:145.25ms
step:788/1390 train_time:113010ms step_avg:145.26ms
step:789/1390 train_time:113163ms step_avg:145.27ms
step:790/1390 train_time:113311ms step_avg:145.27ms
step:791/1390 train_time:113463ms step_avg:145.28ms
step:792/1390 train_time:113614ms step_avg:145.29ms
step:793/1390 train_time:113764ms step_avg:145.29ms
step:794/1390 train_time:113916ms step_avg:145.30ms
step:795/1390 train_time:114071ms step_avg:145.31ms
step:796/1390 train_time:114225ms step_avg:145.32ms
step:797/1390 train_time:114376ms step_avg:145.33ms
step:798/1390 train_time:114528ms step_avg:145.34ms
step:799/1390 train_time:114685ms step_avg:145.36ms
step:800/1390 train_time:114837ms step_avg:145.36ms
step:801/1390 train_time:114987ms step_avg:145.37ms
step:802/1390 train_time:115138ms step_avg:145.38ms
step:803/1390 train_time:115288ms step_avg:145.38ms
step:804/1390 train_time:115438ms step_avg:145.39ms
step:805/1390 train_time:115591ms step_avg:145.40ms
step:806/1390 train_time:115745ms step_avg:145.41ms
step:807/1390 train_time:115894ms step_avg:145.41ms
step:808/1390 train_time:116047ms step_avg:145.42ms
step:809/1390 train_time:116197ms step_avg:145.43ms
step:810/1390 train_time:116348ms step_avg:145.44ms
step:811/1390 train_time:116499ms step_avg:145.44ms
step:812/1390 train_time:116649ms step_avg:145.45ms
step:813/1390 train_time:116800ms step_avg:145.45ms
step:814/1390 train_time:116951ms step_avg:145.46ms
step:815/1390 train_time:117103ms step_avg:145.47ms
step:816/1390 train_time:117256ms step_avg:145.48ms
step:817/1390 train_time:117407ms step_avg:145.49ms
step:818/1390 train_time:117558ms step_avg:145.49ms
step:819/1390 train_time:117712ms step_avg:145.50ms
step:820/1390 train_time:117864ms step_avg:145.51ms
step:821/1390 train_time:118012ms step_avg:145.51ms
step:822/1390 train_time:118163ms step_avg:145.52ms
step:823/1390 train_time:118315ms step_avg:145.53ms
step:824/1390 train_time:118466ms step_avg:145.54ms
step:825/1390 train_time:118619ms step_avg:145.55ms
step:826/1390 train_time:118772ms step_avg:145.55ms
step:827/1390 train_time:118925ms step_avg:145.56ms
step:828/1390 train_time:119077ms step_avg:145.57ms
step:829/1390 train_time:119229ms step_avg:145.58ms
step:830/1390 train_time:119380ms step_avg:145.59ms
step:831/1390 train_time:119531ms step_avg:145.59ms
step:832/1390 train_time:119685ms step_avg:145.60ms
step:833/1390 train_time:119837ms step_avg:145.61ms
step:834/1390 train_time:119989ms step_avg:145.62ms
step:835/1390 train_time:120143ms step_avg:145.63ms
step:836/1390 train_time:120297ms step_avg:145.64ms
step:837/1390 train_time:120448ms step_avg:145.64ms
step:838/1390 train_time:120600ms step_avg:145.65ms
step:839/1390 train_time:120752ms step_avg:145.66ms
step:840/1390 train_time:120906ms step_avg:145.67ms
step:841/1390 train_time:121058ms step_avg:145.68ms
step:842/1390 train_time:121211ms step_avg:145.69ms
step:843/1390 train_time:121364ms step_avg:145.69ms
step:844/1390 train_time:121516ms step_avg:145.70ms
step:845/1390 train_time:121667ms step_avg:145.71ms
step:846/1390 train_time:121820ms step_avg:145.72ms
step:847/1390 train_time:121974ms step_avg:145.73ms
step:848/1390 train_time:122126ms step_avg:145.74ms
step:849/1390 train_time:122278ms step_avg:145.74ms
step:850/1390 train_time:122433ms step_avg:145.75ms
step:851/1390 train_time:122587ms step_avg:145.76ms
step:852/1390 train_time:122740ms step_avg:145.77ms
step:853/1390 train_time:122891ms step_avg:145.78ms
step:854/1390 train_time:123045ms step_avg:145.79ms
step:855/1390 train_time:123197ms step_avg:145.79ms
step:856/1390 train_time:123349ms step_avg:145.80ms
step:857/1390 train_time:123502ms step_avg:145.81ms
step:858/1390 train_time:123658ms step_avg:145.82ms
step:859/1390 train_time:123812ms step_avg:145.83ms
step:860/1390 train_time:123965ms step_avg:145.84ms
step:861/1390 train_time:124118ms step_avg:145.85ms
step:862/1390 train_time:124269ms step_avg:145.86ms
step:863/1390 train_time:124423ms step_avg:145.86ms
step:864/1390 train_time:124576ms step_avg:145.87ms
step:865/1390 train_time:124730ms step_avg:145.88ms
step:866/1390 train_time:124888ms step_avg:145.90ms
step:867/1390 train_time:125039ms step_avg:145.90ms
step:868/1390 train_time:125191ms step_avg:145.91ms
step:869/1390 train_time:125345ms step_avg:145.92ms
step:870/1390 train_time:125500ms step_avg:145.93ms
step:871/1390 train_time:125653ms step_avg:145.94ms
step:872/1390 train_time:125807ms step_avg:145.95ms
step:873/1390 train_time:125957ms step_avg:145.95ms
step:874/1390 train_time:126110ms step_avg:145.96ms
step:875/1390 train_time:126262ms step_avg:145.97ms
step:875/1390 val_loss:3.6701 train_time:126331ms step_avg:146.05ms
step:876/1390 train_time:126414ms step_avg:145.97ms
step:877/1390 train_time:126567ms step_avg:145.98ms
step:878/1390 train_time:126721ms step_avg:145.99ms
step:879/1390 train_time:126873ms step_avg:146.00ms
step:880/1390 train_time:127024ms step_avg:146.00ms
step:881/1390 train_time:127175ms step_avg:146.01ms
step:882/1390 train_time:127329ms step_avg:146.02ms
step:883/1390 train_time:127483ms step_avg:146.03ms
step:884/1390 train_time:127635ms step_avg:146.04ms
step:885/1390 train_time:127787ms step_avg:146.04ms
step:886/1390 train_time:127942ms step_avg:146.05ms
step:887/1390 train_time:128095ms step_avg:146.06ms
step:888/1390 train_time:128250ms step_avg:146.07ms
step:889/1390 train_time:128401ms step_avg:146.08ms
step:890/1390 train_time:128554ms step_avg:146.08ms
step:891/1390 train_time:128707ms step_avg:146.09ms
step:892/1390 train_time:128860ms step_avg:146.10ms
step:893/1390 train_time:129013ms step_avg:146.11ms
step:894/1390 train_time:129167ms step_avg:146.12ms
step:895/1390 train_time:129324ms step_avg:146.13ms
step:896/1390 train_time:129475ms step_avg:146.13ms
step:897/1390 train_time:129627ms step_avg:146.14ms
step:898/1390 train_time:129780ms step_avg:146.15ms
step:899/1390 train_time:129931ms step_avg:146.15ms
step:900/1390 train_time:130085ms step_avg:146.16ms
step:901/1390 train_time:130239ms step_avg:146.17ms
step:902/1390 train_time:130389ms step_avg:146.18ms
step:903/1390 train_time:130544ms step_avg:146.19ms
step:904/1390 train_time:130695ms step_avg:146.19ms
step:905/1390 train_time:130849ms step_avg:146.20ms
step:906/1390 train_time:131003ms step_avg:146.21ms
step:907/1390 train_time:131158ms step_avg:146.22ms
step:908/1390 train_time:131312ms step_avg:146.23ms
step:909/1390 train_time:131467ms step_avg:146.24ms
step:910/1390 train_time:131625ms step_avg:146.25ms
step:911/1390 train_time:131776ms step_avg:146.26ms
step:912/1390 train_time:131927ms step_avg:146.26ms
step:913/1390 train_time:132084ms step_avg:146.27ms
step:914/1390 train_time:132235ms step_avg:146.28ms
step:915/1390 train_time:132389ms step_avg:146.29ms
step:916/1390 train_time:132543ms step_avg:146.29ms
step:917/1390 train_time:132695ms step_avg:146.30ms
step:918/1390 train_time:132848ms step_avg:146.31ms
step:919/1390 train_time:133002ms step_avg:146.32ms
step:920/1390 train_time:133154ms step_avg:146.32ms
step:921/1390 train_time:133308ms step_avg:146.33ms
step:922/1390 train_time:133463ms step_avg:146.34ms
step:923/1390 train_time:133614ms step_avg:146.35ms
step:924/1390 train_time:133767ms step_avg:146.35ms
step:925/1390 train_time:133922ms step_avg:146.36ms
step:926/1390 train_time:134074ms step_avg:146.37ms
step:927/1390 train_time:134226ms step_avg:146.37ms
step:928/1390 train_time:134379ms step_avg:146.38ms
step:929/1390 train_time:134536ms step_avg:146.39ms
step:930/1390 train_time:134690ms step_avg:146.40ms
step:931/1390 train_time:134844ms step_avg:146.41ms
step:932/1390 train_time:134995ms step_avg:146.42ms
step:933/1390 train_time:135150ms step_avg:146.42ms
step:934/1390 train_time:135304ms step_avg:146.43ms
step:935/1390 train_time:135458ms step_avg:146.44ms
step:936/1390 train_time:135613ms step_avg:146.45ms
step:937/1390 train_time:135771ms step_avg:146.46ms
step:938/1390 train_time:135925ms step_avg:146.47ms
step:939/1390 train_time:136080ms step_avg:146.48ms
step:940/1390 train_time:136234ms step_avg:146.49ms
step:941/1390 train_time:136389ms step_avg:146.50ms
step:942/1390 train_time:136541ms step_avg:146.50ms
step:943/1390 train_time:136698ms step_avg:146.51ms
step:944/1390 train_time:136858ms step_avg:146.53ms
step:945/1390 train_time:137012ms step_avg:146.54ms
step:946/1390 train_time:137168ms step_avg:146.55ms
step:947/1390 train_time:137322ms step_avg:146.55ms
step:948/1390 train_time:137475ms step_avg:146.56ms
step:949/1390 train_time:137632ms step_avg:146.57ms
step:950/1390 train_time:137788ms step_avg:146.58ms
step:951/1390 train_time:137990ms step_avg:146.64ms
step:952/1390 train_time:138141ms step_avg:146.65ms
step:953/1390 train_time:138292ms step_avg:146.65ms
step:954/1390 train_time:138446ms step_avg:146.66ms
step:955/1390 train_time:138596ms step_avg:146.66ms
step:956/1390 train_time:138751ms step_avg:146.67ms
step:957/1390 train_time:138908ms step_avg:146.68ms
step:958/1390 train_time:139067ms step_avg:146.69ms
step:959/1390 train_time:139223ms step_avg:146.71ms
step:960/1390 train_time:139379ms step_avg:146.71ms
step:961/1390 train_time:139532ms step_avg:146.72ms
step:962/1390 train_time:139686ms step_avg:146.73ms
step:963/1390 train_time:139845ms step_avg:146.74ms
step:964/1390 train_time:139997ms step_avg:146.75ms
step:965/1390 train_time:140151ms step_avg:146.75ms
step:966/1390 train_time:140308ms step_avg:146.77ms
step:967/1390 train_time:140459ms step_avg:146.77ms
step:968/1390 train_time:140611ms step_avg:146.78ms
step:969/1390 train_time:140766ms step_avg:146.78ms
step:970/1390 train_time:140917ms step_avg:146.79ms
step:971/1390 train_time:141073ms step_avg:146.80ms
step:972/1390 train_time:141228ms step_avg:146.81ms
step:973/1390 train_time:141381ms step_avg:146.81ms
step:974/1390 train_time:141535ms step_avg:146.82ms
step:975/1390 train_time:141689ms step_avg:146.83ms
step:976/1390 train_time:141843ms step_avg:146.84ms
step:977/1390 train_time:141995ms step_avg:146.84ms
step:978/1390 train_time:142151ms step_avg:146.85ms
step:979/1390 train_time:142304ms step_avg:146.86ms
step:980/1390 train_time:142457ms step_avg:146.86ms
step:981/1390 train_time:142609ms step_avg:146.87ms
step:982/1390 train_time:142762ms step_avg:146.87ms
step:983/1390 train_time:142913ms step_avg:146.88ms
step:984/1390 train_time:143066ms step_avg:146.89ms
step:985/1390 train_time:143221ms step_avg:146.89ms
step:986/1390 train_time:143376ms step_avg:146.90ms
step:987/1390 train_time:143528ms step_avg:146.91ms
step:988/1390 train_time:143682ms step_avg:146.91ms
step:989/1390 train_time:143834ms step_avg:146.92ms
step:990/1390 train_time:143989ms step_avg:146.93ms
step:991/1390 train_time:144140ms step_avg:146.93ms
step:992/1390 train_time:144299ms step_avg:146.94ms
step:993/1390 train_time:144462ms step_avg:146.96ms
step:994/1390 train_time:144615ms step_avg:146.97ms
step:995/1390 train_time:144769ms step_avg:146.97ms
step:996/1390 train_time:144922ms step_avg:146.98ms
step:997/1390 train_time:145074ms step_avg:146.99ms
step:998/1390 train_time:145228ms step_avg:146.99ms
step:999/1390 train_time:145383ms step_avg:147.00ms
step:1000/1390 train_time:145537ms step_avg:147.01ms
step:1000/1390 val_loss:3.6122 train_time:145608ms step_avg:147.08ms
step:1001/1390 train_time:145692ms step_avg:147.01ms
step:1002/1390 train_time:145847ms step_avg:147.02ms
step:1003/1390 train_time:146003ms step_avg:147.03ms
step:1004/1390 train_time:146160ms step_avg:147.04ms
step:1005/1390 train_time:146313ms step_avg:147.05ms
step:1006/1390 train_time:146465ms step_avg:147.05ms
step:1007/1390 train_time:146624ms step_avg:147.06ms
step:1008/1390 train_time:146781ms step_avg:147.08ms
step:1009/1390 train_time:146942ms step_avg:147.09ms
step:1010/1390 train_time:147096ms step_avg:147.10ms
step:1011/1390 train_time:147249ms step_avg:147.10ms
step:1012/1390 train_time:147403ms step_avg:147.11ms
step:1013/1390 train_time:147559ms step_avg:147.12ms
step:1014/1390 train_time:147712ms step_avg:147.12ms
step:1015/1390 train_time:147866ms step_avg:147.13ms
step:1016/1390 train_time:148024ms step_avg:147.14ms
step:1017/1390 train_time:148179ms step_avg:147.15ms
step:1018/1390 train_time:148332ms step_avg:147.15ms
step:1019/1390 train_time:148486ms step_avg:147.16ms
step:1020/1390 train_time:148641ms step_avg:147.17ms
step:1021/1390 train_time:148796ms step_avg:147.18ms
step:1022/1390 train_time:148949ms step_avg:147.18ms
step:1023/1390 train_time:149104ms step_avg:147.19ms
step:1024/1390 train_time:149259ms step_avg:147.20ms
step:1025/1390 train_time:149413ms step_avg:147.20ms
step:1026/1390 train_time:149564ms step_avg:147.21ms
step:1027/1390 train_time:149717ms step_avg:147.21ms
step:1028/1390 train_time:149871ms step_avg:147.22ms
step:1029/1390 train_time:150026ms step_avg:147.23ms
step:1030/1390 train_time:150182ms step_avg:147.24ms
step:1031/1390 train_time:150335ms step_avg:147.24ms
step:1032/1390 train_time:150490ms step_avg:147.25ms
step:1033/1390 train_time:150644ms step_avg:147.26ms
step:1034/1390 train_time:150800ms step_avg:147.27ms
step:1035/1390 train_time:150958ms step_avg:147.28ms
step:1036/1390 train_time:151114ms step_avg:147.28ms
step:1037/1390 train_time:151271ms step_avg:147.29ms
step:1038/1390 train_time:151427ms step_avg:147.30ms
step:1039/1390 train_time:151581ms step_avg:147.31ms
step:1040/1390 train_time:151737ms step_avg:147.32ms
step:1041/1390 train_time:151894ms step_avg:147.33ms
step:1042/1390 train_time:152046ms step_avg:147.33ms
step:1043/1390 train_time:152199ms step_avg:147.34ms
step:1044/1390 train_time:152357ms step_avg:147.35ms
step:1045/1390 train_time:152513ms step_avg:147.36ms
step:1046/1390 train_time:152666ms step_avg:147.36ms
step:1047/1390 train_time:152822ms step_avg:147.37ms
step:1048/1390 train_time:152981ms step_avg:147.38ms
step:1049/1390 train_time:153139ms step_avg:147.39ms
step:1050/1390 train_time:153297ms step_avg:147.40ms
step:1051/1390 train_time:153453ms step_avg:147.41ms
step:1052/1390 train_time:153608ms step_avg:147.42ms
step:1053/1390 train_time:153763ms step_avg:147.42ms
step:1054/1390 train_time:153921ms step_avg:147.43ms
step:1055/1390 train_time:154075ms step_avg:147.44ms
step:1056/1390 train_time:154230ms step_avg:147.45ms
step:1057/1390 train_time:154387ms step_avg:147.46ms
step:1058/1390 train_time:154544ms step_avg:147.47ms
step:1059/1390 train_time:154701ms step_avg:147.47ms
step:1060/1390 train_time:154856ms step_avg:147.48ms
step:1061/1390 train_time:155010ms step_avg:147.49ms
step:1062/1390 train_time:155165ms step_avg:147.50ms
step:1063/1390 train_time:155323ms step_avg:147.51ms
step:1064/1390 train_time:155476ms step_avg:147.51ms
step:1065/1390 train_time:155631ms step_avg:147.52ms
step:1066/1390 train_time:155791ms step_avg:147.53ms
step:1067/1390 train_time:155945ms step_avg:147.54ms
step:1068/1390 train_time:156100ms step_avg:147.54ms
step:1069/1390 train_time:156261ms step_avg:147.56ms
step:1070/1390 train_time:156413ms step_avg:147.56ms
step:1071/1390 train_time:156570ms step_avg:147.57ms
step:1072/1390 train_time:156723ms step_avg:147.57ms
step:1073/1390 train_time:156875ms step_avg:147.58ms
step:1074/1390 train_time:157028ms step_avg:147.58ms
step:1075/1390 train_time:157182ms step_avg:147.59ms
step:1076/1390 train_time:157338ms step_avg:147.60ms
step:1077/1390 train_time:157493ms step_avg:147.60ms
step:1078/1390 train_time:157653ms step_avg:147.61ms
step:1079/1390 train_time:157812ms step_avg:147.63ms
step:1080/1390 train_time:157966ms step_avg:147.63ms
step:1081/1390 train_time:158119ms step_avg:147.64ms
step:1082/1390 train_time:158272ms step_avg:147.64ms
step:1083/1390 train_time:158427ms step_avg:147.65ms
step:1084/1390 train_time:158585ms step_avg:147.66ms
step:1085/1390 train_time:158741ms step_avg:147.67ms
step:1086/1390 train_time:158900ms step_avg:147.68ms
step:1087/1390 train_time:159057ms step_avg:147.69ms
step:1088/1390 train_time:159212ms step_avg:147.69ms
step:1089/1390 train_time:159369ms step_avg:147.70ms
step:1090/1390 train_time:159530ms step_avg:147.71ms
step:1091/1390 train_time:159687ms step_avg:147.72ms
step:1092/1390 train_time:159840ms step_avg:147.73ms
step:1093/1390 train_time:159996ms step_avg:147.73ms
step:1094/1390 train_time:160149ms step_avg:147.74ms
step:1095/1390 train_time:160304ms step_avg:147.75ms
step:1096/1390 train_time:160464ms step_avg:147.76ms
step:1097/1390 train_time:160620ms step_avg:147.76ms
step:1098/1390 train_time:160776ms step_avg:147.77ms
step:1099/1390 train_time:160929ms step_avg:147.78ms
step:1100/1390 train_time:161083ms step_avg:147.78ms
step:1101/1390 train_time:161238ms step_avg:147.79ms
step:1102/1390 train_time:161395ms step_avg:147.80ms
step:1103/1390 train_time:161550ms step_avg:147.80ms
step:1104/1390 train_time:161704ms step_avg:147.81ms
step:1105/1390 train_time:161862ms step_avg:147.82ms
step:1106/1390 train_time:162017ms step_avg:147.83ms
step:1107/1390 train_time:162170ms step_avg:147.83ms
step:1108/1390 train_time:162329ms step_avg:147.84ms
step:1109/1390 train_time:162482ms step_avg:147.85ms
step:1110/1390 train_time:162639ms step_avg:147.85ms
step:1111/1390 train_time:162798ms step_avg:147.86ms
step:1112/1390 train_time:162950ms step_avg:147.87ms
step:1113/1390 train_time:163105ms step_avg:147.87ms
step:1114/1390 train_time:163264ms step_avg:147.88ms
step:1115/1390 train_time:163420ms step_avg:147.89ms
step:1116/1390 train_time:163574ms step_avg:147.90ms
step:1117/1390 train_time:163732ms step_avg:147.91ms
step:1118/1390 train_time:163892ms step_avg:147.92ms
step:1119/1390 train_time:164046ms step_avg:147.92ms
step:1120/1390 train_time:164202ms step_avg:147.93ms
step:1121/1390 train_time:164356ms step_avg:147.93ms
step:1122/1390 train_time:164510ms step_avg:147.94ms
step:1123/1390 train_time:164664ms step_avg:147.95ms
step:1124/1390 train_time:164824ms step_avg:147.96ms
step:1125/1390 train_time:164981ms step_avg:147.97ms
step:1125/1390 val_loss:3.5678 train_time:165053ms step_avg:148.03ms
step:1126/1390 train_time:165137ms step_avg:147.97ms
step:1127/1390 train_time:165292ms step_avg:147.98ms
step:1128/1390 train_time:165447ms step_avg:147.98ms
step:1129/1390 train_time:165604ms step_avg:147.99ms
step:1130/1390 train_time:165758ms step_avg:148.00ms
step:1131/1390 train_time:165916ms step_avg:148.01ms
step:1132/1390 train_time:166070ms step_avg:148.01ms
step:1133/1390 train_time:166228ms step_avg:148.02ms
step:1134/1390 train_time:166383ms step_avg:148.03ms
step:1135/1390 train_time:166537ms step_avg:148.03ms
step:1136/1390 train_time:166697ms step_avg:148.04ms
step:1137/1390 train_time:166851ms step_avg:148.05ms
step:1138/1390 train_time:167008ms step_avg:148.06ms
step:1139/1390 train_time:167164ms step_avg:148.06ms
step:1140/1390 train_time:167319ms step_avg:148.07ms
step:1141/1390 train_time:167522ms step_avg:148.12ms
step:1142/1390 train_time:167676ms step_avg:148.12ms
step:1143/1390 train_time:167836ms step_avg:148.13ms
step:1144/1390 train_time:167992ms step_avg:148.14ms
step:1145/1390 train_time:168145ms step_avg:148.15ms
step:1146/1390 train_time:168302ms step_avg:148.15ms
step:1147/1390 train_time:168461ms step_avg:148.16ms
step:1148/1390 train_time:168618ms step_avg:148.17ms
step:1149/1390 train_time:168773ms step_avg:148.18ms
step:1150/1390 train_time:168929ms step_avg:148.18ms
step:1151/1390 train_time:169086ms step_avg:148.19ms
step:1152/1390 train_time:169243ms step_avg:148.20ms
step:1153/1390 train_time:169402ms step_avg:148.21ms
step:1154/1390 train_time:169557ms step_avg:148.21ms
step:1155/1390 train_time:169713ms step_avg:148.22ms
step:1156/1390 train_time:169874ms step_avg:148.23ms
step:1157/1390 train_time:170033ms step_avg:148.24ms
step:1158/1390 train_time:170190ms step_avg:148.25ms
step:1159/1390 train_time:170347ms step_avg:148.26ms
step:1160/1390 train_time:170501ms step_avg:148.26ms
step:1161/1390 train_time:170656ms step_avg:148.27ms
step:1162/1390 train_time:170812ms step_avg:148.27ms
step:1163/1390 train_time:170967ms step_avg:148.28ms
step:1164/1390 train_time:171123ms step_avg:148.29ms
step:1165/1390 train_time:171276ms step_avg:148.29ms
step:1166/1390 train_time:171431ms step_avg:148.30ms
step:1167/1390 train_time:171587ms step_avg:148.30ms
step:1168/1390 train_time:171744ms step_avg:148.31ms
step:1169/1390 train_time:171900ms step_avg:148.32ms
step:1170/1390 train_time:172057ms step_avg:148.33ms
step:1171/1390 train_time:172216ms step_avg:148.33ms
step:1172/1390 train_time:172373ms step_avg:148.34ms
step:1173/1390 train_time:172530ms step_avg:148.35ms
step:1174/1390 train_time:172695ms step_avg:148.36ms
step:1175/1390 train_time:172855ms step_avg:148.37ms
step:1176/1390 train_time:173015ms step_avg:148.38ms
step:1177/1390 train_time:173179ms step_avg:148.40ms
step:1178/1390 train_time:173335ms step_avg:148.40ms
step:1179/1390 train_time:173491ms step_avg:148.41ms
step:1180/1390 train_time:173659ms step_avg:148.43ms
step:1181/1390 train_time:173816ms step_avg:148.43ms
step:1182/1390 train_time:173970ms step_avg:148.44ms
step:1183/1390 train_time:174126ms step_avg:148.44ms
step:1184/1390 train_time:174283ms step_avg:148.45ms
step:1185/1390 train_time:174438ms step_avg:148.46ms
step:1186/1390 train_time:174595ms step_avg:148.47ms
step:1187/1390 train_time:174759ms step_avg:148.48ms
step:1188/1390 train_time:174912ms step_avg:148.48ms
step:1189/1390 train_time:175070ms step_avg:148.49ms
step:1190/1390 train_time:175229ms step_avg:148.50ms
step:1191/1390 train_time:175388ms step_avg:148.51ms
step:1192/1390 train_time:175542ms step_avg:148.51ms
step:1193/1390 train_time:175696ms step_avg:148.52ms
step:1194/1390 train_time:175853ms step_avg:148.52ms
step:1195/1390 train_time:176008ms step_avg:148.53ms
step:1196/1390 train_time:176165ms step_avg:148.54ms
step:1197/1390 train_time:176321ms step_avg:148.54ms
step:1198/1390 train_time:176483ms step_avg:148.55ms
step:1199/1390 train_time:176639ms step_avg:148.56ms
step:1200/1390 train_time:176793ms step_avg:148.57ms
step:1201/1390 train_time:176950ms step_avg:148.57ms
step:1202/1390 train_time:177118ms step_avg:148.59ms
step:1203/1390 train_time:177276ms step_avg:148.60ms
step:1204/1390 train_time:177432ms step_avg:148.60ms
step:1205/1390 train_time:177590ms step_avg:148.61ms
step:1206/1390 train_time:177746ms step_avg:148.62ms
step:1207/1390 train_time:177900ms step_avg:148.62ms
step:1208/1390 train_time:178061ms step_avg:148.63ms
step:1209/1390 train_time:178218ms step_avg:148.64ms
step:1210/1390 train_time:178380ms step_avg:148.65ms
step:1211/1390 train_time:178536ms step_avg:148.66ms
step:1212/1390 train_time:178690ms step_avg:148.66ms
step:1213/1390 train_time:178846ms step_avg:148.67ms
step:1214/1390 train_time:179003ms step_avg:148.67ms
step:1215/1390 train_time:179159ms step_avg:148.68ms
step:1216/1390 train_time:179315ms step_avg:148.69ms
step:1217/1390 train_time:179470ms step_avg:148.69ms
step:1218/1390 train_time:179626ms step_avg:148.70ms
step:1219/1390 train_time:179781ms step_avg:148.70ms
step:1220/1390 train_time:179935ms step_avg:148.71ms
step:1221/1390 train_time:180091ms step_avg:148.71ms
step:1222/1390 train_time:180247ms step_avg:148.72ms
step:1223/1390 train_time:180403ms step_avg:148.72ms
step:1224/1390 train_time:180561ms step_avg:148.73ms
step:1225/1390 train_time:180717ms step_avg:148.74ms
step:1226/1390 train_time:180874ms step_avg:148.75ms
step:1227/1390 train_time:181032ms step_avg:148.75ms
step:1228/1390 train_time:181186ms step_avg:148.76ms
step:1229/1390 train_time:181341ms step_avg:148.76ms
step:1230/1390 train_time:181501ms step_avg:148.77ms
step:1231/1390 train_time:181662ms step_avg:148.78ms
step:1232/1390 train_time:181821ms step_avg:148.79ms
step:1233/1390 train_time:181976ms step_avg:148.79ms
step:1234/1390 train_time:182130ms step_avg:148.80ms
step:1235/1390 train_time:182288ms step_avg:148.81ms
step:1236/1390 train_time:182443ms step_avg:148.81ms
step:1237/1390 train_time:182598ms step_avg:148.82ms
step:1238/1390 train_time:182764ms step_avg:148.83ms
step:1239/1390 train_time:182923ms step_avg:148.84ms
step:1240/1390 train_time:183082ms step_avg:148.85ms
step:1241/1390 train_time:183242ms step_avg:148.86ms
step:1242/1390 train_time:183398ms step_avg:148.86ms
step:1243/1390 train_time:183558ms step_avg:148.87ms
step:1244/1390 train_time:183714ms step_avg:148.88ms
step:1245/1390 train_time:183873ms step_avg:148.88ms
step:1246/1390 train_time:184030ms step_avg:148.89ms
step:1247/1390 train_time:184192ms step_avg:148.90ms
step:1248/1390 train_time:184348ms step_avg:148.91ms
step:1249/1390 train_time:184501ms step_avg:148.91ms
step:1250/1390 train_time:184657ms step_avg:148.92ms
step:1250/1390 val_loss:3.5275 train_time:184733ms step_avg:148.98ms
step:1251/1390 train_time:184819ms step_avg:148.93ms
step:1252/1390 train_time:184975ms step_avg:148.93ms
step:1253/1390 train_time:185129ms step_avg:148.94ms
step:1254/1390 train_time:185284ms step_avg:148.94ms
step:1255/1390 train_time:185450ms step_avg:148.96ms
step:1256/1390 train_time:185606ms step_avg:148.96ms
step:1257/1390 train_time:185763ms step_avg:148.97ms
step:1258/1390 train_time:185924ms step_avg:148.98ms
step:1259/1390 train_time:186081ms step_avg:148.98ms
step:1260/1390 train_time:186233ms step_avg:148.99ms
step:1261/1390 train_time:186390ms step_avg:148.99ms
step:1262/1390 train_time:186549ms step_avg:149.00ms
step:1263/1390 train_time:186706ms step_avg:149.01ms
step:1264/1390 train_time:186862ms step_avg:149.01ms
step:1265/1390 train_time:187021ms step_avg:149.02ms
step:1266/1390 train_time:187181ms step_avg:149.03ms
step:1267/1390 train_time:187339ms step_avg:149.04ms
step:1268/1390 train_time:187498ms step_avg:149.04ms
step:1269/1390 train_time:187660ms step_avg:149.06ms
step:1270/1390 train_time:187815ms step_avg:149.06ms
step:1271/1390 train_time:187972ms step_avg:149.07ms
step:1272/1390 train_time:188127ms step_avg:149.07ms
step:1273/1390 train_time:188283ms step_avg:149.08ms
step:1274/1390 train_time:188439ms step_avg:149.08ms
step:1275/1390 train_time:188595ms step_avg:149.09ms
step:1276/1390 train_time:188749ms step_avg:149.09ms
step:1277/1390 train_time:188907ms step_avg:149.10ms
step:1278/1390 train_time:189062ms step_avg:149.10ms
step:1279/1390 train_time:189221ms step_avg:149.11ms
step:1280/1390 train_time:189384ms step_avg:149.12ms
step:1281/1390 train_time:189542ms step_avg:149.13ms
step:1282/1390 train_time:189696ms step_avg:149.13ms
step:1283/1390 train_time:189852ms step_avg:149.14ms
step:1284/1390 train_time:190010ms step_avg:149.14ms
step:1285/1390 train_time:190166ms step_avg:149.15ms
step:1286/1390 train_time:190326ms step_avg:149.16ms
step:1287/1390 train_time:190484ms step_avg:149.17ms
step:1288/1390 train_time:190644ms step_avg:149.17ms
step:1289/1390 train_time:190808ms step_avg:149.19ms
step:1290/1390 train_time:190968ms step_avg:149.19ms
step:1291/1390 train_time:191129ms step_avg:149.20ms
step:1292/1390 train_time:191286ms step_avg:149.21ms
step:1293/1390 train_time:191443ms step_avg:149.22ms
step:1294/1390 train_time:191601ms step_avg:149.22ms
step:1295/1390 train_time:191759ms step_avg:149.23ms
step:1296/1390 train_time:191919ms step_avg:149.24ms
step:1297/1390 train_time:192078ms step_avg:149.24ms
step:1298/1390 train_time:192232ms step_avg:149.25ms
step:1299/1390 train_time:192388ms step_avg:149.25ms
step:1300/1390 train_time:192546ms step_avg:149.26ms
step:1301/1390 train_time:192700ms step_avg:149.26ms
step:1302/1390 train_time:192859ms step_avg:149.27ms
step:1303/1390 train_time:193017ms step_avg:149.28ms
step:1304/1390 train_time:193176ms step_avg:149.29ms
step:1305/1390 train_time:193331ms step_avg:149.29ms
step:1306/1390 train_time:193490ms step_avg:149.30ms
step:1307/1390 train_time:193645ms step_avg:149.30ms
step:1308/1390 train_time:193804ms step_avg:149.31ms
step:1309/1390 train_time:193960ms step_avg:149.31ms
step:1310/1390 train_time:194117ms step_avg:149.32ms
step:1311/1390 train_time:194272ms step_avg:149.32ms
step:1312/1390 train_time:194426ms step_avg:149.33ms
step:1313/1390 train_time:194582ms step_avg:149.33ms
step:1314/1390 train_time:194741ms step_avg:149.34ms
step:1315/1390 train_time:194898ms step_avg:149.35ms
step:1316/1390 train_time:195053ms step_avg:149.35ms
step:1317/1390 train_time:195207ms step_avg:149.36ms
step:1318/1390 train_time:195368ms step_avg:149.36ms
step:1319/1390 train_time:195526ms step_avg:149.37ms
step:1320/1390 train_time:195685ms step_avg:149.38ms
step:1321/1390 train_time:195844ms step_avg:149.39ms
step:1322/1390 train_time:196004ms step_avg:149.39ms
step:1323/1390 train_time:196160ms step_avg:149.40ms
step:1324/1390 train_time:196316ms step_avg:149.40ms
step:1325/1390 train_time:196474ms step_avg:149.41ms
step:1326/1390 train_time:196632ms step_avg:149.42ms
step:1327/1390 train_time:196788ms step_avg:149.42ms
step:1328/1390 train_time:196947ms step_avg:149.43ms
step:1329/1390 train_time:197121ms step_avg:149.45ms
step:1330/1390 train_time:197280ms step_avg:149.45ms
step:1331/1390 train_time:197481ms step_avg:149.49ms
step:1332/1390 train_time:197644ms step_avg:149.50ms
step:1333/1390 train_time:197801ms step_avg:149.51ms
step:1334/1390 train_time:197956ms step_avg:149.51ms
step:1335/1390 train_time:198110ms step_avg:149.52ms
step:1336/1390 train_time:198271ms step_avg:149.53ms
step:1337/1390 train_time:198430ms step_avg:149.53ms
step:1338/1390 train_time:198590ms step_avg:149.54ms
step:1339/1390 train_time:198752ms step_avg:149.55ms
step:1340/1390 train_time:198913ms step_avg:149.56ms
step:1341/1390 train_time:199068ms step_avg:149.56ms
step:1342/1390 train_time:199228ms step_avg:149.57ms
step:1343/1390 train_time:199384ms step_avg:149.58ms
step:1344/1390 train_time:199539ms step_avg:149.58ms
step:1345/1390 train_time:199697ms step_avg:149.59ms
step:1346/1390 train_time:199855ms step_avg:149.59ms
step:1347/1390 train_time:200018ms step_avg:149.60ms
step:1348/1390 train_time:200174ms step_avg:149.61ms
step:1349/1390 train_time:200331ms step_avg:149.61ms
step:1350/1390 train_time:200487ms step_avg:149.62ms
step:1351/1390 train_time:200645ms step_avg:149.62ms
step:1352/1390 train_time:200808ms step_avg:149.63ms
step:1353/1390 train_time:200969ms step_avg:149.64ms
step:1354/1390 train_time:201130ms step_avg:149.65ms
step:1355/1390 train_time:201288ms step_avg:149.66ms
step:1356/1390 train_time:201445ms step_avg:149.66ms
step:1357/1390 train_time:201603ms step_avg:149.67ms
step:1358/1390 train_time:201762ms step_avg:149.67ms
step:1359/1390 train_time:201921ms step_avg:149.68ms
step:1360/1390 train_time:202080ms step_avg:149.69ms
step:1361/1390 train_time:202240ms step_avg:149.70ms
step:1362/1390 train_time:202399ms step_avg:149.70ms
step:1363/1390 train_time:202563ms step_avg:149.71ms
step:1364/1390 train_time:202720ms step_avg:149.72ms
step:1365/1390 train_time:202875ms step_avg:149.72ms
step:1366/1390 train_time:203034ms step_avg:149.73ms
step:1367/1390 train_time:203192ms step_avg:149.74ms
step:1368/1390 train_time:203351ms step_avg:149.74ms
step:1369/1390 train_time:203517ms step_avg:149.76ms
step:1370/1390 train_time:203677ms step_avg:149.76ms
step:1371/1390 train_time:203834ms step_avg:149.77ms
step:1372/1390 train_time:203998ms step_avg:149.78ms
step:1373/1390 train_time:204154ms step_avg:149.78ms
step:1374/1390 train_time:204312ms step_avg:149.79ms
step:1375/1390 train_time:204468ms step_avg:149.79ms
step:1375/1390 val_loss:3.5034 train_time:204541ms step_avg:149.85ms
step:1376/1390 train_time:204625ms step_avg:149.80ms
step:1377/1390 train_time:204782ms step_avg:149.80ms
step:1378/1390 train_time:204939ms step_avg:149.81ms
step:1379/1390 train_time:205097ms step_avg:149.82ms
step:1380/1390 train_time:205254ms step_avg:149.82ms
step:1381/1390 train_time:205415ms step_avg:149.83ms
step:1382/1390 train_time:205573ms step_avg:149.83ms
step:1383/1390 train_time:205734ms step_avg:149.84ms
step:1384/1390 train_time:205895ms step_avg:149.85ms
step:1385/1390 train_time:206050ms step_avg:149.85ms
step:1386/1390 train_time:206207ms step_avg:149.86ms
step:1387/1390 train_time:206366ms step_avg:149.87ms
step:1388/1390 train_time:206520ms step_avg:149.87ms
step:1389/1390 train_time:206681ms step_avg:149.88ms
step:1390/1390 train_time:206837ms step_avg:149.88ms
step:1390/1390 val_loss:3.5026 train_time:206911ms step_avg:149.94ms
peak memory consumption: 31565 MiB
