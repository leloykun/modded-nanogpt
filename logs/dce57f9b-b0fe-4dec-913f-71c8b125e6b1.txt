import os
import sys
with open(sys.argv[0]) as f:
    code = f.read() # read the code of this file ASAP, for logging
import uuid
import time
import glob
import subprocess
import contextlib
from dataclasses import dataclass

import torch
torch.empty(1, device='cuda', requires_grad=True).backward()
from torch import nn
import torch.nn.functional as F
import torch.distributed as dist
from torch.nn.parallel import DistributedDataParallel as DDP
# use of FlexAttention contributed by @KoszarskyB
from torch.nn.attention.flex_attention import BlockMask, flex_attention

# -----------------------------------------------------------------------------
# Muon optimizer

@torch.compile
def zeropower_via_newtonschulz5(G, steps):
    """
    Newton-Schulz iteration to compute the zeroth power / orthogonalization of G. We opt to use a
    quintic iteration whose coefficients are selected to maximize the slope at zero. For the purpose
    of minimizing steps, it turns out to be empirically effective to keep increasing the slope at
    zero even beyond the point where the iteration no longer converges all the way to one everywhere
    on the interval. This iteration therefore does not produce UV^T but rather something like US'V^T
    where S' is diagonal with S_{ii}' ~ Uniform(0.5, 1.5), which turns out not to hurt model
    performance at all relative to UV^T, where USV^T = G is the SVD.
    """
    assert len(G.shape) == 2
    a, b, c = (3.4445, -4.7750,  2.0315)
    X = G.bfloat16()
    if G.size(0) > G.size(1):
        X = X.T

    # Ensure spectral norm is at most 1
    X = X / (X.norm() + 1e-7)
    # Perform the NS iterations
    for _ in range(steps):
        A = X @ X.T
        B = b * A + c * A @ A # adapted from suggestion by @jxbz, @leloykun, and @YouJiacheng
        X = a * X + B @ X
    
    if G.size(0) > G.size(1):
        X = X.T
    X = torch.einsum("ij,ij,ab->ab", G.type_as(X), X, X)
    return X

class Muon(torch.optim.Optimizer):
    """
    Muon - MomentUm Orthogonalized by Newton-schulz

    Muon internally runs standard SGD-momentum, and then performs an orthogonalization post-
    processing step, in which each 2D parameter's update is replaced with the nearest orthogonal
    matrix. To efficiently orthogonalize each update, we use a Newton-Schulz iteration, which has
    the advantage that it can be stably run in bfloat16 on the GPU.

    Some warnings:
    - This optimizer assumes that all parameters passed in are 2D.
    - It should not be used for the embedding layer, the final fully connected layer, or any {0,1}-D
    parameters; those should all be optimized by a standard method (e.g., AdamW).
    - To use it with 4D convolutional filters, it works well to just flatten their last 3 dimensions.
    - We believe it is unlikely to work well for training with small batch size.
    - We believe it may not work well for finetuning pretrained models, but we haven't tested this.
    - We have not yet tried this optimizer for training scenarios larger than NanoGPT (124M).

    Arguments:
        lr: The learning rate used by the internal SGD.
        momentum: The momentum used by the internal SGD.
        nesterov: Whether to use Nesterov-style momentum in the internal SGD. (recommended)
        ns_steps: The number of Newton-Schulz iteration steps to use.
    """
    def __init__(self, params, lr=0.02, momentum=0.95, nesterov=True, ns_steps=5):
        self.world_size = int(os.environ['WORLD_SIZE'])
        self.rank = int(os.environ['RANK'])
        defaults = dict(lr=lr, momentum=momentum, nesterov=nesterov, ns_steps=ns_steps)
        assert all(isinstance(p, torch.Tensor) for p in params)
        sizes = {p.numel() for p in params}
        param_groups = [dict(params=[p for p in params if p.numel() == size],
                             update_buffer=[torch.empty(size, device='cuda', dtype=torch.bfloat16) for _ in range(self.world_size)])
                        for size in sizes]
        super().__init__(param_groups, defaults)

    def step(self):

        for group in self.param_groups:

            lr = group['lr']
            momentum = group['momentum']
            nesterov = group['nesterov']
            ns_steps = group['ns_steps']
            update_buffers = group['update_buffer']
            # generate weight updates in distributed fashion
            params = group['params']
            handle = None
            params_world = None
            def update_prev():
                if params_world is None:
                    return
                assert handle is not None
                handle.wait()
                for p_world, g_world in zip(params_world, update_buffers):
                    p_world.data.add_(
                        g_world.view_as(p_world),
                        alpha=-lr * max(1, p_world.size(0) / p_world.size(1)) ** 0.5,
                    )
            for base_i in range(len(params))[::self.world_size]:
                if base_i + rank < len(params):
                    p = params[base_i + self.rank]
                    g = p.grad
                    assert g is not None
                    state = self.state[p]
                    if 'momentum_buffer' not in state:
                        state['momentum_buffer'] = torch.zeros_like(g)
                    buf = state['momentum_buffer']
                    buf.lerp_(g, 1 - momentum)
                    g = g.lerp_(buf, momentum) if nesterov else buf
                    g = zeropower_via_newtonschulz5(g, steps=ns_steps).flatten()
                else:
                    g = update_buffers[rank]
                update_prev() # async all_gather instead of sync all_reduce by @YouJiacheng
                handle = dist.all_gather(update_buffers, g, async_op=True)
                params_world = params[base_i : base_i + self.world_size]
            update_prev()

# -----------------------------------------------------------------------------
# PyTorch nn.Module definitions for the GPT-2 model

def norm(x):
    return F.rms_norm(x, (x.size(-1),))

class CastedLinear(nn.Linear):

    def __init__(self, in_features, out_features):
        super().__init__(in_features, out_features, bias=False)

    def forward(self, x):
        return F.linear(x, self.weight.type_as(x))

class Rotary(nn.Module):

    def __init__(self, dim, max_seq_len=65536):
        super().__init__()
        # half-truncate RoPE by @YouJiacheng
        angular_freq = (1 / 1024) ** torch.linspace(0, 1, steps=dim//4, dtype=torch.float32)
        angular_freq = torch.cat([angular_freq, angular_freq.new_zeros(dim//4)])
        t = torch.arange(max_seq_len, dtype=torch.float32)
        theta = torch.einsum('i,j -> ij', t, angular_freq)
        self.cos = nn.Buffer(theta.cos(), persistent=False)
        self.sin = nn.Buffer(theta.sin(), persistent=False)

    def forward(self, x):
        cos, sin = self.cos[None, :x.size(-3), None, :], self.sin[None, :x.size(-3), None, :]
        x1, x2 = x.float().chunk(2, dim=-1)
        y1 = x1 * cos + x2 * sin
        y2 = x1 * (-sin) + x2 * cos
        return torch.cat((y1, y2), 3).type_as(x)

class CausalSelfAttention(nn.Module):

    def __init__(self, dim, num_heads):
        super().__init__()
        assert dim % num_heads == 0
        self.num_heads = num_heads
        self.c_q = CastedLinear(dim, dim)
        self.c_k = CastedLinear(dim, dim)
        self.c_v = CastedLinear(dim, dim)
        self.lambdas = nn.Parameter(torch.tensor([0.5, 0.5]))
        self.rotary = Rotary(dim // num_heads) # dim // num_heads = head_dim
        self.c_proj = CastedLinear(dim, dim)
        self.c_proj.weight.data.zero_() # zero init suggested by @Grad62304977

    def forward(self, x, ve, block_mask):
        B, T = x.size(0), x.size(1) # batch size, sequence length
        assert B == 1, 'Must use batch size = 1 for FlexAttention'
        q = self.c_q(x).view(B, T, self.num_heads, -1)
        k = self.c_k(x).view(B, T, self.num_heads, -1)
        v = self.c_v(x).view(B, T, self.num_heads, -1)
        if ve is not None:
            v = self.lambdas[0] * v + self.lambdas[1] * ve.view_as(v) # @KoszarskyB & @Grad62304977
        else: # skip mid-layers token value embeddings by @YouJiacheng
            v = self.lambdas[0] * v
        q, k = norm(q), norm(k) # QK norm @Grad62304977
        q, k = self.rotary(q), self.rotary(k)
        y = flex_attention(q.transpose(1, 2), k.transpose(1, 2), v.transpose(1, 2), block_mask=block_mask)
        y = y.transpose(1, 2).contiguous().view_as(x) # re-assemble all head outputs side by side
        y = self.c_proj(y)
        return y

class MLP(nn.Module):

    def __init__(self, dim):
        super().__init__()
        self.c_fc = CastedLinear(dim, 4 * dim)
        self.c_proj = CastedLinear(4 * dim, dim)
        self.c_proj.weight.data.zero_() # zero init suggested by @Grad62304977

    def forward(self, x):
        x = self.c_fc(x)
        x = F.relu(x).square() # https://arxiv.org/abs/2109.08668v2; ~1-2% better than GELU; suggested by @SKYLINEZ007 and @Grad62304977
        x = self.c_proj(x)
        return x

class Block(nn.Module):

    def __init__(self, model_dim, num_heads, use_attn=True):
        super().__init__()
        self.attn = CausalSelfAttention(model_dim, num_heads) if use_attn else None
        self.mlp = MLP(model_dim)
        self.lambdas = nn.Parameter(torch.tensor([1., 0.]))

    def forward(self, x, ve, x0, block_mask):
        x = self.lambdas[0] * x + self.lambdas[1] * x0
        if self.attn is not None:
            x = x + self.attn(norm(x), ve, block_mask)
        x = x + self.mlp(norm(x))
        return x

class ValueEmbedding(nn.Module):
    def __init__(self, vocab_size, model_dim):
        super().__init__()
        self.embed = nn.ModuleList([nn.Embedding(vocab_size, model_dim) for _ in range(3)])

    def forward(self, inputs):
        ve = [emb(inputs).bfloat16() for emb in self.embed]
        # 012 ... 012 structure on token value embeddings by @YouJiacheng, improved on @leloykun's U-net structure
        ve = [ve[0], ve[1], ve[2], None, None, None, None, None, None, ve[0], ve[1], ve[2]]
        return ve

# -----------------------------------------------------------------------------
# The main GPT-2 model

class GPT(nn.Module):

    def __init__(self, vocab_size, num_layers, num_heads, model_dim):
        super().__init__()
        self.embed = nn.Embedding(vocab_size, model_dim)
        # skip attention of blocks.7 (the 8th layer) by @YouJiacheng
        self.blocks = nn.ModuleList([Block(model_dim, num_heads, use_attn=(i != 7))
                                     for i in range(num_layers)])
        # token value embeddings by @KoszarskyB - inspired by @Grad62304977's value residual learning
        # U-net structure on token value embeddings by @leloykun
        self.value_embeds = ValueEmbedding(vocab_size, model_dim)
        self.lm_head = CastedLinear(model_dim, vocab_size)
        self.lm_head.weight.data.zero_() # @Grad62304977
        # U-net design by @brendanh0gan
        self.num_encoder_layers = num_layers // 2 # Half of the layers for encoder
        self.num_decoder_layers = num_layers - self.num_encoder_layers # Remaining for decoder
        # Add learnable skip connection weights for decoder layers
        self.skip_weights = nn.Parameter(torch.ones(self.num_decoder_layers))

    def forward(self, inputs, targets, sliding_window_num_blocks):
        BLOCK_SIZE = 128
        seq_len = len(inputs)
        assert seq_len % BLOCK_SIZE == 0
        total_num_blocks = seq_len // BLOCK_SIZE
        assert inputs.ndim == 1
        docs = (inputs == 50256).cumsum(0)
        docs_low = docs.view(-1, BLOCK_SIZE)[:, 0].contiguous()
        docs_high = docs.view(-1, BLOCK_SIZE)[:, -1].contiguous()

        def document_causal(b, h, q_idx, kv_idx):
            causal_mask = q_idx >= kv_idx
            document_mask = docs[q_idx] == docs[kv_idx]
            return causal_mask & document_mask

        def dense_to_ordered(dense_mask):
            num_blocks = dense_mask.sum(dim=-1, dtype=torch.int32)
            indices = dense_mask.argsort(dim=-1, descending=True, stable=True).to(torch.int32)
            return num_blocks[None, None].contiguous(), indices[None, None].contiguous()

        def create_doc_swc_block_mask(sliding_window_num_blocks):
            kv_idx = block_idx = torch.arange(total_num_blocks, dtype=torch.int32, device='cuda')
            q_idx = block_idx[:, None]
            causal_bm = q_idx >= kv_idx
            causal_full_bm = q_idx > kv_idx
            window_bm = q_idx - kv_idx < sliding_window_num_blocks
            window_full_bm = window_bm # block-wise sliding window by @YouJiacheng
            # document_bm = (docs_low[q_idx] <= docs_high[kv_idx]) & (docs_low[kv_idx] <= docs_high[q_idx])
            document_bm = (docs_low[:, None] <= docs_high) & (docs_low <= docs_high[:, None])
            document_full_bm = (docs_low[:, None] == docs_high) & (docs_low == docs_high[:, None])
            nonzero_bm = causal_bm & window_bm & document_bm
            full_bm  = causal_full_bm & window_full_bm & document_full_bm
            kv_num_blocks, kv_indices = dense_to_ordered(nonzero_bm & ~full_bm)
            full_kv_num_blocks, full_kv_indices = dense_to_ordered(full_bm)
            return BlockMask.from_kv_blocks(
                kv_num_blocks,
                kv_indices,
                full_kv_num_blocks,
                full_kv_indices,
                BLOCK_SIZE=BLOCK_SIZE,
                mask_mod=document_causal,
            )

        block_mask = create_doc_swc_block_mask(sliding_window_num_blocks)

        x0 = norm(self.embed(inputs[None]).bfloat16()) # use of norm here by @Grad62304977
        x = x0
        ve = self.value_embeds(inputs)
        assert len(ve) == len(self.blocks)
        ve_enc, ve_dec = ve[:self.num_encoder_layers], ve[self.num_encoder_layers:]

        # Store outputs for U-Net skip connections
        skip_connections = []
        # Encoder pass - process only the first half of the blocks
        for i in range(self.num_encoder_layers):
            x = self.blocks[i](x, ve_enc[i], x0, block_mask)
            skip_connections.append(x)
        # Decoder pass - process the remaining blocks with weighted skip connections
        for i in range(self.num_decoder_layers):
            x = x + self.skip_weights[i] * skip_connections.pop()
            # U-net structure on token value embeddings by @leloykun
            x = self.blocks[self.num_encoder_layers + i](x, ve_dec[i], x0, block_mask)

        x = norm(x)
        logits = self.lm_head(x)
        logits = 15 * torch.tanh(logits / 15) # @Grad62304977 added tanh softcapping, @KoszarskyB reduced it from 30 to 15
        logits = logits.float()
        loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets)
        return loss

# -----------------------------------------------------------------------------
# Our own simple Distributed Data Loader

def _load_data_shard(path):
    # only reads the header, returns header data
    # header is 256 int32
    header = torch.from_file(path, False, 256, dtype=torch.int32)
    assert header[0] == 20240520, 'magic number mismatch in the data .bin file'
    assert header[1] == 1, 'unsupported version'
    num_tokens = int(header[2]) # number of tokens (claimed)
    with open(path, 'rb', buffering=0) as f:
        tokens = torch.empty(num_tokens, dtype=torch.uint16, pin_memory=True) # avoid pin_memory copy by @YouJiacheng
        f.seek(256 * 4)
        nbytes = f.readinto(tokens.numpy()) # avoid bytes->array copy by @YouJiacheng
        assert nbytes == 2 * num_tokens, 'number of tokens read does not match header'
    return tokens

class DistributedDataLoader:

    def __init__(self, filename_pattern):
        self.rank = int(os.environ['RANK'])
        self.world_size = int(os.environ['WORLD_SIZE'])
        self.files = sorted(glob.glob(filename_pattern))
        self.reset()

    def reset(self):
        self.current_shard = -1
        self.advance()

    def advance(self):
        self.current_shard = (self.current_shard + 1) % len(self.files)
        self.current_position = 0
        self.tokens = _load_data_shard(self.files[self.current_shard])

    def next_batch(self, batch_size):
        assert batch_size % self.world_size == 0
        device_batch_size = batch_size // self.world_size
        # load next shard if necessary
        if self.current_position + batch_size + 1 >= len(self.tokens):
            self.advance()
        pos = self.current_position + self.rank * device_batch_size
        device_batch_tokens = self.tokens[pos:pos+device_batch_size+1]
        # advance current position
        self.current_position += batch_size
        inputs = device_batch_tokens[:-1].to(device='cuda', dtype=torch.int32, non_blocking=True)
        targets = device_batch_tokens[1:].to(device='cuda', dtype=torch.int64, non_blocking=True)
        return inputs, targets

# -----------------------------------------------------------------------------
# int main

@dataclass
class Hyperparameters:
    # data
    train_files = 'data/fineweb10B/fineweb_train_*.bin' # input .bin to train on
    val_files = 'data/fineweb10B/fineweb_val_*.bin' # input .bin to eval validation loss on
    val_tokens = 10485760 # how many tokens of validation data? it's important to keep this fixed for consistent comparisons
    # optimization
    batch_size = 8*64*1024 # batch size in tokens
    num_iterations = 1390 # number of iterations to run
    cooldown_frac = 0.4 # fraction of training spent cooling down the learning rate
    bf16_embeds = True
    # evaluation and logging
    val_loss_every = 125 # every how many steps to evaluate val loss? 0 for only at the end
    # implementation
    max_device_batch_size = 64*1024 # batch size per device in tokens
    save_checkpoint = False
args = Hyperparameters()

micro_bs = args.max_device_batch_size

# set up DDP (distributed data parallel). torchrun sets this env variable
rank = int(os.environ['RANK'])
local_rank = int(os.environ['LOCAL_RANK'])
world_size = int(os.environ['WORLD_SIZE'])
assert torch.cuda.is_available()
torch.cuda.set_device(local_rank)
dist.init_process_group(backend='nccl', device_id=torch.device(local_rank))
dist.barrier()
master_process = (rank == 0) # this process will do logging, checkpointing etc.

# begin logging
logfile = None
if master_process:
    run_id = uuid.uuid4()
    os.makedirs('logs', exist_ok=True)
    logfile = f'logs/{run_id}.txt'
    print(logfile)

def print0(s, console=False):
    if master_process:
        with open(logfile, 'a') as f:
            if console:
                print(s)
            print(s, file=f)

# begin by printing this file (the Python code)
print0(code)
print0('='*100)
# log information about the hardware/software environment this is running on
print0(f'Running Python {sys.version}')
print0(f'Running PyTorch {torch.version.__version__} compiled for CUDA {torch.version.cuda}')
print0(subprocess.run(['nvidia-smi'], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True).stdout)
print0('='*100)

# load data
train_loader = DistributedDataLoader(args.train_files)
val_loader = DistributedDataLoader(args.val_files)
print0(f'Training dataloader files: {train_loader.files}')
print0(f'Validation dataloader files: {val_loader.files}')
print0('='*100)

# there are only 50257 unique GPT-2 tokens; we extend to nearest multiple of 128 for efficiency. suggested to me by @Grad62304977.
# this originates from Karpathy's experiments.
model = GPT(vocab_size=50304, num_layers=12, num_heads=6, model_dim=768)
model = model.cuda()
if args.bf16_embeds:
    for m in model.modules():
        if isinstance(m, nn.Embedding):
            m.bfloat16()
model = torch.compile(model)
ddp_model = DDP(model, device_ids=[local_rank], broadcast_buffers=False, gradient_as_bucket_view=True)

# collect the parameters to optimize
hidden_matrix_params = [p for p in model.blocks.parameters() if p.ndim == 2]
embed_params = [model.embed.weight, *model.value_embeds.parameters()]
scalar_params = [p for p in model.parameters() if p.ndim < 2]
head_params = [model.lm_head.weight]

# init the optimizer(s)
optimizer1 = torch.optim.Adam([dict(params=embed_params, lr=0.6),
                               dict(params=head_params, lr=0.008),
                               dict(params=scalar_params, lr=0.04)],
                              betas=(0.8, 0.95), fused=True)
# optimizer2 = Muon(hidden_matrix_params, lr=0.5, momentum=0.95)
# optimizer2 = Muon(hidden_matrix_params, lr=0.25, momentum=0.95)  # done
# optimizer2 = Muon(hidden_matrix_params, lr=0.1, momentum=0.95)  # done
# optimizer2 = Muon(hidden_matrix_params, lr=0.05, momentum=0.95)  # done
optimizer2 = Muon(hidden_matrix_params, lr=0.025, momentum=0.95)
# optimizer2 = Muon(hidden_matrix_params, lr=0.01, momentum=0.95)
# optimizer2 = Muon(hidden_matrix_params, lr=0.005, momentum=0.95)
optimizers = [optimizer1, optimizer2]

# learning rate schedule: stable then decay
def get_lr(it):
    t = 1 - it / args.num_iterations # time remaining in training
    assert 1 >= t > 0
    # 1) constant lr for first part of training
    if t >= args.cooldown_frac:
        return 1.0
    # 2) then linear cooldown
    else:
        return t / args.cooldown_frac
schedulers = [torch.optim.lr_scheduler.LambdaLR(opt, get_lr) for opt in optimizers]

# sliding window size schedule: linear increase over training in chunks of 128 from 128 -> 1792. By @fernbear.bsky.social
def get_sliding_window_blocks(it):
    x = it / args.num_iterations # training progress
    assert 0 <= x <= 1
    return int(((1 - x) * 128 + x * 1856) // 128)
sliding_window_num_blocks = torch.tensor(1, dtype=torch.int32, device='cuda')

# Start training loop
training_time_ms = 0
# start the clock
torch.cuda.synchronize()
t0 = time.perf_counter()
# begin training
train_steps = args.num_iterations
for step in range(train_steps + 1):
    last_step = (step == train_steps)
    # This effectively ignores timing first 10 steps, which are slower for weird reasons.
    # Alternately, and slightly more correctly in terms of benchmarking, we could do 10
    # steps with dummy data first, and then re-initialize the model and reset the loader.
    if step == 10:
        training_time_ms = 0
        t0 = time.perf_counter()
    timed_steps = float('nan') if step <= 11 else (step - 10) + 1 # <= 11 to avoid bug in val

    sliding_window_num_blocks.copy_(get_sliding_window_blocks(step))

    # --------------- VALIDATION SECTION -----------------
    if last_step or (args.val_loss_every > 0 and step % args.val_loss_every == 0):
        # stop the clock
        torch.cuda.synchronize()
        training_time_ms += 1000 * (time.perf_counter() - t0)
        # run validation batches
        model.eval()
        val_loader.reset()
        val_loss = 0.0
        # calculate the number of steps to take in the val loop.
        val_batch_size = world_size * micro_bs
        assert args.val_tokens % val_batch_size == 0
        val_steps = args.val_tokens // val_batch_size
        for _ in range(val_steps):
            with torch.no_grad():
                inputs_val, targets_val = val_loader.next_batch(val_batch_size)
                val_loss += ddp_model(inputs_val, targets_val, sliding_window_num_blocks)
        dist.all_reduce(val_loss, op=dist.ReduceOp.AVG)
        val_loss /= val_steps
        # logging
        print0(f'step:{step}/{train_steps} val_loss:{val_loss:.4f} train_time:{training_time_ms:.0f}ms step_avg:{training_time_ms/(timed_steps-1):.2f}ms', console=True)
        # start the clock again
        torch.cuda.synchronize()
        t0 = time.perf_counter()

    if last_step:
        if master_process and args.save_checkpoint:
            log = dict(step=step, code=code, model=model.state_dict(), optimizers=[opt.state_dict() for opt in optimizers])
            os.makedirs(f'logs/{run_id}', exist_ok=True)
            torch.save(log, f'logs/{run_id}/state_step{step:06d}.pt')
        # the last step only has the validation loop, so break to avoid training
        break

    # --------------- TRAINING SECTION -----------------
    model.train()
    batch_size = args.batch_size
    assert batch_size % world_size == 0
    inputs_train, targets_train = train_loader.next_batch(batch_size)
    assert len(inputs_train) <= micro_bs or len(inputs_train) % micro_bs == 0
    for micro_inputs_train, micro_targets_train in zip(inputs_train.split(micro_bs), targets_train.split(micro_bs)):
        ddp_model(micro_inputs_train, micro_targets_train, sliding_window_num_blocks).backward()
    # momentum warmup for Muon
    frac = min(step/300, 1)
    for group in optimizer2.param_groups:
        group['momentum'] = (1 - frac) * 0.85 + frac * 0.95
    # step the optimizers and schedulers
    for opt, sched in zip(optimizers, schedulers):
        opt.step()
        if step != train_steps-1:
            sched.step()
    # null the gradients
    model.zero_grad(set_to_none=True)
    # logging
    approx_time = training_time_ms + 1000 * (time.perf_counter() - t0)
    print0(f'step:{step+1}/{train_steps} train_time:{approx_time:.0f}ms step_avg:{approx_time/timed_steps:.2f}ms', console=True)

print0(f'peak memory consumption: {torch.cuda.max_memory_allocated() // 1024 // 1024} MiB')
dist.destroy_process_group()

====================================================================================================
Running Python 3.10.12 (main, Sep 11 2024, 15:47:36) [GCC 11.4.0]
Running PyTorch 2.6.0.dev20241231+cu126 compiled for CUDA 12.6
Tue Jan 14 17:38:25 2025       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.183.06             Driver Version: 535.183.06   CUDA Version: 12.4     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA H100 80GB HBM3          On  | 00000000:19:00.0 Off |                    0 |
| N/A   38C    P0             125W / 700W |   7713MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   1  NVIDIA H100 80GB HBM3          On  | 00000000:3B:00.0 Off |                    0 |
| N/A   32C    P0             114W / 700W |   3451MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   2  NVIDIA H100 80GB HBM3          On  | 00000000:4C:00.0 Off |                    0 |
| N/A   29C    P0             118W / 700W |   3451MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   3  NVIDIA H100 80GB HBM3          On  | 00000000:5D:00.0 Off |                    0 |
| N/A   37C    P0             128W / 700W |   3451MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   4  NVIDIA H100 80GB HBM3          On  | 00000000:9B:00.0 Off |                    0 |
| N/A   37C    P0             123W / 700W |   3451MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   5  NVIDIA H100 80GB HBM3          On  | 00000000:BB:00.0 Off |                    0 |
| N/A   30C    P0             114W / 700W |   3451MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   6  NVIDIA H100 80GB HBM3          On  | 00000000:CB:00.0 Off |                    0 |
| N/A   36C    P0             115W / 700W |   3451MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   7  NVIDIA H100 80GB HBM3          On  | 00000000:DB:00.0 Off |                    0 |
| N/A   30C    P0             117W / 700W |   3211MiB / 81559MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
+---------------------------------------------------------------------------------------+

====================================================================================================
Training dataloader files: ['data/fineweb10B/fineweb_train_000001.bin', 'data/fineweb10B/fineweb_train_000002.bin', 'data/fineweb10B/fineweb_train_000003.bin', 'data/fineweb10B/fineweb_train_000004.bin', 'data/fineweb10B/fineweb_train_000005.bin', 'data/fineweb10B/fineweb_train_000006.bin', 'data/fineweb10B/fineweb_train_000007.bin', 'data/fineweb10B/fineweb_train_000008.bin', 'data/fineweb10B/fineweb_train_000009.bin']
Validation dataloader files: ['data/fineweb10B/fineweb_val_000000.bin']
====================================================================================================
step:0/1390 val_loss:10.8258 train_time:0ms step_avg:nanms
step:1/1390 train_time:28061ms step_avg:nanms
step:2/1390 train_time:28150ms step_avg:nanms
step:3/1390 train_time:28376ms step_avg:nanms
step:4/1390 train_time:28507ms step_avg:nanms
step:5/1390 train_time:28643ms step_avg:nanms
step:6/1390 train_time:28778ms step_avg:nanms
step:7/1390 train_time:28912ms step_avg:nanms
step:8/1390 train_time:29046ms step_avg:nanms
step:9/1390 train_time:29180ms step_avg:nanms
step:10/1390 train_time:29319ms step_avg:nanms
step:11/1390 train_time:134ms step_avg:nanms
step:12/1390 train_time:272ms step_avg:nanms
step:13/1390 train_time:408ms step_avg:136.02ms
step:14/1390 train_time:542ms step_avg:135.54ms
step:15/1390 train_time:679ms step_avg:135.87ms
step:16/1390 train_time:815ms step_avg:135.79ms
step:17/1390 train_time:951ms step_avg:135.79ms
step:18/1390 train_time:1088ms step_avg:136.00ms
step:19/1390 train_time:1224ms step_avg:136.04ms
step:20/1390 train_time:1362ms step_avg:136.24ms
step:21/1390 train_time:1500ms step_avg:136.32ms
step:22/1390 train_time:1637ms step_avg:136.41ms
step:23/1390 train_time:1774ms step_avg:136.43ms
step:24/1390 train_time:1910ms step_avg:136.41ms
step:25/1390 train_time:2046ms step_avg:136.38ms
step:26/1390 train_time:2183ms step_avg:136.47ms
step:27/1390 train_time:2321ms step_avg:136.51ms
step:28/1390 train_time:2458ms step_avg:136.55ms
step:29/1390 train_time:2592ms step_avg:136.45ms
step:30/1390 train_time:2729ms step_avg:136.47ms
step:31/1390 train_time:2866ms step_avg:136.48ms
step:32/1390 train_time:3003ms step_avg:136.49ms
step:33/1390 train_time:3141ms step_avg:136.55ms
step:34/1390 train_time:3278ms step_avg:136.60ms
step:35/1390 train_time:3415ms step_avg:136.59ms
step:36/1390 train_time:3550ms step_avg:136.53ms
step:37/1390 train_time:3686ms step_avg:136.51ms
step:38/1390 train_time:3823ms step_avg:136.53ms
step:39/1390 train_time:3960ms step_avg:136.54ms
step:40/1390 train_time:4098ms step_avg:136.60ms
step:41/1390 train_time:4234ms step_avg:136.58ms
step:42/1390 train_time:4370ms step_avg:136.56ms
step:43/1390 train_time:4505ms step_avg:136.52ms
step:44/1390 train_time:4642ms step_avg:136.52ms
step:45/1390 train_time:4778ms step_avg:136.51ms
step:46/1390 train_time:4913ms step_avg:136.46ms
step:47/1390 train_time:5049ms step_avg:136.46ms
step:48/1390 train_time:5185ms step_avg:136.44ms
step:49/1390 train_time:5322ms step_avg:136.46ms
step:50/1390 train_time:5458ms step_avg:136.46ms
step:51/1390 train_time:5593ms step_avg:136.41ms
step:52/1390 train_time:5729ms step_avg:136.40ms
step:53/1390 train_time:5865ms step_avg:136.39ms
step:54/1390 train_time:6001ms step_avg:136.39ms
step:55/1390 train_time:6137ms step_avg:136.38ms
step:56/1390 train_time:6274ms step_avg:136.39ms
step:57/1390 train_time:6409ms step_avg:136.36ms
step:58/1390 train_time:6544ms step_avg:136.34ms
step:59/1390 train_time:6681ms step_avg:136.35ms
step:60/1390 train_time:6818ms step_avg:136.36ms
step:61/1390 train_time:6954ms step_avg:136.35ms
step:62/1390 train_time:7089ms step_avg:136.32ms
step:63/1390 train_time:7223ms step_avg:136.28ms
step:64/1390 train_time:7360ms step_avg:136.30ms
step:65/1390 train_time:7497ms step_avg:136.32ms
step:66/1390 train_time:7632ms step_avg:136.29ms
step:67/1390 train_time:7768ms step_avg:136.29ms
step:68/1390 train_time:7904ms step_avg:136.27ms
step:69/1390 train_time:8041ms step_avg:136.29ms
step:70/1390 train_time:8178ms step_avg:136.29ms
step:71/1390 train_time:8314ms step_avg:136.29ms
step:72/1390 train_time:8450ms step_avg:136.28ms
step:73/1390 train_time:8584ms step_avg:136.26ms
step:74/1390 train_time:8720ms step_avg:136.25ms
step:75/1390 train_time:8857ms step_avg:136.26ms
step:76/1390 train_time:8992ms step_avg:136.24ms
step:77/1390 train_time:9129ms step_avg:136.25ms
step:78/1390 train_time:9263ms step_avg:136.22ms
step:79/1390 train_time:9398ms step_avg:136.21ms
step:80/1390 train_time:9534ms step_avg:136.20ms
step:81/1390 train_time:9670ms step_avg:136.19ms
step:82/1390 train_time:9805ms step_avg:136.19ms
step:83/1390 train_time:9942ms step_avg:136.19ms
step:84/1390 train_time:10079ms step_avg:136.20ms
step:85/1390 train_time:10214ms step_avg:136.18ms
step:86/1390 train_time:10350ms step_avg:136.18ms
step:87/1390 train_time:10485ms step_avg:136.17ms
step:88/1390 train_time:10621ms step_avg:136.17ms
step:89/1390 train_time:10759ms step_avg:136.19ms
step:90/1390 train_time:10896ms step_avg:136.19ms
step:91/1390 train_time:11033ms step_avg:136.21ms
step:92/1390 train_time:11168ms step_avg:136.19ms
step:93/1390 train_time:11304ms step_avg:136.20ms
step:94/1390 train_time:11441ms step_avg:136.21ms
step:95/1390 train_time:11578ms step_avg:136.22ms
step:96/1390 train_time:11714ms step_avg:136.21ms
step:97/1390 train_time:11851ms step_avg:136.21ms
step:98/1390 train_time:11986ms step_avg:136.20ms
step:99/1390 train_time:12121ms step_avg:136.20ms
step:100/1390 train_time:12259ms step_avg:136.21ms
step:101/1390 train_time:12394ms step_avg:136.19ms
step:102/1390 train_time:12530ms step_avg:136.19ms
step:103/1390 train_time:12666ms step_avg:136.19ms
step:104/1390 train_time:12805ms step_avg:136.23ms
step:105/1390 train_time:12944ms step_avg:136.25ms
step:106/1390 train_time:13083ms step_avg:136.28ms
step:107/1390 train_time:13223ms step_avg:136.32ms
step:108/1390 train_time:13362ms step_avg:136.35ms
step:109/1390 train_time:13501ms step_avg:136.38ms
step:110/1390 train_time:13640ms step_avg:136.40ms
step:111/1390 train_time:13778ms step_avg:136.41ms
step:112/1390 train_time:13917ms step_avg:136.45ms
step:113/1390 train_time:14057ms step_avg:136.48ms
step:114/1390 train_time:14197ms step_avg:136.51ms
step:115/1390 train_time:14337ms step_avg:136.54ms
step:116/1390 train_time:14477ms step_avg:136.57ms
step:117/1390 train_time:14615ms step_avg:136.59ms
step:118/1390 train_time:14754ms step_avg:136.62ms
step:119/1390 train_time:14894ms step_avg:136.64ms
step:120/1390 train_time:15033ms step_avg:136.66ms
step:121/1390 train_time:15174ms step_avg:136.70ms
step:122/1390 train_time:15314ms step_avg:136.73ms
step:123/1390 train_time:15454ms step_avg:136.76ms
step:124/1390 train_time:15592ms step_avg:136.77ms
step:125/1390 train_time:15730ms step_avg:136.79ms
step:125/1390 val_loss:4.8999 train_time:15794ms step_avg:137.34ms
step:126/1390 train_time:15873ms step_avg:136.84ms
step:127/1390 train_time:16016ms step_avg:136.89ms
step:128/1390 train_time:16156ms step_avg:136.91ms
step:129/1390 train_time:16293ms step_avg:136.92ms
step:130/1390 train_time:16431ms step_avg:136.93ms
step:131/1390 train_time:16570ms step_avg:136.94ms
step:132/1390 train_time:16708ms step_avg:136.95ms
step:133/1390 train_time:16849ms step_avg:136.99ms
step:134/1390 train_time:16992ms step_avg:137.04ms
step:135/1390 train_time:17132ms step_avg:137.06ms
step:136/1390 train_time:17272ms step_avg:137.08ms
step:137/1390 train_time:17411ms step_avg:137.09ms
step:138/1390 train_time:17550ms step_avg:137.11ms
step:139/1390 train_time:17688ms step_avg:137.12ms
step:140/1390 train_time:17828ms step_avg:137.14ms
step:141/1390 train_time:17970ms step_avg:137.17ms
step:142/1390 train_time:18110ms step_avg:137.20ms
step:143/1390 train_time:18250ms step_avg:137.22ms
step:144/1390 train_time:18390ms step_avg:137.24ms
step:145/1390 train_time:18530ms step_avg:137.26ms
step:146/1390 train_time:18670ms step_avg:137.28ms
step:147/1390 train_time:18810ms step_avg:137.30ms
step:148/1390 train_time:18951ms step_avg:137.32ms
step:149/1390 train_time:19090ms step_avg:137.34ms
step:150/1390 train_time:19231ms step_avg:137.36ms
step:151/1390 train_time:19372ms step_avg:137.39ms
step:152/1390 train_time:19512ms step_avg:137.41ms
step:153/1390 train_time:19652ms step_avg:137.43ms
step:154/1390 train_time:19791ms step_avg:137.43ms
step:155/1390 train_time:19930ms step_avg:137.45ms
step:156/1390 train_time:20071ms step_avg:137.48ms
step:157/1390 train_time:20212ms step_avg:137.50ms
step:158/1390 train_time:20353ms step_avg:137.52ms
step:159/1390 train_time:20492ms step_avg:137.53ms
step:160/1390 train_time:20633ms step_avg:137.56ms
step:161/1390 train_time:20774ms step_avg:137.58ms
step:162/1390 train_time:20915ms step_avg:137.60ms
step:163/1390 train_time:21056ms step_avg:137.62ms
step:164/1390 train_time:21198ms step_avg:137.65ms
step:165/1390 train_time:21337ms step_avg:137.66ms
step:166/1390 train_time:21477ms step_avg:137.67ms
step:167/1390 train_time:21617ms step_avg:137.69ms
step:168/1390 train_time:21757ms step_avg:137.71ms
step:169/1390 train_time:21898ms step_avg:137.72ms
step:170/1390 train_time:22039ms step_avg:137.75ms
step:171/1390 train_time:22181ms step_avg:137.77ms
step:172/1390 train_time:22321ms step_avg:137.78ms
step:173/1390 train_time:22461ms step_avg:137.80ms
step:174/1390 train_time:22603ms step_avg:137.82ms
step:175/1390 train_time:22744ms step_avg:137.84ms
step:176/1390 train_time:22884ms step_avg:137.86ms
step:177/1390 train_time:23024ms step_avg:137.87ms
step:178/1390 train_time:23163ms step_avg:137.88ms
step:179/1390 train_time:23304ms step_avg:137.89ms
step:180/1390 train_time:23445ms step_avg:137.91ms
step:181/1390 train_time:23585ms step_avg:137.92ms
step:182/1390 train_time:23726ms step_avg:137.94ms
step:183/1390 train_time:23866ms step_avg:137.95ms
step:184/1390 train_time:24007ms step_avg:137.97ms
step:185/1390 train_time:24146ms step_avg:137.98ms
step:186/1390 train_time:24286ms step_avg:137.99ms
step:187/1390 train_time:24427ms step_avg:138.01ms
step:188/1390 train_time:24568ms step_avg:138.02ms
step:189/1390 train_time:24708ms step_avg:138.03ms
step:190/1390 train_time:24849ms step_avg:138.05ms
step:191/1390 train_time:25026ms step_avg:138.26ms
step:192/1390 train_time:25164ms step_avg:138.26ms
step:193/1390 train_time:25303ms step_avg:138.27ms
step:194/1390 train_time:25442ms step_avg:138.27ms
step:195/1390 train_time:25579ms step_avg:138.27ms
step:196/1390 train_time:25718ms step_avg:138.27ms
step:197/1390 train_time:25858ms step_avg:138.28ms
step:198/1390 train_time:26006ms step_avg:138.33ms
step:199/1390 train_time:26145ms step_avg:138.33ms
step:200/1390 train_time:26285ms step_avg:138.34ms
step:201/1390 train_time:26424ms step_avg:138.35ms
step:202/1390 train_time:26562ms step_avg:138.34ms
step:203/1390 train_time:26702ms step_avg:138.35ms
step:204/1390 train_time:26842ms step_avg:138.36ms
step:205/1390 train_time:26984ms step_avg:138.38ms
step:206/1390 train_time:27125ms step_avg:138.40ms
step:207/1390 train_time:27267ms step_avg:138.41ms
step:208/1390 train_time:27409ms step_avg:138.43ms
step:209/1390 train_time:27552ms step_avg:138.45ms
step:210/1390 train_time:27693ms step_avg:138.46ms
step:211/1390 train_time:27834ms step_avg:138.48ms
step:212/1390 train_time:27979ms step_avg:138.51ms
step:213/1390 train_time:28123ms step_avg:138.54ms
step:214/1390 train_time:28263ms step_avg:138.55ms
step:215/1390 train_time:28407ms step_avg:138.57ms
step:216/1390 train_time:28550ms step_avg:138.59ms
step:217/1390 train_time:28693ms step_avg:138.61ms
step:218/1390 train_time:28835ms step_avg:138.63ms
step:219/1390 train_time:28977ms step_avg:138.65ms
step:220/1390 train_time:29120ms step_avg:138.67ms
step:221/1390 train_time:29262ms step_avg:138.68ms
step:222/1390 train_time:29407ms step_avg:138.71ms
step:223/1390 train_time:29549ms step_avg:138.73ms
step:224/1390 train_time:29692ms step_avg:138.75ms
step:225/1390 train_time:29835ms step_avg:138.77ms
step:226/1390 train_time:29977ms step_avg:138.78ms
step:227/1390 train_time:30120ms step_avg:138.80ms
step:228/1390 train_time:30263ms step_avg:138.82ms
step:229/1390 train_time:30407ms step_avg:138.84ms
step:230/1390 train_time:30549ms step_avg:138.86ms
step:231/1390 train_time:30693ms step_avg:138.88ms
step:232/1390 train_time:30835ms step_avg:138.90ms
step:233/1390 train_time:30977ms step_avg:138.91ms
step:234/1390 train_time:31120ms step_avg:138.93ms
step:235/1390 train_time:31262ms step_avg:138.94ms
step:236/1390 train_time:31406ms step_avg:138.96ms
step:237/1390 train_time:31548ms step_avg:138.98ms
step:238/1390 train_time:31691ms step_avg:139.00ms
step:239/1390 train_time:31833ms step_avg:139.01ms
step:240/1390 train_time:31977ms step_avg:139.03ms
step:241/1390 train_time:32119ms step_avg:139.04ms
step:242/1390 train_time:32262ms step_avg:139.06ms
step:243/1390 train_time:32404ms step_avg:139.07ms
step:244/1390 train_time:32546ms step_avg:139.08ms
step:245/1390 train_time:32688ms step_avg:139.10ms
step:246/1390 train_time:32834ms step_avg:139.13ms
step:247/1390 train_time:32977ms step_avg:139.14ms
step:248/1390 train_time:33119ms step_avg:139.16ms
step:249/1390 train_time:33260ms step_avg:139.16ms
step:250/1390 train_time:33403ms step_avg:139.18ms
step:250/1390 val_loss:4.3192 train_time:33469ms step_avg:139.45ms
step:251/1390 train_time:33549ms step_avg:139.21ms
step:252/1390 train_time:33696ms step_avg:139.24ms
step:253/1390 train_time:33839ms step_avg:139.25ms
step:254/1390 train_time:33981ms step_avg:139.27ms
step:255/1390 train_time:34122ms step_avg:139.27ms
step:256/1390 train_time:34262ms step_avg:139.28ms
step:257/1390 train_time:34405ms step_avg:139.29ms
step:258/1390 train_time:34549ms step_avg:139.31ms
step:259/1390 train_time:34694ms step_avg:139.33ms
step:260/1390 train_time:34837ms step_avg:139.35ms
step:261/1390 train_time:34979ms step_avg:139.36ms
step:262/1390 train_time:35120ms step_avg:139.37ms
step:263/1390 train_time:35261ms step_avg:139.37ms
step:264/1390 train_time:35403ms step_avg:139.38ms
step:265/1390 train_time:35547ms step_avg:139.40ms
step:266/1390 train_time:35690ms step_avg:139.42ms
step:267/1390 train_time:35836ms step_avg:139.44ms
step:268/1390 train_time:35981ms step_avg:139.46ms
step:269/1390 train_time:36124ms step_avg:139.48ms
step:270/1390 train_time:36266ms step_avg:139.48ms
step:271/1390 train_time:36407ms step_avg:139.49ms
step:272/1390 train_time:36550ms step_avg:139.50ms
step:273/1390 train_time:36695ms step_avg:139.52ms
step:274/1390 train_time:36840ms step_avg:139.54ms
step:275/1390 train_time:36982ms step_avg:139.56ms
step:276/1390 train_time:37125ms step_avg:139.57ms
step:277/1390 train_time:37267ms step_avg:139.58ms
step:278/1390 train_time:37410ms step_avg:139.59ms
step:279/1390 train_time:37554ms step_avg:139.61ms
step:280/1390 train_time:37699ms step_avg:139.63ms
step:281/1390 train_time:37841ms step_avg:139.64ms
step:282/1390 train_time:37985ms step_avg:139.65ms
step:283/1390 train_time:38128ms step_avg:139.66ms
step:284/1390 train_time:38268ms step_avg:139.67ms
step:285/1390 train_time:38411ms step_avg:139.67ms
step:286/1390 train_time:38554ms step_avg:139.69ms
step:287/1390 train_time:38699ms step_avg:139.71ms
step:288/1390 train_time:38844ms step_avg:139.73ms
step:289/1390 train_time:38985ms step_avg:139.73ms
step:290/1390 train_time:39129ms step_avg:139.74ms
step:291/1390 train_time:39271ms step_avg:139.75ms
step:292/1390 train_time:39413ms step_avg:139.76ms
step:293/1390 train_time:39556ms step_avg:139.77ms
step:294/1390 train_time:39699ms step_avg:139.78ms
step:295/1390 train_time:39843ms step_avg:139.80ms
step:296/1390 train_time:39986ms step_avg:139.81ms
step:297/1390 train_time:40130ms step_avg:139.83ms
step:298/1390 train_time:40273ms step_avg:139.84ms
step:299/1390 train_time:40416ms step_avg:139.85ms
step:300/1390 train_time:40557ms step_avg:139.85ms
step:301/1390 train_time:40701ms step_avg:139.86ms
step:302/1390 train_time:40845ms step_avg:139.88ms
step:303/1390 train_time:40989ms step_avg:139.89ms
step:304/1390 train_time:41134ms step_avg:139.91ms
step:305/1390 train_time:41278ms step_avg:139.93ms
step:306/1390 train_time:41420ms step_avg:139.93ms
step:307/1390 train_time:41563ms step_avg:139.94ms
step:308/1390 train_time:41705ms step_avg:139.95ms
step:309/1390 train_time:41849ms step_avg:139.96ms
step:310/1390 train_time:41995ms step_avg:139.98ms
step:311/1390 train_time:42142ms step_avg:140.01ms
step:312/1390 train_time:42286ms step_avg:140.02ms
step:313/1390 train_time:42432ms step_avg:140.04ms
step:314/1390 train_time:42576ms step_avg:140.05ms
step:315/1390 train_time:42722ms step_avg:140.07ms
step:316/1390 train_time:42867ms step_avg:140.09ms
step:317/1390 train_time:43013ms step_avg:140.11ms
step:318/1390 train_time:43160ms step_avg:140.13ms
step:319/1390 train_time:43306ms step_avg:140.15ms
step:320/1390 train_time:43449ms step_avg:140.16ms
step:321/1390 train_time:43594ms step_avg:140.17ms
step:322/1390 train_time:43739ms step_avg:140.19ms
step:323/1390 train_time:43883ms step_avg:140.20ms
step:324/1390 train_time:44027ms step_avg:140.21ms
step:325/1390 train_time:44174ms step_avg:140.24ms
step:326/1390 train_time:44321ms step_avg:140.26ms
step:327/1390 train_time:44465ms step_avg:140.27ms
step:328/1390 train_time:44609ms step_avg:140.28ms
step:329/1390 train_time:44756ms step_avg:140.30ms
step:330/1390 train_time:44902ms step_avg:140.32ms
step:331/1390 train_time:45046ms step_avg:140.33ms
step:332/1390 train_time:45190ms step_avg:140.34ms
step:333/1390 train_time:45336ms step_avg:140.36ms
step:334/1390 train_time:45482ms step_avg:140.38ms
step:335/1390 train_time:45627ms step_avg:140.39ms
step:336/1390 train_time:45771ms step_avg:140.40ms
step:337/1390 train_time:45917ms step_avg:140.42ms
step:338/1390 train_time:46063ms step_avg:140.43ms
step:339/1390 train_time:46207ms step_avg:140.45ms
step:340/1390 train_time:46354ms step_avg:140.47ms
step:341/1390 train_time:46501ms step_avg:140.49ms
step:342/1390 train_time:46646ms step_avg:140.50ms
step:343/1390 train_time:46788ms step_avg:140.50ms
step:344/1390 train_time:46933ms step_avg:140.52ms
step:345/1390 train_time:47079ms step_avg:140.54ms
step:346/1390 train_time:47225ms step_avg:140.55ms
step:347/1390 train_time:47370ms step_avg:140.56ms
step:348/1390 train_time:47516ms step_avg:140.58ms
step:349/1390 train_time:47663ms step_avg:140.60ms
step:350/1390 train_time:47809ms step_avg:140.62ms
step:351/1390 train_time:47954ms step_avg:140.63ms
step:352/1390 train_time:48099ms step_avg:140.64ms
step:353/1390 train_time:48245ms step_avg:140.66ms
step:354/1390 train_time:48389ms step_avg:140.66ms
step:355/1390 train_time:48535ms step_avg:140.68ms
step:356/1390 train_time:48681ms step_avg:140.70ms
step:357/1390 train_time:48826ms step_avg:140.71ms
step:358/1390 train_time:48971ms step_avg:140.72ms
step:359/1390 train_time:49118ms step_avg:140.74ms
step:360/1390 train_time:49264ms step_avg:140.75ms
step:361/1390 train_time:49407ms step_avg:140.76ms
step:362/1390 train_time:49553ms step_avg:140.78ms
step:363/1390 train_time:49700ms step_avg:140.79ms
step:364/1390 train_time:49846ms step_avg:140.81ms
step:365/1390 train_time:49989ms step_avg:140.81ms
step:366/1390 train_time:50136ms step_avg:140.83ms
step:367/1390 train_time:50282ms step_avg:140.85ms
step:368/1390 train_time:50426ms step_avg:140.86ms
step:369/1390 train_time:50569ms step_avg:140.86ms
step:370/1390 train_time:50714ms step_avg:140.87ms
step:371/1390 train_time:50861ms step_avg:140.89ms
step:372/1390 train_time:51005ms step_avg:140.90ms
step:373/1390 train_time:51149ms step_avg:140.91ms
step:374/1390 train_time:51294ms step_avg:140.92ms
step:375/1390 train_time:51441ms step_avg:140.93ms
step:375/1390 val_loss:4.0914 train_time:51506ms step_avg:141.11ms
step:376/1390 train_time:51586ms step_avg:140.95ms
step:377/1390 train_time:51732ms step_avg:140.96ms
step:378/1390 train_time:51881ms step_avg:140.98ms
step:379/1390 train_time:52025ms step_avg:140.99ms
step:380/1390 train_time:52168ms step_avg:140.99ms
step:381/1390 train_time:52361ms step_avg:141.14ms
step:382/1390 train_time:52503ms step_avg:141.14ms
step:383/1390 train_time:52646ms step_avg:141.14ms
step:384/1390 train_time:52789ms step_avg:141.15ms
step:385/1390 train_time:52933ms step_avg:141.16ms
step:386/1390 train_time:53078ms step_avg:141.16ms
step:387/1390 train_time:53227ms step_avg:141.19ms
step:388/1390 train_time:53374ms step_avg:141.20ms
step:389/1390 train_time:53521ms step_avg:141.22ms
step:390/1390 train_time:53665ms step_avg:141.22ms
step:391/1390 train_time:53811ms step_avg:141.23ms
step:392/1390 train_time:53956ms step_avg:141.25ms
step:393/1390 train_time:54101ms step_avg:141.26ms
step:394/1390 train_time:54248ms step_avg:141.27ms
step:395/1390 train_time:54395ms step_avg:141.29ms
step:396/1390 train_time:54542ms step_avg:141.30ms
step:397/1390 train_time:54686ms step_avg:141.31ms
step:398/1390 train_time:54831ms step_avg:141.32ms
step:399/1390 train_time:54975ms step_avg:141.32ms
step:400/1390 train_time:55120ms step_avg:141.33ms
step:401/1390 train_time:55266ms step_avg:141.35ms
step:402/1390 train_time:55410ms step_avg:141.35ms
step:403/1390 train_time:55556ms step_avg:141.36ms
step:404/1390 train_time:55702ms step_avg:141.38ms
step:405/1390 train_time:55848ms step_avg:141.39ms
step:406/1390 train_time:55991ms step_avg:141.39ms
step:407/1390 train_time:56138ms step_avg:141.40ms
step:408/1390 train_time:56283ms step_avg:141.42ms
step:409/1390 train_time:56430ms step_avg:141.43ms
step:410/1390 train_time:56575ms step_avg:141.44ms
step:411/1390 train_time:56721ms step_avg:141.45ms
step:412/1390 train_time:56865ms step_avg:141.45ms
step:413/1390 train_time:57010ms step_avg:141.46ms
step:414/1390 train_time:57158ms step_avg:141.48ms
step:415/1390 train_time:57306ms step_avg:141.50ms
step:416/1390 train_time:57453ms step_avg:141.51ms
step:417/1390 train_time:57603ms step_avg:141.53ms
step:418/1390 train_time:57749ms step_avg:141.54ms
step:419/1390 train_time:57895ms step_avg:141.55ms
step:420/1390 train_time:58044ms step_avg:141.57ms
step:421/1390 train_time:58188ms step_avg:141.58ms
step:422/1390 train_time:58337ms step_avg:141.59ms
step:423/1390 train_time:58484ms step_avg:141.61ms
step:424/1390 train_time:58631ms step_avg:141.62ms
step:425/1390 train_time:58781ms step_avg:141.64ms
step:426/1390 train_time:58928ms step_avg:141.65ms
step:427/1390 train_time:59072ms step_avg:141.66ms
step:428/1390 train_time:59220ms step_avg:141.68ms
step:429/1390 train_time:59367ms step_avg:141.69ms
step:430/1390 train_time:59515ms step_avg:141.70ms
step:431/1390 train_time:59664ms step_avg:141.72ms
step:432/1390 train_time:59810ms step_avg:141.73ms
step:433/1390 train_time:59958ms step_avg:141.74ms
step:434/1390 train_time:60105ms step_avg:141.76ms
step:435/1390 train_time:60250ms step_avg:141.77ms
step:436/1390 train_time:60399ms step_avg:141.78ms
step:437/1390 train_time:60545ms step_avg:141.79ms
step:438/1390 train_time:60690ms step_avg:141.80ms
step:439/1390 train_time:60840ms step_avg:141.82ms
step:440/1390 train_time:60986ms step_avg:141.83ms
step:441/1390 train_time:61131ms step_avg:141.84ms
step:442/1390 train_time:61279ms step_avg:141.85ms
step:443/1390 train_time:61426ms step_avg:141.86ms
step:444/1390 train_time:61572ms step_avg:141.87ms
step:445/1390 train_time:61722ms step_avg:141.89ms
step:446/1390 train_time:61869ms step_avg:141.90ms
step:447/1390 train_time:62016ms step_avg:141.91ms
step:448/1390 train_time:62164ms step_avg:141.93ms
step:449/1390 train_time:62309ms step_avg:141.93ms
step:450/1390 train_time:62457ms step_avg:141.95ms
step:451/1390 train_time:62606ms step_avg:141.96ms
step:452/1390 train_time:62753ms step_avg:141.98ms
step:453/1390 train_time:62903ms step_avg:141.99ms
step:454/1390 train_time:63049ms step_avg:142.00ms
step:455/1390 train_time:63199ms step_avg:142.02ms
step:456/1390 train_time:63345ms step_avg:142.03ms
step:457/1390 train_time:63491ms step_avg:142.04ms
step:458/1390 train_time:63640ms step_avg:142.05ms
step:459/1390 train_time:63787ms step_avg:142.06ms
step:460/1390 train_time:63934ms step_avg:142.08ms
step:461/1390 train_time:64083ms step_avg:142.09ms
step:462/1390 train_time:64230ms step_avg:142.10ms
step:463/1390 train_time:64377ms step_avg:142.11ms
step:464/1390 train_time:64524ms step_avg:142.12ms
step:465/1390 train_time:64670ms step_avg:142.13ms
step:466/1390 train_time:64819ms step_avg:142.15ms
step:467/1390 train_time:64967ms step_avg:142.16ms
step:468/1390 train_time:65114ms step_avg:142.17ms
step:469/1390 train_time:65263ms step_avg:142.18ms
step:470/1390 train_time:65409ms step_avg:142.19ms
step:471/1390 train_time:65556ms step_avg:142.20ms
step:472/1390 train_time:65704ms step_avg:142.22ms
step:473/1390 train_time:65852ms step_avg:142.23ms
step:474/1390 train_time:66001ms step_avg:142.24ms
step:475/1390 train_time:66147ms step_avg:142.25ms
step:476/1390 train_time:66294ms step_avg:142.26ms
step:477/1390 train_time:66444ms step_avg:142.28ms
step:478/1390 train_time:66589ms step_avg:142.28ms
step:479/1390 train_time:66735ms step_avg:142.29ms
step:480/1390 train_time:66884ms step_avg:142.31ms
step:481/1390 train_time:67030ms step_avg:142.31ms
step:482/1390 train_time:67178ms step_avg:142.33ms
step:483/1390 train_time:67326ms step_avg:142.34ms
step:484/1390 train_time:67470ms step_avg:142.34ms
step:485/1390 train_time:67618ms step_avg:142.35ms
step:486/1390 train_time:67766ms step_avg:142.36ms
step:487/1390 train_time:67913ms step_avg:142.37ms
step:488/1390 train_time:68061ms step_avg:142.39ms
step:489/1390 train_time:68208ms step_avg:142.40ms
step:490/1390 train_time:68354ms step_avg:142.40ms
step:491/1390 train_time:68502ms step_avg:142.42ms
step:492/1390 train_time:68648ms step_avg:142.42ms
step:493/1390 train_time:68795ms step_avg:142.43ms
step:494/1390 train_time:68943ms step_avg:142.45ms
step:495/1390 train_time:69090ms step_avg:142.45ms
step:496/1390 train_time:69238ms step_avg:142.47ms
step:497/1390 train_time:69384ms step_avg:142.47ms
step:498/1390 train_time:69531ms step_avg:142.48ms
step:499/1390 train_time:69680ms step_avg:142.50ms
step:500/1390 train_time:69827ms step_avg:142.50ms
step:500/1390 val_loss:3.9677 train_time:69894ms step_avg:142.64ms
step:501/1390 train_time:69975ms step_avg:142.51ms
step:502/1390 train_time:70123ms step_avg:142.53ms
step:503/1390 train_time:70271ms step_avg:142.54ms
step:504/1390 train_time:70417ms step_avg:142.54ms
step:505/1390 train_time:70563ms step_avg:142.55ms
step:506/1390 train_time:70710ms step_avg:142.56ms
step:507/1390 train_time:70857ms step_avg:142.57ms
step:508/1390 train_time:71007ms step_avg:142.58ms
step:509/1390 train_time:71155ms step_avg:142.60ms
step:510/1390 train_time:71300ms step_avg:142.60ms
step:511/1390 train_time:71448ms step_avg:142.61ms
step:512/1390 train_time:71594ms step_avg:142.62ms
step:513/1390 train_time:71741ms step_avg:142.63ms
step:514/1390 train_time:71891ms step_avg:142.64ms
step:515/1390 train_time:72038ms step_avg:142.65ms
step:516/1390 train_time:72190ms step_avg:142.67ms
step:517/1390 train_time:72339ms step_avg:142.68ms
step:518/1390 train_time:72489ms step_avg:142.69ms
step:519/1390 train_time:72636ms step_avg:142.70ms
step:520/1390 train_time:72785ms step_avg:142.72ms
step:521/1390 train_time:72935ms step_avg:142.73ms
step:522/1390 train_time:73084ms step_avg:142.74ms
step:523/1390 train_time:73235ms step_avg:142.76ms
step:524/1390 train_time:73384ms step_avg:142.77ms
step:525/1390 train_time:73533ms step_avg:142.78ms
step:526/1390 train_time:73682ms step_avg:142.79ms
step:527/1390 train_time:73832ms step_avg:142.81ms
step:528/1390 train_time:73978ms step_avg:142.82ms
step:529/1390 train_time:74131ms step_avg:142.83ms
step:530/1390 train_time:74278ms step_avg:142.84ms
step:531/1390 train_time:74428ms step_avg:142.86ms
step:532/1390 train_time:74576ms step_avg:142.87ms
step:533/1390 train_time:74727ms step_avg:142.88ms
step:534/1390 train_time:74875ms step_avg:142.89ms
step:535/1390 train_time:75022ms step_avg:142.90ms
step:536/1390 train_time:75174ms step_avg:142.92ms
step:537/1390 train_time:75323ms step_avg:142.93ms
step:538/1390 train_time:75473ms step_avg:142.94ms
step:539/1390 train_time:75622ms step_avg:142.95ms
step:540/1390 train_time:75771ms step_avg:142.96ms
step:541/1390 train_time:75918ms step_avg:142.97ms
step:542/1390 train_time:76068ms step_avg:142.98ms
step:543/1390 train_time:76216ms step_avg:142.99ms
step:544/1390 train_time:76365ms step_avg:143.00ms
step:545/1390 train_time:76514ms step_avg:143.02ms
step:546/1390 train_time:76663ms step_avg:143.03ms
step:547/1390 train_time:76813ms step_avg:143.04ms
step:548/1390 train_time:76960ms step_avg:143.05ms
step:549/1390 train_time:77112ms step_avg:143.06ms
step:550/1390 train_time:77260ms step_avg:143.07ms
step:551/1390 train_time:77410ms step_avg:143.09ms
step:552/1390 train_time:77558ms step_avg:143.10ms
step:553/1390 train_time:77708ms step_avg:143.11ms
step:554/1390 train_time:77856ms step_avg:143.12ms
step:555/1390 train_time:78003ms step_avg:143.13ms
step:556/1390 train_time:78153ms step_avg:143.14ms
step:557/1390 train_time:78300ms step_avg:143.14ms
step:558/1390 train_time:78450ms step_avg:143.16ms
step:559/1390 train_time:78598ms step_avg:143.17ms
step:560/1390 train_time:78747ms step_avg:143.18ms
step:561/1390 train_time:78895ms step_avg:143.18ms
step:562/1390 train_time:79044ms step_avg:143.20ms
step:563/1390 train_time:79194ms step_avg:143.21ms
step:564/1390 train_time:79343ms step_avg:143.22ms
step:565/1390 train_time:79493ms step_avg:143.23ms
step:566/1390 train_time:79641ms step_avg:143.24ms
step:567/1390 train_time:79792ms step_avg:143.25ms
step:568/1390 train_time:79939ms step_avg:143.26ms
step:569/1390 train_time:80090ms step_avg:143.27ms
step:570/1390 train_time:80237ms step_avg:143.28ms
step:571/1390 train_time:80434ms step_avg:143.38ms
step:572/1390 train_time:80581ms step_avg:143.38ms
step:573/1390 train_time:80730ms step_avg:143.39ms
step:574/1390 train_time:80879ms step_avg:143.40ms
step:575/1390 train_time:81027ms step_avg:143.41ms
step:576/1390 train_time:81174ms step_avg:143.42ms
step:577/1390 train_time:81324ms step_avg:143.43ms
step:578/1390 train_time:81475ms step_avg:143.44ms
step:579/1390 train_time:81626ms step_avg:143.45ms
step:580/1390 train_time:81773ms step_avg:143.46ms
step:581/1390 train_time:81922ms step_avg:143.47ms
step:582/1390 train_time:82071ms step_avg:143.48ms
step:583/1390 train_time:82218ms step_avg:143.49ms
step:584/1390 train_time:82370ms step_avg:143.50ms
step:585/1390 train_time:82518ms step_avg:143.51ms
step:586/1390 train_time:82670ms step_avg:143.53ms
step:587/1390 train_time:82818ms step_avg:143.53ms
step:588/1390 train_time:82968ms step_avg:143.54ms
step:589/1390 train_time:83116ms step_avg:143.55ms
step:590/1390 train_time:83264ms step_avg:143.56ms
step:591/1390 train_time:83413ms step_avg:143.57ms
step:592/1390 train_time:83564ms step_avg:143.58ms
step:593/1390 train_time:83714ms step_avg:143.59ms
step:594/1390 train_time:83860ms step_avg:143.60ms
step:595/1390 train_time:84010ms step_avg:143.61ms
step:596/1390 train_time:84158ms step_avg:143.61ms
step:597/1390 train_time:84307ms step_avg:143.62ms
step:598/1390 train_time:84456ms step_avg:143.63ms
step:599/1390 train_time:84606ms step_avg:143.64ms
step:600/1390 train_time:84756ms step_avg:143.65ms
step:601/1390 train_time:84904ms step_avg:143.66ms
step:602/1390 train_time:85053ms step_avg:143.67ms
step:603/1390 train_time:85200ms step_avg:143.68ms
step:604/1390 train_time:85349ms step_avg:143.69ms
step:605/1390 train_time:85497ms step_avg:143.69ms
step:606/1390 train_time:85647ms step_avg:143.70ms
step:607/1390 train_time:85797ms step_avg:143.71ms
step:608/1390 train_time:85946ms step_avg:143.72ms
step:609/1390 train_time:86095ms step_avg:143.73ms
step:610/1390 train_time:86242ms step_avg:143.74ms
step:611/1390 train_time:86391ms step_avg:143.75ms
step:612/1390 train_time:86539ms step_avg:143.75ms
step:613/1390 train_time:86691ms step_avg:143.77ms
step:614/1390 train_time:86838ms step_avg:143.77ms
step:615/1390 train_time:86987ms step_avg:143.78ms
step:616/1390 train_time:87136ms step_avg:143.79ms
step:617/1390 train_time:87285ms step_avg:143.80ms
step:618/1390 train_time:87434ms step_avg:143.81ms
step:619/1390 train_time:87584ms step_avg:143.82ms
step:620/1390 train_time:87736ms step_avg:143.83ms
step:621/1390 train_time:87887ms step_avg:143.84ms
step:622/1390 train_time:88037ms step_avg:143.85ms
step:623/1390 train_time:88187ms step_avg:143.86ms
step:624/1390 train_time:88337ms step_avg:143.87ms
step:625/1390 train_time:88488ms step_avg:143.88ms
step:625/1390 val_loss:3.8803 train_time:88559ms step_avg:144.00ms
step:626/1390 train_time:88641ms step_avg:143.90ms
step:627/1390 train_time:88791ms step_avg:143.91ms
step:628/1390 train_time:88940ms step_avg:143.92ms
step:629/1390 train_time:89089ms step_avg:143.92ms
step:630/1390 train_time:89238ms step_avg:143.93ms
step:631/1390 train_time:89387ms step_avg:143.94ms
step:632/1390 train_time:89540ms step_avg:143.95ms
step:633/1390 train_time:89690ms step_avg:143.97ms
step:634/1390 train_time:89841ms step_avg:143.98ms
step:635/1390 train_time:89991ms step_avg:143.98ms
step:636/1390 train_time:90140ms step_avg:143.99ms
step:637/1390 train_time:90289ms step_avg:144.00ms
step:638/1390 train_time:90440ms step_avg:144.01ms
step:639/1390 train_time:90593ms step_avg:144.03ms
step:640/1390 train_time:90743ms step_avg:144.04ms
step:641/1390 train_time:90896ms step_avg:144.05ms
step:642/1390 train_time:91047ms step_avg:144.06ms
step:643/1390 train_time:91200ms step_avg:144.08ms
step:644/1390 train_time:91348ms step_avg:144.08ms
step:645/1390 train_time:91501ms step_avg:144.10ms
step:646/1390 train_time:91652ms step_avg:144.11ms
step:647/1390 train_time:91802ms step_avg:144.12ms
step:648/1390 train_time:91955ms step_avg:144.13ms
step:649/1390 train_time:92105ms step_avg:144.14ms
step:650/1390 train_time:92258ms step_avg:144.15ms
step:651/1390 train_time:92407ms step_avg:144.16ms
step:652/1390 train_time:92558ms step_avg:144.17ms
step:653/1390 train_time:92706ms step_avg:144.18ms
step:654/1390 train_time:92859ms step_avg:144.19ms
step:655/1390 train_time:93009ms step_avg:144.20ms
step:656/1390 train_time:93160ms step_avg:144.21ms
step:657/1390 train_time:93310ms step_avg:144.22ms
step:658/1390 train_time:93463ms step_avg:144.23ms
step:659/1390 train_time:93613ms step_avg:144.24ms
step:660/1390 train_time:93762ms step_avg:144.25ms
step:661/1390 train_time:93914ms step_avg:144.26ms
step:662/1390 train_time:94065ms step_avg:144.27ms
step:663/1390 train_time:94216ms step_avg:144.28ms
step:664/1390 train_time:94366ms step_avg:144.29ms
step:665/1390 train_time:94519ms step_avg:144.30ms
step:666/1390 train_time:94666ms step_avg:144.31ms
step:667/1390 train_time:94818ms step_avg:144.32ms
step:668/1390 train_time:94969ms step_avg:144.33ms
step:669/1390 train_time:95122ms step_avg:144.34ms
step:670/1390 train_time:95270ms step_avg:144.35ms
step:671/1390 train_time:95421ms step_avg:144.36ms
step:672/1390 train_time:95571ms step_avg:144.37ms
step:673/1390 train_time:95721ms step_avg:144.38ms
step:674/1390 train_time:95871ms step_avg:144.38ms
step:675/1390 train_time:96021ms step_avg:144.39ms
step:676/1390 train_time:96171ms step_avg:144.40ms
step:677/1390 train_time:96323ms step_avg:144.41ms
step:678/1390 train_time:96476ms step_avg:144.42ms
step:679/1390 train_time:96627ms step_avg:144.44ms
step:680/1390 train_time:96779ms step_avg:144.45ms
step:681/1390 train_time:96927ms step_avg:144.45ms
step:682/1390 train_time:97078ms step_avg:144.46ms
step:683/1390 train_time:97226ms step_avg:144.47ms
step:684/1390 train_time:97378ms step_avg:144.48ms
step:685/1390 train_time:97528ms step_avg:144.49ms
step:686/1390 train_time:97680ms step_avg:144.50ms
step:687/1390 train_time:97829ms step_avg:144.50ms
step:688/1390 train_time:97981ms step_avg:144.51ms
step:689/1390 train_time:98131ms step_avg:144.52ms
step:690/1390 train_time:98283ms step_avg:144.53ms
step:691/1390 train_time:98435ms step_avg:144.54ms
step:692/1390 train_time:98586ms step_avg:144.55ms
step:693/1390 train_time:98737ms step_avg:144.56ms
step:694/1390 train_time:98886ms step_avg:144.57ms
step:695/1390 train_time:99037ms step_avg:144.58ms
step:696/1390 train_time:99186ms step_avg:144.59ms
step:697/1390 train_time:99337ms step_avg:144.60ms
step:698/1390 train_time:99486ms step_avg:144.60ms
step:699/1390 train_time:99637ms step_avg:144.61ms
step:700/1390 train_time:99786ms step_avg:144.62ms
step:701/1390 train_time:99937ms step_avg:144.63ms
step:702/1390 train_time:100088ms step_avg:144.64ms
step:703/1390 train_time:100239ms step_avg:144.65ms
step:704/1390 train_time:100389ms step_avg:144.65ms
step:705/1390 train_time:100542ms step_avg:144.66ms
step:706/1390 train_time:100698ms step_avg:144.68ms
step:707/1390 train_time:100848ms step_avg:144.69ms
step:708/1390 train_time:100999ms step_avg:144.70ms
step:709/1390 train_time:101149ms step_avg:144.71ms
step:710/1390 train_time:101301ms step_avg:144.72ms
step:711/1390 train_time:101453ms step_avg:144.73ms
step:712/1390 train_time:101605ms step_avg:144.74ms
step:713/1390 train_time:101759ms step_avg:144.75ms
step:714/1390 train_time:101907ms step_avg:144.75ms
step:715/1390 train_time:102057ms step_avg:144.76ms
step:716/1390 train_time:102207ms step_avg:144.77ms
step:717/1390 train_time:102360ms step_avg:144.78ms
step:718/1390 train_time:102508ms step_avg:144.78ms
step:719/1390 train_time:102660ms step_avg:144.80ms
step:720/1390 train_time:102810ms step_avg:144.80ms
step:721/1390 train_time:102961ms step_avg:144.81ms
step:722/1390 train_time:103113ms step_avg:144.82ms
step:723/1390 train_time:103263ms step_avg:144.83ms
step:724/1390 train_time:103416ms step_avg:144.84ms
step:725/1390 train_time:103566ms step_avg:144.85ms
step:726/1390 train_time:103719ms step_avg:144.86ms
step:727/1390 train_time:103876ms step_avg:144.88ms
step:728/1390 train_time:104026ms step_avg:144.88ms
step:729/1390 train_time:104178ms step_avg:144.89ms
step:730/1390 train_time:104332ms step_avg:144.91ms
step:731/1390 train_time:104482ms step_avg:144.91ms
step:732/1390 train_time:104634ms step_avg:144.92ms
step:733/1390 train_time:104787ms step_avg:144.93ms
step:734/1390 train_time:104938ms step_avg:144.94ms
step:735/1390 train_time:105092ms step_avg:144.95ms
step:736/1390 train_time:105243ms step_avg:144.96ms
step:737/1390 train_time:105396ms step_avg:144.97ms
step:738/1390 train_time:105547ms step_avg:144.98ms
step:739/1390 train_time:105702ms step_avg:145.00ms
step:740/1390 train_time:105854ms step_avg:145.01ms
step:741/1390 train_time:106006ms step_avg:145.02ms
step:742/1390 train_time:106159ms step_avg:145.03ms
step:743/1390 train_time:106310ms step_avg:145.03ms
step:744/1390 train_time:106463ms step_avg:145.04ms
step:745/1390 train_time:106619ms step_avg:145.06ms
step:746/1390 train_time:106770ms step_avg:145.07ms
step:747/1390 train_time:106922ms step_avg:145.08ms
step:748/1390 train_time:107075ms step_avg:145.09ms
step:749/1390 train_time:107226ms step_avg:145.10ms
step:750/1390 train_time:107378ms step_avg:145.11ms
step:750/1390 val_loss:3.8260 train_time:107449ms step_avg:145.20ms
step:751/1390 train_time:107532ms step_avg:145.12ms
step:752/1390 train_time:107685ms step_avg:145.13ms
step:753/1390 train_time:107836ms step_avg:145.14ms
step:754/1390 train_time:107986ms step_avg:145.14ms
step:755/1390 train_time:108136ms step_avg:145.15ms
step:756/1390 train_time:108285ms step_avg:145.15ms
step:757/1390 train_time:108441ms step_avg:145.17ms
step:758/1390 train_time:108594ms step_avg:145.18ms
step:759/1390 train_time:108746ms step_avg:145.19ms
step:760/1390 train_time:108897ms step_avg:145.20ms
step:761/1390 train_time:109099ms step_avg:145.27ms
step:762/1390 train_time:109248ms step_avg:145.28ms
step:763/1390 train_time:109400ms step_avg:145.29ms
step:764/1390 train_time:109551ms step_avg:145.29ms
step:765/1390 train_time:109701ms step_avg:145.30ms
step:766/1390 train_time:109855ms step_avg:145.31ms
step:767/1390 train_time:110010ms step_avg:145.32ms
step:768/1390 train_time:110162ms step_avg:145.33ms
step:769/1390 train_time:110315ms step_avg:145.34ms
step:770/1390 train_time:110467ms step_avg:145.35ms
step:771/1390 train_time:110618ms step_avg:145.36ms
step:772/1390 train_time:110768ms step_avg:145.36ms
step:773/1390 train_time:110922ms step_avg:145.38ms
step:774/1390 train_time:111076ms step_avg:145.39ms
step:775/1390 train_time:111228ms step_avg:145.40ms
step:776/1390 train_time:111380ms step_avg:145.40ms
step:777/1390 train_time:111532ms step_avg:145.41ms
step:778/1390 train_time:111682ms step_avg:145.42ms
step:779/1390 train_time:111833ms step_avg:145.43ms
step:780/1390 train_time:111984ms step_avg:145.43ms
step:781/1390 train_time:112137ms step_avg:145.44ms
step:782/1390 train_time:112287ms step_avg:145.45ms
step:783/1390 train_time:112440ms step_avg:145.46ms
step:784/1390 train_time:112591ms step_avg:145.47ms
step:785/1390 train_time:112743ms step_avg:145.47ms
step:786/1390 train_time:112894ms step_avg:145.48ms
step:787/1390 train_time:113046ms step_avg:145.49ms
step:788/1390 train_time:113197ms step_avg:145.50ms
step:789/1390 train_time:113349ms step_avg:145.51ms
step:790/1390 train_time:113501ms step_avg:145.51ms
step:791/1390 train_time:113654ms step_avg:145.52ms
step:792/1390 train_time:113807ms step_avg:145.53ms
step:793/1390 train_time:113960ms step_avg:145.54ms
step:794/1390 train_time:114112ms step_avg:145.55ms
step:795/1390 train_time:114264ms step_avg:145.56ms
step:796/1390 train_time:114419ms step_avg:145.57ms
step:797/1390 train_time:114570ms step_avg:145.58ms
step:798/1390 train_time:114725ms step_avg:145.59ms
step:799/1390 train_time:114883ms step_avg:145.61ms
step:800/1390 train_time:115037ms step_avg:145.62ms
step:801/1390 train_time:115188ms step_avg:145.62ms
step:802/1390 train_time:115341ms step_avg:145.63ms
step:803/1390 train_time:115491ms step_avg:145.64ms
step:804/1390 train_time:115642ms step_avg:145.64ms
step:805/1390 train_time:115797ms step_avg:145.66ms
step:806/1390 train_time:115950ms step_avg:145.67ms
step:807/1390 train_time:116101ms step_avg:145.67ms
step:808/1390 train_time:116253ms step_avg:145.68ms
step:809/1390 train_time:116403ms step_avg:145.69ms
step:810/1390 train_time:116556ms step_avg:145.70ms
step:811/1390 train_time:116708ms step_avg:145.70ms
step:812/1390 train_time:116860ms step_avg:145.71ms
step:813/1390 train_time:117009ms step_avg:145.71ms
step:814/1390 train_time:117160ms step_avg:145.72ms
step:815/1390 train_time:117312ms step_avg:145.73ms
step:816/1390 train_time:117468ms step_avg:145.74ms
step:817/1390 train_time:117621ms step_avg:145.75ms
step:818/1390 train_time:117773ms step_avg:145.76ms
step:819/1390 train_time:117924ms step_avg:145.76ms
step:820/1390 train_time:118079ms step_avg:145.78ms
step:821/1390 train_time:118229ms step_avg:145.78ms
step:822/1390 train_time:118380ms step_avg:145.79ms
step:823/1390 train_time:118532ms step_avg:145.80ms
step:824/1390 train_time:118684ms step_avg:145.80ms
step:825/1390 train_time:118840ms step_avg:145.82ms
step:826/1390 train_time:118994ms step_avg:145.83ms
step:827/1390 train_time:119146ms step_avg:145.83ms
step:828/1390 train_time:119299ms step_avg:145.84ms
step:829/1390 train_time:119453ms step_avg:145.85ms
step:830/1390 train_time:119606ms step_avg:145.86ms
step:831/1390 train_time:119759ms step_avg:145.87ms
step:832/1390 train_time:119913ms step_avg:145.88ms
step:833/1390 train_time:120063ms step_avg:145.88ms
step:834/1390 train_time:120217ms step_avg:145.89ms
step:835/1390 train_time:120371ms step_avg:145.90ms
step:836/1390 train_time:120524ms step_avg:145.91ms
step:837/1390 train_time:120678ms step_avg:145.92ms
step:838/1390 train_time:120830ms step_avg:145.93ms
step:839/1390 train_time:120981ms step_avg:145.94ms
step:840/1390 train_time:121134ms step_avg:145.94ms
step:841/1390 train_time:121287ms step_avg:145.95ms
step:842/1390 train_time:121441ms step_avg:145.96ms
step:843/1390 train_time:121594ms step_avg:145.97ms
step:844/1390 train_time:121748ms step_avg:145.98ms
step:845/1390 train_time:121901ms step_avg:145.99ms
step:846/1390 train_time:122056ms step_avg:146.00ms
step:847/1390 train_time:122210ms step_avg:146.01ms
step:848/1390 train_time:122362ms step_avg:146.02ms
step:849/1390 train_time:122517ms step_avg:146.03ms
step:850/1390 train_time:122670ms step_avg:146.04ms
step:851/1390 train_time:122824ms step_avg:146.05ms
step:852/1390 train_time:122979ms step_avg:146.06ms
step:853/1390 train_time:123129ms step_avg:146.06ms
step:854/1390 train_time:123283ms step_avg:146.07ms
step:855/1390 train_time:123437ms step_avg:146.08ms
step:856/1390 train_time:123588ms step_avg:146.09ms
step:857/1390 train_time:123743ms step_avg:146.10ms
step:858/1390 train_time:123902ms step_avg:146.11ms
step:859/1390 train_time:124055ms step_avg:146.12ms
step:860/1390 train_time:124209ms step_avg:146.13ms
step:861/1390 train_time:124363ms step_avg:146.14ms
step:862/1390 train_time:124516ms step_avg:146.15ms
step:863/1390 train_time:124668ms step_avg:146.15ms
step:864/1390 train_time:124822ms step_avg:146.16ms
step:865/1390 train_time:124975ms step_avg:146.17ms
step:866/1390 train_time:125134ms step_avg:146.18ms
step:867/1390 train_time:125285ms step_avg:146.19ms
step:868/1390 train_time:125439ms step_avg:146.20ms
step:869/1390 train_time:125589ms step_avg:146.20ms
step:870/1390 train_time:125744ms step_avg:146.21ms
step:871/1390 train_time:125897ms step_avg:146.22ms
step:872/1390 train_time:126049ms step_avg:146.23ms
step:873/1390 train_time:126202ms step_avg:146.24ms
step:874/1390 train_time:126357ms step_avg:146.25ms
step:875/1390 train_time:126508ms step_avg:146.25ms
step:875/1390 val_loss:3.7697 train_time:126579ms step_avg:146.33ms
step:876/1390 train_time:126662ms step_avg:146.26ms
step:877/1390 train_time:126816ms step_avg:146.27ms
step:878/1390 train_time:126968ms step_avg:146.28ms
step:879/1390 train_time:127121ms step_avg:146.28ms
step:880/1390 train_time:127273ms step_avg:146.29ms
step:881/1390 train_time:127426ms step_avg:146.30ms
step:882/1390 train_time:127582ms step_avg:146.31ms
step:883/1390 train_time:127734ms step_avg:146.32ms
step:884/1390 train_time:127888ms step_avg:146.32ms
step:885/1390 train_time:128039ms step_avg:146.33ms
step:886/1390 train_time:128191ms step_avg:146.34ms
step:887/1390 train_time:128344ms step_avg:146.34ms
step:888/1390 train_time:128499ms step_avg:146.35ms
step:889/1390 train_time:128654ms step_avg:146.36ms
step:890/1390 train_time:128808ms step_avg:146.37ms
step:891/1390 train_time:128962ms step_avg:146.38ms
step:892/1390 train_time:129114ms step_avg:146.39ms
step:893/1390 train_time:129269ms step_avg:146.40ms
step:894/1390 train_time:129423ms step_avg:146.41ms
step:895/1390 train_time:129581ms step_avg:146.42ms
step:896/1390 train_time:129733ms step_avg:146.43ms
step:897/1390 train_time:129888ms step_avg:146.44ms
step:898/1390 train_time:130041ms step_avg:146.44ms
step:899/1390 train_time:130193ms step_avg:146.45ms
step:900/1390 train_time:130344ms step_avg:146.45ms
step:901/1390 train_time:130501ms step_avg:146.47ms
step:902/1390 train_time:130651ms step_avg:146.47ms
step:903/1390 train_time:130806ms step_avg:146.48ms
step:904/1390 train_time:130960ms step_avg:146.49ms
step:905/1390 train_time:131112ms step_avg:146.49ms
step:906/1390 train_time:131265ms step_avg:146.50ms
step:907/1390 train_time:131419ms step_avg:146.51ms
step:908/1390 train_time:131573ms step_avg:146.52ms
step:909/1390 train_time:131730ms step_avg:146.53ms
step:910/1390 train_time:131891ms step_avg:146.55ms
step:911/1390 train_time:132044ms step_avg:146.55ms
step:912/1390 train_time:132197ms step_avg:146.56ms
step:913/1390 train_time:132352ms step_avg:146.57ms
step:914/1390 train_time:132505ms step_avg:146.58ms
step:915/1390 train_time:132659ms step_avg:146.58ms
step:916/1390 train_time:132811ms step_avg:146.59ms
step:917/1390 train_time:132966ms step_avg:146.60ms
step:918/1390 train_time:133119ms step_avg:146.61ms
step:919/1390 train_time:133276ms step_avg:146.62ms
step:920/1390 train_time:133430ms step_avg:146.63ms
step:921/1390 train_time:133583ms step_avg:146.63ms
step:922/1390 train_time:133737ms step_avg:146.64ms
step:923/1390 train_time:133891ms step_avg:146.65ms
step:924/1390 train_time:134046ms step_avg:146.66ms
step:925/1390 train_time:134200ms step_avg:146.67ms
step:926/1390 train_time:134351ms step_avg:146.67ms
step:927/1390 train_time:134505ms step_avg:146.68ms
step:928/1390 train_time:134659ms step_avg:146.69ms
step:929/1390 train_time:134815ms step_avg:146.70ms
step:930/1390 train_time:134975ms step_avg:146.71ms
step:931/1390 train_time:135130ms step_avg:146.72ms
step:932/1390 train_time:135285ms step_avg:146.73ms
step:933/1390 train_time:135438ms step_avg:146.74ms
step:934/1390 train_time:135591ms step_avg:146.74ms
step:935/1390 train_time:135746ms step_avg:146.75ms
step:936/1390 train_time:135902ms step_avg:146.76ms
step:937/1390 train_time:136062ms step_avg:146.78ms
step:938/1390 train_time:136215ms step_avg:146.78ms
step:939/1390 train_time:136371ms step_avg:146.79ms
step:940/1390 train_time:136526ms step_avg:146.80ms
step:941/1390 train_time:136678ms step_avg:146.81ms
step:942/1390 train_time:136830ms step_avg:146.81ms
step:943/1390 train_time:136987ms step_avg:146.82ms
step:944/1390 train_time:137145ms step_avg:146.84ms
step:945/1390 train_time:137301ms step_avg:146.85ms
step:946/1390 train_time:137456ms step_avg:146.85ms
step:947/1390 train_time:137612ms step_avg:146.86ms
step:948/1390 train_time:137767ms step_avg:146.87ms
step:949/1390 train_time:137923ms step_avg:146.88ms
step:950/1390 train_time:138077ms step_avg:146.89ms
step:951/1390 train_time:138288ms step_avg:146.96ms
step:952/1390 train_time:138442ms step_avg:146.97ms
step:953/1390 train_time:138597ms step_avg:146.97ms
step:954/1390 train_time:138750ms step_avg:146.98ms
step:955/1390 train_time:138903ms step_avg:146.99ms
step:956/1390 train_time:139056ms step_avg:146.99ms
step:957/1390 train_time:139212ms step_avg:147.00ms
step:958/1390 train_time:139373ms step_avg:147.02ms
step:959/1390 train_time:139530ms step_avg:147.03ms
step:960/1390 train_time:139685ms step_avg:147.04ms
step:961/1390 train_time:139838ms step_avg:147.04ms
step:962/1390 train_time:139991ms step_avg:147.05ms
step:963/1390 train_time:140148ms step_avg:147.06ms
step:964/1390 train_time:140303ms step_avg:147.07ms
step:965/1390 train_time:140457ms step_avg:147.08ms
step:966/1390 train_time:140610ms step_avg:147.08ms
step:967/1390 train_time:140763ms step_avg:147.09ms
step:968/1390 train_time:140916ms step_avg:147.09ms
step:969/1390 train_time:141070ms step_avg:147.10ms
step:970/1390 train_time:141226ms step_avg:147.11ms
step:971/1390 train_time:141381ms step_avg:147.12ms
step:972/1390 train_time:141532ms step_avg:147.12ms
step:973/1390 train_time:141687ms step_avg:147.13ms
step:974/1390 train_time:141841ms step_avg:147.14ms
step:975/1390 train_time:141996ms step_avg:147.15ms
step:976/1390 train_time:142151ms step_avg:147.15ms
step:977/1390 train_time:142307ms step_avg:147.16ms
step:978/1390 train_time:142461ms step_avg:147.17ms
step:979/1390 train_time:142613ms step_avg:147.18ms
step:980/1390 train_time:142767ms step_avg:147.18ms
step:981/1390 train_time:142919ms step_avg:147.19ms
step:982/1390 train_time:143070ms step_avg:147.19ms
step:983/1390 train_time:143226ms step_avg:147.20ms
step:984/1390 train_time:143379ms step_avg:147.21ms
step:985/1390 train_time:143531ms step_avg:147.21ms
step:986/1390 train_time:143690ms step_avg:147.22ms
step:987/1390 train_time:143842ms step_avg:147.23ms
step:988/1390 train_time:143995ms step_avg:147.23ms
step:989/1390 train_time:144148ms step_avg:147.24ms
step:990/1390 train_time:144304ms step_avg:147.25ms
step:991/1390 train_time:144457ms step_avg:147.25ms
step:992/1390 train_time:144615ms step_avg:147.27ms
step:993/1390 train_time:144781ms step_avg:147.28ms
step:994/1390 train_time:144935ms step_avg:147.29ms
step:995/1390 train_time:145088ms step_avg:147.30ms
step:996/1390 train_time:145241ms step_avg:147.30ms
step:997/1390 train_time:145395ms step_avg:147.31ms
step:998/1390 train_time:145549ms step_avg:147.32ms
step:999/1390 train_time:145706ms step_avg:147.33ms
step:1000/1390 train_time:145859ms step_avg:147.33ms
step:1000/1390 val_loss:3.7107 train_time:145931ms step_avg:147.40ms
step:1001/1390 train_time:146014ms step_avg:147.34ms
step:1002/1390 train_time:146171ms step_avg:147.35ms
step:1003/1390 train_time:146326ms step_avg:147.36ms
step:1004/1390 train_time:146480ms step_avg:147.36ms
step:1005/1390 train_time:146633ms step_avg:147.37ms
step:1006/1390 train_time:146787ms step_avg:147.38ms
step:1007/1390 train_time:146945ms step_avg:147.39ms
step:1008/1390 train_time:147102ms step_avg:147.40ms
step:1009/1390 train_time:147264ms step_avg:147.41ms
step:1010/1390 train_time:147417ms step_avg:147.42ms
step:1011/1390 train_time:147574ms step_avg:147.43ms
step:1012/1390 train_time:147727ms step_avg:147.43ms
step:1013/1390 train_time:147881ms step_avg:147.44ms
step:1014/1390 train_time:148036ms step_avg:147.45ms
step:1015/1390 train_time:148191ms step_avg:147.45ms
step:1016/1390 train_time:148345ms step_avg:147.46ms
step:1017/1390 train_time:148499ms step_avg:147.47ms
step:1018/1390 train_time:148653ms step_avg:147.47ms
step:1019/1390 train_time:148810ms step_avg:147.48ms
step:1020/1390 train_time:148965ms step_avg:147.49ms
step:1021/1390 train_time:149120ms step_avg:147.50ms
step:1022/1390 train_time:149275ms step_avg:147.51ms
step:1023/1390 train_time:149430ms step_avg:147.51ms
step:1024/1390 train_time:149584ms step_avg:147.52ms
step:1025/1390 train_time:149739ms step_avg:147.53ms
step:1026/1390 train_time:149893ms step_avg:147.53ms
step:1027/1390 train_time:150047ms step_avg:147.54ms
step:1028/1390 train_time:150202ms step_avg:147.55ms
step:1029/1390 train_time:150358ms step_avg:147.55ms
step:1030/1390 train_time:150513ms step_avg:147.56ms
step:1031/1390 train_time:150664ms step_avg:147.56ms
step:1032/1390 train_time:150820ms step_avg:147.57ms
step:1033/1390 train_time:150977ms step_avg:147.58ms
step:1034/1390 train_time:151133ms step_avg:147.59ms
step:1035/1390 train_time:151290ms step_avg:147.60ms
step:1036/1390 train_time:151444ms step_avg:147.61ms
step:1037/1390 train_time:151600ms step_avg:147.61ms
step:1038/1390 train_time:151754ms step_avg:147.62ms
step:1039/1390 train_time:151911ms step_avg:147.63ms
step:1040/1390 train_time:152064ms step_avg:147.63ms
step:1041/1390 train_time:152221ms step_avg:147.64ms
step:1042/1390 train_time:152374ms step_avg:147.65ms
step:1043/1390 train_time:152529ms step_avg:147.66ms
step:1044/1390 train_time:152686ms step_avg:147.67ms
step:1045/1390 train_time:152843ms step_avg:147.67ms
step:1046/1390 train_time:152996ms step_avg:147.68ms
step:1047/1390 train_time:153152ms step_avg:147.69ms
step:1048/1390 train_time:153309ms step_avg:147.70ms
step:1049/1390 train_time:153466ms step_avg:147.71ms
step:1050/1390 train_time:153624ms step_avg:147.72ms
step:1051/1390 train_time:153781ms step_avg:147.72ms
step:1052/1390 train_time:153937ms step_avg:147.73ms
step:1053/1390 train_time:154092ms step_avg:147.74ms
step:1054/1390 train_time:154250ms step_avg:147.75ms
step:1055/1390 train_time:154405ms step_avg:147.76ms
step:1056/1390 train_time:154557ms step_avg:147.76ms
step:1057/1390 train_time:154714ms step_avg:147.77ms
step:1058/1390 train_time:154871ms step_avg:147.78ms
step:1059/1390 train_time:155029ms step_avg:147.79ms
step:1060/1390 train_time:155185ms step_avg:147.79ms
step:1061/1390 train_time:155339ms step_avg:147.80ms
step:1062/1390 train_time:155496ms step_avg:147.81ms
step:1063/1390 train_time:155653ms step_avg:147.82ms
step:1064/1390 train_time:155806ms step_avg:147.82ms
step:1065/1390 train_time:155964ms step_avg:147.83ms
step:1066/1390 train_time:156126ms step_avg:147.85ms
step:1067/1390 train_time:156282ms step_avg:147.85ms
step:1068/1390 train_time:156438ms step_avg:147.86ms
step:1069/1390 train_time:156600ms step_avg:147.88ms
step:1070/1390 train_time:156754ms step_avg:147.88ms
step:1071/1390 train_time:156911ms step_avg:147.89ms
step:1072/1390 train_time:157063ms step_avg:147.89ms
step:1073/1390 train_time:157216ms step_avg:147.90ms
step:1074/1390 train_time:157373ms step_avg:147.91ms
step:1075/1390 train_time:157530ms step_avg:147.92ms
step:1076/1390 train_time:157683ms step_avg:147.92ms
step:1077/1390 train_time:157838ms step_avg:147.93ms
step:1078/1390 train_time:157997ms step_avg:147.94ms
step:1079/1390 train_time:158154ms step_avg:147.95ms
step:1080/1390 train_time:158312ms step_avg:147.96ms
step:1081/1390 train_time:158466ms step_avg:147.96ms
step:1082/1390 train_time:158620ms step_avg:147.97ms
step:1083/1390 train_time:158774ms step_avg:147.97ms
step:1084/1390 train_time:158933ms step_avg:147.98ms
step:1085/1390 train_time:159088ms step_avg:147.99ms
step:1086/1390 train_time:159247ms step_avg:148.00ms
step:1087/1390 train_time:159405ms step_avg:148.01ms
step:1088/1390 train_time:159558ms step_avg:148.01ms
step:1089/1390 train_time:159716ms step_avg:148.02ms
step:1090/1390 train_time:159877ms step_avg:148.03ms
step:1091/1390 train_time:160034ms step_avg:148.04ms
step:1092/1390 train_time:160188ms step_avg:148.05ms
step:1093/1390 train_time:160346ms step_avg:148.06ms
step:1094/1390 train_time:160499ms step_avg:148.06ms
step:1095/1390 train_time:160655ms step_avg:148.07ms
step:1096/1390 train_time:160814ms step_avg:148.08ms
step:1097/1390 train_time:160970ms step_avg:148.09ms
step:1098/1390 train_time:161125ms step_avg:148.09ms
step:1099/1390 train_time:161279ms step_avg:148.10ms
step:1100/1390 train_time:161432ms step_avg:148.10ms
step:1101/1390 train_time:161586ms step_avg:148.11ms
step:1102/1390 train_time:161744ms step_avg:148.12ms
step:1103/1390 train_time:161901ms step_avg:148.13ms
step:1104/1390 train_time:162054ms step_avg:148.13ms
step:1105/1390 train_time:162211ms step_avg:148.14ms
step:1106/1390 train_time:162367ms step_avg:148.15ms
step:1107/1390 train_time:162521ms step_avg:148.15ms
step:1108/1390 train_time:162680ms step_avg:148.16ms
step:1109/1390 train_time:162835ms step_avg:148.17ms
step:1110/1390 train_time:162989ms step_avg:148.17ms
step:1111/1390 train_time:163148ms step_avg:148.18ms
step:1112/1390 train_time:163304ms step_avg:148.19ms
step:1113/1390 train_time:163457ms step_avg:148.19ms
step:1114/1390 train_time:163616ms step_avg:148.20ms
step:1115/1390 train_time:163772ms step_avg:148.21ms
step:1116/1390 train_time:163927ms step_avg:148.22ms
step:1117/1390 train_time:164086ms step_avg:148.23ms
step:1118/1390 train_time:164247ms step_avg:148.24ms
step:1119/1390 train_time:164402ms step_avg:148.24ms
step:1120/1390 train_time:164559ms step_avg:148.25ms
step:1121/1390 train_time:164715ms step_avg:148.26ms
step:1122/1390 train_time:164871ms step_avg:148.27ms
step:1123/1390 train_time:165025ms step_avg:148.27ms
step:1124/1390 train_time:165184ms step_avg:148.28ms
step:1125/1390 train_time:165339ms step_avg:148.29ms
step:1125/1390 val_loss:3.6643 train_time:165411ms step_avg:148.35ms
step:1126/1390 train_time:165493ms step_avg:148.29ms
step:1127/1390 train_time:165652ms step_avg:148.30ms
step:1128/1390 train_time:165808ms step_avg:148.31ms
step:1129/1390 train_time:165967ms step_avg:148.32ms
step:1130/1390 train_time:166121ms step_avg:148.32ms
step:1131/1390 train_time:166278ms step_avg:148.33ms
step:1132/1390 train_time:166432ms step_avg:148.34ms
step:1133/1390 train_time:166588ms step_avg:148.34ms
step:1134/1390 train_time:166744ms step_avg:148.35ms
step:1135/1390 train_time:166899ms step_avg:148.35ms
step:1136/1390 train_time:167062ms step_avg:148.37ms
step:1137/1390 train_time:167214ms step_avg:148.37ms
step:1138/1390 train_time:167371ms step_avg:148.38ms
step:1139/1390 train_time:167527ms step_avg:148.39ms
step:1140/1390 train_time:167683ms step_avg:148.39ms
step:1141/1390 train_time:167891ms step_avg:148.44ms
step:1142/1390 train_time:168048ms step_avg:148.45ms
step:1143/1390 train_time:168208ms step_avg:148.46ms
step:1144/1390 train_time:168363ms step_avg:148.47ms
step:1145/1390 train_time:168514ms step_avg:148.47ms
step:1146/1390 train_time:168671ms step_avg:148.48ms
step:1147/1390 train_time:168828ms step_avg:148.49ms
step:1148/1390 train_time:168985ms step_avg:148.49ms
step:1149/1390 train_time:169141ms step_avg:148.50ms
step:1150/1390 train_time:169294ms step_avg:148.50ms
step:1151/1390 train_time:169452ms step_avg:148.51ms
step:1152/1390 train_time:169610ms step_avg:148.52ms
step:1153/1390 train_time:169768ms step_avg:148.53ms
step:1154/1390 train_time:169922ms step_avg:148.53ms
step:1155/1390 train_time:170080ms step_avg:148.54ms
step:1156/1390 train_time:170241ms step_avg:148.55ms
step:1157/1390 train_time:170399ms step_avg:148.56ms
step:1158/1390 train_time:170555ms step_avg:148.57ms
step:1159/1390 train_time:170714ms step_avg:148.58ms
step:1160/1390 train_time:170869ms step_avg:148.58ms
step:1161/1390 train_time:171026ms step_avg:148.59ms
step:1162/1390 train_time:171183ms step_avg:148.60ms
step:1163/1390 train_time:171339ms step_avg:148.60ms
step:1164/1390 train_time:171495ms step_avg:148.61ms
step:1165/1390 train_time:171651ms step_avg:148.62ms
step:1166/1390 train_time:171810ms step_avg:148.62ms
step:1167/1390 train_time:171963ms step_avg:148.63ms
step:1168/1390 train_time:172118ms step_avg:148.63ms
step:1169/1390 train_time:172272ms step_avg:148.64ms
step:1170/1390 train_time:172429ms step_avg:148.65ms
step:1171/1390 train_time:172588ms step_avg:148.65ms
step:1172/1390 train_time:172743ms step_avg:148.66ms
step:1173/1390 train_time:172903ms step_avg:148.67ms
step:1174/1390 train_time:173066ms step_avg:148.68ms
step:1175/1390 train_time:173223ms step_avg:148.69ms
step:1176/1390 train_time:173385ms step_avg:148.70ms
step:1177/1390 train_time:173548ms step_avg:148.71ms
step:1178/1390 train_time:173703ms step_avg:148.72ms
step:1179/1390 train_time:173859ms step_avg:148.72ms
step:1180/1390 train_time:174024ms step_avg:148.74ms
step:1181/1390 train_time:174181ms step_avg:148.75ms
step:1182/1390 train_time:174335ms step_avg:148.75ms
step:1183/1390 train_time:174491ms step_avg:148.76ms
step:1184/1390 train_time:174647ms step_avg:148.76ms
step:1185/1390 train_time:174807ms step_avg:148.77ms
step:1186/1390 train_time:174964ms step_avg:148.78ms
step:1187/1390 train_time:175128ms step_avg:148.79ms
step:1188/1390 train_time:175283ms step_avg:148.80ms
step:1189/1390 train_time:175444ms step_avg:148.81ms
step:1190/1390 train_time:175603ms step_avg:148.82ms
step:1191/1390 train_time:175762ms step_avg:148.82ms
step:1192/1390 train_time:175916ms step_avg:148.83ms
step:1193/1390 train_time:176072ms step_avg:148.83ms
step:1194/1390 train_time:176229ms step_avg:148.84ms
step:1195/1390 train_time:176386ms step_avg:148.85ms
step:1196/1390 train_time:176544ms step_avg:148.86ms
step:1197/1390 train_time:176704ms step_avg:148.87ms
step:1198/1390 train_time:176864ms step_avg:148.88ms
step:1199/1390 train_time:177021ms step_avg:148.88ms
step:1200/1390 train_time:177177ms step_avg:148.89ms
step:1201/1390 train_time:177334ms step_avg:148.90ms
step:1202/1390 train_time:177501ms step_avg:148.91ms
step:1203/1390 train_time:177661ms step_avg:148.92ms
step:1204/1390 train_time:177818ms step_avg:148.93ms
step:1205/1390 train_time:177972ms step_avg:148.93ms
step:1206/1390 train_time:178129ms step_avg:148.94ms
step:1207/1390 train_time:178286ms step_avg:148.94ms
step:1208/1390 train_time:178443ms step_avg:148.95ms
step:1209/1390 train_time:178601ms step_avg:148.96ms
step:1210/1390 train_time:178764ms step_avg:148.97ms
step:1211/1390 train_time:178920ms step_avg:148.98ms
step:1212/1390 train_time:179077ms step_avg:148.98ms
step:1213/1390 train_time:179233ms step_avg:148.99ms
step:1214/1390 train_time:179393ms step_avg:149.00ms
step:1215/1390 train_time:179550ms step_avg:149.00ms
step:1216/1390 train_time:179704ms step_avg:149.01ms
step:1217/1390 train_time:179859ms step_avg:149.01ms
step:1218/1390 train_time:180012ms step_avg:149.02ms
step:1219/1390 train_time:180168ms step_avg:149.02ms
step:1220/1390 train_time:180323ms step_avg:149.03ms
step:1221/1390 train_time:180479ms step_avg:149.03ms
step:1222/1390 train_time:180636ms step_avg:149.04ms
step:1223/1390 train_time:180794ms step_avg:149.05ms
step:1224/1390 train_time:180953ms step_avg:149.06ms
step:1225/1390 train_time:181110ms step_avg:149.06ms
step:1226/1390 train_time:181265ms step_avg:149.07ms
step:1227/1390 train_time:181423ms step_avg:149.07ms
step:1228/1390 train_time:181577ms step_avg:149.08ms
step:1229/1390 train_time:181732ms step_avg:149.08ms
step:1230/1390 train_time:181894ms step_avg:149.09ms
step:1231/1390 train_time:182051ms step_avg:149.10ms
step:1232/1390 train_time:182212ms step_avg:149.11ms
step:1233/1390 train_time:182369ms step_avg:149.12ms
step:1234/1390 train_time:182524ms step_avg:149.12ms
step:1235/1390 train_time:182681ms step_avg:149.13ms
step:1236/1390 train_time:182836ms step_avg:149.13ms
step:1237/1390 train_time:182992ms step_avg:149.14ms
step:1238/1390 train_time:183156ms step_avg:149.15ms
step:1239/1390 train_time:183312ms step_avg:149.16ms
step:1240/1390 train_time:183471ms step_avg:149.16ms
step:1241/1390 train_time:183631ms step_avg:149.17ms
step:1242/1390 train_time:183786ms step_avg:149.18ms
step:1243/1390 train_time:183945ms step_avg:149.18ms
step:1244/1390 train_time:184099ms step_avg:149.19ms
step:1245/1390 train_time:184258ms step_avg:149.20ms
step:1246/1390 train_time:184416ms step_avg:149.20ms
step:1247/1390 train_time:184575ms step_avg:149.21ms
step:1248/1390 train_time:184731ms step_avg:149.22ms
step:1249/1390 train_time:184887ms step_avg:149.22ms
step:1250/1390 train_time:185045ms step_avg:149.23ms
step:1250/1390 val_loss:3.6234 train_time:185119ms step_avg:149.29ms
step:1251/1390 train_time:185205ms step_avg:149.24ms
step:1252/1390 train_time:185360ms step_avg:149.24ms
step:1253/1390 train_time:185516ms step_avg:149.25ms
step:1254/1390 train_time:185669ms step_avg:149.25ms
step:1255/1390 train_time:185837ms step_avg:149.27ms
step:1256/1390 train_time:185993ms step_avg:149.27ms
step:1257/1390 train_time:186151ms step_avg:149.28ms
step:1258/1390 train_time:186314ms step_avg:149.29ms
step:1259/1390 train_time:186473ms step_avg:149.30ms
step:1260/1390 train_time:186626ms step_avg:149.30ms
step:1261/1390 train_time:186788ms step_avg:149.31ms
step:1262/1390 train_time:186949ms step_avg:149.32ms
step:1263/1390 train_time:187106ms step_avg:149.33ms
step:1264/1390 train_time:187261ms step_avg:149.33ms
step:1265/1390 train_time:187420ms step_avg:149.34ms
step:1266/1390 train_time:187578ms step_avg:149.35ms
step:1267/1390 train_time:187735ms step_avg:149.35ms
step:1268/1390 train_time:187894ms step_avg:149.36ms
step:1269/1390 train_time:188056ms step_avg:149.37ms
step:1270/1390 train_time:188214ms step_avg:149.38ms
step:1271/1390 train_time:188373ms step_avg:149.38ms
step:1272/1390 train_time:188528ms step_avg:149.39ms
step:1273/1390 train_time:188684ms step_avg:149.39ms
step:1274/1390 train_time:188841ms step_avg:149.40ms
step:1275/1390 train_time:188997ms step_avg:149.40ms
step:1276/1390 train_time:189153ms step_avg:149.41ms
step:1277/1390 train_time:189312ms step_avg:149.42ms
step:1278/1390 train_time:189466ms step_avg:149.42ms
step:1279/1390 train_time:189625ms step_avg:149.43ms
step:1280/1390 train_time:189788ms step_avg:149.44ms
step:1281/1390 train_time:189945ms step_avg:149.45ms
step:1282/1390 train_time:190100ms step_avg:149.45ms
step:1283/1390 train_time:190259ms step_avg:149.46ms
step:1284/1390 train_time:190417ms step_avg:149.46ms
step:1285/1390 train_time:190575ms step_avg:149.47ms
step:1286/1390 train_time:190733ms step_avg:149.48ms
step:1287/1390 train_time:190889ms step_avg:149.48ms
step:1288/1390 train_time:191048ms step_avg:149.49ms
step:1289/1390 train_time:191211ms step_avg:149.50ms
step:1290/1390 train_time:191373ms step_avg:149.51ms
step:1291/1390 train_time:191535ms step_avg:149.52ms
step:1292/1390 train_time:191692ms step_avg:149.53ms
step:1293/1390 train_time:191853ms step_avg:149.53ms
step:1294/1390 train_time:192012ms step_avg:149.54ms
step:1295/1390 train_time:192171ms step_avg:149.55ms
step:1296/1390 train_time:192330ms step_avg:149.56ms
step:1297/1390 train_time:192491ms step_avg:149.57ms
step:1298/1390 train_time:192646ms step_avg:149.57ms
step:1299/1390 train_time:192802ms step_avg:149.57ms
step:1300/1390 train_time:192957ms step_avg:149.58ms
step:1301/1390 train_time:193114ms step_avg:149.59ms
step:1302/1390 train_time:193272ms step_avg:149.59ms
step:1303/1390 train_time:193432ms step_avg:149.60ms
step:1304/1390 train_time:193593ms step_avg:149.61ms
step:1305/1390 train_time:193748ms step_avg:149.61ms
step:1306/1390 train_time:193908ms step_avg:149.62ms
step:1307/1390 train_time:194064ms step_avg:149.63ms
step:1308/1390 train_time:194223ms step_avg:149.63ms
step:1309/1390 train_time:194380ms step_avg:149.64ms
step:1310/1390 train_time:194537ms step_avg:149.64ms
step:1311/1390 train_time:194691ms step_avg:149.65ms
step:1312/1390 train_time:194845ms step_avg:149.65ms
step:1313/1390 train_time:195001ms step_avg:149.66ms
step:1314/1390 train_time:195157ms step_avg:149.66ms
step:1315/1390 train_time:195315ms step_avg:149.67ms
step:1316/1390 train_time:195471ms step_avg:149.67ms
step:1317/1390 train_time:195626ms step_avg:149.68ms
step:1318/1390 train_time:195789ms step_avg:149.69ms
step:1319/1390 train_time:195948ms step_avg:149.69ms
step:1320/1390 train_time:196106ms step_avg:149.70ms
step:1321/1390 train_time:196267ms step_avg:149.71ms
step:1322/1390 train_time:196427ms step_avg:149.72ms
step:1323/1390 train_time:196582ms step_avg:149.72ms
step:1324/1390 train_time:196738ms step_avg:149.72ms
step:1325/1390 train_time:196895ms step_avg:149.73ms
step:1326/1390 train_time:197056ms step_avg:149.74ms
step:1327/1390 train_time:197212ms step_avg:149.74ms
step:1328/1390 train_time:197367ms step_avg:149.75ms
step:1329/1390 train_time:197540ms step_avg:149.76ms
step:1330/1390 train_time:197699ms step_avg:149.77ms
step:1331/1390 train_time:197907ms step_avg:149.82ms
step:1332/1390 train_time:198062ms step_avg:149.82ms
step:1333/1390 train_time:198220ms step_avg:149.83ms
step:1334/1390 train_time:198374ms step_avg:149.83ms
step:1335/1390 train_time:198527ms step_avg:149.83ms
step:1336/1390 train_time:198691ms step_avg:149.84ms
step:1337/1390 train_time:198851ms step_avg:149.85ms
step:1338/1390 train_time:199010ms step_avg:149.86ms
step:1339/1390 train_time:199169ms step_avg:149.86ms
step:1340/1390 train_time:199327ms step_avg:149.87ms
step:1341/1390 train_time:199483ms step_avg:149.87ms
step:1342/1390 train_time:199643ms step_avg:149.88ms
step:1343/1390 train_time:199800ms step_avg:149.89ms
step:1344/1390 train_time:199956ms step_avg:149.89ms
step:1345/1390 train_time:200115ms step_avg:149.90ms
step:1346/1390 train_time:200273ms step_avg:149.91ms
step:1347/1390 train_time:200432ms step_avg:149.91ms
step:1348/1390 train_time:200592ms step_avg:149.92ms
step:1349/1390 train_time:200751ms step_avg:149.93ms
step:1350/1390 train_time:200907ms step_avg:149.93ms
step:1351/1390 train_time:201063ms step_avg:149.94ms
step:1352/1390 train_time:201224ms step_avg:149.94ms
step:1353/1390 train_time:201389ms step_avg:149.95ms
step:1354/1390 train_time:201548ms step_avg:149.96ms
step:1355/1390 train_time:201705ms step_avg:149.97ms
step:1356/1390 train_time:201860ms step_avg:149.97ms
step:1357/1390 train_time:202020ms step_avg:149.98ms
step:1358/1390 train_time:202181ms step_avg:149.99ms
step:1359/1390 train_time:202340ms step_avg:149.99ms
step:1360/1390 train_time:202502ms step_avg:150.00ms
step:1361/1390 train_time:202662ms step_avg:150.01ms
step:1362/1390 train_time:202821ms step_avg:150.02ms
step:1363/1390 train_time:202983ms step_avg:150.02ms
step:1364/1390 train_time:203141ms step_avg:150.03ms
step:1365/1390 train_time:203297ms step_avg:150.03ms
step:1366/1390 train_time:203456ms step_avg:150.04ms
step:1367/1390 train_time:203615ms step_avg:150.05ms
step:1368/1390 train_time:203773ms step_avg:150.05ms
step:1369/1390 train_time:203937ms step_avg:150.06ms
step:1370/1390 train_time:204097ms step_avg:150.07ms
step:1371/1390 train_time:204255ms step_avg:150.08ms
step:1372/1390 train_time:204417ms step_avg:150.09ms
step:1373/1390 train_time:204573ms step_avg:150.09ms
step:1374/1390 train_time:204733ms step_avg:150.10ms
step:1375/1390 train_time:204889ms step_avg:150.10ms
step:1375/1390 val_loss:3.5996 train_time:204960ms step_avg:150.15ms
step:1376/1390 train_time:205044ms step_avg:150.11ms
step:1377/1390 train_time:205201ms step_avg:150.11ms
step:1378/1390 train_time:205358ms step_avg:150.12ms
step:1379/1390 train_time:205517ms step_avg:150.12ms
step:1380/1390 train_time:205674ms step_avg:150.13ms
step:1381/1390 train_time:205835ms step_avg:150.13ms
step:1382/1390 train_time:205992ms step_avg:150.14ms
step:1383/1390 train_time:206153ms step_avg:150.15ms
step:1384/1390 train_time:206317ms step_avg:150.16ms
step:1385/1390 train_time:206472ms step_avg:150.16ms
step:1386/1390 train_time:206632ms step_avg:150.17ms
step:1387/1390 train_time:206794ms step_avg:150.18ms
step:1388/1390 train_time:206950ms step_avg:150.18ms
step:1389/1390 train_time:207111ms step_avg:150.19ms
step:1390/1390 train_time:207269ms step_avg:150.19ms
step:1390/1390 val_loss:3.5989 train_time:207340ms step_avg:150.25ms
peak memory consumption: 31565 MiB
