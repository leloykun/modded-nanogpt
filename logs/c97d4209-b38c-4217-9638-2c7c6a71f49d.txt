====================================================================================================
import os
import sys
with open(sys.argv[0]) as f:
    code = f.read() # read the code of this file ASAP, for logging
import uuid
import glob
import time
from dataclasses import dataclass

import numpy as np
import torch
from torch import nn
import torch.nn.functional as F
import torch.distributed as dist
import torch._inductor.config as config
from torch.nn.parallel import DistributedDataParallel as DDP
# Use of FlexAttention contributed by @KoszarskyB
from torch.nn.attention.flex_attention import flex_attention, create_block_mask, BlockMask, _score_mod_signature
from torch._inductor.lowering import make_pointwise, register_lowering
# Some internal torch.compile details
from torch._inductor.virtualized import ops
from functools import partial
flex_attention = torch.compile(flex_attention, dynamic=False)
create_block_mask = torch.compile(create_block_mask, dynamic=False)

# -----------------------------------------------------------------------------
# Muon optimizer

def zeropower_via_svd(G, steps=None):
    U, S, V = G.svd()
    return U @ V.T

@torch.compile
def zeropower_via_newtonschulz5(G, steps=10, eps=1e-7):
    """
    Newton-Schulz iteration to compute the zeroth power / orthogonalization of G. We opt to use a
    quintic iteration whose coefficients are selected to maximize the slope at zero. For the purpose
    of minimizing steps, it turns out to be empirically effective to keep increasing the slope at
    zero even beyond the point where the iteration no longer converges all the way to one everywhere
    on the interval. This iteration therefore does not produce UV^T but rather something like US'V^T
    where S' is diagonal with S_{ii}' ~ Uniform(0.5, 1.5), which turns out not to hurt model
    performance at all relative to UV^T, where USV^T = G is the SVD.
    """
    assert len(G.shape) == 2
    a, b, c = (3.4445, -4.7750,  2.0315)
    X = G.bfloat16()
    X /= (X.norm() + eps) # ensure top singular value <= 1
    if G.size(0) > G.size(1):
        X = X.T
    for _ in range(steps):
        A = X @ X.T
        B = b * A + c * A @ A # adapted from suggestion by @jxbz, @leloykun, and @YouJiacheng
        X = a * X + B @ X
    if G.size(0) > G.size(1):
        X = X.T
    return X

zeropower_backends = dict(svd=zeropower_via_svd, newtonschulz5=zeropower_via_newtonschulz5)

class Muon(torch.optim.Optimizer):
    """
    Muon - MomentUm Orthogonalized by Newton-schulz

    Muon internally runs standard SGD-momentum, and then performs an orthogonalization post-
    processing step, in which each 2D parameter's update is replaced with the nearest orthogonal
    matrix. To efficiently orthogonalize each update, we use a Newton-Schulz iteration, which has
    the advantage that it can be stably run in bfloat16 on the GPU.

    Some warnings:
    - This optimizer assumes that all parameters passed in are 2D.
    - It should not be used for the embedding layer, the final fully connected layer, or any {0,1}-D
    parameters; those should all be optimized by a standard method (e.g., AdamW).
    - To use it with 4D convolutional filters, it works well to just flatten their last 3 dimensions.
    - We believe it is unlikely to work well for training with small batch size.
    - We believe it may not work well for finetuning pretrained models, but we haven't tested this.
    - We have not yet tried this optimizer for training scenarios larger than NanoGPT (124M).

    Arguments:
        lr: The learning rate used by the internal SGD.
        momentum: The momentum used by the internal SGD.
        nesterov: Whether to use Nesterov-style momentum in the internal SGD. (recommended)
        backend: The chosen backend for the orthogonalization step. (recommended: 'newtonschulz5')
        backend_steps: The number of iteration steps to use in the backend, if it is iterative.
    """
    def __init__(self, params, lr=0.02, momentum=0.95, nesterov=True,
                 backend='newtonschulz5', backend_steps=5):
        defaults = dict(lr=lr, momentum=momentum, nesterov=nesterov, backend=backend, backend_steps=backend_steps)
        super().__init__(params, defaults)

    def step(self):

        for group in self.param_groups:

            lr = group['lr']
            momentum = group['momentum']
            zeropower_backend = zeropower_backends[group['backend']]

            # generate weight updates in distributed fashion
            total_params = sum(p.numel() for p in group['params'])
            updates_flat = torch.zeros(total_params, device='cuda', dtype=torch.bfloat16)
            curr_idx = 0
            for i, p in enumerate(group['params']):
                # luckily this will perfectly distribute a transformer with multiple of 4 layers to 8 GPUs
                if i % int(os.environ['WORLD_SIZE']) == int(os.environ['RANK']):
                    g = p.grad
                    assert g is not None
                    state = self.state[p]
                    if 'momentum_buffer' not in state:
                        state['momentum_buffer'] = torch.zeros_like(g)
                    buf = state['momentum_buffer']
                    buf.mul_(momentum).add_(g)
                    if group['nesterov']:
                        g = g.add(buf, alpha=momentum)
                    g = zeropower_backend(g, steps=group['backend_steps'])
                    g *= max(1, g.size(0)/g.size(1))**0.5
                    updates_flat[curr_idx:curr_idx+p.numel()] = g.flatten()
                curr_idx += p.numel()

            # sync updates across devices. we are not memory-constrained so can do this simple deserialization
            dist.all_reduce(updates_flat, op=dist.ReduceOp.SUM)

            # deserialize and apply updates
            curr_idx = 0
            for p in group['params']:
                g = updates_flat[curr_idx:curr_idx+p.numel()].view_as(p.data).type_as(p.data)
                p.data.add_(g, alpha=-lr)
                curr_idx += p.numel()

# -----------------------------------------------------------------------------
# Attention Tanh softcapping

@torch.library.custom_op("approx::tanh", mutates_args=())
def _tanh_approx(inp: torch.Tensor) -> torch.Tensor:
    return torch.tanh(inp)

@_tanh_approx.register_fake
def _(inp: torch.Tensor) -> torch.Tensor:
    return torch.tanh(inp)

def _tanh_approx_lowering(inp):
    fn = partial(ops.inline_asm_elementwise, asm="tanh.approx.f32 $0, $1;")
    return make_pointwise(fn)(inp)

register_lowering(torch.ops.approx.tanh)(_tanh_approx_lowering)

class _TanhApprox(torch.autograd.Function):
    @staticmethod
    def forward(x):
        return torch.ops.approx.tanh(x)

    @staticmethod
    def setup_context(ctx, inputs, output):
        (x,) = inputs
        result = output
        ctx.save_for_backward(result)

    @staticmethod
    def backward(ctx, grad_output):
        (result,) = ctx.saved_tensors
        return grad_output * (1 - result * result)

    @staticmethod
    def vmap(info, in_dims, x):
        return torch.tanh(x), 0

_tanh_approx = _TanhApprox.apply

def generate_tanh_softcap(soft_cap: int, approx: bool=True) -> _score_mod_signature:
    tanh = _tanh_approx if approx else torch.tanh

    def tanh_softcap(score, b, h, q_idx, kv_idx):
        return soft_cap * tanh(score / soft_cap)

    prefix = "tanh_softcap_approx" if approx else "tanh_softcap"
    tanh_softcap.__name__ = f"{prefix}_{soft_cap}"

    return tanh_softcap

# -----------------------------------------------------------------------------
# PyTorch nn.Module definitions for the GPT-2 model

class Rotary(torch.nn.Module):

    def __init__(self, dim, base=10000):
        super().__init__()
        self.dim = dim
        self.base = base
        self.inv_freq = None
        self.seq_len_cached = None
        self.cos_cached = None
        self.sin_cached = None

    def forward(self, x):
        seq_len = x.shape[1]
        if seq_len != self.seq_len_cached:
            self.inv_freq = 1.0 / (self.base ** (torch.arange(0, self.dim, 2, device=x.device).float() / self.dim))
            self.seq_len_cached = seq_len
            t = torch.arange(seq_len, device=x.device).type_as(self.inv_freq)
            freqs = torch.outer(t, self.inv_freq)
            self.cos_cached = freqs.cos().bfloat16()
            self.sin_cached = freqs.sin().bfloat16()
        return self.cos_cached[None, :, None, :], self.sin_cached[None, :, None, :]

def apply_rotary_emb(x, cos, sin):
    assert x.ndim == 4 # multihead attention
    d = x.shape[3]//2
    x1 = x[..., :d]
    x2 = x[..., d:]
    y1 = x1 * cos + x2 * sin
    y2 = x1 * (-sin) + x2 * cos
    return torch.cat([y1, y2], 3).type_as(x)

class CastedLinear(nn.Linear):
    def forward(self, x):
        return F.linear(x, self.weight.to(x.dtype))

class CausalSelfAttention(nn.Module):

    def __init__(self, config):
        super().__init__()
        self.n_head = config.n_head
        self.n_embd = config.n_embd
        self.head_dim = self.n_embd // self.n_head
        assert self.n_embd % self.n_head == 0
        self.c_q = CastedLinear(self.n_embd, self.n_embd, bias=False)
        self.c_k = CastedLinear(self.n_embd, self.n_embd, bias=False)
        self.c_v = CastedLinear(self.n_embd, self.n_embd, bias=False)
        # output projection
        self.c_proj = CastedLinear(self.n_embd, self.n_embd, bias=False)
        self.c_proj.weight.data.zero_() # zero init suggested by @Grad62304977
        self.rotary = Rotary(self.head_dim)
        self.lamb = nn.Parameter(torch.tensor(0.5)) # @Grad62304977

    def forward(self, x, v1, block_mask: BlockMask, score_mod: _score_mod_signature):
        B, T, C = x.size() # batch size, sequence length, embedding dimensionality (n_embd)
        q = self.c_q(x).view(B, T, self.n_head, self.head_dim)
        k = self.c_k(x).view(B, T, self.n_head, self.head_dim)
        v = self.c_v(x).view(B, T, self.n_head, self.head_dim)
        if v1 is None:
            v1 = v # This happens if we are in the first block. v needs to be accessed by subsequent blocks
        v = (1 - self.lamb) * v + self.lamb * v1.view_as(v) # @Grad62304977
        cos, sin = self.rotary(q)
        q, k = F.rms_norm(q, (q.size(-1),)), F.rms_norm(k, (k.size(-1),)) # QK norm suggested by @Grad62304977
        q, k = apply_rotary_emb(q, cos, sin), apply_rotary_emb(k, cos, sin)
        y = flex_attention(q.transpose(1, 2), k.transpose(1, 2), v.transpose(1, 2), score_mod=score_mod, block_mask=block_mask)
        y = y.transpose(1, 2).contiguous().view_as(x) # re-assemble all head outputs side by side
        y = self.c_proj(y)
        return y, v1

class MLP(nn.Module):

    def __init__(self, config):
        super().__init__()
        self.c_fc    = CastedLinear(config.n_embd, 4 * config.n_embd, bias=False)
        self.c_proj  = CastedLinear(4 * config.n_embd, config.n_embd, bias=False)
        self.c_proj.weight.data.zero_() # zero init suggested by @Grad62304977

    def forward(self, x):
        x = self.c_fc(x)
        x = F.relu(x).square() # https://arxiv.org/abs/2109.08668v2; ~1-2% better than GELU; suggested by @SKYLINEZ007 and @Grad62304977
        x = self.c_proj(x)
        return x

class Block(nn.Module):

    def __init__(self, config):
        super().__init__()
        self.attn = CausalSelfAttention(config)
        self.mlp = MLP(config)
        self.lambdas = nn.Parameter(torch.tensor([1., 0.]))

    def forward(self, x, v1, x0, block_mask: BlockMask, score_mod: _score_mod_signature):
        x = self.lambdas[0] * x + self.lambdas[1] * x0
        x1, v1 = self.attn(F.rms_norm(x, (x.size(-1),)), v1, block_mask, score_mod)
        x = x + x1
        x = x + self.mlp(F.rms_norm(x, (x.size(-1),)))
        return x, v1

# -----------------------------------------------------------------------------
# The main GPT-2 model

@dataclass
class GPTConfig:
    vocab_size : int = 50304
    n_layer : int = 12
    n_head : int = 6 # head dim 128 suggested by @Grad62304977
    n_embd : int = 768
    attention_soft_cap : int = 50
    lm_head_soft_cap : int = 30

class GPT(nn.Module):

    def __init__(self, config: GPTConfig):
        super().__init__()
        self.attention_soft_cap = config.attention_soft_cap
        self.lm_head_soft_cap = config.lm_head_soft_cap

        # U-net design by @brendanh0gan
        self.num_encoder_layers = config.n_layer // 2 # Half of the layers for encoder
        self.num_decoder_layers = config.n_layer - self.num_encoder_layers # Remaining for decoder
        # Add learnable skip connection weights for decoder layers
        self.skip_weights = nn.Parameter(torch.ones(self.num_decoder_layers))

        self.transformer = nn.ModuleDict(dict(
            wte = nn.Embedding(config.vocab_size, config.n_embd),
            h = nn.ModuleList([Block(config) for _ in range(config.n_layer)]),
        ))
        self.lm_head = CastedLinear(config.n_embd, config.vocab_size, bias=False)
        self.lm_head.weight.data.zero_() # @Grad62304977

    def forward(self, idx, target):

        docs = (idx == 50256).cumsum(0)
        def document_causal_mask(b, h, q_idx, kv_idx):
            causal_mask = q_idx >= kv_idx
            document_mask = docs[q_idx] == docs[kv_idx]
            window_mask = q_idx - kv_idx < 1024
            return causal_mask & document_mask & window_mask

        softcap_mod = generate_tanh_softcap(self.attention_soft_cap, approx=True)  # @leloykun

        S = len(idx)
        block_mask = create_block_mask(document_causal_mask, None, None, S, S, device="cuda", _compile=True)

        # forward the GPT model itself
        x = self.transformer.wte(idx[None]) # token embeddings of shape (b, t, n_embd)
        x = F.rms_norm(x, (x.size(-1),)) # @Grad62304977
        x0 = x
        v1 = None

        # Store outputs for U-Net skip connections
        skip_connections = []
        # Encoder pass - process only the first half of the blocks
        for i in range(self.num_encoder_layers):
            x, v1 = self.transformer.h[i](x, v1, x0, block_mask, softcap_mod)
            skip_connections.append(x)
        # Decoder pass - process the remaining blocks with weighted skip connections
        for i in range(self.num_decoder_layers):
            x = x + self.skip_weights[i] * skip_connections.pop()
            x, v1 = self.transformer.h[self.num_encoder_layers + i](x, v1, x0, block_mask, softcap_mod)

        x = F.rms_norm(x, (x.size(-1),))
        logits = self.lm_head(x)
        logits = self.lm_head_soft_cap * torch.tanh(logits / self.lm_head_soft_cap) # @Grad62304977
        logits = logits.float()
        loss = F.cross_entropy(logits.view(-1, logits.size(-1)), target.view(-1))
        return loss

# -----------------------------------------------------------------------------
# Our own simple Distributed Data Loader

def _peek_data_shard(filename):
    # only reads the header, returns header data
    with open(filename, "rb") as f:
        # first read the header, which is 256 int32 integers (4 bytes each)
        header = np.frombuffer(f.read(256*4), dtype=np.int32)
    if header[0] != 20240520:
        print("ERROR: magic number mismatch in the data .bin file!")
        print("---> HINT: Are you passing in a correct file with --input_bin?")
        print("---> HINT: Dataset encoding changed recently, re-run data prepro or refer again to README")
        print("---> HINT: For example re-run: `python dev/data/tinyshakespeare.py`, then re-try")
        exit(1)
    assert header[1] == 1, "unsupported version"
    ntok = header[2] # number of tokens (claimed)
    return ntok # for now just return the number of tokens

def _load_data_shard(filename):
    with open(filename, "rb") as f:
        # first read the header, which is 256 int32 integers (4 bytes each)
        header = np.frombuffer(f.read(256*4), dtype=np.int32)
        assert header[0] == 20240520, "magic number mismatch in the data .bin file"
        assert header[1] == 1, "unsupported version"
        ntok = header[2] # number of tokens (claimed)
        # the rest of it are tokens, stored as uint16
        tokens = np.frombuffer(f.read(), dtype=np.uint16)
    assert len(tokens) == ntok, "number of tokens read does not match header?"
    return tokens

class DistributedDataLoader:
    def __init__(self, filename_pattern, B, T, process_rank, num_processes):
        self.process_rank = process_rank
        self.num_processes = num_processes
        self.B = B
        self.T = T

        # glob files that match the pattern
        self.files = sorted(glob.glob(filename_pattern))
        assert len(self.files) > 0, f"did not find any files that match the pattern {filename_pattern}"

        # load and validate all data shards, count number of tokens in total
        ntok_total = 0
        for fname in self.files:
            shard_ntok = _peek_data_shard(fname)
            assert shard_ntok >= num_processes * B * T + 1
            ntok_total += int(shard_ntok)
        self.ntok_total = ntok_total

        self.reset()

    def reset(self):
        self.current_shard = -1
        self.advance()

    def advance(self): # advance to next data shard
        self.current_shard = (self.current_shard + 1) % len(self.files)
        self.current_position = self.process_rank * self.B * self.T
        self.tokens = _load_data_shard(self.files[self.current_shard])

    def next_batch(self):
        batch_size = self.B * self.T * self.num_processes
        buf = self.tokens[self.current_position:self.current_position+self.B*self.T+1]
        buf = torch.tensor(buf.astype(np.int32), dtype=torch.long)
        x = buf[:-1] # inputs
        y = buf[1:] # targets
        # advance current position and load next shard if necessary
        self.current_position += batch_size
        if self.current_position + batch_size >= len(self.tokens):
            self.advance()
        return x.cuda(), y.cuda()

# -----------------------------------------------------------------------------
# int main

@dataclass
class Hyperparameters:
    # data hyperparams
    input_bin : str = 'data/fineweb10B/fineweb_train_*.bin' # input .bin to train on
    input_val_bin : str = 'data/fineweb10B/fineweb_val_*.bin' # input .bin to eval validation loss on
    # optimization hyperparams
    batch_size : int = 8 # batch size, in sequences, across all devices
    device_batch_size : int = 1 # batch size, in sequences, per device
    sequence_length : int = 64*1024 # sequence length, in tokens
    num_iterations : int = 1875 # number of iterations to run
    warmup_iters : int = 0
    warmdown_iters : int = 562 # number of iterations of linear warmup/warmdown for triangular or trapezoidal schedule
    weight_decay : float = 0
    # evaluation and logging hyperparams
    val_loss_every : int = 125 # every how many steps to evaluate val loss? 0 for only at the end
    val_tokens : int = 10485760 # how many tokens of validation data? it's important to keep this fixed for consistent comparisons
    save_every : int = 0 # every how many steps to save the checkpoint? 0 for only at the end
args = Hyperparameters()

# set up DDP (distributed data parallel). torchrun sets this env variable
assert torch.cuda.is_available()
dist.init_process_group(backend='nccl')
ddp_rank = int(os.environ['RANK'])
ddp_local_rank = int(os.environ['LOCAL_RANK'])
ddp_world_size = int(os.environ['WORLD_SIZE'])
device = f'cuda:{ddp_local_rank}'
torch.cuda.set_device(device)
print(f"using device: {device}")
master_process = (ddp_rank == 0) # this process will do logging, checkpointing etc.

# begin logging
logfile = None
if master_process:
    run_id = str(uuid.uuid4())
    logdir = 'logs/%s/' % run_id
    os.makedirs(logdir, exist_ok=True)
    logfile = 'logs/%s.txt' % run_id
    # create the log file
    with open(logfile, "w") as f:
        # begin the log by printing this file (the Python code)
        f.write('='*100 + '\n')
        f.write(code)
        f.write('='*100 + '\n')
def print0(s, logonly=False):
    if master_process:
        with open(logfile, "a") as f:
            if not logonly:
                print(s)
            f.write(s+'\n')
# log information about the hardware/software environment this is running on
# and print the full `nvidia-smi` to file
print0(f"Running pytorch {torch.version.__version__} compiled for CUDA {torch.version.cuda}\nnvidia-smi:")
import subprocess
result = subprocess.run(['nvidia-smi'], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
print0(f'{result.stdout}', logonly=True)
print0('='*100, logonly=True)

# convenience variables
B, T = args.device_batch_size, args.sequence_length
# calculate the number of steps to take in the val loop.
assert args.val_tokens % (B * T * ddp_world_size) == 0
val_steps = args.val_tokens // (B * T * ddp_world_size)
# calculate the steps of gradient accumulation required to attain the desired global batch size.
assert args.batch_size % (B * ddp_world_size) == 0
train_accumulation_steps = args.batch_size // (B * ddp_world_size)

# load tokens
train_loader = DistributedDataLoader(args.input_bin, B, T, ddp_rank, ddp_world_size)
val_loader = DistributedDataLoader(args.input_val_bin, B, T, ddp_rank, ddp_world_size)
print0(f"Training DataLoader: total number of tokens: {train_loader.ntok_total} across {len(train_loader.files)} files")
print0(f"Validation DataLoader: total number of tokens: {val_loader.ntok_total} across {len(val_loader.files)} files")
print0('='*100, logonly=True)
x, y = train_loader.next_batch()

# there are only 50257 unique GPT-2 tokens; we extend to nearest multiple of 128 for efficiency. suggested to me by @Grad62304977.
# this originates from Karpathy's experiments.
num_vocab = 50304
model = GPT(GPTConfig(vocab_size=num_vocab, n_layer=12, n_head=6, n_embd=768))
model = model.cuda().bfloat16()
for m in model.modules():
    if isinstance(m, CastedLinear):
        m.float()
if hasattr(config, "coordinate_descent_tuning"):
    config.coordinate_descent_tuning = True # suggested by @Chillee
model = torch.compile(model)
# here we wrap model into DDP container
model = DDP(model, device_ids=[ddp_local_rank])
raw_model = model.module # always contains the "raw" unwrapped model

# CUDNN attention is ~4ms faster than Flash, but doesn't get selected by default in PyTorch 2.5.1
from torch.backends.cuda import enable_cudnn_sdp, enable_flash_sdp, enable_math_sdp, enable_mem_efficient_sdp
enable_cudnn_sdp(True)
enable_flash_sdp(False)
enable_mem_efficient_sdp(False)
enable_math_sdp(False)

# init the optimizer(s)
optimizer1 = torch.optim.Adam([raw_model.transformer.wte.weight], lr=0.6,   betas=(0.9, 0.95), fused=True)
optimizer2 = torch.optim.Adam([raw_model.lm_head.weight],         lr=0.008, betas=(0.9, 0.95), fused=True)
param_names = [name for name, _ in raw_model.named_parameters()]
params = list(raw_model.transformer.h.parameters())
non_att_matrix_params = [
    p
    for p, name in zip(params, param_names)
    if p.ndim == 2 and "c_q" not in name and "c_k" not in name
]
att_matrix_params = [
    p
    for p, name in zip(params, param_names)
    if p.ndim == 2 and ("c_q" in name or "c_k" in name)
]
scalar_params = [p for p in params if p.ndim < 2] + [raw_model.skip_weights]
# optimizer3 = Muon(matrix_params, lr=0.04, momentum=0.95)
optimizer3 = Muon(att_matrix_params, lr=0.04, momentum=0.95)
optimizer5 = torch.optim.AdamW(non_att_matrix_params, lr=0.0018, betas=(0.9, 0.95),
                               weight_decay=args.weight_decay, fused=True)
optimizer4 = torch.optim.Adam(scalar_params, lr=0.04, betas=(0.9, 0.95), fused=True) # note that this learning rate is neither sensitive nor tuned
optimizers = [optimizer1, optimizer2, optimizer3, optimizer4, optimizer5]
# learning rate decay scheduler (linear warmup and warmdown)
def get_lr(it):
    assert it <= args.num_iterations
    # 1) linear warmup for warmup_iters steps
    if it < args.warmup_iters:
        return (it+1) / args.warmup_iters
    # 2) constant lr for a while
    elif it < args.num_iterations - args.warmdown_iters:
        return 1.0
    # 3) linear warmdown
    else:
        decay_ratio = (args.num_iterations - it) / args.warmdown_iters
        return decay_ratio
schedulers = [torch.optim.lr_scheduler.LambdaLR(opt, get_lr) for opt in optimizers]

# Start training loop
training_time_ms = 0
# start the clock
torch.cuda.synchronize()
t0 = time.time()
# begin training
for step in range(args.num_iterations + 1):
    last_step = (step == args.num_iterations)
    # This effectively ignores timing first 10 steps, which are slower for weird reasons.
    # Alternately, and slightly more correctly in terms of benchmarking, we could do 10
    # steps with dummy data first, and then re-initialize the model and reset the loader.
    if step == 10:
        training_time_ms = 0
        t0 = time.time()
    timed_steps = float('nan') if step <= 11 else (step - 10) + 1 # <= 11 to avoid bug in val

    # once in a while evaluate the validation dataset
    if (last_step or (args.val_loss_every > 0 and step % args.val_loss_every == 0)):
        # stop the clock
        torch.cuda.synchronize()
        training_time_ms += 1000 * (time.time() - t0)
        # run validation batches
        model.eval()
        val_loader.reset()
        val_loss = 0.0
        for _ in range(val_steps):
            with torch.no_grad():
                x_val, y_val = val_loader.next_batch()
                val_loss += model(x_val, y_val)
        dist.all_reduce(val_loss, op=dist.ReduceOp.AVG)
        val_loss /= val_steps
        # log val loss to console and to logfile
        print0(f'step:{step}/{args.num_iterations} val_loss:{val_loss:.4f} train_time:{training_time_ms:.0f}ms step_avg:{training_time_ms/(timed_steps-1):.2f}ms')
        if master_process:
            with open(logfile, "a") as f:
                print("============== Weight norms: ==============")
                f.write("============== Weight norms: ==============\n")
                for name, p in model.named_parameters():
                    if p.ndim != 2:
                        continue
                    if "c_q" not in name and "c_k" not in name:
                        continue
                    fro_norm = torch.linalg.norm(p.data.float(), ord="fro").item()
                    spectral_norm = torch.linalg.matrix_norm(p.data.float(), ord=2).item()
                    nuclear_norm = torch.linalg.matrix_norm(p.data.float(), ord="nuc").item()
                    print(f"{name = } | {fro_norm = :.5f} | {spectral_norm = :.5f} | {nuclear_norm = :.5f}")
                    f.write(f"{name = } | {fro_norm = :.5f} | {spectral_norm = :.5f} | {nuclear_norm = :.5f}\n")
                f.write("===========================================\n")
                print("===========================================")
        # start the clock again
        torch.cuda.synchronize()
        t0 = time.time()

    if master_process and (last_step or (args.save_every > 0 and step % args.save_every == 0)):
        # stop the clock
        torch.cuda.synchronize()
        training_time_ms += 1000 * (time.time() - t0)
        # save the state of the training process
        log = dict(step=step, code=code, model=raw_model.state_dict(), optimizers=[opt.state_dict() for opt in optimizers])
        torch.save(log, 'logs/%s/state_step%06d.pt' % (run_id, step))
        # start the clock again
        torch.cuda.synchronize()
        t0 = time.time()

    # bit confusing: we want to make sure to eval on 0th iteration
    # but also after the very last iteration. so we loop for step <= num_iterations
    # instead of just < num_iterations (one extra due to <=), only to do
    # the validation/sampling one last time, and then we break right here as we're done.
    if last_step:
        break

    # --------------- TRAINING SECTION BEGIN -----------------
    model.train()
    for i in range(1, train_accumulation_steps+1):
        # forward pass
        loss = model(x, y)
        train_loss = loss.detach()
        # advance the dataset for the next batch
        x, y = train_loader.next_batch()
        # backward pass
        if i < train_accumulation_steps:
            with model.no_sync(): # there's no need to sync gradients every accumulation step
                loss.backward()
        else:
            loss.backward() # just sync on the last step
    for p in model.parameters():
        p.grad /= train_accumulation_steps
    # momentum warmup for Muon
    frac = min(step/500, 1)
    optimizer3.param_groups[0]['momentum'] = (1 - frac) * 0.85 + frac * 0.95
    # step the optimizers and schedulers
    for opt, sched in zip(optimizers, schedulers):
        opt.step()
        sched.step()
    # null the gradients
    model.zero_grad(set_to_none=True)
    # --------------- TRAINING SECTION END -------------------
    # everything that follows now is just diagnostics, prints, logging, etc.

    #dist.all_reduce(train_loss, op=dist.ReduceOp.AVG) # all-reducing the training loss would be more correct in terms of logging, but slower
    approx_time = training_time_ms + 1000 * (time.time() - t0)
    print0(f"step:{step+1}/{args.num_iterations} train_loss:{train_loss.item():.4f} train_time:{approx_time:.0f}ms step_avg:{approx_time/timed_steps:.2f}ms")

if master_process:
    print(f"peak memory consumption: {torch.cuda.max_memory_allocated() // 1024 // 1024} MiB")

# -------------------------------------------------------------------------
# clean up nice
dist.destroy_process_group()
====================================================================================================
Running pytorch 2.6.0.dev20241122+cu124 compiled for CUDA 12.4
nvidia-smi:
Fri Nov 22 14:36:21 2024       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A100-SXM4-80GB          On  |   00000000:48:00.0 Off |                    0 |
| N/A   31C    P0             63W /  400W |       3MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA A100-SXM4-80GB          On  |   00000000:4E:00.0 Off |                    0 |
| N/A   27C    P0             66W /  400W |      29MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA A100-SXM4-80GB          On  |   00000000:9B:00.0 Off |                    0 |
| N/A   28C    P0             69W /  400W |      23MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA A100-SXM4-80GB          On  |   00000000:A1:00.0 Off |                    0 |
| N/A   32C    P0             70W /  400W |      33MiB /  81920MiB |      1%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
+-----------------------------------------------------------------------------------------+

====================================================================================================
Training DataLoader: total number of tokens: 1100000000 across 11 files
Validation DataLoader: total number of tokens: 100000000 across 1 files
====================================================================================================
step:0/1875 val_loss:10.8258 train_time:0ms step_avg:nanms
============== Weight norms: ==============
name = 'module._orig_mod.transformer.h.0.attn.c_q.weight' | fro_norm = 16.01196 | spectral_norm = 1.14615 | nuclear_norm = 376.86722
name = 'module._orig_mod.transformer.h.0.attn.c_k.weight' | fro_norm = 15.99174 | spectral_norm = 1.15867 | nuclear_norm = 376.17804
name = 'module._orig_mod.transformer.h.1.attn.c_q.weight' | fro_norm = 15.99440 | spectral_norm = 1.16063 | nuclear_norm = 376.25580
name = 'module._orig_mod.transformer.h.1.attn.c_k.weight' | fro_norm = 16.00596 | spectral_norm = 1.14348 | nuclear_norm = 376.35742
name = 'module._orig_mod.transformer.h.2.attn.c_q.weight' | fro_norm = 16.01415 | spectral_norm = 1.14409 | nuclear_norm = 376.61618
name = 'module._orig_mod.transformer.h.2.attn.c_k.weight' | fro_norm = 15.99946 | spectral_norm = 1.14640 | nuclear_norm = 376.57043
name = 'module._orig_mod.transformer.h.3.attn.c_q.weight' | fro_norm = 16.00552 | spectral_norm = 1.15701 | nuclear_norm = 376.49014
name = 'module._orig_mod.transformer.h.3.attn.c_k.weight' | fro_norm = 15.98900 | spectral_norm = 1.15091 | nuclear_norm = 375.90295
name = 'module._orig_mod.transformer.h.4.attn.c_q.weight' | fro_norm = 15.99520 | spectral_norm = 1.14421 | nuclear_norm = 376.22675
name = 'module._orig_mod.transformer.h.4.attn.c_k.weight' | fro_norm = 15.99492 | spectral_norm = 1.14628 | nuclear_norm = 376.38818
name = 'module._orig_mod.transformer.h.5.attn.c_q.weight' | fro_norm = 15.98089 | spectral_norm = 1.13620 | nuclear_norm = 376.15735
name = 'module._orig_mod.transformer.h.5.attn.c_k.weight' | fro_norm = 16.01217 | spectral_norm = 1.14897 | nuclear_norm = 376.59149
name = 'module._orig_mod.transformer.h.6.attn.c_q.weight' | fro_norm = 16.00599 | spectral_norm = 1.14740 | nuclear_norm = 376.67828
name = 'module._orig_mod.transformer.h.6.attn.c_k.weight' | fro_norm = 16.00540 | spectral_norm = 1.14504 | nuclear_norm = 376.41272
name = 'module._orig_mod.transformer.h.7.attn.c_q.weight' | fro_norm = 15.99145 | spectral_norm = 1.14437 | nuclear_norm = 376.11182
name = 'module._orig_mod.transformer.h.7.attn.c_k.weight' | fro_norm = 15.99689 | spectral_norm = 1.15496 | nuclear_norm = 376.18579
name = 'module._orig_mod.transformer.h.8.attn.c_q.weight' | fro_norm = 16.00258 | spectral_norm = 1.15013 | nuclear_norm = 376.26147
name = 'module._orig_mod.transformer.h.8.attn.c_k.weight' | fro_norm = 15.98882 | spectral_norm = 1.14956 | nuclear_norm = 375.90680
name = 'module._orig_mod.transformer.h.9.attn.c_q.weight' | fro_norm = 15.99204 | spectral_norm = 1.14384 | nuclear_norm = 376.40094
name = 'module._orig_mod.transformer.h.9.attn.c_k.weight' | fro_norm = 16.00423 | spectral_norm = 1.14164 | nuclear_norm = 376.52917
name = 'module._orig_mod.transformer.h.10.attn.c_q.weight' | fro_norm = 15.99639 | spectral_norm = 1.14850 | nuclear_norm = 376.25745
name = 'module._orig_mod.transformer.h.10.attn.c_k.weight' | fro_norm = 16.00113 | spectral_norm = 1.14685 | nuclear_norm = 376.59299
name = 'module._orig_mod.transformer.h.11.attn.c_q.weight' | fro_norm = 16.00627 | spectral_norm = 1.14213 | nuclear_norm = 376.57147
name = 'module._orig_mod.transformer.h.11.attn.c_k.weight' | fro_norm = 16.01252 | spectral_norm = 1.16375 | nuclear_norm = 376.65601
===========================================
step:1/1875 train_loss:10.8258 train_time:23256ms step_avg:nanms
step:2/1875 train_loss:10.1163 train_time:23840ms step_avg:nanms
step:3/1875 train_loss:9.1483 train_time:24552ms step_avg:nanms
step:4/1875 train_loss:7.9778 train_time:25269ms step_avg:nanms
step:5/1875 train_loss:7.6709 train_time:25987ms step_avg:nanms
step:6/1875 train_loss:7.4392 train_time:26699ms step_avg:nanms
step:7/1875 train_loss:7.4189 train_time:27424ms step_avg:nanms
step:8/1875 train_loss:6.8767 train_time:28149ms step_avg:nanms
step:9/1875 train_loss:7.1770 train_time:28881ms step_avg:nanms
step:10/1875 train_loss:6.9134 train_time:29607ms step_avg:nanms
step:11/1875 train_loss:6.8215 train_time:586ms step_avg:nanms
step:12/1875 train_loss:6.6480 train_time:1305ms step_avg:nanms
step:13/1875 train_loss:6.6681 train_time:2035ms step_avg:678.48ms
step:14/1875 train_loss:6.5783 train_time:2756ms step_avg:689.09ms
step:15/1875 train_loss:6.5461 train_time:3479ms step_avg:695.75ms
step:16/1875 train_loss:6.3561 train_time:4196ms step_avg:699.36ms
step:17/1875 train_loss:6.3239 train_time:4921ms step_avg:702.99ms
step:18/1875 train_loss:7.0098 train_time:5665ms step_avg:708.13ms
step:19/1875 train_loss:6.3110 train_time:6394ms step_avg:710.43ms
step:20/1875 train_loss:6.4313 train_time:7116ms step_avg:711.60ms
step:21/1875 train_loss:6.3154 train_time:7838ms step_avg:712.54ms
step:22/1875 train_loss:6.1147 train_time:8568ms step_avg:714.02ms
step:23/1875 train_loss:6.1516 train_time:9295ms step_avg:715.02ms
step:24/1875 train_loss:6.1748 train_time:10022ms step_avg:715.89ms
step:25/1875 train_loss:5.9709 train_time:10739ms step_avg:715.92ms
step:26/1875 train_loss:6.1224 train_time:11471ms step_avg:716.94ms
step:27/1875 train_loss:6.0526 train_time:12202ms step_avg:717.77ms
step:28/1875 train_loss:6.0459 train_time:12920ms step_avg:717.80ms
step:29/1875 train_loss:6.0372 train_time:13642ms step_avg:718.00ms
step:30/1875 train_loss:6.0865 train_time:14362ms step_avg:718.08ms
step:31/1875 train_loss:6.5514 train_time:15093ms step_avg:718.71ms
step:32/1875 train_loss:5.8913 train_time:15818ms step_avg:718.98ms
step:33/1875 train_loss:5.7564 train_time:16546ms step_avg:719.40ms
step:34/1875 train_loss:5.7754 train_time:17266ms step_avg:719.41ms
step:35/1875 train_loss:5.9930 train_time:18002ms step_avg:720.07ms
step:36/1875 train_loss:5.8959 train_time:18727ms step_avg:720.27ms
step:37/1875 train_loss:5.8891 train_time:19457ms step_avg:720.64ms
step:38/1875 train_loss:5.7006 train_time:20192ms step_avg:721.13ms
step:39/1875 train_loss:5.8093 train_time:20913ms step_avg:721.15ms
step:40/1875 train_loss:5.5918 train_time:21650ms step_avg:721.68ms
step:41/1875 train_loss:5.7503 train_time:22377ms step_avg:721.84ms
step:42/1875 train_loss:5.6362 train_time:23095ms step_avg:721.71ms
step:43/1875 train_loss:5.6575 train_time:23807ms step_avg:721.44ms
step:44/1875 train_loss:5.5324 train_time:24538ms step_avg:721.70ms
step:45/1875 train_loss:5.4364 train_time:25270ms step_avg:721.99ms
step:46/1875 train_loss:5.5275 train_time:26006ms step_avg:722.38ms
step:47/1875 train_loss:5.4255 train_time:26730ms step_avg:722.42ms
step:48/1875 train_loss:5.5567 train_time:27453ms step_avg:722.45ms
step:49/1875 train_loss:5.3884 train_time:28195ms step_avg:722.94ms
step:50/1875 train_loss:5.4660 train_time:28918ms step_avg:722.95ms
step:51/1875 train_loss:5.4708 train_time:29650ms step_avg:723.16ms
step:52/1875 train_loss:5.5454 train_time:30386ms step_avg:723.48ms
step:53/1875 train_loss:5.3958 train_time:31110ms step_avg:723.48ms
step:54/1875 train_loss:5.4234 train_time:31822ms step_avg:723.22ms
step:55/1875 train_loss:5.3265 train_time:32551ms step_avg:723.35ms
step:56/1875 train_loss:5.3442 train_time:33283ms step_avg:723.54ms
step:57/1875 train_loss:5.3644 train_time:34002ms step_avg:723.44ms
step:58/1875 train_loss:5.3759 train_time:34719ms step_avg:723.32ms
step:59/1875 train_loss:5.3910 train_time:35445ms step_avg:723.36ms
step:60/1875 train_loss:5.2562 train_time:36184ms step_avg:723.67ms
step:61/1875 train_loss:5.3787 train_time:36907ms step_avg:723.67ms
step:62/1875 train_loss:5.3853 train_time:37630ms step_avg:723.66ms
step:63/1875 train_loss:5.3113 train_time:38363ms step_avg:723.82ms
step:64/1875 train_loss:5.2869 train_time:39098ms step_avg:724.04ms
step:65/1875 train_loss:5.1279 train_time:39827ms step_avg:724.12ms
step:66/1875 train_loss:5.1339 train_time:40554ms step_avg:724.18ms
step:67/1875 train_loss:5.2919 train_time:41280ms step_avg:724.22ms
step:68/1875 train_loss:5.2603 train_time:42017ms step_avg:724.43ms
step:69/1875 train_loss:5.2923 train_time:42746ms step_avg:724.50ms
step:70/1875 train_loss:5.1770 train_time:43476ms step_avg:724.59ms
step:71/1875 train_loss:5.2284 train_time:44203ms step_avg:724.63ms
step:72/1875 train_loss:5.2149 train_time:44944ms step_avg:724.90ms
step:73/1875 train_loss:5.1980 train_time:45683ms step_avg:725.13ms
step:74/1875 train_loss:5.0544 train_time:46414ms step_avg:725.21ms
step:75/1875 train_loss:5.0878 train_time:47139ms step_avg:725.21ms
step:76/1875 train_loss:4.9973 train_time:47875ms step_avg:725.38ms
step:77/1875 train_loss:5.2205 train_time:48604ms step_avg:725.44ms
step:78/1875 train_loss:5.1186 train_time:49330ms step_avg:725.45ms
step:79/1875 train_loss:4.8360 train_time:50075ms step_avg:725.72ms
step:80/1875 train_loss:5.1387 train_time:50801ms step_avg:725.73ms
step:81/1875 train_loss:5.1043 train_time:51519ms step_avg:725.62ms
step:82/1875 train_loss:5.1078 train_time:52250ms step_avg:725.69ms
step:83/1875 train_loss:5.1417 train_time:52981ms step_avg:725.77ms
step:84/1875 train_loss:5.0231 train_time:53700ms step_avg:725.68ms
step:85/1875 train_loss:5.0591 train_time:54428ms step_avg:725.71ms
step:86/1875 train_loss:5.1098 train_time:55152ms step_avg:725.69ms
step:87/1875 train_loss:5.1435 train_time:55874ms step_avg:725.63ms
step:88/1875 train_loss:4.9768 train_time:56605ms step_avg:725.71ms
step:89/1875 train_loss:4.9650 train_time:57334ms step_avg:725.74ms
step:90/1875 train_loss:4.8923 train_time:58078ms step_avg:725.98ms
step:91/1875 train_loss:5.0661 train_time:58796ms step_avg:725.87ms
step:92/1875 train_loss:5.0261 train_time:59523ms step_avg:725.89ms
step:93/1875 train_loss:5.1897 train_time:60252ms step_avg:725.93ms
step:94/1875 train_loss:5.2149 train_time:60975ms step_avg:725.90ms
step:95/1875 train_loss:4.9455 train_time:61702ms step_avg:725.90ms
step:96/1875 train_loss:4.8981 train_time:62426ms step_avg:725.88ms
step:97/1875 train_loss:5.0592 train_time:63150ms step_avg:725.86ms
step:98/1875 train_loss:4.8863 train_time:63875ms step_avg:725.85ms
step:99/1875 train_loss:4.8845 train_time:64606ms step_avg:725.92ms
step:100/1875 train_loss:4.9321 train_time:65332ms step_avg:725.92ms
step:101/1875 train_loss:4.7860 train_time:66091ms step_avg:726.27ms
step:102/1875 train_loss:4.9469 train_time:66817ms step_avg:726.27ms
step:103/1875 train_loss:4.8321 train_time:67549ms step_avg:726.33ms
step:104/1875 train_loss:4.9695 train_time:68286ms step_avg:726.45ms
step:105/1875 train_loss:4.9591 train_time:69011ms step_avg:726.43ms
step:106/1875 train_loss:5.1135 train_time:69741ms step_avg:726.47ms
step:107/1875 train_loss:4.9172 train_time:70470ms step_avg:726.50ms
step:108/1875 train_loss:4.7749 train_time:71195ms step_avg:726.48ms
step:109/1875 train_loss:5.1318 train_time:71916ms step_avg:726.42ms
step:110/1875 train_loss:4.9439 train_time:72641ms step_avg:726.41ms
step:111/1875 train_loss:4.8333 train_time:73371ms step_avg:726.44ms
step:112/1875 train_loss:5.0300 train_time:74100ms step_avg:726.47ms
step:113/1875 train_loss:4.7130 train_time:74828ms step_avg:726.48ms
step:114/1875 train_loss:4.9220 train_time:75552ms step_avg:726.46ms
step:115/1875 train_loss:4.8198 train_time:76273ms step_avg:726.41ms
step:116/1875 train_loss:4.9360 train_time:77002ms step_avg:726.43ms
step:117/1875 train_loss:4.7273 train_time:77720ms step_avg:726.36ms
step:118/1875 train_loss:4.8913 train_time:78451ms step_avg:726.40ms
step:119/1875 train_loss:4.7957 train_time:79169ms step_avg:726.32ms
step:120/1875 train_loss:4.8776 train_time:79895ms step_avg:726.32ms
step:121/1875 train_loss:4.8445 train_time:80615ms step_avg:726.26ms
step:122/1875 train_loss:4.7124 train_time:81342ms step_avg:726.27ms
step:123/1875 train_loss:4.8050 train_time:82065ms step_avg:726.24ms
step:124/1875 train_loss:4.6728 train_time:82789ms step_avg:726.22ms
step:125/1875 train_loss:4.6646 train_time:83511ms step_avg:726.18ms
step:125/1875 val_loss:4.7758 train_time:83642ms step_avg:727.33ms
============== Weight norms: ==============
name = 'module._orig_mod.transformer.h.0.attn.c_q.weight' | fro_norm = 20.94995 | spectral_norm = 5.54147 | nuclear_norm = 438.84863
name = 'module._orig_mod.transformer.h.0.attn.c_k.weight' | fro_norm = 20.10192 | spectral_norm = 4.56758 | nuclear_norm = 429.94196
name = 'module._orig_mod.transformer.h.1.attn.c_q.weight' | fro_norm = 21.22304 | spectral_norm = 6.05878 | nuclear_norm = 439.06409
name = 'module._orig_mod.transformer.h.1.attn.c_k.weight' | fro_norm = 20.33481 | spectral_norm = 6.20852 | nuclear_norm = 431.19293
name = 'module._orig_mod.transformer.h.2.attn.c_q.weight' | fro_norm = 20.94190 | spectral_norm = 5.77779 | nuclear_norm = 432.99637
name = 'module._orig_mod.transformer.h.2.attn.c_k.weight' | fro_norm = 20.43144 | spectral_norm = 5.83189 | nuclear_norm = 431.37274
name = 'module._orig_mod.transformer.h.3.attn.c_q.weight' | fro_norm = 21.25813 | spectral_norm = 6.30855 | nuclear_norm = 438.52420
name = 'module._orig_mod.transformer.h.3.attn.c_k.weight' | fro_norm = 20.28322 | spectral_norm = 5.62255 | nuclear_norm = 430.23550
name = 'module._orig_mod.transformer.h.4.attn.c_q.weight' | fro_norm = 21.72866 | spectral_norm = 5.82943 | nuclear_norm = 446.39584
name = 'module._orig_mod.transformer.h.4.attn.c_k.weight' | fro_norm = 20.63699 | spectral_norm = 4.78175 | nuclear_norm = 439.71045
name = 'module._orig_mod.transformer.h.5.attn.c_q.weight' | fro_norm = 21.39741 | spectral_norm = 5.73861 | nuclear_norm = 441.93860
name = 'module._orig_mod.transformer.h.5.attn.c_k.weight' | fro_norm = 20.17719 | spectral_norm = 4.75099 | nuclear_norm = 431.41144
name = 'module._orig_mod.transformer.h.6.attn.c_q.weight' | fro_norm = 22.30498 | spectral_norm = 5.62973 | nuclear_norm = 456.03870
name = 'module._orig_mod.transformer.h.6.attn.c_k.weight' | fro_norm = 20.95336 | spectral_norm = 4.97289 | nuclear_norm = 442.59982
name = 'module._orig_mod.transformer.h.7.attn.c_q.weight' | fro_norm = 21.97004 | spectral_norm = 5.70398 | nuclear_norm = 451.47800
name = 'module._orig_mod.transformer.h.7.attn.c_k.weight' | fro_norm = 20.56794 | spectral_norm = 4.53016 | nuclear_norm = 439.21713
name = 'module._orig_mod.transformer.h.8.attn.c_q.weight' | fro_norm = 21.53662 | spectral_norm = 4.98791 | nuclear_norm = 446.13281
name = 'module._orig_mod.transformer.h.8.attn.c_k.weight' | fro_norm = 20.55363 | spectral_norm = 4.67491 | nuclear_norm = 439.37347
name = 'module._orig_mod.transformer.h.9.attn.c_q.weight' | fro_norm = 21.89743 | spectral_norm = 5.45908 | nuclear_norm = 449.30493
name = 'module._orig_mod.transformer.h.9.attn.c_k.weight' | fro_norm = 20.93644 | spectral_norm = 4.71902 | nuclear_norm = 442.08093
name = 'module._orig_mod.transformer.h.10.attn.c_q.weight' | fro_norm = 21.89480 | spectral_norm = 5.09462 | nuclear_norm = 448.32605
name = 'module._orig_mod.transformer.h.10.attn.c_k.weight' | fro_norm = 21.25379 | spectral_norm = 5.08577 | nuclear_norm = 447.17252
name = 'module._orig_mod.transformer.h.11.attn.c_q.weight' | fro_norm = 21.64451 | spectral_norm = 5.06288 | nuclear_norm = 448.79938
name = 'module._orig_mod.transformer.h.11.attn.c_k.weight' | fro_norm = 20.60620 | spectral_norm = 4.22185 | nuclear_norm = 441.56308
===========================================
step:126/1875 train_loss:4.6398 train_time:84229ms step_avg:726.11ms
step:127/1875 train_loss:4.8159 train_time:84948ms step_avg:726.05ms
step:128/1875 train_loss:4.8221 train_time:85673ms step_avg:726.04ms
step:129/1875 train_loss:4.7956 train_time:86396ms step_avg:726.02ms
step:130/1875 train_loss:4.8159 train_time:87138ms step_avg:726.15ms
step:131/1875 train_loss:4.9154 train_time:87868ms step_avg:726.18ms
step:132/1875 train_loss:4.6420 train_time:88599ms step_avg:726.22ms
step:133/1875 train_loss:4.6481 train_time:89316ms step_avg:726.15ms
step:134/1875 train_loss:4.7638 train_time:90040ms step_avg:726.13ms
step:135/1875 train_loss:4.6166 train_time:90764ms step_avg:726.11ms
step:136/1875 train_loss:4.6172 train_time:91489ms step_avg:726.10ms
step:137/1875 train_loss:4.6952 train_time:92223ms step_avg:726.17ms
step:138/1875 train_loss:4.7057 train_time:92943ms step_avg:726.12ms
step:139/1875 train_loss:4.7802 train_time:93665ms step_avg:726.08ms
step:140/1875 train_loss:4.6764 train_time:94389ms step_avg:726.07ms
step:141/1875 train_loss:4.5960 train_time:95125ms step_avg:726.14ms
step:142/1875 train_loss:4.6763 train_time:95848ms step_avg:726.12ms
step:143/1875 train_loss:4.7645 train_time:96575ms step_avg:726.13ms
step:144/1875 train_loss:5.0665 train_time:97302ms step_avg:726.14ms
step:145/1875 train_loss:4.6228 train_time:98022ms step_avg:726.09ms
step:146/1875 train_loss:4.6566 train_time:98751ms step_avg:726.11ms
step:147/1875 train_loss:4.6767 train_time:99470ms step_avg:726.06ms
step:148/1875 train_loss:4.4340 train_time:100193ms step_avg:726.04ms
step:149/1875 train_loss:4.7362 train_time:100930ms step_avg:726.11ms
step:150/1875 train_loss:4.6430 train_time:101661ms step_avg:726.15ms
step:151/1875 train_loss:4.5753 train_time:102383ms step_avg:726.12ms
step:152/1875 train_loss:4.5445 train_time:103120ms step_avg:726.20ms
step:153/1875 train_loss:4.6304 train_time:103858ms step_avg:726.28ms
step:154/1875 train_loss:4.4702 train_time:104581ms step_avg:726.26ms
step:155/1875 train_loss:4.4706 train_time:105303ms step_avg:726.23ms
step:156/1875 train_loss:4.6071 train_time:106035ms step_avg:726.27ms
step:157/1875 train_loss:4.6450 train_time:106772ms step_avg:726.34ms
step:158/1875 train_loss:4.5393 train_time:107488ms step_avg:726.27ms
step:159/1875 train_loss:4.4812 train_time:108211ms step_avg:726.25ms
step:160/1875 train_loss:4.4297 train_time:108934ms step_avg:726.22ms
step:161/1875 train_loss:4.5016 train_time:109658ms step_avg:726.21ms
step:162/1875 train_loss:4.5200 train_time:110378ms step_avg:726.17ms
step:163/1875 train_loss:4.4911 train_time:111102ms step_avg:726.15ms
step:164/1875 train_loss:4.4143 train_time:111826ms step_avg:726.14ms
step:165/1875 train_loss:4.4994 train_time:112555ms step_avg:726.16ms
step:166/1875 train_loss:4.6085 train_time:113283ms step_avg:726.17ms
step:167/1875 train_loss:4.4935 train_time:114007ms step_avg:726.16ms
step:168/1875 train_loss:4.4531 train_time:114733ms step_avg:726.16ms
step:169/1875 train_loss:4.5239 train_time:115462ms step_avg:726.17ms
step:170/1875 train_loss:4.5192 train_time:116210ms step_avg:726.32ms
step:171/1875 train_loss:3.9960 train_time:116959ms step_avg:726.46ms
step:172/1875 train_loss:4.3853 train_time:117694ms step_avg:726.51ms
step:173/1875 train_loss:4.3656 train_time:118419ms step_avg:726.50ms
step:174/1875 train_loss:4.5726 train_time:119137ms step_avg:726.45ms
step:175/1875 train_loss:4.3944 train_time:119862ms step_avg:726.43ms
step:176/1875 train_loss:4.4708 train_time:120589ms step_avg:726.44ms
step:177/1875 train_loss:4.5820 train_time:121312ms step_avg:726.42ms
step:178/1875 train_loss:4.4485 train_time:122036ms step_avg:726.40ms
step:179/1875 train_loss:4.3909 train_time:122764ms step_avg:726.41ms
step:180/1875 train_loss:4.4545 train_time:123485ms step_avg:726.39ms
step:181/1875 train_loss:4.3372 train_time:124207ms step_avg:726.36ms
step:182/1875 train_loss:4.3772 train_time:124928ms step_avg:726.33ms
step:183/1875 train_loss:4.3612 train_time:125656ms step_avg:726.33ms
step:184/1875 train_loss:4.5005 train_time:126381ms step_avg:726.33ms
step:185/1875 train_loss:4.3922 train_time:127106ms step_avg:726.32ms
step:186/1875 train_loss:4.4537 train_time:127834ms step_avg:726.33ms
step:187/1875 train_loss:4.4023 train_time:128563ms step_avg:726.34ms
step:188/1875 train_loss:4.3893 train_time:129296ms step_avg:726.38ms
step:189/1875 train_loss:4.1608 train_time:130026ms step_avg:726.40ms
step:190/1875 train_loss:4.3067 train_time:130969ms step_avg:727.61ms
step:191/1875 train_loss:4.2992 train_time:131713ms step_avg:727.70ms
step:192/1875 train_loss:4.2362 train_time:132445ms step_avg:727.72ms
step:193/1875 train_loss:4.4614 train_time:133185ms step_avg:727.79ms
step:194/1875 train_loss:4.3763 train_time:133922ms step_avg:727.83ms
step:195/1875 train_loss:4.5612 train_time:134645ms step_avg:727.81ms
step:196/1875 train_loss:4.4037 train_time:135367ms step_avg:727.78ms
step:197/1875 train_loss:4.2296 train_time:136105ms step_avg:727.83ms
step:198/1875 train_loss:4.3893 train_time:136829ms step_avg:727.82ms
step:199/1875 train_loss:4.2395 train_time:137551ms step_avg:727.78ms
step:200/1875 train_loss:4.3232 train_time:138280ms step_avg:727.79ms
step:201/1875 train_loss:4.1861 train_time:139014ms step_avg:727.82ms
step:202/1875 train_loss:4.4279 train_time:139747ms step_avg:727.85ms
step:203/1875 train_loss:4.2674 train_time:140474ms step_avg:727.85ms
step:204/1875 train_loss:4.4041 train_time:141197ms step_avg:727.82ms
step:205/1875 train_loss:4.4417 train_time:141928ms step_avg:727.84ms
step:206/1875 train_loss:4.1489 train_time:142657ms step_avg:727.84ms
step:207/1875 train_loss:4.2949 train_time:143383ms step_avg:727.83ms
step:208/1875 train_loss:4.2798 train_time:144108ms step_avg:727.82ms
step:209/1875 train_loss:4.4463 train_time:144833ms step_avg:727.81ms
step:210/1875 train_loss:4.3652 train_time:145573ms step_avg:727.87ms
step:211/1875 train_loss:4.2588 train_time:146302ms step_avg:727.87ms
step:212/1875 train_loss:4.2385 train_time:147028ms step_avg:727.86ms
step:213/1875 train_loss:4.2381 train_time:147760ms step_avg:727.88ms
step:214/1875 train_loss:4.3090 train_time:148493ms step_avg:727.91ms
step:215/1875 train_loss:4.1070 train_time:149221ms step_avg:727.91ms
step:216/1875 train_loss:4.1864 train_time:149946ms step_avg:727.89ms
step:217/1875 train_loss:4.1795 train_time:150668ms step_avg:727.87ms
step:218/1875 train_loss:4.2676 train_time:151391ms step_avg:727.84ms
step:219/1875 train_loss:4.2720 train_time:152111ms step_avg:727.80ms
step:220/1875 train_loss:4.2756 train_time:152830ms step_avg:727.76ms
step:221/1875 train_loss:4.2894 train_time:153562ms step_avg:727.78ms
step:222/1875 train_loss:4.1913 train_time:154297ms step_avg:727.82ms
step:223/1875 train_loss:4.1362 train_time:155021ms step_avg:727.80ms
step:224/1875 train_loss:4.4537 train_time:155751ms step_avg:727.81ms
step:225/1875 train_loss:4.0793 train_time:156478ms step_avg:727.80ms
step:226/1875 train_loss:4.1746 train_time:157201ms step_avg:727.78ms
step:227/1875 train_loss:4.1638 train_time:157923ms step_avg:727.75ms
step:228/1875 train_loss:4.3190 train_time:158643ms step_avg:727.72ms
step:229/1875 train_loss:4.0972 train_time:159370ms step_avg:727.71ms
step:230/1875 train_loss:4.2326 train_time:160106ms step_avg:727.75ms
step:231/1875 train_loss:4.0717 train_time:160831ms step_avg:727.74ms
step:232/1875 train_loss:4.1466 train_time:161554ms step_avg:727.72ms
step:233/1875 train_loss:4.2829 train_time:162276ms step_avg:727.70ms
step:234/1875 train_loss:4.2151 train_time:163011ms step_avg:727.73ms
step:235/1875 train_loss:4.0257 train_time:163751ms step_avg:727.78ms
step:236/1875 train_loss:4.2376 train_time:164480ms step_avg:727.79ms
step:237/1875 train_loss:4.2621 train_time:165215ms step_avg:727.82ms
step:238/1875 train_loss:4.1091 train_time:165944ms step_avg:727.83ms
step:239/1875 train_loss:4.2393 train_time:166677ms step_avg:727.85ms
step:240/1875 train_loss:4.2821 train_time:167404ms step_avg:727.85ms
step:241/1875 train_loss:4.1459 train_time:168148ms step_avg:727.91ms
step:242/1875 train_loss:4.3061 train_time:168878ms step_avg:727.92ms
step:243/1875 train_loss:4.1898 train_time:169606ms step_avg:727.92ms
step:244/1875 train_loss:4.2504 train_time:170330ms step_avg:727.91ms
step:245/1875 train_loss:4.3302 train_time:171053ms step_avg:727.88ms
step:246/1875 train_loss:4.2424 train_time:171779ms step_avg:727.88ms
step:247/1875 train_loss:4.1899 train_time:172506ms step_avg:727.87ms
step:248/1875 train_loss:4.2713 train_time:173238ms step_avg:727.89ms
step:249/1875 train_loss:4.1020 train_time:173962ms step_avg:727.87ms
step:250/1875 train_loss:4.1552 train_time:174683ms step_avg:727.85ms
step:250/1875 val_loss:4.1745 train_time:174816ms step_avg:728.40ms
============== Weight norms: ==============
name = 'module._orig_mod.transformer.h.0.attn.c_q.weight' | fro_norm = 23.48004 | spectral_norm = 5.81870 | nuclear_norm = 485.69162
name = 'module._orig_mod.transformer.h.0.attn.c_k.weight' | fro_norm = 22.17808 | spectral_norm = 6.27573 | nuclear_norm = 462.38550
name = 'module._orig_mod.transformer.h.1.attn.c_q.weight' | fro_norm = 23.59055 | spectral_norm = 6.78997 | nuclear_norm = 480.26016
name = 'module._orig_mod.transformer.h.1.attn.c_k.weight' | fro_norm = 22.15468 | spectral_norm = 7.67770 | nuclear_norm = 458.99295
name = 'module._orig_mod.transformer.h.2.attn.c_q.weight' | fro_norm = 23.48141 | spectral_norm = 5.69746 | nuclear_norm = 478.38306
name = 'module._orig_mod.transformer.h.2.attn.c_k.weight' | fro_norm = 22.42649 | spectral_norm = 6.69426 | nuclear_norm = 464.40863
name = 'module._orig_mod.transformer.h.3.attn.c_q.weight' | fro_norm = 23.78671 | spectral_norm = 6.63180 | nuclear_norm = 482.83270
name = 'module._orig_mod.transformer.h.3.attn.c_k.weight' | fro_norm = 22.32182 | spectral_norm = 6.72174 | nuclear_norm = 463.02899
name = 'module._orig_mod.transformer.h.4.attn.c_q.weight' | fro_norm = 24.39266 | spectral_norm = 5.92592 | nuclear_norm = 494.09579
name = 'module._orig_mod.transformer.h.4.attn.c_k.weight' | fro_norm = 22.92395 | spectral_norm = 5.44717 | nuclear_norm = 477.99490
name = 'module._orig_mod.transformer.h.5.attn.c_q.weight' | fro_norm = 23.91861 | spectral_norm = 6.08448 | nuclear_norm = 487.04120
name = 'module._orig_mod.transformer.h.5.attn.c_k.weight' | fro_norm = 22.39747 | spectral_norm = 5.65879 | nuclear_norm = 468.84851
name = 'module._orig_mod.transformer.h.6.attn.c_q.weight' | fro_norm = 24.54269 | spectral_norm = 5.53874 | nuclear_norm = 497.41968
name = 'module._orig_mod.transformer.h.6.attn.c_k.weight' | fro_norm = 23.05074 | spectral_norm = 5.56184 | nuclear_norm = 479.40424
name = 'module._orig_mod.transformer.h.7.attn.c_q.weight' | fro_norm = 24.26772 | spectral_norm = 5.42204 | nuclear_norm = 490.58408
name = 'module._orig_mod.transformer.h.7.attn.c_k.weight' | fro_norm = 22.82718 | spectral_norm = 4.40449 | nuclear_norm = 478.37552
name = 'module._orig_mod.transformer.h.8.attn.c_q.weight' | fro_norm = 23.94841 | spectral_norm = 5.27360 | nuclear_norm = 487.92358
name = 'module._orig_mod.transformer.h.8.attn.c_k.weight' | fro_norm = 22.70605 | spectral_norm = 4.75243 | nuclear_norm = 476.53152
name = 'module._orig_mod.transformer.h.9.attn.c_q.weight' | fro_norm = 24.10048 | spectral_norm = 5.16316 | nuclear_norm = 487.65247
name = 'module._orig_mod.transformer.h.9.attn.c_k.weight' | fro_norm = 22.98553 | spectral_norm = 4.89028 | nuclear_norm = 477.23178
name = 'module._orig_mod.transformer.h.10.attn.c_q.weight' | fro_norm = 24.10475 | spectral_norm = 5.16755 | nuclear_norm = 486.37018
name = 'module._orig_mod.transformer.h.10.attn.c_k.weight' | fro_norm = 23.40072 | spectral_norm = 4.97222 | nuclear_norm = 485.44403
name = 'module._orig_mod.transformer.h.11.attn.c_q.weight' | fro_norm = 23.92573 | spectral_norm = 5.23635 | nuclear_norm = 486.79434
name = 'module._orig_mod.transformer.h.11.attn.c_k.weight' | fro_norm = 22.55219 | spectral_norm = 4.41536 | nuclear_norm = 474.75555
===========================================
step:251/1875 train_loss:4.2434 train_time:175394ms step_avg:727.78ms
step:252/1875 train_loss:4.3080 train_time:176118ms step_avg:727.76ms
step:253/1875 train_loss:4.1115 train_time:176846ms step_avg:727.76ms
step:254/1875 train_loss:4.0383 train_time:177572ms step_avg:727.75ms
step:255/1875 train_loss:4.2272 train_time:178295ms step_avg:727.74ms
step:256/1875 train_loss:4.1398 train_time:179018ms step_avg:727.71ms
step:257/1875 train_loss:4.1687 train_time:179744ms step_avg:727.71ms
step:258/1875 train_loss:4.1466 train_time:180476ms step_avg:727.73ms
step:259/1875 train_loss:4.1963 train_time:181205ms step_avg:727.73ms
step:260/1875 train_loss:4.2278 train_time:181930ms step_avg:727.72ms
step:261/1875 train_loss:4.1819 train_time:182660ms step_avg:727.73ms
step:262/1875 train_loss:4.1685 train_time:183405ms step_avg:727.80ms
step:263/1875 train_loss:4.0829 train_time:184130ms step_avg:727.79ms
step:264/1875 train_loss:4.1530 train_time:184870ms step_avg:727.83ms
step:265/1875 train_loss:4.0244 train_time:185596ms step_avg:727.83ms
step:266/1875 train_loss:4.0981 train_time:186325ms step_avg:727.83ms
step:267/1875 train_loss:4.0940 train_time:187066ms step_avg:727.88ms
step:268/1875 train_loss:4.1361 train_time:187797ms step_avg:727.89ms
step:269/1875 train_loss:4.0305 train_time:188526ms step_avg:727.90ms
step:270/1875 train_loss:4.2528 train_time:189246ms step_avg:727.87ms
step:271/1875 train_loss:4.1430 train_time:189970ms step_avg:727.86ms
step:272/1875 train_loss:4.0770 train_time:190697ms step_avg:727.85ms
step:273/1875 train_loss:4.1206 train_time:191417ms step_avg:727.82ms
step:274/1875 train_loss:4.2009 train_time:192149ms step_avg:727.84ms
step:275/1875 train_loss:4.2239 train_time:192882ms step_avg:727.86ms
step:276/1875 train_loss:4.3581 train_time:193608ms step_avg:727.85ms
step:277/1875 train_loss:4.1988 train_time:194337ms step_avg:727.85ms
step:278/1875 train_loss:4.2470 train_time:195059ms step_avg:727.83ms
step:279/1875 train_loss:4.1619 train_time:195785ms step_avg:727.82ms
step:280/1875 train_loss:4.2638 train_time:196521ms step_avg:727.86ms
step:281/1875 train_loss:4.1139 train_time:197262ms step_avg:727.90ms
step:282/1875 train_loss:4.1029 train_time:198009ms step_avg:727.97ms
step:283/1875 train_loss:4.0814 train_time:198744ms step_avg:728.00ms
step:284/1875 train_loss:4.2009 train_time:199467ms step_avg:727.98ms
step:285/1875 train_loss:4.2203 train_time:200202ms step_avg:728.01ms
step:286/1875 train_loss:4.2438 train_time:200929ms step_avg:728.00ms
step:287/1875 train_loss:4.0683 train_time:201660ms step_avg:728.02ms
step:288/1875 train_loss:4.1827 train_time:202387ms step_avg:728.01ms
step:289/1875 train_loss:4.0134 train_time:203131ms step_avg:728.07ms
step:290/1875 train_loss:4.0127 train_time:203857ms step_avg:728.06ms
step:291/1875 train_loss:4.0953 train_time:204583ms step_avg:728.05ms
step:292/1875 train_loss:4.0269 train_time:205308ms step_avg:728.04ms
step:293/1875 train_loss:4.0606 train_time:206028ms step_avg:728.01ms
step:294/1875 train_loss:4.1086 train_time:206752ms step_avg:728.00ms
step:295/1875 train_loss:4.0002 train_time:207482ms step_avg:728.01ms
step:296/1875 train_loss:4.0355 train_time:208216ms step_avg:728.03ms
step:297/1875 train_loss:4.0181 train_time:208946ms step_avg:728.03ms
step:298/1875 train_loss:4.1241 train_time:209676ms step_avg:728.04ms
step:299/1875 train_loss:3.9867 train_time:210411ms step_avg:728.07ms
step:300/1875 train_loss:4.1171 train_time:211145ms step_avg:728.09ms
step:301/1875 train_loss:4.1302 train_time:211868ms step_avg:728.07ms
step:302/1875 train_loss:4.0922 train_time:212592ms step_avg:728.05ms
step:303/1875 train_loss:4.1302 train_time:213312ms step_avg:728.03ms
step:304/1875 train_loss:4.1116 train_time:214031ms step_avg:728.00ms
step:305/1875 train_loss:4.5988 train_time:214753ms step_avg:727.98ms
step:306/1875 train_loss:4.1143 train_time:215477ms step_avg:727.96ms
step:307/1875 train_loss:3.9930 train_time:216210ms step_avg:727.98ms
step:308/1875 train_loss:4.1318 train_time:216945ms step_avg:728.00ms
step:309/1875 train_loss:3.9980 train_time:217667ms step_avg:727.98ms
step:310/1875 train_loss:4.2371 train_time:218395ms step_avg:727.98ms
step:311/1875 train_loss:4.0608 train_time:219121ms step_avg:727.98ms
step:312/1875 train_loss:4.0176 train_time:219847ms step_avg:727.97ms
step:313/1875 train_loss:4.1141 train_time:220587ms step_avg:728.01ms
step:314/1875 train_loss:4.2202 train_time:221314ms step_avg:728.01ms
step:315/1875 train_loss:4.0861 train_time:222044ms step_avg:728.01ms
step:316/1875 train_loss:3.9308 train_time:222765ms step_avg:727.99ms
step:317/1875 train_loss:4.0191 train_time:223501ms step_avg:728.02ms
step:318/1875 train_loss:4.0795 train_time:224233ms step_avg:728.03ms
step:319/1875 train_loss:4.0549 train_time:224962ms step_avg:728.03ms
step:320/1875 train_loss:4.1582 train_time:225689ms step_avg:728.03ms
step:321/1875 train_loss:4.1072 train_time:226416ms step_avg:728.03ms
step:322/1875 train_loss:4.0654 train_time:227148ms step_avg:728.04ms
step:323/1875 train_loss:4.1402 train_time:227873ms step_avg:728.03ms
step:324/1875 train_loss:4.1068 train_time:228598ms step_avg:728.02ms
step:325/1875 train_loss:4.1716 train_time:229331ms step_avg:728.03ms
step:326/1875 train_loss:4.0308 train_time:230053ms step_avg:728.01ms
step:327/1875 train_loss:4.5333 train_time:230786ms step_avg:728.03ms
step:328/1875 train_loss:4.2262 train_time:231525ms step_avg:728.07ms
step:329/1875 train_loss:3.9570 train_time:232290ms step_avg:728.18ms
step:330/1875 train_loss:3.8796 train_time:233017ms step_avg:728.18ms
step:331/1875 train_loss:4.1234 train_time:233747ms step_avg:728.18ms
step:332/1875 train_loss:4.0580 train_time:234472ms step_avg:728.17ms
step:333/1875 train_loss:4.0226 train_time:235193ms step_avg:728.15ms
step:334/1875 train_loss:3.9902 train_time:235925ms step_avg:728.16ms
step:335/1875 train_loss:4.1564 train_time:236653ms step_avg:728.16ms
step:336/1875 train_loss:4.1103 train_time:237375ms step_avg:728.14ms
step:337/1875 train_loss:4.5329 train_time:238117ms step_avg:728.19ms
step:338/1875 train_loss:4.1055 train_time:238852ms step_avg:728.21ms
step:339/1875 train_loss:4.0016 train_time:239591ms step_avg:728.24ms
step:340/1875 train_loss:4.0813 train_time:240314ms step_avg:728.22ms
step:341/1875 train_loss:4.0109 train_time:241046ms step_avg:728.23ms
step:342/1875 train_loss:3.9630 train_time:241765ms step_avg:728.21ms
step:343/1875 train_loss:3.9899 train_time:242498ms step_avg:728.22ms
step:344/1875 train_loss:4.1592 train_time:243227ms step_avg:728.23ms
step:345/1875 train_loss:3.9755 train_time:243964ms step_avg:728.25ms
step:346/1875 train_loss:3.9118 train_time:244693ms step_avg:728.25ms
step:347/1875 train_loss:3.9368 train_time:245432ms step_avg:728.28ms
step:348/1875 train_loss:4.0048 train_time:246162ms step_avg:728.29ms
step:349/1875 train_loss:3.9824 train_time:246885ms step_avg:728.27ms
step:350/1875 train_loss:3.7165 train_time:247616ms step_avg:728.28ms
step:351/1875 train_loss:3.9742 train_time:248344ms step_avg:728.28ms
step:352/1875 train_loss:4.3320 train_time:249073ms step_avg:728.28ms
step:353/1875 train_loss:3.7934 train_time:249803ms step_avg:728.29ms
step:354/1875 train_loss:4.0920 train_time:250533ms step_avg:728.29ms
step:355/1875 train_loss:3.9385 train_time:251267ms step_avg:728.31ms
step:356/1875 train_loss:4.0341 train_time:251991ms step_avg:728.30ms
step:357/1875 train_loss:3.9199 train_time:252716ms step_avg:728.29ms
step:358/1875 train_loss:3.9925 train_time:253455ms step_avg:728.32ms
step:359/1875 train_loss:3.9028 train_time:254195ms step_avg:728.35ms
step:360/1875 train_loss:3.5916 train_time:254939ms step_avg:728.40ms
step:361/1875 train_loss:4.1568 train_time:255678ms step_avg:728.43ms
step:362/1875 train_loss:4.0468 train_time:256410ms step_avg:728.44ms
step:363/1875 train_loss:3.9888 train_time:257135ms step_avg:728.43ms
step:364/1875 train_loss:3.8837 train_time:257877ms step_avg:728.47ms
step:365/1875 train_loss:4.0447 train_time:258609ms step_avg:728.48ms
step:366/1875 train_loss:4.0190 train_time:259353ms step_avg:728.52ms
step:367/1875 train_loss:4.0029 train_time:260076ms step_avg:728.50ms
step:368/1875 train_loss:4.0004 train_time:260815ms step_avg:728.53ms
step:369/1875 train_loss:3.8877 train_time:261542ms step_avg:728.53ms
step:370/1875 train_loss:4.0531 train_time:262268ms step_avg:728.52ms
step:371/1875 train_loss:3.8922 train_time:262993ms step_avg:728.51ms
step:372/1875 train_loss:3.8304 train_time:263716ms step_avg:728.50ms
step:373/1875 train_loss:4.0656 train_time:264441ms step_avg:728.49ms
step:374/1875 train_loss:3.9841 train_time:265163ms step_avg:728.47ms
step:375/1875 train_loss:3.9442 train_time:265888ms step_avg:728.46ms
step:375/1875 val_loss:3.9694 train_time:266026ms step_avg:728.84ms
============== Weight norms: ==============
name = 'module._orig_mod.transformer.h.0.attn.c_q.weight' | fro_norm = 26.13354 | spectral_norm = 6.54010 | nuclear_norm = 532.74969
name = 'module._orig_mod.transformer.h.0.attn.c_k.weight' | fro_norm = 24.49924 | spectral_norm = 7.89115 | nuclear_norm = 498.79944
name = 'module._orig_mod.transformer.h.1.attn.c_q.weight' | fro_norm = 25.99666 | spectral_norm = 7.19661 | nuclear_norm = 523.46570
name = 'module._orig_mod.transformer.h.1.attn.c_k.weight' | fro_norm = 24.20057 | spectral_norm = 8.58940 | nuclear_norm = 493.46570
name = 'module._orig_mod.transformer.h.2.attn.c_q.weight' | fro_norm = 25.99897 | spectral_norm = 5.84203 | nuclear_norm = 524.54315
name = 'module._orig_mod.transformer.h.2.attn.c_k.weight' | fro_norm = 24.62226 | spectral_norm = 7.02496 | nuclear_norm = 503.37924
name = 'module._orig_mod.transformer.h.3.attn.c_q.weight' | fro_norm = 26.08175 | spectral_norm = 6.70557 | nuclear_norm = 525.46936
name = 'module._orig_mod.transformer.h.3.attn.c_k.weight' | fro_norm = 24.42777 | spectral_norm = 7.15127 | nuclear_norm = 500.87744
name = 'module._orig_mod.transformer.h.4.attn.c_q.weight' | fro_norm = 26.62424 | spectral_norm = 5.84160 | nuclear_norm = 534.27429
name = 'module._orig_mod.transformer.h.4.attn.c_k.weight' | fro_norm = 25.05140 | spectral_norm = 5.68914 | nuclear_norm = 515.44226
name = 'module._orig_mod.transformer.h.5.attn.c_q.weight' | fro_norm = 26.09396 | spectral_norm = 6.13363 | nuclear_norm = 527.49890
name = 'module._orig_mod.transformer.h.5.attn.c_k.weight' | fro_norm = 24.50172 | spectral_norm = 6.00632 | nuclear_norm = 506.82904
name = 'module._orig_mod.transformer.h.6.attn.c_q.weight' | fro_norm = 26.48445 | spectral_norm = 5.86912 | nuclear_norm = 533.95721
name = 'module._orig_mod.transformer.h.6.attn.c_k.weight' | fro_norm = 25.00806 | spectral_norm = 6.11071 | nuclear_norm = 514.77509
name = 'module._orig_mod.transformer.h.7.attn.c_q.weight' | fro_norm = 26.22167 | spectral_norm = 5.46953 | nuclear_norm = 524.40845
name = 'module._orig_mod.transformer.h.7.attn.c_k.weight' | fro_norm = 24.67696 | spectral_norm = 4.57986 | nuclear_norm = 510.80450
name = 'module._orig_mod.transformer.h.8.attn.c_q.weight' | fro_norm = 26.12898 | spectral_norm = 5.52109 | nuclear_norm = 526.79095
name = 'module._orig_mod.transformer.h.8.attn.c_k.weight' | fro_norm = 24.74138 | spectral_norm = 5.05730 | nuclear_norm = 513.10559
name = 'module._orig_mod.transformer.h.9.attn.c_q.weight' | fro_norm = 26.10487 | spectral_norm = 5.24328 | nuclear_norm = 523.24353
name = 'module._orig_mod.transformer.h.9.attn.c_k.weight' | fro_norm = 24.95823 | spectral_norm = 5.03955 | nuclear_norm = 512.09320
name = 'module._orig_mod.transformer.h.10.attn.c_q.weight' | fro_norm = 26.10275 | spectral_norm = 5.37283 | nuclear_norm = 520.52930
name = 'module._orig_mod.transformer.h.10.attn.c_k.weight' | fro_norm = 25.29160 | spectral_norm = 5.18560 | nuclear_norm = 518.30231
name = 'module._orig_mod.transformer.h.11.attn.c_q.weight' | fro_norm = 25.93516 | spectral_norm = 5.36666 | nuclear_norm = 521.29333
name = 'module._orig_mod.transformer.h.11.attn.c_k.weight' | fro_norm = 24.38985 | spectral_norm = 4.76896 | nuclear_norm = 506.14328
===========================================
step:376/1875 train_loss:4.0216 train_time:266610ms step_avg:728.44ms
step:377/1875 train_loss:3.9242 train_time:267352ms step_avg:728.48ms
step:378/1875 train_loss:3.9898 train_time:268099ms step_avg:728.53ms
step:379/1875 train_loss:4.0360 train_time:268827ms step_avg:728.53ms
step:380/1875 train_loss:4.0872 train_time:269768ms step_avg:729.10ms
step:381/1875 train_loss:3.8580 train_time:270727ms step_avg:729.72ms
step:382/1875 train_loss:3.9271 train_time:271471ms step_avg:729.76ms
step:383/1875 train_loss:3.9354 train_time:272209ms step_avg:729.78ms
step:384/1875 train_loss:4.0260 train_time:272938ms step_avg:729.78ms
step:385/1875 train_loss:3.8242 train_time:273670ms step_avg:729.79ms
step:386/1875 train_loss:4.0209 train_time:274393ms step_avg:729.77ms
step:387/1875 train_loss:3.9298 train_time:275132ms step_avg:729.79ms
step:388/1875 train_loss:4.0881 train_time:275856ms step_avg:729.78ms
step:389/1875 train_loss:3.9579 train_time:276576ms step_avg:729.75ms
step:390/1875 train_loss:3.9991 train_time:277313ms step_avg:729.77ms
step:391/1875 train_loss:3.8588 train_time:278046ms step_avg:729.78ms
step:392/1875 train_loss:3.9283 train_time:278769ms step_avg:729.76ms
step:393/1875 train_loss:3.9671 train_time:279495ms step_avg:729.75ms
step:394/1875 train_loss:3.9453 train_time:280217ms step_avg:729.73ms
step:395/1875 train_loss:3.9538 train_time:280947ms step_avg:729.73ms
step:396/1875 train_loss:3.8766 train_time:281685ms step_avg:729.75ms
step:397/1875 train_loss:3.7266 train_time:282418ms step_avg:729.76ms
step:398/1875 train_loss:3.9706 train_time:283144ms step_avg:729.75ms
step:399/1875 train_loss:3.9221 train_time:283872ms step_avg:729.75ms
step:400/1875 train_loss:3.8610 train_time:284597ms step_avg:729.74ms
step:401/1875 train_loss:3.9620 train_time:285325ms step_avg:729.73ms
step:402/1875 train_loss:3.8334 train_time:286052ms step_avg:729.73ms
step:403/1875 train_loss:4.1272 train_time:286779ms step_avg:729.72ms
step:404/1875 train_loss:3.9916 train_time:287520ms step_avg:729.75ms
step:405/1875 train_loss:3.9986 train_time:288245ms step_avg:729.73ms
step:406/1875 train_loss:4.0176 train_time:288969ms step_avg:729.72ms
step:407/1875 train_loss:3.9778 train_time:289694ms step_avg:729.71ms
step:408/1875 train_loss:3.8841 train_time:290423ms step_avg:729.71ms
step:409/1875 train_loss:3.9510 train_time:291153ms step_avg:729.71ms
step:410/1875 train_loss:3.9092 train_time:291879ms step_avg:729.70ms
step:411/1875 train_loss:3.9133 train_time:292606ms step_avg:729.69ms
step:412/1875 train_loss:3.9274 train_time:293327ms step_avg:729.67ms
step:413/1875 train_loss:3.9065 train_time:294059ms step_avg:729.68ms
step:414/1875 train_loss:4.0105 train_time:294793ms step_avg:729.69ms
step:415/1875 train_loss:3.8702 train_time:295516ms step_avg:729.67ms
step:416/1875 train_loss:3.9459 train_time:296248ms step_avg:729.67ms
step:417/1875 train_loss:4.0144 train_time:296973ms step_avg:729.66ms
step:418/1875 train_loss:3.8209 train_time:297702ms step_avg:729.66ms
step:419/1875 train_loss:4.0765 train_time:298427ms step_avg:729.65ms
step:420/1875 train_loss:4.1318 train_time:299153ms step_avg:729.64ms
step:421/1875 train_loss:3.9066 train_time:299880ms step_avg:729.63ms
step:422/1875 train_loss:4.0571 train_time:300598ms step_avg:729.61ms
step:423/1875 train_loss:3.7351 train_time:301330ms step_avg:729.61ms
step:424/1875 train_loss:3.9279 train_time:302059ms step_avg:729.61ms
step:425/1875 train_loss:3.7907 train_time:302792ms step_avg:729.62ms
step:426/1875 train_loss:4.0004 train_time:303527ms step_avg:729.63ms
step:427/1875 train_loss:3.9827 train_time:304253ms step_avg:729.62ms
step:428/1875 train_loss:3.8972 train_time:304987ms step_avg:729.63ms
step:429/1875 train_loss:4.0257 train_time:305718ms step_avg:729.64ms
step:430/1875 train_loss:3.8499 train_time:306454ms step_avg:729.65ms
step:431/1875 train_loss:3.7736 train_time:307195ms step_avg:729.68ms
step:432/1875 train_loss:3.9719 train_time:307918ms step_avg:729.66ms
step:433/1875 train_loss:4.0095 train_time:308637ms step_avg:729.64ms
step:434/1875 train_loss:4.0020 train_time:309369ms step_avg:729.64ms
step:435/1875 train_loss:3.8965 train_time:310091ms step_avg:729.62ms
step:436/1875 train_loss:3.9759 train_time:310820ms step_avg:729.62ms
step:437/1875 train_loss:3.9844 train_time:311543ms step_avg:729.61ms
step:438/1875 train_loss:3.9408 train_time:312271ms step_avg:729.61ms
step:439/1875 train_loss:4.0127 train_time:312998ms step_avg:729.60ms
step:440/1875 train_loss:3.8416 train_time:313726ms step_avg:729.60ms
step:441/1875 train_loss:3.9361 train_time:314455ms step_avg:729.59ms
step:442/1875 train_loss:3.8744 train_time:315182ms step_avg:729.59ms
step:443/1875 train_loss:3.7649 train_time:315917ms step_avg:729.60ms
step:444/1875 train_loss:3.9119 train_time:316635ms step_avg:729.57ms
step:445/1875 train_loss:4.1513 train_time:317362ms step_avg:729.57ms
step:446/1875 train_loss:3.8006 train_time:318093ms step_avg:729.57ms
step:447/1875 train_loss:3.9923 train_time:318818ms step_avg:729.56ms
step:448/1875 train_loss:4.0082 train_time:319552ms step_avg:729.57ms
step:449/1875 train_loss:3.8597 train_time:320287ms step_avg:729.58ms
step:450/1875 train_loss:3.8250 train_time:321025ms step_avg:729.60ms
step:451/1875 train_loss:3.8543 train_time:321760ms step_avg:729.62ms
step:452/1875 train_loss:4.1950 train_time:322492ms step_avg:729.62ms
step:453/1875 train_loss:4.0844 train_time:323223ms step_avg:729.62ms
step:454/1875 train_loss:3.9527 train_time:323962ms step_avg:729.64ms
step:455/1875 train_loss:3.8526 train_time:324691ms step_avg:729.64ms
step:456/1875 train_loss:3.9728 train_time:325418ms step_avg:729.64ms
step:457/1875 train_loss:3.9006 train_time:326143ms step_avg:729.63ms
step:458/1875 train_loss:3.9156 train_time:326865ms step_avg:729.61ms
step:459/1875 train_loss:4.0124 train_time:327587ms step_avg:729.59ms
step:460/1875 train_loss:3.8224 train_time:328321ms step_avg:729.60ms
step:461/1875 train_loss:3.9320 train_time:329063ms step_avg:729.63ms
step:462/1875 train_loss:3.8809 train_time:329790ms step_avg:729.62ms
step:463/1875 train_loss:3.7381 train_time:330520ms step_avg:729.63ms
step:464/1875 train_loss:3.8917 train_time:331245ms step_avg:729.61ms
step:465/1875 train_loss:3.9743 train_time:331965ms step_avg:729.59ms
step:466/1875 train_loss:3.8410 train_time:332693ms step_avg:729.59ms
step:467/1875 train_loss:3.8652 train_time:333423ms step_avg:729.59ms
step:468/1875 train_loss:3.8418 train_time:334157ms step_avg:729.60ms
step:469/1875 train_loss:4.0405 train_time:334878ms step_avg:729.58ms
step:470/1875 train_loss:3.9022 train_time:335599ms step_avg:729.56ms
step:471/1875 train_loss:3.7594 train_time:336341ms step_avg:729.59ms
step:472/1875 train_loss:3.9775 train_time:337069ms step_avg:729.59ms
step:473/1875 train_loss:3.8278 train_time:337786ms step_avg:729.56ms
step:474/1875 train_loss:3.9502 train_time:338516ms step_avg:729.56ms
step:475/1875 train_loss:4.0108 train_time:339239ms step_avg:729.55ms
step:476/1875 train_loss:4.1808 train_time:339964ms step_avg:729.54ms
step:477/1875 train_loss:3.9589 train_time:340690ms step_avg:729.53ms
step:478/1875 train_loss:3.9339 train_time:341421ms step_avg:729.53ms
step:479/1875 train_loss:3.8778 train_time:342152ms step_avg:729.54ms
step:480/1875 train_loss:3.8221 train_time:342887ms step_avg:729.55ms
step:481/1875 train_loss:3.8720 train_time:343621ms step_avg:729.56ms
step:482/1875 train_loss:3.9805 train_time:344342ms step_avg:729.54ms
step:483/1875 train_loss:3.9058 train_time:345069ms step_avg:729.53ms
step:484/1875 train_loss:3.9715 train_time:345803ms step_avg:729.54ms
step:485/1875 train_loss:3.9208 train_time:346530ms step_avg:729.54ms
step:486/1875 train_loss:3.7527 train_time:347264ms step_avg:729.55ms
step:487/1875 train_loss:3.8844 train_time:347992ms step_avg:729.54ms
step:488/1875 train_loss:3.8860 train_time:348719ms step_avg:729.54ms
step:489/1875 train_loss:3.9019 train_time:349439ms step_avg:729.52ms
step:490/1875 train_loss:4.1097 train_time:350164ms step_avg:729.51ms
step:491/1875 train_loss:3.8580 train_time:350896ms step_avg:729.51ms
step:492/1875 train_loss:3.8055 train_time:351618ms step_avg:729.50ms
step:493/1875 train_loss:3.9377 train_time:352336ms step_avg:729.47ms
step:494/1875 train_loss:3.6981 train_time:353072ms step_avg:729.49ms
step:495/1875 train_loss:3.8752 train_time:353809ms step_avg:729.50ms
step:496/1875 train_loss:4.0360 train_time:354546ms step_avg:729.52ms
step:497/1875 train_loss:3.8861 train_time:355287ms step_avg:729.54ms
step:498/1875 train_loss:3.8683 train_time:356026ms step_avg:729.56ms
step:499/1875 train_loss:3.8458 train_time:356747ms step_avg:729.54ms
step:500/1875 train_loss:3.9638 train_time:357478ms step_avg:729.55ms
step:500/1875 val_loss:3.8581 train_time:357609ms step_avg:729.81ms
============== Weight norms: ==============
name = 'module._orig_mod.transformer.h.0.attn.c_q.weight' | fro_norm = 28.89539 | spectral_norm = 7.52422 | nuclear_norm = 581.68365
name = 'module._orig_mod.transformer.h.0.attn.c_k.weight' | fro_norm = 26.91989 | spectral_norm = 9.43762 | nuclear_norm = 537.19586
name = 'module._orig_mod.transformer.h.1.attn.c_q.weight' | fro_norm = 28.50831 | spectral_norm = 7.71242 | nuclear_norm = 569.14349
name = 'module._orig_mod.transformer.h.1.attn.c_k.weight' | fro_norm = 26.43375 | spectral_norm = 9.40800 | nuclear_norm = 531.84485
name = 'module._orig_mod.transformer.h.2.attn.c_q.weight' | fro_norm = 28.43801 | spectral_norm = 6.19863 | nuclear_norm = 568.32349
name = 'module._orig_mod.transformer.h.2.attn.c_k.weight' | fro_norm = 26.88409 | spectral_norm = 7.37685 | nuclear_norm = 543.81091
name = 'module._orig_mod.transformer.h.3.attn.c_q.weight' | fro_norm = 28.28358 | spectral_norm = 6.87916 | nuclear_norm = 565.96143
name = 'module._orig_mod.transformer.h.3.attn.c_k.weight' | fro_norm = 26.53701 | spectral_norm = 7.67393 | nuclear_norm = 538.54175
name = 'module._orig_mod.transformer.h.4.attn.c_q.weight' | fro_norm = 28.75915 | spectral_norm = 6.07266 | nuclear_norm = 572.82465
name = 'module._orig_mod.transformer.h.4.attn.c_k.weight' | fro_norm = 27.12927 | spectral_norm = 6.08073 | nuclear_norm = 552.59796
name = 'module._orig_mod.transformer.h.5.attn.c_q.weight' | fro_norm = 28.19939 | spectral_norm = 6.38325 | nuclear_norm = 565.54828
name = 'module._orig_mod.transformer.h.5.attn.c_k.weight' | fro_norm = 26.59588 | spectral_norm = 6.41036 | nuclear_norm = 544.33875
name = 'module._orig_mod.transformer.h.6.attn.c_q.weight' | fro_norm = 28.40449 | spectral_norm = 6.36044 | nuclear_norm = 569.52661
name = 'module._orig_mod.transformer.h.6.attn.c_k.weight' | fro_norm = 26.95077 | spectral_norm = 6.79734 | nuclear_norm = 549.72845
name = 'module._orig_mod.transformer.h.7.attn.c_q.weight' | fro_norm = 28.15696 | spectral_norm = 5.81929 | nuclear_norm = 558.08704
name = 'module._orig_mod.transformer.h.7.attn.c_k.weight' | fro_norm = 26.59233 | spectral_norm = 4.96054 | nuclear_norm = 544.59357
name = 'module._orig_mod.transformer.h.8.attn.c_q.weight' | fro_norm = 28.34594 | spectral_norm = 5.97133 | nuclear_norm = 565.78204
name = 'module._orig_mod.transformer.h.8.attn.c_k.weight' | fro_norm = 26.83004 | spectral_norm = 5.55923 | nuclear_norm = 550.19818
name = 'module._orig_mod.transformer.h.9.attn.c_q.weight' | fro_norm = 28.15080 | spectral_norm = 5.57905 | nuclear_norm = 559.40967
name = 'module._orig_mod.transformer.h.9.attn.c_k.weight' | fro_norm = 27.02299 | spectral_norm = 5.35975 | nuclear_norm = 548.49597
name = 'module._orig_mod.transformer.h.10.attn.c_q.weight' | fro_norm = 28.12346 | spectral_norm = 5.71542 | nuclear_norm = 554.86572
name = 'module._orig_mod.transformer.h.10.attn.c_k.weight' | fro_norm = 27.30363 | spectral_norm = 5.60173 | nuclear_norm = 552.43073
name = 'module._orig_mod.transformer.h.11.attn.c_q.weight' | fro_norm = 27.99164 | spectral_norm = 5.55970 | nuclear_norm = 557.06476
name = 'module._orig_mod.transformer.h.11.attn.c_k.weight' | fro_norm = 26.29146 | spectral_norm = 5.34111 | nuclear_norm = 538.63684
===========================================
step:501/1875 train_loss:3.8610 train_time:358198ms step_avg:729.53ms
step:502/1875 train_loss:3.7884 train_time:358937ms step_avg:729.55ms
step:503/1875 train_loss:3.9019 train_time:359661ms step_avg:729.54ms
step:504/1875 train_loss:3.7593 train_time:360387ms step_avg:729.53ms
step:505/1875 train_loss:4.1752 train_time:361109ms step_avg:729.51ms
step:506/1875 train_loss:3.8391 train_time:361837ms step_avg:729.51ms
step:507/1875 train_loss:3.9144 train_time:362572ms step_avg:729.52ms
step:508/1875 train_loss:4.0710 train_time:363296ms step_avg:729.51ms
step:509/1875 train_loss:3.7875 train_time:364033ms step_avg:729.52ms
step:510/1875 train_loss:3.8949 train_time:364755ms step_avg:729.51ms
step:511/1875 train_loss:3.8971 train_time:365499ms step_avg:729.54ms
step:512/1875 train_loss:3.7158 train_time:366226ms step_avg:729.53ms
step:513/1875 train_loss:3.6978 train_time:366964ms step_avg:729.55ms
step:514/1875 train_loss:3.9483 train_time:367699ms step_avg:729.56ms
step:515/1875 train_loss:4.0544 train_time:368433ms step_avg:729.57ms
step:516/1875 train_loss:3.9392 train_time:369160ms step_avg:729.56ms
step:517/1875 train_loss:3.7665 train_time:369897ms step_avg:729.58ms
step:518/1875 train_loss:3.9387 train_time:370621ms step_avg:729.57ms
step:519/1875 train_loss:3.6857 train_time:371345ms step_avg:729.56ms
step:520/1875 train_loss:3.9270 train_time:372075ms step_avg:729.56ms
step:521/1875 train_loss:3.8168 train_time:372802ms step_avg:729.55ms
step:522/1875 train_loss:3.7128 train_time:373531ms step_avg:729.55ms
step:523/1875 train_loss:3.9558 train_time:374261ms step_avg:729.55ms
step:524/1875 train_loss:3.7531 train_time:375000ms step_avg:729.57ms
step:525/1875 train_loss:3.8143 train_time:375727ms step_avg:729.57ms
step:526/1875 train_loss:3.8623 train_time:376464ms step_avg:729.58ms
step:527/1875 train_loss:4.1079 train_time:377190ms step_avg:729.58ms
step:528/1875 train_loss:3.8262 train_time:377914ms step_avg:729.56ms
step:529/1875 train_loss:3.8063 train_time:378636ms step_avg:729.55ms
step:530/1875 train_loss:3.8230 train_time:379369ms step_avg:729.56ms
step:531/1875 train_loss:3.9333 train_time:380100ms step_avg:729.56ms
step:532/1875 train_loss:3.8865 train_time:380828ms step_avg:729.56ms
step:533/1875 train_loss:3.8875 train_time:381569ms step_avg:729.58ms
step:534/1875 train_loss:3.9657 train_time:382302ms step_avg:729.58ms
step:535/1875 train_loss:3.9160 train_time:383045ms step_avg:729.61ms
step:536/1875 train_loss:3.7779 train_time:383771ms step_avg:729.60ms
step:537/1875 train_loss:3.8548 train_time:384501ms step_avg:729.60ms
step:538/1875 train_loss:3.7874 train_time:385233ms step_avg:729.61ms
step:539/1875 train_loss:3.7671 train_time:385964ms step_avg:729.61ms
step:540/1875 train_loss:3.8562 train_time:386718ms step_avg:729.66ms
step:541/1875 train_loss:3.7755 train_time:387452ms step_avg:729.66ms
step:542/1875 train_loss:3.8071 train_time:388186ms step_avg:729.67ms
step:543/1875 train_loss:3.8725 train_time:388909ms step_avg:729.66ms
step:544/1875 train_loss:3.8490 train_time:389641ms step_avg:729.67ms
step:545/1875 train_loss:3.8844 train_time:390378ms step_avg:729.68ms
step:546/1875 train_loss:3.9024 train_time:391103ms step_avg:729.67ms
step:547/1875 train_loss:3.7556 train_time:391833ms step_avg:729.67ms
step:548/1875 train_loss:3.9967 train_time:392570ms step_avg:729.68ms
step:549/1875 train_loss:3.3796 train_time:393307ms step_avg:729.70ms
step:550/1875 train_loss:3.8833 train_time:394041ms step_avg:729.71ms
step:551/1875 train_loss:3.8886 train_time:394779ms step_avg:729.72ms
step:552/1875 train_loss:3.8171 train_time:395503ms step_avg:729.71ms
step:553/1875 train_loss:3.9177 train_time:396234ms step_avg:729.71ms
step:554/1875 train_loss:3.8375 train_time:396968ms step_avg:729.72ms
step:555/1875 train_loss:3.8072 train_time:397698ms step_avg:729.72ms
step:556/1875 train_loss:3.9421 train_time:398425ms step_avg:729.72ms
step:557/1875 train_loss:3.8508 train_time:399145ms step_avg:729.70ms
step:558/1875 train_loss:3.7673 train_time:399876ms step_avg:729.70ms
step:559/1875 train_loss:3.8826 train_time:400599ms step_avg:729.69ms
step:560/1875 train_loss:3.7726 train_time:401325ms step_avg:729.68ms
step:561/1875 train_loss:3.8236 train_time:402049ms step_avg:729.67ms
step:562/1875 train_loss:3.8274 train_time:402774ms step_avg:729.66ms
step:563/1875 train_loss:3.6346 train_time:403502ms step_avg:729.66ms
step:564/1875 train_loss:3.8910 train_time:404222ms step_avg:729.64ms
step:565/1875 train_loss:3.7573 train_time:404954ms step_avg:729.65ms
step:566/1875 train_loss:3.7950 train_time:405686ms step_avg:729.65ms
step:567/1875 train_loss:3.8842 train_time:406422ms step_avg:729.66ms
step:568/1875 train_loss:3.7992 train_time:407147ms step_avg:729.65ms
step:569/1875 train_loss:4.1257 train_time:407870ms step_avg:729.64ms
step:570/1875 train_loss:3.8433 train_time:408797ms step_avg:729.99ms
step:571/1875 train_loss:3.8072 train_time:409785ms step_avg:730.45ms
step:572/1875 train_loss:3.9177 train_time:410513ms step_avg:730.45ms
step:573/1875 train_loss:3.8639 train_time:411245ms step_avg:730.45ms
step:574/1875 train_loss:3.8744 train_time:411971ms step_avg:730.44ms
step:575/1875 train_loss:3.9297 train_time:412721ms step_avg:730.48ms
step:576/1875 train_loss:3.8902 train_time:413450ms step_avg:730.48ms
step:577/1875 train_loss:3.9091 train_time:414173ms step_avg:730.46ms
step:578/1875 train_loss:3.8306 train_time:414895ms step_avg:730.45ms
step:579/1875 train_loss:3.8231 train_time:415626ms step_avg:730.45ms
step:580/1875 train_loss:3.8232 train_time:416353ms step_avg:730.44ms
step:581/1875 train_loss:3.7522 train_time:417083ms step_avg:730.44ms
step:582/1875 train_loss:3.7929 train_time:417805ms step_avg:730.43ms
step:583/1875 train_loss:4.0130 train_time:418544ms step_avg:730.44ms
step:584/1875 train_loss:3.7896 train_time:419270ms step_avg:730.44ms
step:585/1875 train_loss:3.7332 train_time:420004ms step_avg:730.44ms
step:586/1875 train_loss:3.9447 train_time:420728ms step_avg:730.43ms
step:587/1875 train_loss:3.6587 train_time:421463ms step_avg:730.44ms
step:588/1875 train_loss:3.8211 train_time:422190ms step_avg:730.43ms
step:589/1875 train_loss:3.8048 train_time:422915ms step_avg:730.42ms
step:590/1875 train_loss:4.1566 train_time:423646ms step_avg:730.42ms
step:591/1875 train_loss:3.9184 train_time:424382ms step_avg:730.43ms
step:592/1875 train_loss:3.6592 train_time:425099ms step_avg:730.41ms
step:593/1875 train_loss:3.6878 train_time:425832ms step_avg:730.42ms
step:594/1875 train_loss:3.6557 train_time:426562ms step_avg:730.41ms
step:595/1875 train_loss:3.7071 train_time:427295ms step_avg:730.42ms
step:596/1875 train_loss:4.0770 train_time:428037ms step_avg:730.44ms
step:597/1875 train_loss:3.7898 train_time:428771ms step_avg:730.44ms
step:598/1875 train_loss:3.7412 train_time:429498ms step_avg:730.44ms
step:599/1875 train_loss:3.8119 train_time:430221ms step_avg:730.43ms
step:600/1875 train_loss:3.6322 train_time:430948ms step_avg:730.42ms
step:601/1875 train_loss:3.7553 train_time:431679ms step_avg:730.42ms
step:602/1875 train_loss:3.7901 train_time:432400ms step_avg:730.41ms
step:603/1875 train_loss:3.8158 train_time:433122ms step_avg:730.39ms
step:604/1875 train_loss:3.9273 train_time:433865ms step_avg:730.41ms
step:605/1875 train_loss:3.7716 train_time:434598ms step_avg:730.42ms
step:606/1875 train_loss:3.7738 train_time:435329ms step_avg:730.42ms
step:607/1875 train_loss:3.7049 train_time:436061ms step_avg:730.42ms
step:608/1875 train_loss:3.9722 train_time:436793ms step_avg:730.42ms
step:609/1875 train_loss:3.8016 train_time:437515ms step_avg:730.41ms
step:610/1875 train_loss:3.7628 train_time:438238ms step_avg:730.40ms
step:611/1875 train_loss:3.8578 train_time:438962ms step_avg:730.39ms
step:612/1875 train_loss:3.7578 train_time:439695ms step_avg:730.39ms
step:613/1875 train_loss:3.7177 train_time:440417ms step_avg:730.38ms
step:614/1875 train_loss:3.9061 train_time:441148ms step_avg:730.38ms
step:615/1875 train_loss:3.8597 train_time:441872ms step_avg:730.37ms
step:616/1875 train_loss:3.8506 train_time:442595ms step_avg:730.35ms
step:617/1875 train_loss:3.7888 train_time:443325ms step_avg:730.35ms
step:618/1875 train_loss:3.7031 train_time:444050ms step_avg:730.34ms
step:619/1875 train_loss:3.8375 train_time:444772ms step_avg:730.33ms
step:620/1875 train_loss:3.7116 train_time:445509ms step_avg:730.34ms
step:621/1875 train_loss:3.7390 train_time:446241ms step_avg:730.35ms
step:622/1875 train_loss:4.0557 train_time:446969ms step_avg:730.34ms
step:623/1875 train_loss:3.7249 train_time:447702ms step_avg:730.35ms
step:624/1875 train_loss:3.7568 train_time:448439ms step_avg:730.36ms
step:625/1875 train_loss:3.8396 train_time:449175ms step_avg:730.37ms
step:625/1875 val_loss:3.7723 train_time:449317ms step_avg:730.60ms
============== Weight norms: ==============
name = 'module._orig_mod.transformer.h.0.attn.c_q.weight' | fro_norm = 31.71319 | spectral_norm = 8.49409 | nuclear_norm = 633.46796
name = 'module._orig_mod.transformer.h.0.attn.c_k.weight' | fro_norm = 29.45725 | spectral_norm = 10.97564 | nuclear_norm = 578.11108
name = 'module._orig_mod.transformer.h.1.attn.c_q.weight' | fro_norm = 31.05708 | spectral_norm = 8.19287 | nuclear_norm = 616.11877
name = 'module._orig_mod.transformer.h.1.attn.c_k.weight' | fro_norm = 28.76827 | spectral_norm = 10.12565 | nuclear_norm = 572.70148
name = 'module._orig_mod.transformer.h.2.attn.c_q.weight' | fro_norm = 30.87365 | spectral_norm = 6.68347 | nuclear_norm = 611.69684
name = 'module._orig_mod.transformer.h.2.attn.c_k.weight' | fro_norm = 29.23957 | spectral_norm = 7.87621 | nuclear_norm = 585.14612
name = 'module._orig_mod.transformer.h.3.attn.c_q.weight' | fro_norm = 30.49352 | spectral_norm = 7.13542 | nuclear_norm = 606.70673
name = 'module._orig_mod.transformer.h.3.attn.c_k.weight' | fro_norm = 28.71066 | spectral_norm = 8.27993 | nuclear_norm = 577.25366
name = 'module._orig_mod.transformer.h.4.attn.c_q.weight' | fro_norm = 30.89714 | spectral_norm = 6.45621 | nuclear_norm = 612.33551
name = 'module._orig_mod.transformer.h.4.attn.c_k.weight' | fro_norm = 29.24385 | spectral_norm = 6.60513 | nuclear_norm = 591.38440
name = 'module._orig_mod.transformer.h.5.attn.c_q.weight' | fro_norm = 30.31984 | spectral_norm = 6.64284 | nuclear_norm = 604.20483
name = 'module._orig_mod.transformer.h.5.attn.c_k.weight' | fro_norm = 28.77011 | spectral_norm = 6.95519 | nuclear_norm = 583.02930
name = 'module._orig_mod.transformer.h.6.attn.c_q.weight' | fro_norm = 30.30567 | spectral_norm = 6.95657 | nuclear_norm = 604.51245
name = 'module._orig_mod.transformer.h.6.attn.c_k.weight' | fro_norm = 28.93204 | spectral_norm = 7.44981 | nuclear_norm = 585.33850
name = 'module._orig_mod.transformer.h.7.attn.c_q.weight' | fro_norm = 30.13282 | spectral_norm = 6.17937 | nuclear_norm = 593.08459
name = 'module._orig_mod.transformer.h.7.attn.c_k.weight' | fro_norm = 28.60493 | spectral_norm = 5.42567 | nuclear_norm = 579.92029
name = 'module._orig_mod.transformer.h.8.attn.c_q.weight' | fro_norm = 30.60991 | spectral_norm = 6.55202 | nuclear_norm = 606.38770
name = 'module._orig_mod.transformer.h.8.attn.c_k.weight' | fro_norm = 28.98843 | spectral_norm = 6.18691 | nuclear_norm = 589.37097
name = 'module._orig_mod.transformer.h.9.attn.c_q.weight' | fro_norm = 30.26713 | spectral_norm = 6.13569 | nuclear_norm = 597.28491
name = 'module._orig_mod.transformer.h.9.attn.c_k.weight' | fro_norm = 29.16813 | spectral_norm = 5.79949 | nuclear_norm = 586.60693
name = 'module._orig_mod.transformer.h.10.attn.c_q.weight' | fro_norm = 30.23715 | spectral_norm = 6.17755 | nuclear_norm = 591.06299
name = 'module._orig_mod.transformer.h.10.attn.c_k.weight' | fro_norm = 29.45599 | spectral_norm = 6.05228 | nuclear_norm = 588.99927
name = 'module._orig_mod.transformer.h.11.attn.c_q.weight' | fro_norm = 30.04767 | spectral_norm = 6.08084 | nuclear_norm = 593.21503
name = 'module._orig_mod.transformer.h.11.attn.c_k.weight' | fro_norm = 28.21671 | spectral_norm = 5.89566 | nuclear_norm = 571.93622
===========================================
step:626/1875 train_loss:3.8551 train_time:449899ms step_avg:730.36ms
step:627/1875 train_loss:3.8940 train_time:450635ms step_avg:730.36ms
step:628/1875 train_loss:3.8687 train_time:451364ms step_avg:730.36ms
step:629/1875 train_loss:3.9155 train_time:452088ms step_avg:730.35ms
step:630/1875 train_loss:3.7369 train_time:452810ms step_avg:730.34ms
step:631/1875 train_loss:3.8666 train_time:453530ms step_avg:730.32ms
step:632/1875 train_loss:3.8905 train_time:454258ms step_avg:730.32ms
step:633/1875 train_loss:3.8073 train_time:454989ms step_avg:730.32ms
step:634/1875 train_loss:3.7481 train_time:455715ms step_avg:730.31ms
step:635/1875 train_loss:3.8534 train_time:456451ms step_avg:730.32ms
step:636/1875 train_loss:4.0978 train_time:457186ms step_avg:730.33ms
step:637/1875 train_loss:3.6867 train_time:457912ms step_avg:730.32ms
step:638/1875 train_loss:3.4927 train_time:458638ms step_avg:730.32ms
step:639/1875 train_loss:3.7402 train_time:459367ms step_avg:730.31ms
step:640/1875 train_loss:3.7727 train_time:460098ms step_avg:730.31ms
step:641/1875 train_loss:3.7213 train_time:460823ms step_avg:730.31ms
step:642/1875 train_loss:3.7256 train_time:461549ms step_avg:730.30ms
step:643/1875 train_loss:3.7818 train_time:462277ms step_avg:730.30ms
step:644/1875 train_loss:3.7768 train_time:463012ms step_avg:730.30ms
step:645/1875 train_loss:3.7126 train_time:463734ms step_avg:730.29ms
step:646/1875 train_loss:3.9299 train_time:464461ms step_avg:730.29ms
step:647/1875 train_loss:3.8362 train_time:465195ms step_avg:730.29ms
step:648/1875 train_loss:3.8041 train_time:465919ms step_avg:730.28ms
step:649/1875 train_loss:3.8510 train_time:466668ms step_avg:730.31ms
step:650/1875 train_loss:3.9168 train_time:467397ms step_avg:730.31ms
step:651/1875 train_loss:3.7697 train_time:468131ms step_avg:730.31ms
step:652/1875 train_loss:3.9096 train_time:468861ms step_avg:730.31ms
step:653/1875 train_loss:3.7337 train_time:469588ms step_avg:730.31ms
step:654/1875 train_loss:3.8106 train_time:470314ms step_avg:730.30ms
step:655/1875 train_loss:3.5807 train_time:471042ms step_avg:730.30ms
step:656/1875 train_loss:3.7321 train_time:471762ms step_avg:730.28ms
step:657/1875 train_loss:3.7271 train_time:472489ms step_avg:730.28ms
step:658/1875 train_loss:3.6475 train_time:473219ms step_avg:730.28ms
step:659/1875 train_loss:3.8351 train_time:473947ms step_avg:730.27ms
step:660/1875 train_loss:3.7381 train_time:474682ms step_avg:730.28ms
step:661/1875 train_loss:3.8252 train_time:475409ms step_avg:730.27ms
step:662/1875 train_loss:3.9009 train_time:476137ms step_avg:730.27ms
step:663/1875 train_loss:3.8193 train_time:476868ms step_avg:730.27ms
step:664/1875 train_loss:3.7001 train_time:477592ms step_avg:730.26ms
step:665/1875 train_loss:3.7554 train_time:478327ms step_avg:730.27ms
step:666/1875 train_loss:3.6397 train_time:479053ms step_avg:730.26ms
step:667/1875 train_loss:3.9329 train_time:479777ms step_avg:730.25ms
step:668/1875 train_loss:3.7742 train_time:480510ms step_avg:730.26ms
step:669/1875 train_loss:3.7933 train_time:481241ms step_avg:730.26ms
step:670/1875 train_loss:3.6295 train_time:481977ms step_avg:730.27ms
step:671/1875 train_loss:3.7487 train_time:482703ms step_avg:730.26ms
step:672/1875 train_loss:3.7072 train_time:483437ms step_avg:730.27ms
step:673/1875 train_loss:3.7117 train_time:484166ms step_avg:730.27ms
step:674/1875 train_loss:3.9868 train_time:484892ms step_avg:730.26ms
step:675/1875 train_loss:3.7832 train_time:485626ms step_avg:730.27ms
step:676/1875 train_loss:3.8609 train_time:486355ms step_avg:730.26ms
step:677/1875 train_loss:3.6323 train_time:487085ms step_avg:730.26ms
step:678/1875 train_loss:3.7575 train_time:487812ms step_avg:730.26ms
step:679/1875 train_loss:3.7070 train_time:488533ms step_avg:730.24ms
step:680/1875 train_loss:3.8218 train_time:489268ms step_avg:730.25ms
step:681/1875 train_loss:3.7379 train_time:490011ms step_avg:730.27ms
step:682/1875 train_loss:3.7660 train_time:490734ms step_avg:730.26ms
step:683/1875 train_loss:3.8075 train_time:491460ms step_avg:730.25ms
step:684/1875 train_loss:3.8926 train_time:492192ms step_avg:730.25ms
step:685/1875 train_loss:3.7944 train_time:492934ms step_avg:730.27ms
step:686/1875 train_loss:3.8511 train_time:493664ms step_avg:730.27ms
step:687/1875 train_loss:3.7781 train_time:494392ms step_avg:730.27ms
step:688/1875 train_loss:3.8136 train_time:495126ms step_avg:730.27ms
step:689/1875 train_loss:3.3626 train_time:495881ms step_avg:730.31ms
step:690/1875 train_loss:3.5518 train_time:496610ms step_avg:730.31ms
step:691/1875 train_loss:3.6884 train_time:497339ms step_avg:730.31ms
step:692/1875 train_loss:3.5742 train_time:498063ms step_avg:730.30ms
step:693/1875 train_loss:3.7778 train_time:498788ms step_avg:730.29ms
step:694/1875 train_loss:3.8030 train_time:499509ms step_avg:730.28ms
step:695/1875 train_loss:3.7048 train_time:500235ms step_avg:730.27ms
step:696/1875 train_loss:3.6864 train_time:500955ms step_avg:730.26ms
step:697/1875 train_loss:3.9986 train_time:501693ms step_avg:730.27ms
step:698/1875 train_loss:3.7372 train_time:502423ms step_avg:730.27ms
step:699/1875 train_loss:3.7886 train_time:503148ms step_avg:730.26ms
step:700/1875 train_loss:3.9217 train_time:503877ms step_avg:730.26ms
step:701/1875 train_loss:3.7154 train_time:504601ms step_avg:730.25ms
step:702/1875 train_loss:3.6894 train_time:505326ms step_avg:730.24ms
step:703/1875 train_loss:3.6598 train_time:506059ms step_avg:730.24ms
step:704/1875 train_loss:3.6370 train_time:506787ms step_avg:730.24ms
step:705/1875 train_loss:3.7207 train_time:507539ms step_avg:730.27ms
step:706/1875 train_loss:3.7056 train_time:508266ms step_avg:730.27ms
step:707/1875 train_loss:3.7275 train_time:508997ms step_avg:730.27ms
step:708/1875 train_loss:3.7958 train_time:509736ms step_avg:730.28ms
step:709/1875 train_loss:3.7529 train_time:510474ms step_avg:730.29ms
step:710/1875 train_loss:3.7262 train_time:511214ms step_avg:730.31ms
step:711/1875 train_loss:3.6962 train_time:511945ms step_avg:730.31ms
step:712/1875 train_loss:3.7443 train_time:512676ms step_avg:730.31ms
step:713/1875 train_loss:3.7967 train_time:513412ms step_avg:730.32ms
step:714/1875 train_loss:3.7924 train_time:514146ms step_avg:730.32ms
step:715/1875 train_loss:3.7089 train_time:514877ms step_avg:730.32ms
step:716/1875 train_loss:3.7251 train_time:515611ms step_avg:730.33ms
step:717/1875 train_loss:3.7379 train_time:516334ms step_avg:730.32ms
step:718/1875 train_loss:3.8485 train_time:517059ms step_avg:730.31ms
step:719/1875 train_loss:3.7425 train_time:517783ms step_avg:730.30ms
step:720/1875 train_loss:3.8286 train_time:518507ms step_avg:730.29ms
step:721/1875 train_loss:3.9857 train_time:519245ms step_avg:730.30ms
step:722/1875 train_loss:3.6138 train_time:519972ms step_avg:730.30ms
step:723/1875 train_loss:3.8779 train_time:520708ms step_avg:730.31ms
step:724/1875 train_loss:3.9128 train_time:521426ms step_avg:730.29ms
step:725/1875 train_loss:3.7141 train_time:522149ms step_avg:730.28ms
step:726/1875 train_loss:3.8002 train_time:522894ms step_avg:730.30ms
step:727/1875 train_loss:3.6921 train_time:523629ms step_avg:730.31ms
step:728/1875 train_loss:3.7128 train_time:524355ms step_avg:730.30ms
step:729/1875 train_loss:3.8826 train_time:525084ms step_avg:730.30ms
step:730/1875 train_loss:3.8146 train_time:525809ms step_avg:730.29ms
step:731/1875 train_loss:3.8213 train_time:526549ms step_avg:730.30ms
step:732/1875 train_loss:3.7101 train_time:527281ms step_avg:730.31ms
step:733/1875 train_loss:3.7426 train_time:528001ms step_avg:730.29ms
step:734/1875 train_loss:3.9778 train_time:528729ms step_avg:730.29ms
step:735/1875 train_loss:3.7056 train_time:529450ms step_avg:730.28ms
step:736/1875 train_loss:3.7559 train_time:530189ms step_avg:730.29ms
step:737/1875 train_loss:3.8797 train_time:530918ms step_avg:730.29ms
step:738/1875 train_loss:3.8189 train_time:531643ms step_avg:730.28ms
step:739/1875 train_loss:3.7527 train_time:532368ms step_avg:730.27ms
step:740/1875 train_loss:3.6605 train_time:533092ms step_avg:730.26ms
step:741/1875 train_loss:4.2607 train_time:533829ms step_avg:730.27ms
step:742/1875 train_loss:3.6532 train_time:534565ms step_avg:730.28ms
step:743/1875 train_loss:3.7076 train_time:535302ms step_avg:730.29ms
step:744/1875 train_loss:3.7275 train_time:536047ms step_avg:730.31ms
step:745/1875 train_loss:3.7918 train_time:536780ms step_avg:730.31ms
step:746/1875 train_loss:3.7479 train_time:537514ms step_avg:730.32ms
step:747/1875 train_loss:3.7405 train_time:538236ms step_avg:730.31ms
step:748/1875 train_loss:3.7896 train_time:538960ms step_avg:730.30ms
step:749/1875 train_loss:3.7100 train_time:539689ms step_avg:730.30ms
step:750/1875 train_loss:3.7125 train_time:540429ms step_avg:730.31ms
step:750/1875 val_loss:3.7142 train_time:540579ms step_avg:730.51ms
============== Weight norms: ==============
name = 'module._orig_mod.transformer.h.0.attn.c_q.weight' | fro_norm = 34.42185 | spectral_norm = 9.49169 | nuclear_norm = 683.63525
name = 'module._orig_mod.transformer.h.0.attn.c_k.weight' | fro_norm = 32.01133 | spectral_norm = 12.28996 | nuclear_norm = 620.61621
name = 'module._orig_mod.transformer.h.1.attn.c_q.weight' | fro_norm = 33.53615 | spectral_norm = 8.61798 | nuclear_norm = 661.71802
name = 'module._orig_mod.transformer.h.1.attn.c_k.weight' | fro_norm = 31.14640 | spectral_norm = 10.97509 | nuclear_norm = 613.88538
name = 'module._orig_mod.transformer.h.2.attn.c_q.weight' | fro_norm = 33.22756 | spectral_norm = 7.21743 | nuclear_norm = 653.61523
name = 'module._orig_mod.transformer.h.2.attn.c_k.weight' | fro_norm = 31.54399 | spectral_norm = 8.39296 | nuclear_norm = 625.88354
name = 'module._orig_mod.transformer.h.3.attn.c_q.weight' | fro_norm = 32.63175 | spectral_norm = 7.54057 | nuclear_norm = 646.24695
name = 'module._orig_mod.transformer.h.3.attn.c_k.weight' | fro_norm = 30.88471 | spectral_norm = 8.87669 | nuclear_norm = 615.86218
name = 'module._orig_mod.transformer.h.4.attn.c_q.weight' | fro_norm = 33.01657 | spectral_norm = 6.91094 | nuclear_norm = 651.63684
name = 'module._orig_mod.transformer.h.4.attn.c_k.weight' | fro_norm = 31.33545 | spectral_norm = 7.18313 | nuclear_norm = 629.54175
name = 'module._orig_mod.transformer.h.5.attn.c_q.weight' | fro_norm = 32.38206 | spectral_norm = 7.02029 | nuclear_norm = 642.02295
name = 'module._orig_mod.transformer.h.5.attn.c_k.weight' | fro_norm = 30.92615 | spectral_norm = 7.50231 | nuclear_norm = 621.73761
name = 'module._orig_mod.transformer.h.6.attn.c_q.weight' | fro_norm = 32.19423 | spectral_norm = 7.46036 | nuclear_norm = 639.41162
name = 'module._orig_mod.transformer.h.6.attn.c_k.weight' | fro_norm = 30.89881 | spectral_norm = 8.02423 | nuclear_norm = 621.42609
name = 'module._orig_mod.transformer.h.7.attn.c_q.weight' | fro_norm = 32.04712 | spectral_norm = 6.56198 | nuclear_norm = 627.80225
name = 'module._orig_mod.transformer.h.7.attn.c_k.weight' | fro_norm = 30.60517 | spectral_norm = 5.86701 | nuclear_norm = 615.93292
name = 'module._orig_mod.transformer.h.8.attn.c_q.weight' | fro_norm = 32.85058 | spectral_norm = 7.13108 | nuclear_norm = 647.20654
name = 'module._orig_mod.transformer.h.8.attn.c_k.weight' | fro_norm = 31.14539 | spectral_norm = 6.79999 | nuclear_norm = 629.08252
name = 'module._orig_mod.transformer.h.9.attn.c_q.weight' | fro_norm = 32.42092 | spectral_norm = 6.64104 | nuclear_norm = 636.18140
name = 'module._orig_mod.transformer.h.9.attn.c_k.weight' | fro_norm = 31.34277 | spectral_norm = 6.21496 | nuclear_norm = 626.27911
name = 'module._orig_mod.transformer.h.10.attn.c_q.weight' | fro_norm = 32.35933 | spectral_norm = 6.65743 | nuclear_norm = 628.65149
name = 'module._orig_mod.transformer.h.10.attn.c_k.weight' | fro_norm = 31.60830 | spectral_norm = 6.54366 | nuclear_norm = 626.72906
name = 'module._orig_mod.transformer.h.11.attn.c_q.weight' | fro_norm = 32.05938 | spectral_norm = 6.61221 | nuclear_norm = 628.69861
name = 'module._orig_mod.transformer.h.11.attn.c_k.weight' | fro_norm = 30.14235 | spectral_norm = 6.36709 | nuclear_norm = 605.86316
===========================================
step:751/1875 train_loss:3.7559 train_time:541166ms step_avg:730.32ms
step:752/1875 train_loss:3.7153 train_time:541895ms step_avg:730.32ms
step:753/1875 train_loss:3.7604 train_time:542624ms step_avg:730.32ms
step:754/1875 train_loss:3.7632 train_time:543353ms step_avg:730.31ms
step:755/1875 train_loss:3.7353 train_time:544074ms step_avg:730.30ms
step:756/1875 train_loss:3.8318 train_time:544801ms step_avg:730.30ms
step:757/1875 train_loss:3.6166 train_time:545539ms step_avg:730.31ms
step:758/1875 train_loss:3.8639 train_time:546288ms step_avg:730.33ms
step:759/1875 train_loss:3.7981 train_time:547013ms step_avg:730.32ms
step:760/1875 train_loss:3.7344 train_time:547937ms step_avg:730.58ms
step:761/1875 train_loss:3.8452 train_time:548658ms step_avg:730.57ms
step:762/1875 train_loss:3.7605 train_time:549594ms step_avg:730.84ms
step:763/1875 train_loss:3.5852 train_time:550324ms step_avg:730.84ms
step:764/1875 train_loss:3.5787 train_time:551062ms step_avg:730.85ms
step:765/1875 train_loss:3.6855 train_time:551791ms step_avg:730.85ms
step:766/1875 train_loss:3.6937 train_time:552519ms step_avg:730.85ms
step:767/1875 train_loss:4.7253 train_time:553256ms step_avg:730.85ms
step:768/1875 train_loss:3.6977 train_time:553992ms step_avg:730.86ms
step:769/1875 train_loss:3.7414 train_time:554726ms step_avg:730.86ms
step:770/1875 train_loss:3.8162 train_time:555452ms step_avg:730.86ms
step:771/1875 train_loss:4.3199 train_time:556176ms step_avg:730.85ms
step:772/1875 train_loss:3.7458 train_time:556905ms step_avg:730.85ms
step:773/1875 train_loss:3.7452 train_time:557641ms step_avg:730.85ms
step:774/1875 train_loss:3.7227 train_time:558370ms step_avg:730.85ms
step:775/1875 train_loss:3.8380 train_time:559094ms step_avg:730.84ms
step:776/1875 train_loss:3.6345 train_time:559820ms step_avg:730.84ms
step:777/1875 train_loss:3.7656 train_time:560544ms step_avg:730.83ms
step:778/1875 train_loss:3.7674 train_time:561280ms step_avg:730.83ms
step:779/1875 train_loss:3.7264 train_time:562012ms step_avg:730.83ms
step:780/1875 train_loss:3.7197 train_time:562742ms step_avg:730.83ms
step:781/1875 train_loss:3.5984 train_time:563477ms step_avg:730.84ms
step:782/1875 train_loss:3.7648 train_time:564206ms step_avg:730.84ms
step:783/1875 train_loss:3.7152 train_time:564934ms step_avg:730.83ms
step:784/1875 train_loss:3.6841 train_time:565669ms step_avg:730.84ms
step:785/1875 train_loss:3.6796 train_time:566398ms step_avg:730.84ms
step:786/1875 train_loss:3.7085 train_time:567129ms step_avg:730.84ms
step:787/1875 train_loss:3.6658 train_time:567852ms step_avg:730.83ms
step:788/1875 train_loss:3.7235 train_time:568584ms step_avg:730.83ms
step:789/1875 train_loss:3.6850 train_time:569309ms step_avg:730.82ms
step:790/1875 train_loss:3.6430 train_time:570039ms step_avg:730.82ms
step:791/1875 train_loss:3.6702 train_time:570767ms step_avg:730.82ms
step:792/1875 train_loss:3.7473 train_time:571500ms step_avg:730.82ms
step:793/1875 train_loss:3.7560 train_time:572228ms step_avg:730.81ms
step:794/1875 train_loss:3.7726 train_time:572955ms step_avg:730.81ms
step:795/1875 train_loss:3.7093 train_time:573695ms step_avg:730.82ms
step:796/1875 train_loss:3.8109 train_time:574428ms step_avg:730.82ms
step:797/1875 train_loss:3.7289 train_time:575162ms step_avg:730.83ms
step:798/1875 train_loss:3.5349 train_time:575897ms step_avg:730.83ms
step:799/1875 train_loss:3.6143 train_time:576624ms step_avg:730.83ms
step:800/1875 train_loss:4.3112 train_time:577369ms step_avg:730.85ms
step:801/1875 train_loss:3.8396 train_time:578104ms step_avg:730.85ms
step:802/1875 train_loss:3.6990 train_time:578824ms step_avg:730.84ms
step:803/1875 train_loss:3.7472 train_time:579561ms step_avg:730.85ms
step:804/1875 train_loss:3.7333 train_time:580295ms step_avg:730.85ms
step:805/1875 train_loss:3.6773 train_time:581027ms step_avg:730.85ms
step:806/1875 train_loss:3.6593 train_time:581758ms step_avg:730.85ms
step:807/1875 train_loss:3.7105 train_time:582492ms step_avg:730.86ms
step:808/1875 train_loss:3.7620 train_time:583210ms step_avg:730.84ms
step:809/1875 train_loss:3.9767 train_time:583945ms step_avg:730.85ms
step:810/1875 train_loss:3.8287 train_time:584667ms step_avg:730.83ms
step:811/1875 train_loss:3.6334 train_time:585389ms step_avg:730.82ms
step:812/1875 train_loss:3.7577 train_time:586116ms step_avg:730.82ms
step:813/1875 train_loss:3.7629 train_time:586843ms step_avg:730.81ms
step:814/1875 train_loss:3.7095 train_time:587568ms step_avg:730.81ms
step:815/1875 train_loss:3.5577 train_time:588304ms step_avg:730.81ms
step:816/1875 train_loss:3.8993 train_time:589022ms step_avg:730.80ms
step:817/1875 train_loss:3.7151 train_time:589747ms step_avg:730.79ms
step:818/1875 train_loss:3.6815 train_time:590480ms step_avg:730.79ms
step:819/1875 train_loss:3.6830 train_time:591208ms step_avg:730.79ms
step:820/1875 train_loss:3.6790 train_time:591935ms step_avg:730.78ms
step:821/1875 train_loss:3.5556 train_time:592663ms step_avg:730.78ms
step:822/1875 train_loss:3.6971 train_time:593391ms step_avg:730.78ms
step:823/1875 train_loss:3.7923 train_time:594117ms step_avg:730.77ms
step:824/1875 train_loss:3.5191 train_time:594843ms step_avg:730.77ms
step:825/1875 train_loss:3.7307 train_time:595572ms step_avg:730.76ms
step:826/1875 train_loss:3.8342 train_time:596302ms step_avg:730.76ms
step:827/1875 train_loss:3.5765 train_time:597040ms step_avg:730.77ms
step:828/1875 train_loss:3.6442 train_time:597781ms step_avg:730.78ms
step:829/1875 train_loss:3.6521 train_time:598512ms step_avg:730.78ms
step:830/1875 train_loss:3.7422 train_time:599236ms step_avg:730.78ms
step:831/1875 train_loss:3.5916 train_time:599967ms step_avg:730.78ms
step:832/1875 train_loss:3.7284 train_time:600703ms step_avg:730.78ms
step:833/1875 train_loss:3.7384 train_time:601430ms step_avg:730.78ms
step:834/1875 train_loss:3.7599 train_time:602164ms step_avg:730.78ms
step:835/1875 train_loss:3.6034 train_time:602904ms step_avg:730.79ms
step:836/1875 train_loss:3.8249 train_time:603637ms step_avg:730.80ms
step:837/1875 train_loss:3.6012 train_time:604366ms step_avg:730.79ms
step:838/1875 train_loss:3.5209 train_time:605088ms step_avg:730.78ms
step:839/1875 train_loss:3.7537 train_time:605819ms step_avg:730.78ms
step:840/1875 train_loss:3.6855 train_time:606541ms step_avg:730.77ms
step:841/1875 train_loss:3.7571 train_time:607273ms step_avg:730.77ms
step:842/1875 train_loss:3.6538 train_time:607993ms step_avg:730.76ms
step:843/1875 train_loss:3.7018 train_time:608725ms step_avg:730.76ms
step:844/1875 train_loss:3.6609 train_time:609451ms step_avg:730.76ms
step:845/1875 train_loss:3.6810 train_time:610179ms step_avg:730.75ms
step:846/1875 train_loss:3.6981 train_time:610915ms step_avg:730.76ms
step:847/1875 train_loss:3.7373 train_time:611640ms step_avg:730.75ms
step:848/1875 train_loss:3.6753 train_time:612378ms step_avg:730.76ms
step:849/1875 train_loss:3.5233 train_time:613106ms step_avg:730.76ms
step:850/1875 train_loss:3.7319 train_time:613835ms step_avg:730.76ms
step:851/1875 train_loss:3.6120 train_time:614560ms step_avg:730.75ms
step:852/1875 train_loss:3.7352 train_time:615293ms step_avg:730.75ms
step:853/1875 train_loss:3.5001 train_time:616023ms step_avg:730.75ms
step:854/1875 train_loss:3.8017 train_time:616746ms step_avg:730.74ms
step:855/1875 train_loss:3.7180 train_time:617467ms step_avg:730.73ms
step:856/1875 train_loss:3.4965 train_time:618193ms step_avg:730.72ms
step:857/1875 train_loss:3.7954 train_time:618926ms step_avg:730.73ms
step:858/1875 train_loss:3.8010 train_time:619667ms step_avg:730.74ms
step:859/1875 train_loss:3.5224 train_time:620400ms step_avg:730.74ms
step:860/1875 train_loss:3.7033 train_time:621138ms step_avg:730.75ms
step:861/1875 train_loss:3.7599 train_time:621869ms step_avg:730.75ms
step:862/1875 train_loss:3.5612 train_time:622592ms step_avg:730.74ms
step:863/1875 train_loss:3.6426 train_time:623330ms step_avg:730.75ms
step:864/1875 train_loss:3.9404 train_time:624071ms step_avg:730.76ms
step:865/1875 train_loss:3.8810 train_time:624805ms step_avg:730.77ms
step:866/1875 train_loss:3.7043 train_time:625551ms step_avg:730.78ms
step:867/1875 train_loss:3.6548 train_time:626275ms step_avg:730.78ms
step:868/1875 train_loss:3.8435 train_time:627010ms step_avg:730.78ms
step:869/1875 train_loss:3.5864 train_time:627746ms step_avg:730.79ms
step:870/1875 train_loss:3.5347 train_time:628477ms step_avg:730.79ms
step:871/1875 train_loss:3.7207 train_time:629202ms step_avg:730.78ms
step:872/1875 train_loss:3.6679 train_time:629930ms step_avg:730.78ms
step:873/1875 train_loss:3.6098 train_time:630658ms step_avg:730.77ms
step:874/1875 train_loss:3.7514 train_time:631380ms step_avg:730.76ms
step:875/1875 train_loss:3.6615 train_time:632107ms step_avg:730.76ms
step:875/1875 val_loss:3.6643 train_time:632247ms step_avg:730.92ms
============== Weight norms: ==============
name = 'module._orig_mod.transformer.h.0.attn.c_q.weight' | fro_norm = 37.02768 | spectral_norm = 10.39643 | nuclear_norm = 733.18231
name = 'module._orig_mod.transformer.h.0.attn.c_k.weight' | fro_norm = 34.48486 | spectral_norm = 13.65787 | nuclear_norm = 662.58801
name = 'module._orig_mod.transformer.h.1.attn.c_q.weight' | fro_norm = 35.92063 | spectral_norm = 9.08560 | nuclear_norm = 706.05945
name = 'module._orig_mod.transformer.h.1.attn.c_k.weight' | fro_norm = 33.51045 | spectral_norm = 11.67286 | nuclear_norm = 655.88892
name = 'module._orig_mod.transformer.h.2.attn.c_q.weight' | fro_norm = 35.51770 | spectral_norm = 7.74424 | nuclear_norm = 694.40863
name = 'module._orig_mod.transformer.h.2.attn.c_k.weight' | fro_norm = 33.84253 | spectral_norm = 8.88855 | nuclear_norm = 666.86218
name = 'module._orig_mod.transformer.h.3.attn.c_q.weight' | fro_norm = 34.69278 | spectral_norm = 7.85149 | nuclear_norm = 684.70020
name = 'module._orig_mod.transformer.h.3.attn.c_k.weight' | fro_norm = 33.01545 | spectral_norm = 9.55539 | nuclear_norm = 654.18469
name = 'module._orig_mod.transformer.h.4.attn.c_q.weight' | fro_norm = 35.03860 | spectral_norm = 7.20252 | nuclear_norm = 690.27057
name = 'module._orig_mod.transformer.h.4.attn.c_k.weight' | fro_norm = 33.38998 | spectral_norm = 7.71730 | nuclear_norm = 667.74249
name = 'module._orig_mod.transformer.h.5.attn.c_q.weight' | fro_norm = 34.42083 | spectral_norm = 7.41249 | nuclear_norm = 679.37750
name = 'module._orig_mod.transformer.h.5.attn.c_k.weight' | fro_norm = 33.03093 | spectral_norm = 7.93991 | nuclear_norm = 659.87671
name = 'module._orig_mod.transformer.h.6.attn.c_q.weight' | fro_norm = 34.05000 | spectral_norm = 8.01773 | nuclear_norm = 673.94446
name = 'module._orig_mod.transformer.h.6.attn.c_k.weight' | fro_norm = 32.84118 | spectral_norm = 8.62642 | nuclear_norm = 657.40149
name = 'module._orig_mod.transformer.h.7.attn.c_q.weight' | fro_norm = 33.94673 | spectral_norm = 6.91654 | nuclear_norm = 662.42505
name = 'module._orig_mod.transformer.h.7.attn.c_k.weight' | fro_norm = 32.59501 | spectral_norm = 6.23583 | nuclear_norm = 652.37537
name = 'module._orig_mod.transformer.h.8.attn.c_q.weight' | fro_norm = 34.99522 | spectral_norm = 7.69050 | nuclear_norm = 686.50775
name = 'module._orig_mod.transformer.h.8.attn.c_k.weight' | fro_norm = 33.24333 | spectral_norm = 7.29034 | nuclear_norm = 668.07330
name = 'module._orig_mod.transformer.h.9.attn.c_q.weight' | fro_norm = 34.52445 | spectral_norm = 7.20993 | nuclear_norm = 674.39618
name = 'module._orig_mod.transformer.h.9.attn.c_k.weight' | fro_norm = 33.44409 | spectral_norm = 6.61169 | nuclear_norm = 665.04700
name = 'module._orig_mod.transformer.h.10.attn.c_q.weight' | fro_norm = 34.44574 | spectral_norm = 7.16181 | nuclear_norm = 665.56854
name = 'module._orig_mod.transformer.h.10.attn.c_k.weight' | fro_norm = 33.72283 | spectral_norm = 6.95009 | nuclear_norm = 664.48572
name = 'module._orig_mod.transformer.h.11.attn.c_q.weight' | fro_norm = 34.07307 | spectral_norm = 7.09269 | nuclear_norm = 664.37170
name = 'module._orig_mod.transformer.h.11.attn.c_k.weight' | fro_norm = 32.05301 | spectral_norm = 6.80195 | nuclear_norm = 639.59253
===========================================
step:876/1875 train_loss:3.7683 train_time:632847ms step_avg:730.77ms
step:877/1875 train_loss:3.5431 train_time:633571ms step_avg:730.76ms
step:878/1875 train_loss:3.7794 train_time:634305ms step_avg:730.77ms
step:879/1875 train_loss:3.6381 train_time:635028ms step_avg:730.76ms
step:880/1875 train_loss:3.9961 train_time:635753ms step_avg:730.75ms
step:881/1875 train_loss:3.7165 train_time:636478ms step_avg:730.74ms
step:882/1875 train_loss:3.5314 train_time:637196ms step_avg:730.73ms
step:883/1875 train_loss:3.8529 train_time:637923ms step_avg:730.72ms
step:884/1875 train_loss:3.5576 train_time:638651ms step_avg:730.72ms
step:885/1875 train_loss:3.8030 train_time:639375ms step_avg:730.71ms
step:886/1875 train_loss:3.6700 train_time:640107ms step_avg:730.72ms
step:887/1875 train_loss:3.7480 train_time:640843ms step_avg:730.72ms
step:888/1875 train_loss:3.7227 train_time:641572ms step_avg:730.72ms
step:889/1875 train_loss:3.7559 train_time:642298ms step_avg:730.71ms
step:890/1875 train_loss:3.7125 train_time:643044ms step_avg:730.73ms
step:891/1875 train_loss:3.5580 train_time:643768ms step_avg:730.72ms
step:892/1875 train_loss:3.7256 train_time:644489ms step_avg:730.71ms
step:893/1875 train_loss:3.6316 train_time:645224ms step_avg:730.72ms
step:894/1875 train_loss:3.6974 train_time:645951ms step_avg:730.71ms
step:895/1875 train_loss:3.5207 train_time:646672ms step_avg:730.70ms
step:896/1875 train_loss:3.4869 train_time:647407ms step_avg:730.71ms
step:897/1875 train_loss:3.6046 train_time:648144ms step_avg:730.71ms
step:898/1875 train_loss:3.7856 train_time:648875ms step_avg:730.72ms
step:899/1875 train_loss:3.6537 train_time:649607ms step_avg:730.72ms
step:900/1875 train_loss:3.7047 train_time:650337ms step_avg:730.72ms
step:901/1875 train_loss:3.8642 train_time:651062ms step_avg:730.71ms
step:902/1875 train_loss:3.6466 train_time:651787ms step_avg:730.70ms
step:903/1875 train_loss:3.5902 train_time:652520ms step_avg:730.71ms
step:904/1875 train_loss:3.8110 train_time:653257ms step_avg:730.71ms
step:905/1875 train_loss:3.7588 train_time:653982ms step_avg:730.71ms
step:906/1875 train_loss:3.6071 train_time:654710ms step_avg:730.70ms
step:907/1875 train_loss:3.6097 train_time:655437ms step_avg:730.70ms
step:908/1875 train_loss:3.9036 train_time:656176ms step_avg:730.71ms
step:909/1875 train_loss:3.6239 train_time:656916ms step_avg:730.72ms
step:910/1875 train_loss:3.7992 train_time:657643ms step_avg:730.71ms
step:911/1875 train_loss:4.0000 train_time:658377ms step_avg:730.72ms
step:912/1875 train_loss:3.4834 train_time:659111ms step_avg:730.72ms
step:913/1875 train_loss:3.7758 train_time:659831ms step_avg:730.71ms
step:914/1875 train_loss:3.6490 train_time:660566ms step_avg:730.71ms
step:915/1875 train_loss:3.7088 train_time:661300ms step_avg:730.72ms
step:916/1875 train_loss:3.8501 train_time:662040ms step_avg:730.73ms
step:917/1875 train_loss:3.6092 train_time:662767ms step_avg:730.72ms
step:918/1875 train_loss:3.5979 train_time:663493ms step_avg:730.72ms
step:919/1875 train_loss:3.6921 train_time:664232ms step_avg:730.73ms
step:920/1875 train_loss:3.5798 train_time:664971ms step_avg:730.74ms
step:921/1875 train_loss:3.6416 train_time:665711ms step_avg:730.75ms
step:922/1875 train_loss:3.5908 train_time:666438ms step_avg:730.74ms
step:923/1875 train_loss:3.7484 train_time:667163ms step_avg:730.74ms
step:924/1875 train_loss:3.6516 train_time:667890ms step_avg:730.73ms
step:925/1875 train_loss:3.6060 train_time:668611ms step_avg:730.72ms
step:926/1875 train_loss:3.7296 train_time:669345ms step_avg:730.73ms
step:927/1875 train_loss:3.6047 train_time:670075ms step_avg:730.72ms
step:928/1875 train_loss:3.7912 train_time:670807ms step_avg:730.73ms
step:929/1875 train_loss:3.6655 train_time:671532ms step_avg:730.72ms
step:930/1875 train_loss:3.4986 train_time:672261ms step_avg:730.72ms
step:931/1875 train_loss:3.8367 train_time:672987ms step_avg:730.71ms
step:932/1875 train_loss:3.5182 train_time:673717ms step_avg:730.71ms
step:933/1875 train_loss:3.5147 train_time:674441ms step_avg:730.71ms
step:934/1875 train_loss:3.7167 train_time:675177ms step_avg:730.71ms
step:935/1875 train_loss:3.6803 train_time:675900ms step_avg:730.70ms
step:936/1875 train_loss:3.5314 train_time:676644ms step_avg:730.72ms
step:937/1875 train_loss:3.4821 train_time:677372ms step_avg:730.71ms
step:938/1875 train_loss:3.6469 train_time:678102ms step_avg:730.71ms
step:939/1875 train_loss:3.4464 train_time:678827ms step_avg:730.71ms
step:940/1875 train_loss:3.7190 train_time:679551ms step_avg:730.70ms
step:941/1875 train_loss:3.5722 train_time:680292ms step_avg:730.71ms
step:942/1875 train_loss:3.5631 train_time:681028ms step_avg:730.72ms
step:943/1875 train_loss:3.6869 train_time:681767ms step_avg:730.73ms
step:944/1875 train_loss:3.5699 train_time:682494ms step_avg:730.72ms
step:945/1875 train_loss:3.5842 train_time:683218ms step_avg:730.71ms
step:946/1875 train_loss:3.7708 train_time:683955ms step_avg:730.72ms
step:947/1875 train_loss:3.6530 train_time:684687ms step_avg:730.72ms
step:948/1875 train_loss:3.7283 train_time:685427ms step_avg:730.73ms
step:949/1875 train_loss:3.8937 train_time:686159ms step_avg:730.73ms
step:950/1875 train_loss:3.5079 train_time:687078ms step_avg:730.93ms
step:951/1875 train_loss:3.5889 train_time:687808ms step_avg:730.93ms
step:952/1875 train_loss:3.8426 train_time:688554ms step_avg:730.95ms
step:953/1875 train_loss:3.5458 train_time:689284ms step_avg:730.95ms
step:954/1875 train_loss:3.6184 train_time:690014ms step_avg:730.95ms
step:955/1875 train_loss:3.7075 train_time:690753ms step_avg:730.96ms
step:956/1875 train_loss:3.5780 train_time:691493ms step_avg:730.96ms
step:957/1875 train_loss:3.6166 train_time:692212ms step_avg:730.95ms
step:958/1875 train_loss:3.5839 train_time:692944ms step_avg:730.95ms
step:959/1875 train_loss:3.6459 train_time:693687ms step_avg:730.97ms
step:960/1875 train_loss:3.6432 train_time:694424ms step_avg:730.97ms
step:961/1875 train_loss:3.6530 train_time:695148ms step_avg:730.97ms
step:962/1875 train_loss:3.5388 train_time:695887ms step_avg:730.97ms
step:963/1875 train_loss:3.7918 train_time:696628ms step_avg:730.98ms
step:964/1875 train_loss:3.7486 train_time:697355ms step_avg:730.98ms
step:965/1875 train_loss:3.7632 train_time:698083ms step_avg:730.98ms
step:966/1875 train_loss:3.5728 train_time:698817ms step_avg:730.98ms
step:967/1875 train_loss:3.6296 train_time:699542ms step_avg:730.97ms
step:968/1875 train_loss:3.8589 train_time:700274ms step_avg:730.98ms
step:969/1875 train_loss:3.6755 train_time:701001ms step_avg:730.97ms
step:970/1875 train_loss:3.6722 train_time:701723ms step_avg:730.96ms
step:971/1875 train_loss:3.7207 train_time:702456ms step_avg:730.96ms
step:972/1875 train_loss:3.5202 train_time:703181ms step_avg:730.96ms
step:973/1875 train_loss:3.6839 train_time:703915ms step_avg:730.96ms
step:974/1875 train_loss:3.6652 train_time:704640ms step_avg:730.95ms
step:975/1875 train_loss:3.6961 train_time:705361ms step_avg:730.94ms
step:976/1875 train_loss:3.7521 train_time:706094ms step_avg:730.95ms
step:977/1875 train_loss:3.6217 train_time:706823ms step_avg:730.94ms
step:978/1875 train_loss:3.8224 train_time:707551ms step_avg:730.94ms
step:979/1875 train_loss:3.7224 train_time:708273ms step_avg:730.93ms
step:980/1875 train_loss:3.5056 train_time:709000ms step_avg:730.93ms
step:981/1875 train_loss:3.7798 train_time:709728ms step_avg:730.93ms
step:982/1875 train_loss:3.5648 train_time:710455ms step_avg:730.92ms
step:983/1875 train_loss:3.7179 train_time:711175ms step_avg:730.91ms
step:984/1875 train_loss:3.6932 train_time:711899ms step_avg:730.90ms
step:985/1875 train_loss:3.6757 train_time:712636ms step_avg:730.91ms
step:986/1875 train_loss:3.6498 train_time:713375ms step_avg:730.92ms
step:987/1875 train_loss:3.7258 train_time:714105ms step_avg:730.92ms
step:988/1875 train_loss:3.5605 train_time:714830ms step_avg:730.91ms
step:989/1875 train_loss:3.6393 train_time:715550ms step_avg:730.90ms
step:990/1875 train_loss:3.6470 train_time:716283ms step_avg:730.90ms
step:991/1875 train_loss:3.5695 train_time:717027ms step_avg:730.91ms
step:992/1875 train_loss:3.7935 train_time:717772ms step_avg:730.93ms
step:993/1875 train_loss:3.6133 train_time:718498ms step_avg:730.92ms
step:994/1875 train_loss:3.5891 train_time:719227ms step_avg:730.92ms
step:995/1875 train_loss:3.6587 train_time:719978ms step_avg:730.94ms
step:996/1875 train_loss:3.7394 train_time:720703ms step_avg:730.94ms
step:997/1875 train_loss:3.6862 train_time:721427ms step_avg:730.93ms
step:998/1875 train_loss:3.6083 train_time:722154ms step_avg:730.92ms
step:999/1875 train_loss:3.9326 train_time:722875ms step_avg:730.92ms
step:1000/1875 train_loss:3.5934 train_time:723604ms step_avg:730.91ms
step:1000/1875 val_loss:3.6189 train_time:723735ms step_avg:731.05ms
============== Weight norms: ==============
name = 'module._orig_mod.transformer.h.0.attn.c_q.weight' | fro_norm = 39.55239 | spectral_norm = 11.45483 | nuclear_norm = 780.58136
name = 'module._orig_mod.transformer.h.0.attn.c_k.weight' | fro_norm = 36.90657 | spectral_norm = 14.93164 | nuclear_norm = 704.77087
name = 'module._orig_mod.transformer.h.1.attn.c_q.weight' | fro_norm = 38.25262 | spectral_norm = 9.45269 | nuclear_norm = 749.91418
name = 'module._orig_mod.transformer.h.1.attn.c_k.weight' | fro_norm = 35.79974 | spectral_norm = 12.26093 | nuclear_norm = 696.83765
name = 'module._orig_mod.transformer.h.2.attn.c_q.weight' | fro_norm = 37.72295 | spectral_norm = 8.21743 | nuclear_norm = 734.04077
name = 'module._orig_mod.transformer.h.2.attn.c_k.weight' | fro_norm = 36.05627 | spectral_norm = 9.39549 | nuclear_norm = 706.23804
name = 'module._orig_mod.transformer.h.3.attn.c_q.weight' | fro_norm = 36.68870 | spectral_norm = 8.09459 | nuclear_norm = 722.62378
name = 'module._orig_mod.transformer.h.3.attn.c_k.weight' | fro_norm = 35.09624 | spectral_norm = 10.13242 | nuclear_norm = 692.56067
name = 'module._orig_mod.transformer.h.4.attn.c_q.weight' | fro_norm = 36.98973 | spectral_norm = 7.56416 | nuclear_norm = 727.82916
name = 'module._orig_mod.transformer.h.4.attn.c_k.weight' | fro_norm = 35.37863 | spectral_norm = 8.18762 | nuclear_norm = 704.91199
name = 'module._orig_mod.transformer.h.5.attn.c_q.weight' | fro_norm = 36.36366 | spectral_norm = 7.73422 | nuclear_norm = 715.58301
name = 'module._orig_mod.transformer.h.5.attn.c_k.weight' | fro_norm = 35.06280 | spectral_norm = 8.36407 | nuclear_norm = 697.69794
name = 'module._orig_mod.transformer.h.6.attn.c_q.weight' | fro_norm = 35.84709 | spectral_norm = 8.46880 | nuclear_norm = 707.37390
name = 'module._orig_mod.transformer.h.6.attn.c_k.weight' | fro_norm = 34.74429 | spectral_norm = 9.19418 | nuclear_norm = 692.79828
name = 'module._orig_mod.transformer.h.7.attn.c_q.weight' | fro_norm = 35.81876 | spectral_norm = 7.19716 | nuclear_norm = 696.95520
name = 'module._orig_mod.transformer.h.7.attn.c_k.weight' | fro_norm = 34.54865 | spectral_norm = 6.58920 | nuclear_norm = 688.48236
name = 'module._orig_mod.transformer.h.8.attn.c_q.weight' | fro_norm = 37.06185 | spectral_norm = 8.21532 | nuclear_norm = 724.77527
name = 'module._orig_mod.transformer.h.8.attn.c_k.weight' | fro_norm = 35.29625 | spectral_norm = 7.82872 | nuclear_norm = 706.16370
name = 'module._orig_mod.transformer.h.9.attn.c_q.weight' | fro_norm = 36.59757 | spectral_norm = 7.64122 | nuclear_norm = 712.85291
name = 'module._orig_mod.transformer.h.9.attn.c_k.weight' | fro_norm = 35.52528 | spectral_norm = 7.07084 | nuclear_norm = 703.83972
name = 'module._orig_mod.transformer.h.10.attn.c_q.weight' | fro_norm = 36.47245 | spectral_norm = 7.63221 | nuclear_norm = 702.05212
name = 'module._orig_mod.transformer.h.10.attn.c_k.weight' | fro_norm = 35.80601 | spectral_norm = 7.41724 | nuclear_norm = 702.04694
name = 'module._orig_mod.transformer.h.11.attn.c_q.weight' | fro_norm = 36.07073 | spectral_norm = 7.48978 | nuclear_norm = 699.77094
name = 'module._orig_mod.transformer.h.11.attn.c_k.weight' | fro_norm = 33.94481 | spectral_norm = 7.16314 | nuclear_norm = 673.04248
===========================================
step:1001/1875 train_loss:3.7233 train_time:724319ms step_avg:730.90ms
step:1002/1875 train_loss:3.5836 train_time:725046ms step_avg:730.89ms
step:1003/1875 train_loss:3.6612 train_time:725762ms step_avg:730.88ms
step:1004/1875 train_loss:3.5346 train_time:726494ms step_avg:730.88ms
step:1005/1875 train_loss:3.7059 train_time:727237ms step_avg:730.89ms
step:1006/1875 train_loss:3.7586 train_time:727970ms step_avg:730.89ms
step:1007/1875 train_loss:3.5440 train_time:728698ms step_avg:730.89ms
step:1008/1875 train_loss:3.6132 train_time:729430ms step_avg:730.89ms
step:1009/1875 train_loss:3.5956 train_time:730156ms step_avg:730.89ms
step:1010/1875 train_loss:3.7073 train_time:730890ms step_avg:730.89ms
step:1011/1875 train_loss:3.8221 train_time:731641ms step_avg:730.91ms
step:1012/1875 train_loss:3.7082 train_time:732374ms step_avg:730.91ms
step:1013/1875 train_loss:3.6790 train_time:733095ms step_avg:730.90ms
step:1014/1875 train_loss:3.5447 train_time:733825ms step_avg:730.90ms
step:1015/1875 train_loss:3.6912 train_time:734553ms step_avg:730.90ms
step:1016/1875 train_loss:3.7807 train_time:735277ms step_avg:730.89ms
step:1017/1875 train_loss:3.4744 train_time:735999ms step_avg:730.88ms
step:1018/1875 train_loss:3.5768 train_time:736739ms step_avg:730.89ms
step:1019/1875 train_loss:3.5719 train_time:737476ms step_avg:730.90ms
step:1020/1875 train_loss:3.5441 train_time:738206ms step_avg:730.90ms
step:1021/1875 train_loss:3.6769 train_time:738931ms step_avg:730.89ms
step:1022/1875 train_loss:3.5547 train_time:739658ms step_avg:730.89ms
step:1023/1875 train_loss:3.5107 train_time:740390ms step_avg:730.89ms
step:1024/1875 train_loss:3.6403 train_time:741128ms step_avg:730.90ms
step:1025/1875 train_loss:3.6624 train_time:741861ms step_avg:730.90ms
step:1026/1875 train_loss:3.6307 train_time:742595ms step_avg:730.90ms
step:1027/1875 train_loss:3.6443 train_time:743330ms step_avg:730.90ms
step:1028/1875 train_loss:3.7891 train_time:744057ms step_avg:730.90ms
step:1029/1875 train_loss:3.4806 train_time:744794ms step_avg:730.91ms
step:1030/1875 train_loss:3.5435 train_time:745536ms step_avg:730.92ms
step:1031/1875 train_loss:3.4818 train_time:746277ms step_avg:730.93ms
step:1032/1875 train_loss:3.6842 train_time:747000ms step_avg:730.92ms
step:1033/1875 train_loss:3.6705 train_time:747728ms step_avg:730.92ms
step:1034/1875 train_loss:3.8554 train_time:748460ms step_avg:730.92ms
step:1035/1875 train_loss:3.6502 train_time:749188ms step_avg:730.92ms
step:1036/1875 train_loss:3.5903 train_time:749922ms step_avg:730.92ms
step:1037/1875 train_loss:3.5978 train_time:750668ms step_avg:730.93ms
step:1038/1875 train_loss:3.6461 train_time:751394ms step_avg:730.93ms
step:1039/1875 train_loss:3.9524 train_time:752124ms step_avg:730.93ms
step:1040/1875 train_loss:3.7728 train_time:752848ms step_avg:730.92ms
step:1041/1875 train_loss:3.6681 train_time:753572ms step_avg:730.91ms
step:1042/1875 train_loss:3.5681 train_time:754297ms step_avg:730.91ms
step:1043/1875 train_loss:3.6370 train_time:755029ms step_avg:730.91ms
step:1044/1875 train_loss:3.6762 train_time:755768ms step_avg:730.92ms
step:1045/1875 train_loss:3.5932 train_time:756494ms step_avg:730.91ms
step:1046/1875 train_loss:3.6065 train_time:757218ms step_avg:730.91ms
step:1047/1875 train_loss:3.6738 train_time:757946ms step_avg:730.90ms
step:1048/1875 train_loss:3.5819 train_time:758679ms step_avg:730.90ms
step:1049/1875 train_loss:3.8055 train_time:759416ms step_avg:730.91ms
step:1050/1875 train_loss:3.6566 train_time:760154ms step_avg:730.92ms
step:1051/1875 train_loss:3.5681 train_time:760883ms step_avg:730.92ms
step:1052/1875 train_loss:3.5523 train_time:761608ms step_avg:730.91ms
step:1053/1875 train_loss:3.6624 train_time:762341ms step_avg:730.91ms
step:1054/1875 train_loss:3.5212 train_time:763067ms step_avg:730.91ms
step:1055/1875 train_loss:3.8589 train_time:763796ms step_avg:730.90ms
step:1056/1875 train_loss:3.7053 train_time:764525ms step_avg:730.90ms
step:1057/1875 train_loss:3.5356 train_time:765253ms step_avg:730.90ms
step:1058/1875 train_loss:3.6615 train_time:765985ms step_avg:730.90ms
step:1059/1875 train_loss:3.7435 train_time:766713ms step_avg:730.90ms
step:1060/1875 train_loss:3.4636 train_time:767444ms step_avg:730.90ms
step:1061/1875 train_loss:3.5344 train_time:768180ms step_avg:730.90ms
step:1062/1875 train_loss:3.6008 train_time:768914ms step_avg:730.91ms
step:1063/1875 train_loss:3.5773 train_time:769637ms step_avg:730.90ms
step:1064/1875 train_loss:3.5453 train_time:770369ms step_avg:730.90ms
step:1065/1875 train_loss:3.6361 train_time:771096ms step_avg:730.90ms
step:1066/1875 train_loss:3.5610 train_time:771825ms step_avg:730.89ms
step:1067/1875 train_loss:3.5196 train_time:772549ms step_avg:730.89ms
step:1068/1875 train_loss:3.5711 train_time:773286ms step_avg:730.89ms
step:1069/1875 train_loss:3.4458 train_time:774016ms step_avg:730.89ms
step:1070/1875 train_loss:3.5966 train_time:774741ms step_avg:730.89ms
step:1071/1875 train_loss:3.4801 train_time:775482ms step_avg:730.90ms
step:1072/1875 train_loss:3.7272 train_time:776207ms step_avg:730.89ms
step:1073/1875 train_loss:3.6652 train_time:776946ms step_avg:730.90ms
step:1074/1875 train_loss:3.6019 train_time:777673ms step_avg:730.90ms
step:1075/1875 train_loss:3.6915 train_time:778394ms step_avg:730.89ms
step:1076/1875 train_loss:3.6099 train_time:779122ms step_avg:730.88ms
step:1077/1875 train_loss:3.5640 train_time:779851ms step_avg:730.88ms
step:1078/1875 train_loss:3.9461 train_time:780574ms step_avg:730.87ms
step:1079/1875 train_loss:3.6234 train_time:781303ms step_avg:730.87ms
step:1080/1875 train_loss:3.2655 train_time:782041ms step_avg:730.88ms
step:1081/1875 train_loss:3.6908 train_time:782777ms step_avg:730.88ms
step:1082/1875 train_loss:3.5941 train_time:783510ms step_avg:730.89ms
step:1083/1875 train_loss:3.6758 train_time:784245ms step_avg:730.89ms
step:1084/1875 train_loss:3.7601 train_time:784987ms step_avg:730.90ms
step:1085/1875 train_loss:3.6680 train_time:785713ms step_avg:730.90ms
step:1086/1875 train_loss:3.6390 train_time:786435ms step_avg:730.89ms
step:1087/1875 train_loss:3.5913 train_time:787165ms step_avg:730.89ms
step:1088/1875 train_loss:3.8087 train_time:787906ms step_avg:730.90ms
step:1089/1875 train_loss:3.6840 train_time:788643ms step_avg:730.90ms
step:1090/1875 train_loss:3.5318 train_time:789373ms step_avg:730.90ms
step:1091/1875 train_loss:3.5525 train_time:790100ms step_avg:730.90ms
step:1092/1875 train_loss:3.6573 train_time:790835ms step_avg:730.90ms
step:1093/1875 train_loss:3.4588 train_time:791564ms step_avg:730.90ms
step:1094/1875 train_loss:3.6629 train_time:792286ms step_avg:730.89ms
step:1095/1875 train_loss:3.7787 train_time:793009ms step_avg:730.88ms
step:1096/1875 train_loss:3.6286 train_time:793737ms step_avg:730.88ms
step:1097/1875 train_loss:3.5834 train_time:794470ms step_avg:730.88ms
step:1098/1875 train_loss:3.5977 train_time:795208ms step_avg:730.89ms
step:1099/1875 train_loss:3.6598 train_time:795932ms step_avg:730.88ms
step:1100/1875 train_loss:3.7250 train_time:796671ms step_avg:730.89ms
step:1101/1875 train_loss:3.6918 train_time:797407ms step_avg:730.90ms
step:1102/1875 train_loss:3.6035 train_time:798143ms step_avg:730.90ms
step:1103/1875 train_loss:3.4598 train_time:798875ms step_avg:730.90ms
step:1104/1875 train_loss:3.5025 train_time:799602ms step_avg:730.90ms
step:1105/1875 train_loss:3.6188 train_time:800339ms step_avg:730.90ms
step:1106/1875 train_loss:3.4880 train_time:801075ms step_avg:730.91ms
step:1107/1875 train_loss:4.2363 train_time:801803ms step_avg:730.91ms
step:1108/1875 train_loss:3.4069 train_time:802537ms step_avg:730.91ms
step:1109/1875 train_loss:3.7353 train_time:803263ms step_avg:730.90ms
step:1110/1875 train_loss:3.5148 train_time:803990ms step_avg:730.90ms
step:1111/1875 train_loss:3.6734 train_time:804714ms step_avg:730.89ms
step:1112/1875 train_loss:3.6013 train_time:805438ms step_avg:730.89ms
step:1113/1875 train_loss:3.6494 train_time:806174ms step_avg:730.89ms
step:1114/1875 train_loss:3.7445 train_time:806904ms step_avg:730.89ms
step:1115/1875 train_loss:3.6100 train_time:807625ms step_avg:730.88ms
step:1116/1875 train_loss:3.5266 train_time:808353ms step_avg:730.88ms
step:1117/1875 train_loss:3.4243 train_time:809098ms step_avg:730.89ms
step:1118/1875 train_loss:3.6003 train_time:809834ms step_avg:730.90ms
step:1119/1875 train_loss:3.7630 train_time:810569ms step_avg:730.90ms
step:1120/1875 train_loss:3.8021 train_time:811304ms step_avg:730.90ms
step:1121/1875 train_loss:3.6525 train_time:812029ms step_avg:730.90ms
step:1122/1875 train_loss:3.6715 train_time:812753ms step_avg:730.89ms
step:1123/1875 train_loss:3.5603 train_time:813478ms step_avg:730.89ms
step:1124/1875 train_loss:3.6304 train_time:814196ms step_avg:730.88ms
step:1125/1875 train_loss:3.7611 train_time:814926ms step_avg:730.88ms
step:1125/1875 val_loss:3.5919 train_time:815067ms step_avg:731.00ms
============== Weight norms: ==============
name = 'module._orig_mod.transformer.h.0.attn.c_q.weight' | fro_norm = 41.95004 | spectral_norm = 12.42412 | nuclear_norm = 826.72949
name = 'module._orig_mod.transformer.h.0.attn.c_k.weight' | fro_norm = 39.22513 | spectral_norm = 16.20443 | nuclear_norm = 745.49591
name = 'module._orig_mod.transformer.h.1.attn.c_q.weight' | fro_norm = 40.49583 | spectral_norm = 9.80952 | nuclear_norm = 792.72632
name = 'module._orig_mod.transformer.h.1.attn.c_k.weight' | fro_norm = 38.01177 | spectral_norm = 12.86494 | nuclear_norm = 737.16394
name = 'module._orig_mod.transformer.h.2.attn.c_q.weight' | fro_norm = 39.83602 | spectral_norm = 8.73834 | nuclear_norm = 772.09595
name = 'module._orig_mod.transformer.h.2.attn.c_k.weight' | fro_norm = 38.19133 | spectral_norm = 9.85286 | nuclear_norm = 744.57123
name = 'module._orig_mod.transformer.h.3.attn.c_q.weight' | fro_norm = 38.58066 | spectral_norm = 8.43686 | nuclear_norm = 758.87823
name = 'module._orig_mod.transformer.h.3.attn.c_k.weight' | fro_norm = 37.10699 | spectral_norm = 10.73725 | nuclear_norm = 730.43463
name = 'module._orig_mod.transformer.h.4.attn.c_q.weight' | fro_norm = 38.86719 | spectral_norm = 7.87239 | nuclear_norm = 764.41113
name = 'module._orig_mod.transformer.h.4.attn.c_k.weight' | fro_norm = 37.30100 | spectral_norm = 8.72955 | nuclear_norm = 741.29260
name = 'module._orig_mod.transformer.h.5.attn.c_q.weight' | fro_norm = 38.25898 | spectral_norm = 8.15612 | nuclear_norm = 751.13794
name = 'module._orig_mod.transformer.h.5.attn.c_k.weight' | fro_norm = 37.06391 | spectral_norm = 8.82867 | nuclear_norm = 735.13037
name = 'module._orig_mod.transformer.h.6.attn.c_q.weight' | fro_norm = 37.56170 | spectral_norm = 8.85039 | nuclear_norm = 739.94366
name = 'module._orig_mod.transformer.h.6.attn.c_k.weight' | fro_norm = 36.55949 | spectral_norm = 9.59536 | nuclear_norm = 727.51880
name = 'module._orig_mod.transformer.h.7.attn.c_q.weight' | fro_norm = 37.62130 | spectral_norm = 7.57974 | nuclear_norm = 731.00757
name = 'module._orig_mod.transformer.h.7.attn.c_k.weight' | fro_norm = 36.42965 | spectral_norm = 6.93928 | nuclear_norm = 724.34772
name = 'module._orig_mod.transformer.h.8.attn.c_q.weight' | fro_norm = 39.03352 | spectral_norm = 8.67502 | nuclear_norm = 762.27905
name = 'module._orig_mod.transformer.h.8.attn.c_k.weight' | fro_norm = 37.25554 | spectral_norm = 8.27777 | nuclear_norm = 743.35364
name = 'module._orig_mod.transformer.h.9.attn.c_q.weight' | fro_norm = 38.54475 | spectral_norm = 8.12948 | nuclear_norm = 749.58240
name = 'module._orig_mod.transformer.h.9.attn.c_k.weight' | fro_norm = 37.48214 | spectral_norm = 7.34666 | nuclear_norm = 741.52771
name = 'module._orig_mod.transformer.h.10.attn.c_q.weight' | fro_norm = 38.43303 | spectral_norm = 8.09760 | nuclear_norm = 738.05847
name = 'module._orig_mod.transformer.h.10.attn.c_k.weight' | fro_norm = 37.78518 | spectral_norm = 7.74662 | nuclear_norm = 738.88293
name = 'module._orig_mod.transformer.h.11.attn.c_q.weight' | fro_norm = 37.92628 | spectral_norm = 7.85718 | nuclear_norm = 733.98975
name = 'module._orig_mod.transformer.h.11.attn.c_k.weight' | fro_norm = 35.72526 | spectral_norm = 7.52534 | nuclear_norm = 705.50592
===========================================
step:1126/1875 train_loss:3.5265 train_time:815663ms step_avg:730.88ms
step:1127/1875 train_loss:3.3927 train_time:816398ms step_avg:730.88ms
step:1128/1875 train_loss:3.6561 train_time:817137ms step_avg:730.89ms
step:1129/1875 train_loss:3.8657 train_time:817866ms step_avg:730.89ms
step:1130/1875 train_loss:3.4090 train_time:818603ms step_avg:730.90ms
step:1131/1875 train_loss:3.7437 train_time:819330ms step_avg:730.89ms
step:1132/1875 train_loss:3.5612 train_time:820054ms step_avg:730.89ms
step:1133/1875 train_loss:3.5767 train_time:820779ms step_avg:730.88ms
step:1134/1875 train_loss:3.5385 train_time:821506ms step_avg:730.88ms
step:1135/1875 train_loss:3.6879 train_time:822240ms step_avg:730.88ms
step:1136/1875 train_loss:3.6335 train_time:822978ms step_avg:730.89ms
step:1137/1875 train_loss:3.6957 train_time:823707ms step_avg:730.88ms
step:1138/1875 train_loss:3.7279 train_time:824441ms step_avg:730.89ms
step:1139/1875 train_loss:3.6363 train_time:825178ms step_avg:730.89ms
step:1140/1875 train_loss:3.5377 train_time:826113ms step_avg:731.07ms
step:1141/1875 train_loss:3.8383 train_time:826843ms step_avg:731.07ms
step:1142/1875 train_loss:3.6468 train_time:827569ms step_avg:731.07ms
step:1143/1875 train_loss:3.7103 train_time:828514ms step_avg:731.26ms
step:1144/1875 train_loss:3.7462 train_time:829236ms step_avg:731.25ms
step:1145/1875 train_loss:3.3618 train_time:829969ms step_avg:731.25ms
step:1146/1875 train_loss:3.6793 train_time:830704ms step_avg:731.25ms
step:1147/1875 train_loss:3.5255 train_time:831441ms step_avg:731.26ms
step:1148/1875 train_loss:3.5759 train_time:832163ms step_avg:731.25ms
step:1149/1875 train_loss:3.6407 train_time:832894ms step_avg:731.25ms
step:1150/1875 train_loss:3.7153 train_time:833619ms step_avg:731.24ms
step:1151/1875 train_loss:3.6767 train_time:834344ms step_avg:731.24ms
step:1152/1875 train_loss:3.5762 train_time:835076ms step_avg:731.24ms
step:1153/1875 train_loss:3.5279 train_time:835815ms step_avg:731.25ms
step:1154/1875 train_loss:3.7696 train_time:836550ms step_avg:731.25ms
step:1155/1875 train_loss:3.7620 train_time:837287ms step_avg:731.26ms
step:1156/1875 train_loss:3.4753 train_time:838016ms step_avg:731.25ms
step:1157/1875 train_loss:3.4793 train_time:838738ms step_avg:731.24ms
step:1158/1875 train_loss:3.6253 train_time:839478ms step_avg:731.25ms
step:1159/1875 train_loss:3.6682 train_time:840208ms step_avg:731.25ms
step:1160/1875 train_loss:3.4072 train_time:840937ms step_avg:731.25ms
step:1161/1875 train_loss:3.4808 train_time:841665ms step_avg:731.25ms
step:1162/1875 train_loss:3.4679 train_time:842388ms step_avg:731.24ms
step:1163/1875 train_loss:3.6833 train_time:843120ms step_avg:731.24ms
step:1164/1875 train_loss:3.4875 train_time:843853ms step_avg:731.24ms
step:1165/1875 train_loss:3.6152 train_time:844582ms step_avg:731.24ms
step:1166/1875 train_loss:3.5920 train_time:845315ms step_avg:731.24ms
step:1167/1875 train_loss:3.5891 train_time:846044ms step_avg:731.24ms
step:1168/1875 train_loss:3.5619 train_time:846771ms step_avg:731.24ms
step:1169/1875 train_loss:3.5701 train_time:847498ms step_avg:731.23ms
step:1170/1875 train_loss:3.7757 train_time:848221ms step_avg:731.22ms
step:1171/1875 train_loss:3.5461 train_time:848952ms step_avg:731.22ms
step:1172/1875 train_loss:3.6500 train_time:849683ms step_avg:731.22ms
step:1173/1875 train_loss:3.6074 train_time:850411ms step_avg:731.22ms
step:1174/1875 train_loss:3.5033 train_time:851138ms step_avg:731.22ms
step:1175/1875 train_loss:3.5985 train_time:851866ms step_avg:731.22ms
step:1176/1875 train_loss:3.9432 train_time:852616ms step_avg:731.23ms
step:1177/1875 train_loss:3.5673 train_time:853364ms step_avg:731.25ms
step:1178/1875 train_loss:3.5623 train_time:854094ms step_avg:731.24ms
step:1179/1875 train_loss:3.4716 train_time:854840ms step_avg:731.26ms
step:1180/1875 train_loss:3.5996 train_time:855574ms step_avg:731.26ms
step:1181/1875 train_loss:3.6218 train_time:856300ms step_avg:731.26ms
step:1182/1875 train_loss:3.5571 train_time:857028ms step_avg:731.25ms
step:1183/1875 train_loss:3.4604 train_time:857765ms step_avg:731.26ms
step:1184/1875 train_loss:3.5976 train_time:858497ms step_avg:731.26ms
step:1185/1875 train_loss:3.7067 train_time:859226ms step_avg:731.26ms
step:1186/1875 train_loss:3.8778 train_time:859955ms step_avg:731.25ms
step:1187/1875 train_loss:3.7222 train_time:860687ms step_avg:731.25ms
step:1188/1875 train_loss:3.5713 train_time:861422ms step_avg:731.26ms
step:1189/1875 train_loss:3.4287 train_time:862160ms step_avg:731.26ms
step:1190/1875 train_loss:3.5475 train_time:862904ms step_avg:731.27ms
step:1191/1875 train_loss:3.5600 train_time:863635ms step_avg:731.27ms
step:1192/1875 train_loss:3.6126 train_time:864366ms step_avg:731.27ms
step:1193/1875 train_loss:3.5243 train_time:865096ms step_avg:731.27ms
step:1194/1875 train_loss:3.6777 train_time:865826ms step_avg:731.27ms
step:1195/1875 train_loss:3.5345 train_time:866548ms step_avg:731.26ms
step:1196/1875 train_loss:3.5420 train_time:867283ms step_avg:731.27ms
step:1197/1875 train_loss:3.5232 train_time:868023ms step_avg:731.28ms
step:1198/1875 train_loss:3.6013 train_time:868757ms step_avg:731.28ms
step:1199/1875 train_loss:3.5844 train_time:869486ms step_avg:731.28ms
step:1200/1875 train_loss:3.5317 train_time:870223ms step_avg:731.28ms
step:1201/1875 train_loss:3.9595 train_time:870962ms step_avg:731.29ms
step:1202/1875 train_loss:3.4854 train_time:871711ms step_avg:731.30ms
step:1203/1875 train_loss:3.5700 train_time:872438ms step_avg:731.30ms
step:1204/1875 train_loss:3.5732 train_time:873164ms step_avg:731.29ms
step:1205/1875 train_loss:3.6436 train_time:873915ms step_avg:731.31ms
step:1206/1875 train_loss:3.6469 train_time:874653ms step_avg:731.31ms
step:1207/1875 train_loss:3.6131 train_time:875381ms step_avg:731.31ms
step:1208/1875 train_loss:3.5335 train_time:876112ms step_avg:731.31ms
step:1209/1875 train_loss:3.5923 train_time:876839ms step_avg:731.31ms
step:1210/1875 train_loss:3.5247 train_time:877566ms step_avg:731.30ms
step:1211/1875 train_loss:3.6134 train_time:878296ms step_avg:731.30ms
step:1212/1875 train_loss:3.8450 train_time:879037ms step_avg:731.31ms
step:1213/1875 train_loss:3.5060 train_time:879773ms step_avg:731.32ms
step:1214/1875 train_loss:3.7682 train_time:880495ms step_avg:731.31ms
step:1215/1875 train_loss:3.5749 train_time:881221ms step_avg:731.30ms
step:1216/1875 train_loss:3.6524 train_time:881951ms step_avg:731.30ms
step:1217/1875 train_loss:3.6102 train_time:882686ms step_avg:731.31ms
step:1218/1875 train_loss:3.6155 train_time:883402ms step_avg:731.29ms
step:1219/1875 train_loss:3.6462 train_time:884134ms step_avg:731.29ms
step:1220/1875 train_loss:3.5680 train_time:884859ms step_avg:731.29ms
step:1221/1875 train_loss:3.6084 train_time:885588ms step_avg:731.29ms
step:1222/1875 train_loss:3.6302 train_time:886314ms step_avg:731.28ms
step:1223/1875 train_loss:3.6531 train_time:887046ms step_avg:731.28ms
step:1224/1875 train_loss:3.6017 train_time:887785ms step_avg:731.29ms
step:1225/1875 train_loss:3.5827 train_time:888520ms step_avg:731.29ms
step:1226/1875 train_loss:3.4882 train_time:889255ms step_avg:731.30ms
step:1227/1875 train_loss:3.6306 train_time:889991ms step_avg:731.30ms
step:1228/1875 train_loss:3.4259 train_time:890710ms step_avg:731.29ms
step:1229/1875 train_loss:3.7505 train_time:891443ms step_avg:731.29ms
step:1230/1875 train_loss:3.5428 train_time:892176ms step_avg:731.29ms
step:1231/1875 train_loss:3.5498 train_time:892912ms step_avg:731.30ms
step:1232/1875 train_loss:3.7105 train_time:893655ms step_avg:731.30ms
step:1233/1875 train_loss:3.4345 train_time:894395ms step_avg:731.31ms
step:1234/1875 train_loss:3.5198 train_time:895123ms step_avg:731.31ms
step:1235/1875 train_loss:3.5663 train_time:895846ms step_avg:731.30ms
step:1236/1875 train_loss:3.5792 train_time:896572ms step_avg:731.30ms
step:1237/1875 train_loss:3.5682 train_time:897301ms step_avg:731.30ms
step:1238/1875 train_loss:3.5393 train_time:898035ms step_avg:731.30ms
step:1239/1875 train_loss:3.7686 train_time:898762ms step_avg:731.30ms
step:1240/1875 train_loss:3.5248 train_time:899491ms step_avg:731.29ms
step:1241/1875 train_loss:3.4037 train_time:900233ms step_avg:731.30ms
step:1242/1875 train_loss:3.6921 train_time:900969ms step_avg:731.31ms
step:1243/1875 train_loss:3.3974 train_time:901710ms step_avg:731.31ms
step:1244/1875 train_loss:3.5786 train_time:902439ms step_avg:731.31ms
step:1245/1875 train_loss:3.8263 train_time:903166ms step_avg:731.31ms
step:1246/1875 train_loss:3.5007 train_time:903891ms step_avg:731.30ms
step:1247/1875 train_loss:3.5800 train_time:904614ms step_avg:731.30ms
step:1248/1875 train_loss:3.6834 train_time:905337ms step_avg:731.29ms
step:1249/1875 train_loss:3.4149 train_time:906061ms step_avg:731.28ms
step:1250/1875 train_loss:3.4974 train_time:906796ms step_avg:731.29ms
step:1250/1875 val_loss:3.5593 train_time:906927ms step_avg:731.39ms
============== Weight norms: ==============
name = 'module._orig_mod.transformer.h.0.attn.c_q.weight' | fro_norm = 44.26213 | spectral_norm = 13.29196 | nuclear_norm = 872.23511
name = 'module._orig_mod.transformer.h.0.attn.c_k.weight' | fro_norm = 41.49467 | spectral_norm = 17.35161 | nuclear_norm = 785.53571
name = 'module._orig_mod.transformer.h.1.attn.c_q.weight' | fro_norm = 42.63389 | spectral_norm = 10.20462 | nuclear_norm = 833.04132
name = 'module._orig_mod.transformer.h.1.attn.c_k.weight' | fro_norm = 40.15843 | spectral_norm = 13.44443 | nuclear_norm = 776.15753
name = 'module._orig_mod.transformer.h.2.attn.c_q.weight' | fro_norm = 41.88018 | spectral_norm = 9.20138 | nuclear_norm = 809.01953
name = 'module._orig_mod.transformer.h.2.attn.c_k.weight' | fro_norm = 40.27631 | spectral_norm = 10.25506 | nuclear_norm = 782.68982
name = 'module._orig_mod.transformer.h.3.attn.c_q.weight' | fro_norm = 40.43653 | spectral_norm = 8.77426 | nuclear_norm = 794.75067
name = 'module._orig_mod.transformer.h.3.attn.c_k.weight' | fro_norm = 39.04767 | spectral_norm = 11.35444 | nuclear_norm = 766.56995
name = 'module._orig_mod.transformer.h.4.attn.c_q.weight' | fro_norm = 40.69298 | spectral_norm = 8.27461 | nuclear_norm = 800.07434
name = 'module._orig_mod.transformer.h.4.attn.c_k.weight' | fro_norm = 39.16620 | spectral_norm = 9.16058 | nuclear_norm = 777.11572
name = 'module._orig_mod.transformer.h.5.attn.c_q.weight' | fro_norm = 40.10418 | spectral_norm = 8.48458 | nuclear_norm = 786.08252
name = 'module._orig_mod.transformer.h.5.attn.c_k.weight' | fro_norm = 39.00410 | spectral_norm = 9.30577 | nuclear_norm = 771.42706
name = 'module._orig_mod.transformer.h.6.attn.c_q.weight' | fro_norm = 39.26548 | spectral_norm = 9.28169 | nuclear_norm = 772.18109
name = 'module._orig_mod.transformer.h.6.attn.c_k.weight' | fro_norm = 38.35173 | spectral_norm = 10.02150 | nuclear_norm = 761.82959
name = 'module._orig_mod.transformer.h.7.attn.c_q.weight' | fro_norm = 39.38787 | spectral_norm = 7.81716 | nuclear_norm = 764.38037
name = 'module._orig_mod.transformer.h.7.attn.c_k.weight' | fro_norm = 38.27451 | spectral_norm = 7.33709 | nuclear_norm = 759.14313
name = 'module._orig_mod.transformer.h.8.attn.c_q.weight' | fro_norm = 40.93579 | spectral_norm = 9.14754 | nuclear_norm = 798.36633
name = 'module._orig_mod.transformer.h.8.attn.c_k.weight' | fro_norm = 39.13989 | spectral_norm = 8.72387 | nuclear_norm = 779.16388
name = 'module._orig_mod.transformer.h.9.attn.c_q.weight' | fro_norm = 40.43762 | spectral_norm = 8.47277 | nuclear_norm = 785.62427
name = 'module._orig_mod.transformer.h.9.attn.c_k.weight' | fro_norm = 39.41552 | spectral_norm = 7.66330 | nuclear_norm = 778.79938
name = 'module._orig_mod.transformer.h.10.attn.c_q.weight' | fro_norm = 40.33553 | spectral_norm = 8.53663 | nuclear_norm = 772.96497
name = 'module._orig_mod.transformer.h.10.attn.c_k.weight' | fro_norm = 39.72486 | spectral_norm = 8.14129 | nuclear_norm = 774.78833
name = 'module._orig_mod.transformer.h.11.attn.c_q.weight' | fro_norm = 39.75377 | spectral_norm = 8.24166 | nuclear_norm = 767.41736
name = 'module._orig_mod.transformer.h.11.attn.c_k.weight' | fro_norm = 37.46898 | spectral_norm = 7.88442 | nuclear_norm = 736.80896
===========================================
step:1251/1875 train_loss:3.5096 train_time:907512ms step_avg:731.28ms
step:1252/1875 train_loss:3.3865 train_time:908246ms step_avg:731.28ms
step:1253/1875 train_loss:3.6430 train_time:908972ms step_avg:731.27ms
step:1254/1875 train_loss:3.7392 train_time:909720ms step_avg:731.29ms
step:1255/1875 train_loss:3.4874 train_time:910444ms step_avg:731.28ms
step:1256/1875 train_loss:3.6868 train_time:911167ms step_avg:731.27ms
step:1257/1875 train_loss:3.4272 train_time:911900ms step_avg:731.28ms
step:1258/1875 train_loss:3.6087 train_time:912635ms step_avg:731.28ms
step:1259/1875 train_loss:3.7072 train_time:913360ms step_avg:731.27ms
step:1260/1875 train_loss:3.5445 train_time:914084ms step_avg:731.27ms
step:1261/1875 train_loss:3.6019 train_time:914820ms step_avg:731.27ms
step:1262/1875 train_loss:3.7263 train_time:915554ms step_avg:731.27ms
step:1263/1875 train_loss:3.4009 train_time:916284ms step_avg:731.27ms
step:1264/1875 train_loss:3.6473 train_time:917017ms step_avg:731.27ms
step:1265/1875 train_loss:3.5659 train_time:917747ms step_avg:731.27ms
step:1266/1875 train_loss:3.5573 train_time:918474ms step_avg:731.27ms
step:1267/1875 train_loss:3.4857 train_time:919200ms step_avg:731.27ms
step:1268/1875 train_loss:3.4823 train_time:919929ms step_avg:731.26ms
step:1269/1875 train_loss:3.5986 train_time:920668ms step_avg:731.27ms
step:1270/1875 train_loss:3.4917 train_time:921400ms step_avg:731.27ms
step:1271/1875 train_loss:3.6054 train_time:922127ms step_avg:731.27ms
step:1272/1875 train_loss:3.5599 train_time:922863ms step_avg:731.27ms
step:1273/1875 train_loss:3.5947 train_time:923591ms step_avg:731.27ms
step:1274/1875 train_loss:3.4955 train_time:924316ms step_avg:731.26ms
step:1275/1875 train_loss:3.6157 train_time:925042ms step_avg:731.26ms
step:1276/1875 train_loss:3.5545 train_time:925762ms step_avg:731.25ms
step:1277/1875 train_loss:3.6420 train_time:926485ms step_avg:731.24ms
step:1278/1875 train_loss:3.5881 train_time:927209ms step_avg:731.24ms
step:1279/1875 train_loss:3.5141 train_time:927954ms step_avg:731.25ms
step:1280/1875 train_loss:3.4551 train_time:928694ms step_avg:731.26ms
step:1281/1875 train_loss:3.5587 train_time:929418ms step_avg:731.25ms
step:1282/1875 train_loss:3.5184 train_time:930149ms step_avg:731.25ms
step:1283/1875 train_loss:3.7052 train_time:930871ms step_avg:731.24ms
step:1284/1875 train_loss:3.5194 train_time:931596ms step_avg:731.24ms
step:1285/1875 train_loss:3.6609 train_time:932326ms step_avg:731.24ms
step:1286/1875 train_loss:3.5310 train_time:933060ms step_avg:731.24ms
step:1287/1875 train_loss:3.6203 train_time:933789ms step_avg:731.24ms
step:1288/1875 train_loss:3.5898 train_time:934514ms step_avg:731.23ms
step:1289/1875 train_loss:3.5764 train_time:935240ms step_avg:731.23ms
step:1290/1875 train_loss:3.5972 train_time:935984ms step_avg:731.24ms
step:1291/1875 train_loss:3.7277 train_time:936720ms step_avg:731.24ms
step:1292/1875 train_loss:3.5510 train_time:937455ms step_avg:731.24ms
step:1293/1875 train_loss:3.3455 train_time:938201ms step_avg:731.26ms
step:1294/1875 train_loss:3.5755 train_time:938923ms step_avg:731.25ms
step:1295/1875 train_loss:3.5595 train_time:939664ms step_avg:731.26ms
step:1296/1875 train_loss:3.5984 train_time:940407ms step_avg:731.27ms
step:1297/1875 train_loss:3.6396 train_time:941139ms step_avg:731.27ms
step:1298/1875 train_loss:3.6392 train_time:941862ms step_avg:731.26ms
step:1299/1875 train_loss:3.6280 train_time:942587ms step_avg:731.25ms
step:1300/1875 train_loss:3.5776 train_time:943317ms step_avg:731.25ms
step:1301/1875 train_loss:3.7142 train_time:944042ms step_avg:731.25ms
step:1302/1875 train_loss:3.5695 train_time:944767ms step_avg:731.24ms
step:1303/1875 train_loss:3.6466 train_time:945492ms step_avg:731.24ms
step:1304/1875 train_loss:3.5684 train_time:946216ms step_avg:731.23ms
step:1305/1875 train_loss:3.6745 train_time:946947ms step_avg:731.23ms
step:1306/1875 train_loss:3.7412 train_time:947690ms step_avg:731.24ms
step:1307/1875 train_loss:3.5350 train_time:948427ms step_avg:731.25ms
step:1308/1875 train_loss:3.5043 train_time:949155ms step_avg:731.24ms
step:1309/1875 train_loss:3.5127 train_time:949888ms step_avg:731.25ms
step:1310/1875 train_loss:3.5561 train_time:950611ms step_avg:731.24ms
step:1311/1875 train_loss:3.4931 train_time:951333ms step_avg:731.23ms
step:1312/1875 train_loss:3.6737 train_time:952064ms step_avg:731.23ms
step:1313/1875 train_loss:3.5578 train_time:952790ms step_avg:731.23ms
step:1314/1875 train_loss:3.6255 train_time:953512ms step_avg:731.22ms
step:1315/1875 train_loss:3.5986 train_time:954244ms step_avg:731.22ms
step:1316/1875 train_loss:3.6195 train_time:954969ms step_avg:731.22ms
step:1317/1875 train_loss:3.4581 train_time:955707ms step_avg:731.22ms
step:1318/1875 train_loss:3.7257 train_time:956441ms step_avg:731.22ms
step:1319/1875 train_loss:3.6458 train_time:957164ms step_avg:731.22ms
step:1320/1875 train_loss:3.5365 train_time:957893ms step_avg:731.22ms
step:1321/1875 train_loss:3.6380 train_time:958629ms step_avg:731.22ms
step:1322/1875 train_loss:3.6106 train_time:959351ms step_avg:731.21ms
step:1323/1875 train_loss:3.5839 train_time:960079ms step_avg:731.21ms
step:1324/1875 train_loss:3.7818 train_time:960810ms step_avg:731.21ms
step:1325/1875 train_loss:3.6439 train_time:961555ms step_avg:731.22ms
step:1326/1875 train_loss:3.6822 train_time:962290ms step_avg:731.22ms
step:1327/1875 train_loss:3.7040 train_time:963015ms step_avg:731.22ms
step:1328/1875 train_loss:3.4544 train_time:963747ms step_avg:731.22ms
step:1329/1875 train_loss:3.5258 train_time:964479ms step_avg:731.22ms
step:1330/1875 train_loss:3.5897 train_time:965413ms step_avg:731.37ms
step:1331/1875 train_loss:2.7440 train_time:966159ms step_avg:731.38ms
step:1332/1875 train_loss:3.5951 train_time:966905ms step_avg:731.40ms
step:1333/1875 train_loss:3.5670 train_time:967855ms step_avg:731.56ms
step:1334/1875 train_loss:3.5580 train_time:968572ms step_avg:731.55ms
step:1335/1875 train_loss:3.9598 train_time:969317ms step_avg:731.56ms
step:1336/1875 train_loss:3.6786 train_time:970047ms step_avg:731.56ms
step:1337/1875 train_loss:3.5737 train_time:970769ms step_avg:731.55ms
step:1338/1875 train_loss:3.5186 train_time:971499ms step_avg:731.55ms
step:1339/1875 train_loss:3.5059 train_time:972229ms step_avg:731.55ms
step:1340/1875 train_loss:3.7646 train_time:972972ms step_avg:731.56ms
step:1341/1875 train_loss:3.7173 train_time:973707ms step_avg:731.56ms
step:1342/1875 train_loss:3.5452 train_time:974437ms step_avg:731.56ms
step:1343/1875 train_loss:3.4965 train_time:975161ms step_avg:731.55ms
step:1344/1875 train_loss:3.8061 train_time:975888ms step_avg:731.55ms
step:1345/1875 train_loss:3.5664 train_time:976619ms step_avg:731.55ms
step:1346/1875 train_loss:3.5749 train_time:977344ms step_avg:731.55ms
step:1347/1875 train_loss:3.6256 train_time:978074ms step_avg:731.54ms
step:1348/1875 train_loss:3.5902 train_time:978801ms step_avg:731.54ms
step:1349/1875 train_loss:3.4989 train_time:979527ms step_avg:731.54ms
step:1350/1875 train_loss:3.4593 train_time:980254ms step_avg:731.53ms
step:1351/1875 train_loss:3.5411 train_time:980981ms step_avg:731.53ms
step:1352/1875 train_loss:3.4845 train_time:981729ms step_avg:731.54ms
step:1353/1875 train_loss:3.6017 train_time:982456ms step_avg:731.54ms
step:1354/1875 train_loss:3.4540 train_time:983181ms step_avg:731.53ms
step:1355/1875 train_loss:3.5106 train_time:983905ms step_avg:731.53ms
step:1356/1875 train_loss:3.6190 train_time:984634ms step_avg:731.53ms
step:1357/1875 train_loss:3.4592 train_time:985373ms step_avg:731.53ms
step:1358/1875 train_loss:3.3987 train_time:986102ms step_avg:731.53ms
step:1359/1875 train_loss:3.7266 train_time:986834ms step_avg:731.53ms
step:1360/1875 train_loss:3.6439 train_time:987563ms step_avg:731.53ms
step:1361/1875 train_loss:3.3864 train_time:988297ms step_avg:731.53ms
step:1362/1875 train_loss:3.6585 train_time:989031ms step_avg:731.53ms
step:1363/1875 train_loss:3.5576 train_time:989764ms step_avg:731.53ms
step:1364/1875 train_loss:3.3889 train_time:990501ms step_avg:731.54ms
step:1365/1875 train_loss:3.5940 train_time:991232ms step_avg:731.54ms
step:1366/1875 train_loss:3.4822 train_time:991971ms step_avg:731.54ms
step:1367/1875 train_loss:3.5168 train_time:992699ms step_avg:731.54ms
step:1368/1875 train_loss:3.5234 train_time:993431ms step_avg:731.54ms
step:1369/1875 train_loss:3.6336 train_time:994159ms step_avg:731.54ms
step:1370/1875 train_loss:3.5998 train_time:994880ms step_avg:731.53ms
step:1371/1875 train_loss:3.5667 train_time:995623ms step_avg:731.54ms
step:1372/1875 train_loss:3.4602 train_time:996356ms step_avg:731.54ms
step:1373/1875 train_loss:3.8191 train_time:997092ms step_avg:731.54ms
step:1374/1875 train_loss:3.5316 train_time:997814ms step_avg:731.54ms
step:1375/1875 train_loss:3.5694 train_time:998546ms step_avg:731.54ms
step:1375/1875 val_loss:3.5249 train_time:998681ms step_avg:731.63ms
============== Weight norms: ==============
name = 'module._orig_mod.transformer.h.0.attn.c_q.weight' | fro_norm = 46.37461 | spectral_norm = 14.12883 | nuclear_norm = 913.69763
name = 'module._orig_mod.transformer.h.0.attn.c_k.weight' | fro_norm = 43.58332 | spectral_norm = 18.39194 | nuclear_norm = 823.66248
name = 'module._orig_mod.transformer.h.1.attn.c_q.weight' | fro_norm = 44.63998 | spectral_norm = 10.59516 | nuclear_norm = 871.03375
name = 'module._orig_mod.transformer.h.1.attn.c_k.weight' | fro_norm = 42.19406 | spectral_norm = 14.01040 | nuclear_norm = 813.86487
name = 'module._orig_mod.transformer.h.2.attn.c_q.weight' | fro_norm = 43.77794 | spectral_norm = 9.59335 | nuclear_norm = 843.83557
name = 'module._orig_mod.transformer.h.2.attn.c_k.weight' | fro_norm = 42.22837 | spectral_norm = 10.75635 | nuclear_norm = 818.22321
name = 'module._orig_mod.transformer.h.3.attn.c_q.weight' | fro_norm = 42.16726 | spectral_norm = 9.11548 | nuclear_norm = 828.40979
name = 'module._orig_mod.transformer.h.3.attn.c_k.weight' | fro_norm = 40.87947 | spectral_norm = 11.92318 | nuclear_norm = 801.38043
name = 'module._orig_mod.transformer.h.4.attn.c_q.weight' | fro_norm = 42.37351 | spectral_norm = 8.59524 | nuclear_norm = 833.21069
name = 'module._orig_mod.transformer.h.4.attn.c_k.weight' | fro_norm = 40.89308 | spectral_norm = 9.54026 | nuclear_norm = 810.13110
name = 'module._orig_mod.transformer.h.5.attn.c_q.weight' | fro_norm = 41.86269 | spectral_norm = 8.81073 | nuclear_norm = 819.73486
name = 'module._orig_mod.transformer.h.5.attn.c_k.weight' | fro_norm = 40.85129 | spectral_norm = 9.72807 | nuclear_norm = 806.74402
name = 'module._orig_mod.transformer.h.6.attn.c_q.weight' | fro_norm = 40.86651 | spectral_norm = 9.69863 | nuclear_norm = 803.16138
name = 'module._orig_mod.transformer.h.6.attn.c_k.weight' | fro_norm = 40.05388 | spectral_norm = 10.42963 | nuclear_norm = 794.57935
name = 'module._orig_mod.transformer.h.7.attn.c_q.weight' | fro_norm = 41.06350 | spectral_norm = 8.14052 | nuclear_norm = 796.57031
name = 'module._orig_mod.transformer.h.7.attn.c_k.weight' | fro_norm = 40.01614 | spectral_norm = 7.56015 | nuclear_norm = 792.75287
name = 'module._orig_mod.transformer.h.8.attn.c_q.weight' | fro_norm = 42.72272 | spectral_norm = 9.57514 | nuclear_norm = 833.07324
name = 'module._orig_mod.transformer.h.8.attn.c_k.weight' | fro_norm = 40.93601 | spectral_norm = 9.09079 | nuclear_norm = 814.09204
name = 'module._orig_mod.transformer.h.9.attn.c_q.weight' | fro_norm = 42.24350 | spectral_norm = 8.86227 | nuclear_norm = 820.35895
name = 'module._orig_mod.transformer.h.9.attn.c_k.weight' | fro_norm = 41.25523 | spectral_norm = 7.98747 | nuclear_norm = 814.87793
name = 'module._orig_mod.transformer.h.10.attn.c_q.weight' | fro_norm = 42.15830 | spectral_norm = 8.96891 | nuclear_norm = 807.05634
name = 'module._orig_mod.transformer.h.10.attn.c_k.weight' | fro_norm = 41.57462 | spectral_norm = 8.49928 | nuclear_norm = 809.61987
name = 'module._orig_mod.transformer.h.11.attn.c_q.weight' | fro_norm = 41.48893 | spectral_norm = 8.58553 | nuclear_norm = 799.86523
name = 'module._orig_mod.transformer.h.11.attn.c_k.weight' | fro_norm = 39.15886 | spectral_norm = 8.25905 | nuclear_norm = 767.79089
===========================================
step:1376/1875 train_loss:3.5662 train_time:999261ms step_avg:731.52ms
step:1377/1875 train_loss:3.3730 train_time:999997ms step_avg:731.53ms
step:1378/1875 train_loss:3.7631 train_time:1000729ms step_avg:731.53ms
step:1379/1875 train_loss:3.5494 train_time:1001448ms step_avg:731.52ms
step:1380/1875 train_loss:3.6893 train_time:1002179ms step_avg:731.52ms
step:1381/1875 train_loss:3.7074 train_time:1002907ms step_avg:731.52ms
step:1382/1875 train_loss:3.3459 train_time:1003633ms step_avg:731.51ms
step:1383/1875 train_loss:3.5293 train_time:1004370ms step_avg:731.51ms
step:1384/1875 train_loss:3.9409 train_time:1005106ms step_avg:731.52ms
step:1385/1875 train_loss:3.4418 train_time:1005836ms step_avg:731.52ms
step:1386/1875 train_loss:3.6057 train_time:1006560ms step_avg:731.51ms
step:1387/1875 train_loss:3.6942 train_time:1007288ms step_avg:731.51ms
step:1388/1875 train_loss:3.6064 train_time:1008009ms step_avg:731.50ms
step:1389/1875 train_loss:3.5605 train_time:1008733ms step_avg:731.50ms
step:1390/1875 train_loss:3.4035 train_time:1009464ms step_avg:731.50ms
step:1391/1875 train_loss:3.5473 train_time:1010197ms step_avg:731.50ms
step:1392/1875 train_loss:3.5264 train_time:1010926ms step_avg:731.50ms
step:1393/1875 train_loss:3.7831 train_time:1011650ms step_avg:731.49ms
step:1394/1875 train_loss:3.4941 train_time:1012374ms step_avg:731.48ms
step:1395/1875 train_loss:3.5006 train_time:1013095ms step_avg:731.48ms
step:1396/1875 train_loss:3.4686 train_time:1013826ms step_avg:731.48ms
step:1397/1875 train_loss:3.7298 train_time:1014552ms step_avg:731.47ms
step:1398/1875 train_loss:3.6056 train_time:1015277ms step_avg:731.47ms
step:1399/1875 train_loss:3.6205 train_time:1016009ms step_avg:731.47ms
step:1400/1875 train_loss:3.5063 train_time:1016727ms step_avg:731.46ms
step:1401/1875 train_loss:3.4641 train_time:1017450ms step_avg:731.45ms
step:1402/1875 train_loss:3.5390 train_time:1018176ms step_avg:731.45ms
step:1403/1875 train_loss:3.5158 train_time:1018915ms step_avg:731.45ms
step:1404/1875 train_loss:3.5438 train_time:1019635ms step_avg:731.45ms
step:1405/1875 train_loss:3.4969 train_time:1020361ms step_avg:731.44ms
step:1406/1875 train_loss:3.7113 train_time:1021099ms step_avg:731.45ms
step:1407/1875 train_loss:3.4793 train_time:1021822ms step_avg:731.44ms
step:1408/1875 train_loss:3.5219 train_time:1022553ms step_avg:731.44ms
step:1409/1875 train_loss:3.5155 train_time:1023281ms step_avg:731.44ms
step:1410/1875 train_loss:3.3901 train_time:1024001ms step_avg:731.43ms
step:1411/1875 train_loss:3.5030 train_time:1024724ms step_avg:731.42ms
step:1412/1875 train_loss:3.4930 train_time:1025467ms step_avg:731.43ms
step:1413/1875 train_loss:3.4830 train_time:1026193ms step_avg:731.43ms
step:1414/1875 train_loss:3.5707 train_time:1026916ms step_avg:731.42ms
step:1415/1875 train_loss:3.5232 train_time:1027641ms step_avg:731.42ms
step:1416/1875 train_loss:3.5641 train_time:1028368ms step_avg:731.41ms
step:1417/1875 train_loss:3.5459 train_time:1029093ms step_avg:731.41ms
step:1418/1875 train_loss:3.6169 train_time:1029819ms step_avg:731.41ms
step:1419/1875 train_loss:3.4256 train_time:1030567ms step_avg:731.42ms
step:1420/1875 train_loss:3.4936 train_time:1031303ms step_avg:731.42ms
step:1421/1875 train_loss:3.5975 train_time:1032030ms step_avg:731.42ms
step:1422/1875 train_loss:3.5669 train_time:1032759ms step_avg:731.42ms
step:1423/1875 train_loss:3.5732 train_time:1033490ms step_avg:731.42ms
step:1424/1875 train_loss:3.5752 train_time:1034218ms step_avg:731.41ms
step:1425/1875 train_loss:3.5560 train_time:1034954ms step_avg:731.42ms
step:1426/1875 train_loss:3.5252 train_time:1035679ms step_avg:731.41ms
step:1427/1875 train_loss:3.5290 train_time:1036408ms step_avg:731.41ms
step:1428/1875 train_loss:3.3820 train_time:1037149ms step_avg:731.42ms
step:1429/1875 train_loss:3.5304 train_time:1037875ms step_avg:731.41ms
step:1430/1875 train_loss:3.4709 train_time:1038596ms step_avg:731.41ms
step:1431/1875 train_loss:3.5766 train_time:1039326ms step_avg:731.40ms
step:1432/1875 train_loss:3.5634 train_time:1040046ms step_avg:731.40ms
step:1433/1875 train_loss:3.4573 train_time:1040774ms step_avg:731.39ms
step:1434/1875 train_loss:3.5230 train_time:1041506ms step_avg:731.39ms
step:1435/1875 train_loss:3.5536 train_time:1042236ms step_avg:731.39ms
step:1436/1875 train_loss:3.3653 train_time:1042975ms step_avg:731.40ms
step:1437/1875 train_loss:3.5024 train_time:1043713ms step_avg:731.40ms
step:1438/1875 train_loss:3.3266 train_time:1044438ms step_avg:731.40ms
step:1439/1875 train_loss:3.4203 train_time:1045170ms step_avg:731.40ms
step:1440/1875 train_loss:3.6066 train_time:1045902ms step_avg:731.40ms
step:1441/1875 train_loss:3.5749 train_time:1046633ms step_avg:731.40ms
step:1442/1875 train_loss:3.5163 train_time:1047364ms step_avg:731.40ms
step:1443/1875 train_loss:3.3876 train_time:1048095ms step_avg:731.40ms
step:1444/1875 train_loss:3.5489 train_time:1048823ms step_avg:731.40ms
step:1445/1875 train_loss:3.5954 train_time:1049558ms step_avg:731.40ms
step:1446/1875 train_loss:3.6681 train_time:1050307ms step_avg:731.41ms
step:1447/1875 train_loss:3.6510 train_time:1051032ms step_avg:731.41ms
step:1448/1875 train_loss:3.5339 train_time:1051755ms step_avg:731.40ms
step:1449/1875 train_loss:3.4108 train_time:1052490ms step_avg:731.40ms
step:1450/1875 train_loss:3.4842 train_time:1053216ms step_avg:731.40ms
step:1451/1875 train_loss:3.4994 train_time:1053944ms step_avg:731.40ms
step:1452/1875 train_loss:3.6025 train_time:1054667ms step_avg:731.39ms
step:1453/1875 train_loss:3.6010 train_time:1055391ms step_avg:731.39ms
step:1454/1875 train_loss:3.4168 train_time:1056119ms step_avg:731.38ms
step:1455/1875 train_loss:3.5336 train_time:1056847ms step_avg:731.38ms
step:1456/1875 train_loss:3.4573 train_time:1057576ms step_avg:731.38ms
step:1457/1875 train_loss:3.4861 train_time:1058304ms step_avg:731.38ms
step:1458/1875 train_loss:3.5285 train_time:1059040ms step_avg:731.38ms
step:1459/1875 train_loss:3.4688 train_time:1059769ms step_avg:731.38ms
step:1460/1875 train_loss:3.3623 train_time:1060495ms step_avg:731.38ms
step:1461/1875 train_loss:3.6133 train_time:1061224ms step_avg:731.37ms
step:1462/1875 train_loss:3.4716 train_time:1061952ms step_avg:731.37ms
step:1463/1875 train_loss:3.5157 train_time:1062688ms step_avg:731.37ms
step:1464/1875 train_loss:3.6393 train_time:1063409ms step_avg:731.37ms
step:1465/1875 train_loss:3.4645 train_time:1064135ms step_avg:731.36ms
step:1466/1875 train_loss:3.6612 train_time:1064863ms step_avg:731.36ms
step:1467/1875 train_loss:3.5550 train_time:1065588ms step_avg:731.36ms
step:1468/1875 train_loss:3.5459 train_time:1066308ms step_avg:731.35ms
step:1469/1875 train_loss:3.4794 train_time:1067045ms step_avg:731.35ms
step:1470/1875 train_loss:3.6072 train_time:1067774ms step_avg:731.35ms
step:1471/1875 train_loss:3.4848 train_time:1068502ms step_avg:731.35ms
step:1472/1875 train_loss:3.4579 train_time:1069235ms step_avg:731.35ms
step:1473/1875 train_loss:3.5300 train_time:1069969ms step_avg:731.35ms
step:1474/1875 train_loss:3.4434 train_time:1070713ms step_avg:731.36ms
step:1475/1875 train_loss:3.4629 train_time:1071453ms step_avg:731.37ms
step:1476/1875 train_loss:3.6222 train_time:1072177ms step_avg:731.36ms
step:1477/1875 train_loss:3.5100 train_time:1072904ms step_avg:731.36ms
step:1478/1875 train_loss:3.3382 train_time:1073626ms step_avg:731.35ms
step:1479/1875 train_loss:3.4558 train_time:1074354ms step_avg:731.35ms
step:1480/1875 train_loss:3.4416 train_time:1075089ms step_avg:731.35ms
step:1481/1875 train_loss:3.5094 train_time:1075834ms step_avg:731.36ms
step:1482/1875 train_loss:3.5895 train_time:1076566ms step_avg:731.36ms
step:1483/1875 train_loss:3.4735 train_time:1077291ms step_avg:731.36ms
step:1484/1875 train_loss:3.6466 train_time:1078021ms step_avg:731.36ms
step:1485/1875 train_loss:3.5655 train_time:1078749ms step_avg:731.36ms
step:1486/1875 train_loss:3.4767 train_time:1079499ms step_avg:731.37ms
step:1487/1875 train_loss:3.4500 train_time:1080220ms step_avg:731.36ms
step:1488/1875 train_loss:3.4625 train_time:1080944ms step_avg:731.36ms
step:1489/1875 train_loss:3.4160 train_time:1081682ms step_avg:731.36ms
step:1490/1875 train_loss:3.5254 train_time:1082419ms step_avg:731.36ms
step:1491/1875 train_loss:3.4193 train_time:1083162ms step_avg:731.37ms
step:1492/1875 train_loss:3.5161 train_time:1083891ms step_avg:731.37ms
step:1493/1875 train_loss:3.4414 train_time:1084624ms step_avg:731.37ms
step:1494/1875 train_loss:3.3702 train_time:1085355ms step_avg:731.37ms
step:1495/1875 train_loss:3.4548 train_time:1086083ms step_avg:731.37ms
step:1496/1875 train_loss:3.6333 train_time:1086810ms step_avg:731.37ms
step:1497/1875 train_loss:3.4976 train_time:1087538ms step_avg:731.36ms
step:1498/1875 train_loss:3.2340 train_time:1088277ms step_avg:731.37ms
step:1499/1875 train_loss:3.5449 train_time:1089005ms step_avg:731.37ms
step:1500/1875 train_loss:3.4974 train_time:1089735ms step_avg:731.37ms
step:1500/1875 val_loss:3.4742 train_time:1089870ms step_avg:731.46ms
============== Weight norms: ==============
name = 'module._orig_mod.transformer.h.0.attn.c_q.weight' | fro_norm = 47.75086 | spectral_norm = 14.76937 | nuclear_norm = 941.19519
name = 'module._orig_mod.transformer.h.0.attn.c_k.weight' | fro_norm = 44.97994 | spectral_norm = 19.12006 | nuclear_norm = 849.41132
name = 'module._orig_mod.transformer.h.1.attn.c_q.weight' | fro_norm = 46.00341 | spectral_norm = 10.86790 | nuclear_norm = 897.95074
name = 'module._orig_mod.transformer.h.1.attn.c_k.weight' | fro_norm = 43.58874 | spectral_norm = 14.29020 | nuclear_norm = 840.65387
name = 'module._orig_mod.transformer.h.2.attn.c_q.weight' | fro_norm = 45.07728 | spectral_norm = 9.93601 | nuclear_norm = 867.90131
name = 'module._orig_mod.transformer.h.2.attn.c_k.weight' | fro_norm = 43.56366 | spectral_norm = 10.99248 | nuclear_norm = 843.68201
name = 'module._orig_mod.transformer.h.3.attn.c_q.weight' | fro_norm = 43.37732 | spectral_norm = 9.31462 | nuclear_norm = 852.18201
name = 'module._orig_mod.transformer.h.3.attn.c_k.weight' | fro_norm = 42.16014 | spectral_norm = 12.29985 | nuclear_norm = 825.83301
name = 'module._orig_mod.transformer.h.4.attn.c_q.weight' | fro_norm = 43.54364 | spectral_norm = 8.85517 | nuclear_norm = 856.72327
name = 'module._orig_mod.transformer.h.4.attn.c_k.weight' | fro_norm = 42.11129 | spectral_norm = 9.86258 | nuclear_norm = 833.77026
name = 'module._orig_mod.transformer.h.5.attn.c_q.weight' | fro_norm = 43.09002 | spectral_norm = 9.08065 | nuclear_norm = 843.17163
name = 'module._orig_mod.transformer.h.5.attn.c_k.weight' | fro_norm = 42.13558 | spectral_norm = 10.05340 | nuclear_norm = 831.69202
name = 'module._orig_mod.transformer.h.6.attn.c_q.weight' | fro_norm = 42.04359 | spectral_norm = 9.97858 | nuclear_norm = 826.26257
name = 'module._orig_mod.transformer.h.6.attn.c_k.weight' | fro_norm = 41.26259 | spectral_norm = 10.75153 | nuclear_norm = 818.39777
name = 'module._orig_mod.transformer.h.7.attn.c_q.weight' | fro_norm = 42.19018 | spectral_norm = 8.37337 | nuclear_norm = 817.56964
name = 'module._orig_mod.transformer.h.7.attn.c_k.weight' | fro_norm = 41.21564 | spectral_norm = 7.77643 | nuclear_norm = 815.91705
name = 'module._orig_mod.transformer.h.8.attn.c_q.weight' | fro_norm = 43.94925 | spectral_norm = 9.88714 | nuclear_norm = 857.21472
name = 'module._orig_mod.transformer.h.8.attn.c_k.weight' | fro_norm = 42.18503 | spectral_norm = 9.41353 | nuclear_norm = 838.70361
name = 'module._orig_mod.transformer.h.9.attn.c_q.weight' | fro_norm = 43.46188 | spectral_norm = 9.08837 | nuclear_norm = 844.27789
name = 'module._orig_mod.transformer.h.9.attn.c_k.weight' | fro_norm = 42.48960 | spectral_norm = 8.15921 | nuclear_norm = 839.73785
name = 'module._orig_mod.transformer.h.10.attn.c_q.weight' | fro_norm = 43.40541 | spectral_norm = 9.21812 | nuclear_norm = 830.59229
name = 'module._orig_mod.transformer.h.10.attn.c_k.weight' | fro_norm = 42.85696 | spectral_norm = 8.72520 | nuclear_norm = 834.62756
name = 'module._orig_mod.transformer.h.11.attn.c_q.weight' | fro_norm = 42.67883 | spectral_norm = 8.82643 | nuclear_norm = 821.54852
name = 'module._orig_mod.transformer.h.11.attn.c_k.weight' | fro_norm = 40.34289 | spectral_norm = 8.48635 | nuclear_norm = 789.42773
===========================================
step:1501/1875 train_loss:3.5354 train_time:1090452ms step_avg:731.36ms
step:1502/1875 train_loss:3.5082 train_time:1091182ms step_avg:731.36ms
step:1503/1875 train_loss:3.4829 train_time:1091921ms step_avg:731.36ms
step:1504/1875 train_loss:3.2736 train_time:1092654ms step_avg:731.36ms
step:1505/1875 train_loss:3.5460 train_time:1093400ms step_avg:731.37ms
step:1506/1875 train_loss:3.4324 train_time:1094151ms step_avg:731.38ms
step:1507/1875 train_loss:3.4396 train_time:1094883ms step_avg:731.38ms
step:1508/1875 train_loss:3.3982 train_time:1095620ms step_avg:731.39ms
step:1509/1875 train_loss:3.4711 train_time:1096345ms step_avg:731.38ms
step:1510/1875 train_loss:3.3661 train_time:1097073ms step_avg:731.38ms
step:1511/1875 train_loss:3.6871 train_time:1097804ms step_avg:731.38ms
step:1512/1875 train_loss:3.4678 train_time:1098525ms step_avg:731.37ms
step:1513/1875 train_loss:3.4679 train_time:1099255ms step_avg:731.37ms
step:1514/1875 train_loss:3.5922 train_time:1099979ms step_avg:731.37ms
step:1515/1875 train_loss:3.6116 train_time:1100714ms step_avg:731.37ms
step:1516/1875 train_loss:3.4531 train_time:1101449ms step_avg:731.37ms
step:1517/1875 train_loss:3.2803 train_time:1102185ms step_avg:731.38ms
step:1518/1875 train_loss:3.4225 train_time:1102911ms step_avg:731.37ms
step:1519/1875 train_loss:3.4390 train_time:1103646ms step_avg:731.38ms
step:1520/1875 train_loss:3.4980 train_time:1104579ms step_avg:731.51ms
step:1521/1875 train_loss:3.4018 train_time:1105309ms step_avg:731.51ms
step:1522/1875 train_loss:3.7010 train_time:1106033ms step_avg:731.50ms
step:1523/1875 train_loss:3.3290 train_time:1106758ms step_avg:731.50ms
step:1524/1875 train_loss:3.4360 train_time:1107783ms step_avg:731.69ms
step:1525/1875 train_loss:3.4885 train_time:1108529ms step_avg:731.70ms
step:1526/1875 train_loss:3.4766 train_time:1109261ms step_avg:731.70ms
step:1527/1875 train_loss:3.5370 train_time:1109995ms step_avg:731.70ms
step:1528/1875 train_loss:3.4295 train_time:1110728ms step_avg:731.71ms
step:1529/1875 train_loss:3.4150 train_time:1111452ms step_avg:731.70ms
step:1530/1875 train_loss:3.4467 train_time:1112175ms step_avg:731.69ms
step:1531/1875 train_loss:3.4706 train_time:1112900ms step_avg:731.69ms
step:1532/1875 train_loss:3.4679 train_time:1113636ms step_avg:731.69ms
step:1533/1875 train_loss:3.4323 train_time:1114383ms step_avg:731.70ms
step:1534/1875 train_loss:3.6019 train_time:1115126ms step_avg:731.71ms
step:1535/1875 train_loss:3.3895 train_time:1115857ms step_avg:731.71ms
step:1536/1875 train_loss:3.5188 train_time:1116580ms step_avg:731.70ms
step:1537/1875 train_loss:3.4331 train_time:1117317ms step_avg:731.71ms
step:1538/1875 train_loss:3.3169 train_time:1118054ms step_avg:731.71ms
step:1539/1875 train_loss:3.2705 train_time:1118786ms step_avg:731.71ms
step:1540/1875 train_loss:3.3787 train_time:1119516ms step_avg:731.71ms
step:1541/1875 train_loss:3.3907 train_time:1120243ms step_avg:731.71ms
step:1542/1875 train_loss:3.3064 train_time:1120980ms step_avg:731.71ms
step:1543/1875 train_loss:3.5867 train_time:1121708ms step_avg:731.71ms
step:1544/1875 train_loss:3.3928 train_time:1122435ms step_avg:731.70ms
step:1545/1875 train_loss:3.2734 train_time:1123183ms step_avg:731.72ms
step:1546/1875 train_loss:3.4623 train_time:1123915ms step_avg:731.72ms
step:1547/1875 train_loss:3.4785 train_time:1124645ms step_avg:731.71ms
step:1548/1875 train_loss:3.2561 train_time:1125372ms step_avg:731.71ms
step:1549/1875 train_loss:3.6291 train_time:1126102ms step_avg:731.71ms
step:1550/1875 train_loss:3.5846 train_time:1126835ms step_avg:731.71ms
step:1551/1875 train_loss:3.4562 train_time:1127577ms step_avg:731.72ms
step:1552/1875 train_loss:3.6036 train_time:1128310ms step_avg:731.72ms
step:1553/1875 train_loss:3.5075 train_time:1129041ms step_avg:731.72ms
step:1554/1875 train_loss:3.4270 train_time:1129769ms step_avg:731.72ms
step:1555/1875 train_loss:3.5924 train_time:1130500ms step_avg:731.72ms
step:1556/1875 train_loss:3.5394 train_time:1131228ms step_avg:731.71ms
step:1557/1875 train_loss:3.4288 train_time:1131946ms step_avg:731.70ms
step:1558/1875 train_loss:3.3795 train_time:1132670ms step_avg:731.70ms
step:1559/1875 train_loss:3.4002 train_time:1133399ms step_avg:731.70ms
step:1560/1875 train_loss:3.4207 train_time:1134128ms step_avg:731.70ms
step:1561/1875 train_loss:3.4536 train_time:1134858ms step_avg:731.69ms
step:1562/1875 train_loss:3.4463 train_time:1135585ms step_avg:731.69ms
step:1563/1875 train_loss:3.5202 train_time:1136327ms step_avg:731.70ms
step:1564/1875 train_loss:3.4120 train_time:1137049ms step_avg:731.69ms
step:1565/1875 train_loss:3.5208 train_time:1137781ms step_avg:731.69ms
step:1566/1875 train_loss:3.3942 train_time:1138509ms step_avg:731.69ms
step:1567/1875 train_loss:3.5369 train_time:1139235ms step_avg:731.69ms
step:1568/1875 train_loss:3.3463 train_time:1139969ms step_avg:731.69ms
step:1569/1875 train_loss:3.3855 train_time:1140699ms step_avg:731.69ms
step:1570/1875 train_loss:3.3206 train_time:1141426ms step_avg:731.68ms
step:1571/1875 train_loss:3.3141 train_time:1142153ms step_avg:731.68ms
step:1572/1875 train_loss:3.3717 train_time:1142893ms step_avg:731.69ms
step:1573/1875 train_loss:3.4375 train_time:1143617ms step_avg:731.68ms
step:1574/1875 train_loss:3.2290 train_time:1144346ms step_avg:731.68ms
step:1575/1875 train_loss:3.4290 train_time:1145076ms step_avg:731.68ms
step:1576/1875 train_loss:3.4446 train_time:1145801ms step_avg:731.67ms
step:1577/1875 train_loss:3.4209 train_time:1146545ms step_avg:731.68ms
step:1578/1875 train_loss:3.4514 train_time:1147291ms step_avg:731.69ms
step:1579/1875 train_loss:3.4384 train_time:1148027ms step_avg:731.69ms
step:1580/1875 train_loss:3.3905 train_time:1148746ms step_avg:731.69ms
step:1581/1875 train_loss:3.6195 train_time:1149476ms step_avg:731.68ms
step:1582/1875 train_loss:3.4806 train_time:1150206ms step_avg:731.68ms
step:1583/1875 train_loss:3.5324 train_time:1150930ms step_avg:731.68ms
step:1584/1875 train_loss:3.2707 train_time:1151665ms step_avg:731.68ms
step:1585/1875 train_loss:3.4091 train_time:1152410ms step_avg:731.69ms
step:1586/1875 train_loss:3.3452 train_time:1153132ms step_avg:731.68ms
step:1587/1875 train_loss:3.5184 train_time:1153862ms step_avg:731.68ms
step:1588/1875 train_loss:3.4068 train_time:1154591ms step_avg:731.68ms
step:1589/1875 train_loss:3.3751 train_time:1155311ms step_avg:731.67ms
step:1590/1875 train_loss:3.4016 train_time:1156043ms step_avg:731.67ms
step:1591/1875 train_loss:3.4174 train_time:1156775ms step_avg:731.67ms
step:1592/1875 train_loss:3.2811 train_time:1157510ms step_avg:731.68ms
step:1593/1875 train_loss:3.3634 train_time:1158238ms step_avg:731.67ms
step:1594/1875 train_loss:3.7263 train_time:1158969ms step_avg:731.67ms
step:1595/1875 train_loss:3.3256 train_time:1159700ms step_avg:731.67ms
step:1596/1875 train_loss:3.3319 train_time:1160443ms step_avg:731.68ms
step:1597/1875 train_loss:3.4816 train_time:1161171ms step_avg:731.68ms
step:1598/1875 train_loss:3.4015 train_time:1161912ms step_avg:731.68ms
step:1599/1875 train_loss:3.2616 train_time:1162653ms step_avg:731.69ms
step:1600/1875 train_loss:3.4154 train_time:1163385ms step_avg:731.69ms
step:1601/1875 train_loss:3.4034 train_time:1164114ms step_avg:731.69ms
step:1602/1875 train_loss:3.4723 train_time:1164837ms step_avg:731.68ms
step:1603/1875 train_loss:3.3737 train_time:1165562ms step_avg:731.68ms
step:1604/1875 train_loss:3.3002 train_time:1166306ms step_avg:731.69ms
step:1605/1875 train_loss:3.4473 train_time:1167037ms step_avg:731.68ms
step:1606/1875 train_loss:3.2537 train_time:1167786ms step_avg:731.70ms
step:1607/1875 train_loss:3.4524 train_time:1168508ms step_avg:731.69ms
step:1608/1875 train_loss:3.3193 train_time:1169243ms step_avg:731.69ms
step:1609/1875 train_loss:3.4071 train_time:1169964ms step_avg:731.69ms
step:1610/1875 train_loss:3.4378 train_time:1170710ms step_avg:731.69ms
step:1611/1875 train_loss:3.2859 train_time:1171446ms step_avg:731.70ms
step:1612/1875 train_loss:3.4267 train_time:1172193ms step_avg:731.71ms
step:1613/1875 train_loss:3.4145 train_time:1172925ms step_avg:731.71ms
step:1614/1875 train_loss:3.2674 train_time:1173682ms step_avg:731.72ms
step:1615/1875 train_loss:3.5005 train_time:1174440ms step_avg:731.74ms
step:1616/1875 train_loss:3.4608 train_time:1175176ms step_avg:731.74ms
step:1617/1875 train_loss:3.4473 train_time:1175902ms step_avg:731.74ms
step:1618/1875 train_loss:3.3623 train_time:1176638ms step_avg:731.74ms
step:1619/1875 train_loss:3.5286 train_time:1177367ms step_avg:731.74ms
step:1620/1875 train_loss:3.4990 train_time:1178099ms step_avg:731.74ms
step:1621/1875 train_loss:3.4117 train_time:1178829ms step_avg:731.74ms
step:1622/1875 train_loss:3.6723 train_time:1179559ms step_avg:731.74ms
step:1623/1875 train_loss:3.3615 train_time:1180291ms step_avg:731.74ms
step:1624/1875 train_loss:3.6638 train_time:1181021ms step_avg:731.74ms
step:1625/1875 train_loss:3.4054 train_time:1181759ms step_avg:731.74ms
step:1625/1875 val_loss:3.4320 train_time:1181891ms step_avg:731.82ms
============== Weight norms: ==============
name = 'module._orig_mod.transformer.h.0.attn.c_q.weight' | fro_norm = 48.45553 | spectral_norm = 15.15347 | nuclear_norm = 955.28033
name = 'module._orig_mod.transformer.h.0.attn.c_k.weight' | fro_norm = 45.73379 | spectral_norm = 19.53609 | nuclear_norm = 863.20789
name = 'module._orig_mod.transformer.h.1.attn.c_q.weight' | fro_norm = 46.75954 | spectral_norm = 11.06827 | nuclear_norm = 913.62189
name = 'module._orig_mod.transformer.h.1.attn.c_k.weight' | fro_norm = 44.35899 | spectral_norm = 14.45949 | nuclear_norm = 856.33905
name = 'module._orig_mod.transformer.h.2.attn.c_q.weight' | fro_norm = 45.76611 | spectral_norm = 10.10096 | nuclear_norm = 881.32513
name = 'module._orig_mod.transformer.h.2.attn.c_k.weight' | fro_norm = 44.29913 | spectral_norm = 11.12159 | nuclear_norm = 858.25354
name = 'module._orig_mod.transformer.h.3.attn.c_q.weight' | fro_norm = 44.04355 | spectral_norm = 9.46925 | nuclear_norm = 865.61536
name = 'module._orig_mod.transformer.h.3.attn.c_k.weight' | fro_norm = 42.86852 | spectral_norm = 12.58354 | nuclear_norm = 839.74011
name = 'module._orig_mod.transformer.h.4.attn.c_q.weight' | fro_norm = 44.17339 | spectral_norm = 8.93998 | nuclear_norm = 870.09570
name = 'module._orig_mod.transformer.h.4.attn.c_k.weight' | fro_norm = 42.78104 | spectral_norm = 10.01980 | nuclear_norm = 847.43140
name = 'module._orig_mod.transformer.h.5.attn.c_q.weight' | fro_norm = 43.77544 | spectral_norm = 9.22861 | nuclear_norm = 857.09839
name = 'module._orig_mod.transformer.h.5.attn.c_k.weight' | fro_norm = 42.86231 | spectral_norm = 10.19021 | nuclear_norm = 846.67273
name = 'module._orig_mod.transformer.h.6.attn.c_q.weight' | fro_norm = 42.69062 | spectral_norm = 10.14122 | nuclear_norm = 839.28186
name = 'module._orig_mod.transformer.h.6.attn.c_k.weight' | fro_norm = 41.94851 | spectral_norm = 10.88842 | nuclear_norm = 832.54663
name = 'module._orig_mod.transformer.h.7.attn.c_q.weight' | fro_norm = 42.80794 | spectral_norm = 8.46552 | nuclear_norm = 829.49445
name = 'module._orig_mod.transformer.h.7.attn.c_k.weight' | fro_norm = 41.87531 | spectral_norm = 7.89437 | nuclear_norm = 829.12573
name = 'module._orig_mod.transformer.h.8.attn.c_q.weight' | fro_norm = 44.62106 | spectral_norm = 10.07413 | nuclear_norm = 870.82635
name = 'module._orig_mod.transformer.h.8.attn.c_k.weight' | fro_norm = 42.88033 | spectral_norm = 9.57519 | nuclear_norm = 853.09711
name = 'module._orig_mod.transformer.h.9.attn.c_q.weight' | fro_norm = 44.12494 | spectral_norm = 9.25501 | nuclear_norm = 857.41339
name = 'module._orig_mod.transformer.h.9.attn.c_k.weight' | fro_norm = 43.17419 | spectral_norm = 8.30023 | nuclear_norm = 853.68152
name = 'module._orig_mod.transformer.h.10.attn.c_q.weight' | fro_norm = 44.11198 | spectral_norm = 9.42248 | nuclear_norm = 844.52344
name = 'module._orig_mod.transformer.h.10.attn.c_k.weight' | fro_norm = 43.57000 | spectral_norm = 8.82929 | nuclear_norm = 849.47485
name = 'module._orig_mod.transformer.h.11.attn.c_q.weight' | fro_norm = 43.31911 | spectral_norm = 9.01165 | nuclear_norm = 833.17865
name = 'module._orig_mod.transformer.h.11.attn.c_k.weight' | fro_norm = 40.99386 | spectral_norm = 8.64643 | nuclear_norm = 801.00146
===========================================
step:1626/1875 train_loss:3.4786 train_time:1182476ms step_avg:731.73ms
step:1627/1875 train_loss:3.5061 train_time:1183201ms step_avg:731.73ms
step:1628/1875 train_loss:3.5307 train_time:1183928ms step_avg:731.72ms
step:1629/1875 train_loss:3.3867 train_time:1184652ms step_avg:731.72ms
step:1630/1875 train_loss:3.4356 train_time:1185383ms step_avg:731.72ms
step:1631/1875 train_loss:3.4033 train_time:1186113ms step_avg:731.72ms
step:1632/1875 train_loss:3.2981 train_time:1186839ms step_avg:731.71ms
step:1633/1875 train_loss:3.4075 train_time:1187561ms step_avg:731.71ms
step:1634/1875 train_loss:3.4162 train_time:1188286ms step_avg:731.70ms
step:1635/1875 train_loss:3.4095 train_time:1189022ms step_avg:731.71ms
step:1636/1875 train_loss:3.4916 train_time:1189747ms step_avg:731.70ms
step:1637/1875 train_loss:3.7602 train_time:1190487ms step_avg:731.71ms
step:1638/1875 train_loss:3.3836 train_time:1191224ms step_avg:731.71ms
step:1639/1875 train_loss:3.3572 train_time:1191971ms step_avg:731.72ms
step:1640/1875 train_loss:3.3795 train_time:1192706ms step_avg:731.72ms
step:1641/1875 train_loss:3.4929 train_time:1193425ms step_avg:731.71ms
step:1642/1875 train_loss:3.4401 train_time:1194150ms step_avg:731.71ms
step:1643/1875 train_loss:3.4364 train_time:1194887ms step_avg:731.71ms
step:1644/1875 train_loss:3.3389 train_time:1195608ms step_avg:731.71ms
step:1645/1875 train_loss:3.3468 train_time:1196338ms step_avg:731.71ms
step:1646/1875 train_loss:3.4257 train_time:1197068ms step_avg:731.70ms
step:1647/1875 train_loss:3.2978 train_time:1197810ms step_avg:731.71ms
step:1648/1875 train_loss:3.4434 train_time:1198539ms step_avg:731.71ms
step:1649/1875 train_loss:3.4850 train_time:1199262ms step_avg:731.70ms
step:1650/1875 train_loss:3.3819 train_time:1199993ms step_avg:731.70ms
step:1651/1875 train_loss:3.4660 train_time:1200725ms step_avg:731.70ms
step:1652/1875 train_loss:3.4209 train_time:1201460ms step_avg:731.71ms
step:1653/1875 train_loss:3.3954 train_time:1202180ms step_avg:731.70ms
step:1654/1875 train_loss:3.4921 train_time:1202908ms step_avg:731.70ms
step:1655/1875 train_loss:3.3269 train_time:1203634ms step_avg:731.69ms
step:1656/1875 train_loss:3.1174 train_time:1204368ms step_avg:731.69ms
step:1657/1875 train_loss:3.4399 train_time:1205101ms step_avg:731.69ms
step:1658/1875 train_loss:3.4564 train_time:1205821ms step_avg:731.69ms
step:1659/1875 train_loss:3.4034 train_time:1206555ms step_avg:731.69ms
step:1660/1875 train_loss:3.6575 train_time:1207296ms step_avg:731.69ms
step:1661/1875 train_loss:3.4881 train_time:1208023ms step_avg:731.69ms
step:1662/1875 train_loss:3.4703 train_time:1208759ms step_avg:731.69ms
step:1663/1875 train_loss:3.4423 train_time:1209493ms step_avg:731.70ms
step:1664/1875 train_loss:3.4772 train_time:1210219ms step_avg:731.69ms
step:1665/1875 train_loss:3.2949 train_time:1210944ms step_avg:731.69ms
step:1666/1875 train_loss:3.4418 train_time:1211673ms step_avg:731.69ms
step:1667/1875 train_loss:3.2484 train_time:1212409ms step_avg:731.69ms
step:1668/1875 train_loss:3.3939 train_time:1213130ms step_avg:731.68ms
step:1669/1875 train_loss:3.4312 train_time:1213864ms step_avg:731.68ms
step:1670/1875 train_loss:3.2528 train_time:1214594ms step_avg:731.68ms
step:1671/1875 train_loss:3.4137 train_time:1215334ms step_avg:731.69ms
step:1672/1875 train_loss:3.2923 train_time:1216087ms step_avg:731.70ms
step:1673/1875 train_loss:3.5749 train_time:1216816ms step_avg:731.70ms
step:1674/1875 train_loss:3.4486 train_time:1217550ms step_avg:731.70ms
step:1675/1875 train_loss:3.4189 train_time:1218275ms step_avg:731.70ms
step:1676/1875 train_loss:3.2889 train_time:1219010ms step_avg:731.70ms
step:1677/1875 train_loss:3.3617 train_time:1219745ms step_avg:731.70ms
step:1678/1875 train_loss:3.6987 train_time:1220472ms step_avg:731.70ms
step:1679/1875 train_loss:3.4246 train_time:1221201ms step_avg:731.70ms
step:1680/1875 train_loss:3.3984 train_time:1221940ms step_avg:731.70ms
step:1681/1875 train_loss:3.5392 train_time:1222668ms step_avg:731.70ms
step:1682/1875 train_loss:3.4602 train_time:1223394ms step_avg:731.69ms
step:1683/1875 train_loss:3.3659 train_time:1224135ms step_avg:731.70ms
step:1684/1875 train_loss:3.4580 train_time:1224868ms step_avg:731.70ms
step:1685/1875 train_loss:3.2957 train_time:1225602ms step_avg:731.70ms
step:1686/1875 train_loss:3.4610 train_time:1226331ms step_avg:731.70ms
step:1687/1875 train_loss:3.3494 train_time:1227066ms step_avg:731.70ms
step:1688/1875 train_loss:3.1702 train_time:1227802ms step_avg:731.71ms
step:1689/1875 train_loss:3.5019 train_time:1228541ms step_avg:731.71ms
step:1690/1875 train_loss:3.4470 train_time:1229274ms step_avg:731.71ms
step:1691/1875 train_loss:3.4522 train_time:1230005ms step_avg:731.71ms
step:1692/1875 train_loss:3.3526 train_time:1230750ms step_avg:731.72ms
step:1693/1875 train_loss:3.3297 train_time:1231484ms step_avg:731.72ms
step:1694/1875 train_loss:3.4350 train_time:1232218ms step_avg:731.72ms
step:1695/1875 train_loss:3.3610 train_time:1232943ms step_avg:731.72ms
step:1696/1875 train_loss:3.4428 train_time:1233668ms step_avg:731.71ms
step:1697/1875 train_loss:3.4033 train_time:1234400ms step_avg:731.71ms
step:1698/1875 train_loss:3.5015 train_time:1235133ms step_avg:731.71ms
step:1699/1875 train_loss:3.3485 train_time:1235867ms step_avg:731.72ms
step:1700/1875 train_loss:3.3782 train_time:1236594ms step_avg:731.71ms
step:1701/1875 train_loss:3.3037 train_time:1237319ms step_avg:731.71ms
step:1702/1875 train_loss:3.3308 train_time:1238049ms step_avg:731.71ms
step:1703/1875 train_loss:3.4037 train_time:1238777ms step_avg:731.71ms
step:1704/1875 train_loss:3.4303 train_time:1239503ms step_avg:731.70ms
step:1705/1875 train_loss:3.4051 train_time:1240224ms step_avg:731.70ms
step:1706/1875 train_loss:3.4419 train_time:1240949ms step_avg:731.69ms
step:1707/1875 train_loss:3.3882 train_time:1241678ms step_avg:731.69ms
step:1708/1875 train_loss:3.5393 train_time:1242412ms step_avg:731.69ms
step:1709/1875 train_loss:3.2496 train_time:1243137ms step_avg:731.69ms
step:1710/1875 train_loss:3.3684 train_time:1244073ms step_avg:731.81ms
step:1711/1875 train_loss:3.3500 train_time:1244802ms step_avg:731.81ms
step:1712/1875 train_loss:3.3526 train_time:1245535ms step_avg:731.81ms
step:1713/1875 train_loss:3.8350 train_time:1246266ms step_avg:731.81ms
step:1714/1875 train_loss:3.3988 train_time:1247297ms step_avg:731.98ms
step:1715/1875 train_loss:3.3984 train_time:1248016ms step_avg:731.97ms
step:1716/1875 train_loss:3.4342 train_time:1248741ms step_avg:731.97ms
step:1717/1875 train_loss:3.4665 train_time:1249466ms step_avg:731.97ms
step:1718/1875 train_loss:3.3698 train_time:1250201ms step_avg:731.97ms
step:1719/1875 train_loss:3.3964 train_time:1250937ms step_avg:731.97ms
step:1720/1875 train_loss:3.2224 train_time:1251670ms step_avg:731.97ms
step:1721/1875 train_loss:3.3667 train_time:1252392ms step_avg:731.97ms
step:1722/1875 train_loss:3.3807 train_time:1253112ms step_avg:731.96ms
step:1723/1875 train_loss:3.3409 train_time:1253837ms step_avg:731.95ms
step:1724/1875 train_loss:3.4901 train_time:1254563ms step_avg:731.95ms
step:1725/1875 train_loss:3.2872 train_time:1255313ms step_avg:731.96ms
step:1726/1875 train_loss:3.4350 train_time:1256041ms step_avg:731.96ms
step:1727/1875 train_loss:3.5223 train_time:1256774ms step_avg:731.96ms
step:1728/1875 train_loss:3.3745 train_time:1257505ms step_avg:731.96ms
step:1729/1875 train_loss:3.6104 train_time:1258237ms step_avg:731.96ms
step:1730/1875 train_loss:3.3753 train_time:1258973ms step_avg:731.96ms
step:1731/1875 train_loss:3.4458 train_time:1259698ms step_avg:731.96ms
step:1732/1875 train_loss:3.4183 train_time:1260418ms step_avg:731.95ms
step:1733/1875 train_loss:3.4005 train_time:1261149ms step_avg:731.95ms
step:1734/1875 train_loss:3.7862 train_time:1261882ms step_avg:731.95ms
step:1735/1875 train_loss:3.4091 train_time:1262622ms step_avg:731.95ms
step:1736/1875 train_loss:3.5496 train_time:1263349ms step_avg:731.95ms
step:1737/1875 train_loss:3.3153 train_time:1264086ms step_avg:731.95ms
step:1738/1875 train_loss:3.3645 train_time:1264813ms step_avg:731.95ms
step:1739/1875 train_loss:3.3866 train_time:1265537ms step_avg:731.95ms
step:1740/1875 train_loss:3.3736 train_time:1266262ms step_avg:731.94ms
step:1741/1875 train_loss:3.5001 train_time:1266985ms step_avg:731.94ms
step:1742/1875 train_loss:3.3427 train_time:1267715ms step_avg:731.94ms
step:1743/1875 train_loss:3.4153 train_time:1268446ms step_avg:731.94ms
step:1744/1875 train_loss:3.4828 train_time:1269171ms step_avg:731.93ms
step:1745/1875 train_loss:3.2854 train_time:1269906ms step_avg:731.93ms
step:1746/1875 train_loss:3.1744 train_time:1270632ms step_avg:731.93ms
step:1747/1875 train_loss:3.0749 train_time:1271375ms step_avg:731.94ms
step:1748/1875 train_loss:3.4041 train_time:1272105ms step_avg:731.94ms
step:1749/1875 train_loss:3.4303 train_time:1272825ms step_avg:731.93ms
step:1750/1875 train_loss:3.3823 train_time:1273552ms step_avg:731.93ms
step:1750/1875 val_loss:3.3928 train_time:1273687ms step_avg:732.00ms
============== Weight norms: ==============
name = 'module._orig_mod.transformer.h.0.attn.c_q.weight' | fro_norm = 48.73658 | spectral_norm = 15.42836 | nuclear_norm = 960.84766
name = 'module._orig_mod.transformer.h.0.attn.c_k.weight' | fro_norm = 46.02520 | spectral_norm = 19.74151 | nuclear_norm = 869.02057
name = 'module._orig_mod.transformer.h.1.attn.c_q.weight' | fro_norm = 47.05781 | spectral_norm = 11.19617 | nuclear_norm = 920.23389
name = 'module._orig_mod.transformer.h.1.attn.c_k.weight' | fro_norm = 44.67547 | spectral_norm = 14.51036 | nuclear_norm = 863.41162
name = 'module._orig_mod.transformer.h.2.attn.c_q.weight' | fro_norm = 46.04890 | spectral_norm = 10.24746 | nuclear_norm = 887.28516
name = 'module._orig_mod.transformer.h.2.attn.c_k.weight' | fro_norm = 44.59644 | spectral_norm = 11.18696 | nuclear_norm = 864.91376
name = 'module._orig_mod.transformer.h.3.attn.c_q.weight' | fro_norm = 44.31685 | spectral_norm = 9.54641 | nuclear_norm = 871.69543
name = 'module._orig_mod.transformer.h.3.attn.c_k.weight' | fro_norm = 43.15773 | spectral_norm = 12.65502 | nuclear_norm = 846.01050
name = 'module._orig_mod.transformer.h.4.attn.c_q.weight' | fro_norm = 44.41880 | spectral_norm = 9.05826 | nuclear_norm = 875.71478
name = 'module._orig_mod.transformer.h.4.attn.c_k.weight' | fro_norm = 43.04734 | spectral_norm = 10.11458 | nuclear_norm = 853.30603
name = 'module._orig_mod.transformer.h.5.attn.c_q.weight' | fro_norm = 44.05100 | spectral_norm = 9.34026 | nuclear_norm = 863.28772
name = 'module._orig_mod.transformer.h.5.attn.c_k.weight' | fro_norm = 43.16287 | spectral_norm = 10.32147 | nuclear_norm = 853.23645
name = 'module._orig_mod.transformer.h.6.attn.c_q.weight' | fro_norm = 42.96686 | spectral_norm = 10.19724 | nuclear_norm = 845.37781
name = 'module._orig_mod.transformer.h.6.attn.c_k.weight' | fro_norm = 42.24139 | spectral_norm = 10.99227 | nuclear_norm = 839.03027
name = 'module._orig_mod.transformer.h.7.attn.c_q.weight' | fro_norm = 43.04653 | spectral_norm = 8.50814 | nuclear_norm = 834.09558
name = 'module._orig_mod.transformer.h.7.attn.c_k.weight' | fro_norm = 42.13013 | spectral_norm = 7.95411 | nuclear_norm = 834.19727
name = 'module._orig_mod.transformer.h.8.attn.c_q.weight' | fro_norm = 44.88577 | spectral_norm = 10.20919 | nuclear_norm = 876.59985
name = 'module._orig_mod.transformer.h.8.attn.c_k.weight' | fro_norm = 43.16138 | spectral_norm = 9.66070 | nuclear_norm = 859.54895
name = 'module._orig_mod.transformer.h.9.attn.c_q.weight' | fro_norm = 44.39262 | spectral_norm = 9.33831 | nuclear_norm = 862.84698
name = 'module._orig_mod.transformer.h.9.attn.c_k.weight' | fro_norm = 43.45314 | spectral_norm = 8.36844 | nuclear_norm = 859.76965
name = 'module._orig_mod.transformer.h.10.attn.c_q.weight' | fro_norm = 44.39248 | spectral_norm = 9.48566 | nuclear_norm = 850.51636
name = 'module._orig_mod.transformer.h.10.attn.c_k.weight' | fro_norm = 43.86232 | spectral_norm = 8.82435 | nuclear_norm = 856.20172
name = 'module._orig_mod.transformer.h.11.attn.c_q.weight' | fro_norm = 43.56823 | spectral_norm = 9.08945 | nuclear_norm = 837.78748
name = 'module._orig_mod.transformer.h.11.attn.c_k.weight' | fro_norm = 41.27137 | spectral_norm = 8.71611 | nuclear_norm = 805.97778
===========================================
step:1751/1875 train_loss:3.4006 train_time:1274274ms step_avg:731.92ms
step:1752/1875 train_loss:3.6240 train_time:1275022ms step_avg:731.93ms
step:1753/1875 train_loss:3.3428 train_time:1275749ms step_avg:731.93ms
step:1754/1875 train_loss:3.4038 train_time:1276479ms step_avg:731.93ms
step:1755/1875 train_loss:3.4121 train_time:1277206ms step_avg:731.92ms
step:1756/1875 train_loss:3.0082 train_time:1277948ms step_avg:731.93ms
step:1757/1875 train_loss:3.1403 train_time:1278677ms step_avg:731.93ms
step:1758/1875 train_loss:3.2031 train_time:1279413ms step_avg:731.93ms
step:1759/1875 train_loss:3.1930 train_time:1280143ms step_avg:731.93ms
step:1760/1875 train_loss:3.3811 train_time:1280866ms step_avg:731.92ms
step:1761/1875 train_loss:3.2621 train_time:1281596ms step_avg:731.92ms
step:1762/1875 train_loss:3.2304 train_time:1282322ms step_avg:731.92ms
step:1763/1875 train_loss:4.3125 train_time:1283049ms step_avg:731.92ms
step:1764/1875 train_loss:3.3733 train_time:1283778ms step_avg:731.91ms
step:1765/1875 train_loss:3.4212 train_time:1284498ms step_avg:731.91ms
step:1766/1875 train_loss:3.4226 train_time:1285224ms step_avg:731.90ms
step:1767/1875 train_loss:3.4255 train_time:1285944ms step_avg:731.90ms
step:1768/1875 train_loss:3.3434 train_time:1286679ms step_avg:731.90ms
step:1769/1875 train_loss:3.3980 train_time:1287415ms step_avg:731.90ms
step:1770/1875 train_loss:3.3962 train_time:1288159ms step_avg:731.91ms
step:1771/1875 train_loss:3.6253 train_time:1288884ms step_avg:731.90ms
step:1772/1875 train_loss:3.3904 train_time:1289606ms step_avg:731.90ms
step:1773/1875 train_loss:3.4579 train_time:1290333ms step_avg:731.90ms
step:1774/1875 train_loss:3.6882 train_time:1291072ms step_avg:731.90ms
step:1775/1875 train_loss:3.3582 train_time:1291802ms step_avg:731.90ms
step:1776/1875 train_loss:3.2791 train_time:1292539ms step_avg:731.90ms
step:1777/1875 train_loss:3.5242 train_time:1293270ms step_avg:731.90ms
step:1778/1875 train_loss:3.2634 train_time:1294007ms step_avg:731.90ms
step:1779/1875 train_loss:3.4373 train_time:1294748ms step_avg:731.91ms
step:1780/1875 train_loss:3.4685 train_time:1295478ms step_avg:731.91ms
step:1781/1875 train_loss:3.5880 train_time:1296203ms step_avg:731.90ms
step:1782/1875 train_loss:3.3872 train_time:1296924ms step_avg:731.90ms
step:1783/1875 train_loss:3.6819 train_time:1297649ms step_avg:731.89ms
step:1784/1875 train_loss:3.4516 train_time:1298378ms step_avg:731.89ms
step:1785/1875 train_loss:3.4517 train_time:1299110ms step_avg:731.89ms
step:1786/1875 train_loss:3.2404 train_time:1299840ms step_avg:731.89ms
step:1787/1875 train_loss:3.3446 train_time:1300567ms step_avg:731.89ms
step:1788/1875 train_loss:3.4773 train_time:1301294ms step_avg:731.89ms
step:1789/1875 train_loss:3.3822 train_time:1302024ms step_avg:731.89ms
step:1790/1875 train_loss:3.5481 train_time:1302748ms step_avg:731.88ms
step:1791/1875 train_loss:3.3559 train_time:1303480ms step_avg:731.88ms
step:1792/1875 train_loss:3.3276 train_time:1304211ms step_avg:731.88ms
step:1793/1875 train_loss:3.4729 train_time:1304933ms step_avg:731.88ms
step:1794/1875 train_loss:3.3826 train_time:1305659ms step_avg:731.87ms
step:1795/1875 train_loss:3.3351 train_time:1306384ms step_avg:731.87ms
step:1796/1875 train_loss:3.4495 train_time:1307106ms step_avg:731.86ms
step:1797/1875 train_loss:3.3410 train_time:1307840ms step_avg:731.86ms
step:1798/1875 train_loss:3.3328 train_time:1308566ms step_avg:731.86ms
step:1799/1875 train_loss:3.3804 train_time:1309296ms step_avg:731.86ms
step:1800/1875 train_loss:3.3128 train_time:1310036ms step_avg:731.86ms
step:1801/1875 train_loss:3.4840 train_time:1310761ms step_avg:731.86ms
step:1802/1875 train_loss:3.3791 train_time:1311494ms step_avg:731.86ms
step:1803/1875 train_loss:3.4499 train_time:1312230ms step_avg:731.86ms
step:1804/1875 train_loss:3.3612 train_time:1312963ms step_avg:731.86ms
step:1805/1875 train_loss:3.4240 train_time:1313687ms step_avg:731.86ms
step:1806/1875 train_loss:3.2965 train_time:1314418ms step_avg:731.86ms
step:1807/1875 train_loss:3.2374 train_time:1315145ms step_avg:731.86ms
step:1808/1875 train_loss:3.5041 train_time:1315879ms step_avg:731.86ms
step:1809/1875 train_loss:3.4189 train_time:1316604ms step_avg:731.85ms
step:1810/1875 train_loss:3.4165 train_time:1317346ms step_avg:731.86ms
step:1811/1875 train_loss:3.5436 train_time:1318081ms step_avg:731.86ms
step:1812/1875 train_loss:3.3326 train_time:1318813ms step_avg:731.86ms
step:1813/1875 train_loss:3.4378 train_time:1319539ms step_avg:731.86ms
step:1814/1875 train_loss:3.5805 train_time:1320269ms step_avg:731.86ms
step:1815/1875 train_loss:3.4322 train_time:1320991ms step_avg:731.85ms
step:1816/1875 train_loss:3.4705 train_time:1321722ms step_avg:731.85ms
step:1817/1875 train_loss:3.4861 train_time:1322462ms step_avg:731.86ms
step:1818/1875 train_loss:3.4378 train_time:1323188ms step_avg:731.85ms
step:1819/1875 train_loss:3.4571 train_time:1323921ms step_avg:731.85ms
step:1820/1875 train_loss:3.4274 train_time:1324664ms step_avg:731.86ms
step:1821/1875 train_loss:3.4772 train_time:1325407ms step_avg:731.86ms
step:1822/1875 train_loss:3.4047 train_time:1326131ms step_avg:731.86ms
step:1823/1875 train_loss:3.4050 train_time:1326865ms step_avg:731.86ms
step:1824/1875 train_loss:3.3619 train_time:1327601ms step_avg:731.86ms
step:1825/1875 train_loss:3.3004 train_time:1328344ms step_avg:731.87ms
step:1826/1875 train_loss:3.2557 train_time:1329075ms step_avg:731.87ms
step:1827/1875 train_loss:3.4200 train_time:1329793ms step_avg:731.86ms
step:1828/1875 train_loss:3.5029 train_time:1330528ms step_avg:731.86ms
step:1829/1875 train_loss:3.4770 train_time:1331262ms step_avg:731.86ms
step:1830/1875 train_loss:3.4595 train_time:1332007ms step_avg:731.87ms
step:1831/1875 train_loss:3.3401 train_time:1332734ms step_avg:731.87ms
step:1832/1875 train_loss:3.3021 train_time:1333474ms step_avg:731.87ms
step:1833/1875 train_loss:3.5000 train_time:1334220ms step_avg:731.88ms
step:1834/1875 train_loss:3.2552 train_time:1334950ms step_avg:731.88ms
step:1835/1875 train_loss:3.4067 train_time:1335678ms step_avg:731.88ms
step:1836/1875 train_loss:3.2871 train_time:1336405ms step_avg:731.88ms
step:1837/1875 train_loss:3.6217 train_time:1337129ms step_avg:731.87ms
step:1838/1875 train_loss:3.4490 train_time:1337855ms step_avg:731.87ms
step:1839/1875 train_loss:3.4295 train_time:1338598ms step_avg:731.87ms
step:1840/1875 train_loss:3.5374 train_time:1339336ms step_avg:731.88ms
step:1841/1875 train_loss:3.4205 train_time:1340062ms step_avg:731.87ms
step:1842/1875 train_loss:3.3063 train_time:1340796ms step_avg:731.88ms
step:1843/1875 train_loss:3.4103 train_time:1341544ms step_avg:731.88ms
step:1844/1875 train_loss:3.2895 train_time:1342275ms step_avg:731.88ms
step:1845/1875 train_loss:3.4144 train_time:1343004ms step_avg:731.88ms
step:1846/1875 train_loss:3.4569 train_time:1343743ms step_avg:731.89ms
step:1847/1875 train_loss:3.2115 train_time:1344479ms step_avg:731.89ms
step:1848/1875 train_loss:3.3434 train_time:1345203ms step_avg:731.88ms
step:1849/1875 train_loss:3.4036 train_time:1345943ms step_avg:731.89ms
step:1850/1875 train_loss:3.3483 train_time:1346679ms step_avg:731.89ms
step:1851/1875 train_loss:3.2452 train_time:1347412ms step_avg:731.89ms
step:1852/1875 train_loss:3.4884 train_time:1348149ms step_avg:731.89ms
step:1853/1875 train_loss:3.2735 train_time:1348875ms step_avg:731.89ms
step:1854/1875 train_loss:3.3711 train_time:1349600ms step_avg:731.89ms
step:1855/1875 train_loss:3.3157 train_time:1350328ms step_avg:731.89ms
step:1856/1875 train_loss:3.5193 train_time:1351053ms step_avg:731.88ms
step:1857/1875 train_loss:3.4953 train_time:1351783ms step_avg:731.88ms
step:1858/1875 train_loss:3.3644 train_time:1352519ms step_avg:731.88ms
step:1859/1875 train_loss:3.3206 train_time:1353245ms step_avg:731.88ms
step:1860/1875 train_loss:3.3528 train_time:1353970ms step_avg:731.88ms
step:1861/1875 train_loss:3.5851 train_time:1354717ms step_avg:731.88ms
step:1862/1875 train_loss:3.3984 train_time:1355451ms step_avg:731.89ms
step:1863/1875 train_loss:3.3760 train_time:1356179ms step_avg:731.88ms
step:1864/1875 train_loss:3.4267 train_time:1356903ms step_avg:731.88ms
step:1865/1875 train_loss:3.2782 train_time:1357628ms step_avg:731.88ms
step:1866/1875 train_loss:3.2870 train_time:1358361ms step_avg:731.88ms
step:1867/1875 train_loss:3.3786 train_time:1359086ms step_avg:731.87ms
step:1868/1875 train_loss:3.4227 train_time:1359820ms step_avg:731.87ms
step:1869/1875 train_loss:3.1747 train_time:1360557ms step_avg:731.88ms
step:1870/1875 train_loss:3.3171 train_time:1361283ms step_avg:731.87ms
step:1871/1875 train_loss:3.2682 train_time:1362005ms step_avg:731.87ms
step:1872/1875 train_loss:3.2529 train_time:1362744ms step_avg:731.87ms
step:1873/1875 train_loss:3.4312 train_time:1363468ms step_avg:731.87ms
step:1874/1875 train_loss:3.4162 train_time:1364201ms step_avg:731.87ms
step:1875/1875 train_loss:3.3570 train_time:1364926ms step_avg:731.86ms
step:1875/1875 val_loss:3.3698 train_time:1365060ms step_avg:731.94ms
============== Weight norms: ==============
name = 'module._orig_mod.transformer.h.0.attn.c_q.weight' | fro_norm = 48.78207 | spectral_norm = 15.51918 | nuclear_norm = 961.79333
name = 'module._orig_mod.transformer.h.0.attn.c_k.weight' | fro_norm = 46.07306 | spectral_norm = 19.77616 | nuclear_norm = 870.10986
name = 'module._orig_mod.transformer.h.1.attn.c_q.weight' | fro_norm = 47.11605 | spectral_norm = 11.23446 | nuclear_norm = 921.73499
name = 'module._orig_mod.transformer.h.1.attn.c_k.weight' | fro_norm = 44.73977 | spectral_norm = 14.52493 | nuclear_norm = 865.11237
name = 'module._orig_mod.transformer.h.2.attn.c_q.weight' | fro_norm = 46.09776 | spectral_norm = 10.29558 | nuclear_norm = 888.56476
name = 'module._orig_mod.transformer.h.2.attn.c_k.weight' | fro_norm = 44.64902 | spectral_norm = 11.18861 | nuclear_norm = 866.28015
name = 'module._orig_mod.transformer.h.3.attn.c_q.weight' | fro_norm = 44.36465 | spectral_norm = 9.55980 | nuclear_norm = 873.00452
name = 'module._orig_mod.transformer.h.3.attn.c_k.weight' | fro_norm = 43.21257 | spectral_norm = 12.68477 | nuclear_norm = 847.36328
name = 'module._orig_mod.transformer.h.4.attn.c_q.weight' | fro_norm = 44.45566 | spectral_norm = 9.08077 | nuclear_norm = 876.79694
name = 'module._orig_mod.transformer.h.4.attn.c_k.weight' | fro_norm = 43.09270 | spectral_norm = 10.13522 | nuclear_norm = 854.58557
name = 'module._orig_mod.transformer.h.5.attn.c_q.weight' | fro_norm = 44.09688 | spectral_norm = 9.36982 | nuclear_norm = 864.57373
name = 'module._orig_mod.transformer.h.5.attn.c_k.weight' | fro_norm = 43.21610 | spectral_norm = 10.34749 | nuclear_norm = 854.74182
name = 'module._orig_mod.transformer.h.6.attn.c_q.weight' | fro_norm = 43.01292 | spectral_norm = 10.22219 | nuclear_norm = 846.55389
name = 'module._orig_mod.transformer.h.6.attn.c_k.weight' | fro_norm = 42.29651 | spectral_norm = 11.01307 | nuclear_norm = 840.47461
name = 'module._orig_mod.transformer.h.7.attn.c_q.weight' | fro_norm = 43.08226 | spectral_norm = 8.54056 | nuclear_norm = 834.65704
name = 'module._orig_mod.transformer.h.7.attn.c_k.weight' | fro_norm = 42.17000 | spectral_norm = 7.96940 | nuclear_norm = 835.12341
name = 'module._orig_mod.transformer.h.8.attn.c_q.weight' | fro_norm = 44.92832 | spectral_norm = 10.25931 | nuclear_norm = 877.64496
name = 'module._orig_mod.transformer.h.8.attn.c_k.weight' | fro_norm = 43.20798 | spectral_norm = 9.69666 | nuclear_norm = 860.79932
name = 'module._orig_mod.transformer.h.9.attn.c_q.weight' | fro_norm = 44.43621 | spectral_norm = 9.35091 | nuclear_norm = 863.83618
name = 'module._orig_mod.transformer.h.9.attn.c_k.weight' | fro_norm = 43.49886 | spectral_norm = 8.37929 | nuclear_norm = 861.04382
name = 'module._orig_mod.transformer.h.10.attn.c_q.weight' | fro_norm = 44.43976 | spectral_norm = 9.52885 | nuclear_norm = 851.66406
name = 'module._orig_mod.transformer.h.10.attn.c_k.weight' | fro_norm = 43.91183 | spectral_norm = 8.83599 | nuclear_norm = 857.61395
name = 'module._orig_mod.transformer.h.11.attn.c_q.weight' | fro_norm = 43.60122 | spectral_norm = 9.11443 | nuclear_norm = 838.28278
name = 'module._orig_mod.transformer.h.11.attn.c_k.weight' | fro_norm = 41.31204 | spectral_norm = 8.73763 | nuclear_norm = 806.73468
===========================================
