import os
import sys
with open(sys.argv[0]) as f:
    code = f.read() # read the code of this file ASAP, for logging
import uuid
import time
import copy
import glob
from dataclasses import dataclass
from functools import lru_cache
from pathlib import Path

os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True"
import torch
torch.empty(1, device="cuda", requires_grad=True).backward() # prevents a bug on some systems
from torch import Tensor, nn
import torch.nn.functional as F
import torch.distributed as dist
# use of FlexAttention contributed by @KoszarskyB
from torch.nn.attention.flex_attention import BlockMask, flex_attention
#torch._inductor.config.coordinate_descent_tuning = True # we have banned this flag for new records because it causes compilation to take 30min

# -----------------------------------------------------------------------------
# Custom operators: FP8 matmul by @YouJiacheng

@torch.library.custom_op("nanogpt::mm", mutates_args=())
def mm_op(x: Tensor, w: Tensor, x_s: float, w_s: float, grad_s: float) -> tuple[Tensor, Tensor, Tensor]:
    @torch.compile
    def impl(x: Tensor, w: Tensor):
        assert x.is_contiguous() and w.is_contiguous()
        x_f8 = x.div(x_s).to(torch.float8_e4m3fn)
        w_f8 = w.div(w_s).to(torch.float8_e4m3fn)
        out = torch._scaled_mm(
            x_f8,
            w_f8.T,
            out_dtype=torch.bfloat16,
            scale_a=x.new_tensor(x_s, dtype=torch.float32),
            scale_b=x.new_tensor(w_s, dtype=torch.float32),
            use_fast_accum=True,
        )
        return out, x_f8, w_f8

    return impl(x, w)

@mm_op.register_fake
def _(x: Tensor, w: Tensor, *_):
    assert x.ndim == w.ndim == 2
    assert x.shape[1] == w.shape[1]
    assert x.device == w.device
    assert x.is_contiguous() and w.is_contiguous()
    return x @ w.T, x.to(torch.float8_e4m3fn), w.to(torch.float8_e4m3fn)

@torch.library.custom_op("nanogpt::mm_backward", mutates_args=())
def mm_backward_op(g: Tensor, x_f8: Tensor, w_f8: Tensor, x_s: float, w_s: float, grad_s: float) -> tuple[Tensor, Tensor]:
    @torch.compile
    def impl(grad: Tensor, x_f8: Tensor, w_f8: Tensor):
        assert grad.is_contiguous()
        x_inv_s = grad.new_tensor(x_s, dtype=torch.float32)
        w_inv_s = grad.new_tensor(w_s, dtype=torch.float32)
        grad_inv_s = grad.new_tensor(grad_s, dtype=torch.float32)
        grad_f8 = grad.div(grad_s).to(torch.float8_e5m2)
        grad_x = torch._scaled_mm(
            grad_f8,
            w_f8.T.contiguous().T,
            out_dtype=torch.bfloat16,
            scale_a=grad_inv_s,
            scale_b=w_inv_s,
            use_fast_accum=False,
        )
        # faster than grad_f8_t @ x_f8, for (d_out, d_in) == (50304, 768)
        grad_w = torch._scaled_mm(
            x_f8.T.contiguous(),
            grad_f8.T.contiguous().T,
            out_dtype=torch.float32,
            scale_a=x_inv_s,
            scale_b=grad_inv_s,
            use_fast_accum=False,
        ).T
        return grad_x, grad_w

    return impl(g, x_f8, w_f8)

@mm_backward_op.register_fake
def _(g: Tensor, x_f8: Tensor, w_f8: Tensor, *_):
    return x_f8.to(torch.bfloat16), w_f8.to(torch.float32)

def backward(ctx, grad_out: Tensor, *_):
    x_f8, w_f8 = ctx.saved_tensors
    x_s, w_s, grad_s = ctx.scales
    grad_x, grad_w = torch.ops.nanogpt.mm_backward(
        grad_out, x_f8, w_f8, x_s, w_s, grad_s
    )
    return grad_x, grad_w, None, None, None

def setup_context(ctx: torch.autograd.function.FunctionCtx, inputs, output):
    *_, x_s, w_s, grad_s = inputs
    _, x_f8, w_f8 = output
    ctx.save_for_backward(x_f8, w_f8)
    ctx.scales = x_s, w_s, grad_s
    ctx.set_materialize_grads(False)

mm_op.register_autograd(backward, setup_context=setup_context)

# -----------------------------------------------------------------------------
# Muon optimizer

@torch.compile
def zeropower_via_newtonschulz5(G: Tensor, steps: int) -> Tensor:
    """
    Newton-Schulz iteration to compute the zeroth power / orthogonalization of G. We opt to use a
    quintic iteration whose coefficients are selected to maximize the slope at zero. For the purpose
    of minimizing steps, it turns out to be empirically effective to keep increasing the slope at
    zero even beyond the point where the iteration no longer converges all the way to one everywhere
    on the interval. This iteration therefore does not produce UV^T but rather something like US'V^T
    where S' is diagonal with S_{ii}' ~ Uniform(0.5, 1.5), which turns out not to hurt model
    performance at all relative to UV^T, where USV^T = G is the SVD.
    """
    assert G.ndim >= 2 # batched Muon implementation by @scottjmaddox, and put into practice in the record by @YouJiacheng
    X = G.bfloat16()
    if G.size(-2) > G.size(-1):
        X = X.mT

    # Ensure spectral norm is at most 1
    X = X / (X.norm(dim=(-2, -1), keepdim=True) + 1e-7)
    # Perform the NS iterations
    for a, b, c in [
        (4.1357, -4.2084, 1.0726),
        (4.132, -4.2045, 1.0725),
        (4.077, -4.1489, 1.0719),
        (4.0422, -4.1139, 1.0717),
        (3.9129, -3.9845, 1.0715),
        (3.3337, -3.2386, 0.9049),
        (2.2005, -1.6921, 0.4915),
    ]:
        A = X @ X.mT
        B = b * A + c * A @ A # quintic computation strategy adapted from suggestion by @jxbz, @leloykun, and @YouJiacheng
        X = a * X + B @ X
    
    if G.size(-2) > G.size(-1):
        X = X.mT
    return X

class Muon(torch.optim.Optimizer):
    """
    Muon - MomentUm Orthogonalized by Newton-schulz

    https://kellerjordan.github.io/posts/muon/

    Muon internally runs standard SGD-momentum, and then performs an orthogonalization post-
    processing step, in which each 2D parameter's update is replaced with the nearest orthogonal
    matrix. To efficiently orthogonalize each update, we use a Newton-Schulz iteration, which has
    the advantage that it can be stably run in bfloat16 on the GPU.

    Some warnings:
    - This optimizer should not be used for the embedding layer, the final fully connected layer,
    or any {0,1}-D parameters; those should all be optimized by a standard method (e.g., AdamW).
    - To use it with 4D convolutional filters, it works well to just flatten their last 3 dimensions.

    Arguments:
        lr: The learning rate used by the internal SGD.
        momentum: The momentum used by the internal SGD.
        nesterov: Whether to use Nesterov-style momentum in the internal SGD. (recommended)
        ns_steps: The number of Newton-Schulz iteration steps to use.
    """
    def __init__(self, params, lr=0.02, momentum=0.95, nesterov=True, ns_steps=5, rank=0, world_size=1):
        self.rank = rank
        self.world_size = world_size
        defaults = dict(lr=lr, momentum=momentum, nesterov=nesterov, ns_steps=ns_steps)
        params: list[Tensor] = [*params]
        param_groups = []
        for size in {p.numel() for p in params}:
            b = torch.empty(world_size, size, dtype=torch.bfloat16, device="cuda")
            group = dict(params=[p for p in params if p.numel() == size],
                         update_buffer=b, update_buffer_views=[b[i] for i in range(world_size)])
            param_groups.append(group)
        super().__init__(param_groups, defaults)

    @torch.no_grad()
    def step(self):
        for group in self.param_groups:
            update_buffer: Tensor = group["update_buffer"]
            update_buffer_views: list[Tensor] = group["update_buffer_views"]
            # generate weight updates in distributed fashion
            params: list[Tensor] = group["params"]
            handle = None
            params_world = None
            def update_prev(): # optimized Muon implementation contributed by @YouJiacheng
                handle.wait()
                for p_world, g_world in zip(params_world, update_buffer_views):
                    p_world.add_(g_world.view_as(p_world),
                                 alpha=-group["lr"] * max(1, p_world.size(-2) / p_world.size(-1))**0.5)
            for base_i in range(len(params))[::self.world_size]:
                if base_i + self.rank < len(params):
                    p = params[base_i + self.rank]
                    g = p.grad
                    assert g is not None
                    state = self.state[p]
                    if "momentum_buffer" not in state:
                        state["momentum_buffer"] = torch.zeros_like(g)
                    buf: Tensor = state["momentum_buffer"]
                    buf.lerp_(g, 1 - group["momentum"])
                    g = g.lerp_(buf, group["momentum"]) if group["nesterov"] else buf
                    g = zeropower_via_newtonschulz5(g, steps=group["ns_steps"]).flatten()
                else:
                    g = update_buffer_views[self.rank]
                if base_i > 0:
                    update_prev() # async all_gather instead of sync all_reduce by @YouJiacheng
                handle = dist.all_gather_into_tensor(update_buffer, g, async_op=True)
                params_world = params[base_i : base_i + self.world_size]
            update_prev()

# -----------------------------------------------------------------------------
# PyTorch nn.Module definitions for the model

def norm(x: Tensor):
    return F.rms_norm(x, (x.size(-1),))

class CastedLinear(nn.Linear):
    def __init__(self, in_features: int, out_features: int, use_fp8=False, x_s=1.0, w_s=1.0, grad_s=1.0):
        super().__init__(in_features, out_features, bias=False)
        self.use_fp8 = use_fp8
        self.x_s = x_s
        self.w_s = w_s
        self.grad_s = grad_s

    def reset_parameters(self) -> None:
        std = 0.5 * (self.in_features ** -0.5) # 0.5 is a bit better than the default 1/sqrt(3)
        bound = (3 ** 0.5) * std
        with torch.no_grad():
            self.weight.uniform_(-bound, bound)

    def forward(self, x: Tensor):
        if self.use_fp8 and self.training:
            _x = x.flatten(0, -2)
            out: Tensor = torch.ops.nanogpt.mm(_x, self.weight, x_s=self.x_s, w_s=self.w_s, grad_s=self.grad_s)[0]
            return out.reshape(*x.shape[:-1], -1)
        else:
            return F.linear(x, self.weight.type_as(x))

class Rotary(nn.Module):
    def __init__(self, dim: int, max_seq_len: int):
        super().__init__()
        # half-truncate RoPE by @YouJiacheng (w/ base freq tuning)
        angular_freq = (1 / 1024) ** torch.linspace(0, 1, steps=dim//4, dtype=torch.float32)
        angular_freq = torch.cat([angular_freq, angular_freq.new_zeros(dim//4)])
        t = torch.arange(max_seq_len, dtype=torch.float32)
        theta = torch.einsum("i,j -> ij", t, angular_freq)
        self.cos = nn.Buffer(theta.cos(), persistent=False)
        self.sin = nn.Buffer(theta.sin(), persistent=False)

    def forward(self, x_BTHD: Tensor):
        assert self.cos.size(0) >= x_BTHD.size(-3)
        cos, sin = self.cos[None, :x_BTHD.size(-3), None, :], self.sin[None, :x_BTHD.size(-3), None, :]
        x1, x2 = x_BTHD.to(dtype=torch.float32).chunk(2, dim=-1)
        y1 = x1 * cos + x2 * sin
        y2 = x1 * (-sin) + x2 * cos
        return torch.cat((y1, y2), 3).type_as(x_BTHD)

class CausalSelfAttention(nn.Module):
    def __init__(self, dim: int, num_heads: int, max_seq_len: int, head_dim=128):
        super().__init__()
        self.num_heads = num_heads
        self.head_dim = head_dim
        hdim = num_heads * head_dim
        std = 0.5 * (dim ** -0.5)
        bound = (3 ** 0.5) * std # improved init scale by @YouJiacheng
        # merged QKV weights: suggested by many, implemented by @fernbear.bsky.social, and further improved by @YouJiacheng
        # https://x.com/hi_tysam/status/1879699187107033311
        self.qkv_w = nn.Parameter(torch.empty(3, hdim, dim).uniform_(-bound, bound))
        self.lambdas = nn.Parameter(torch.tensor([0.5, 0.5]))
        self.rotary = Rotary(head_dim, max_seq_len)
        self.c_proj = CastedLinear(hdim, dim)
        self.c_proj.weight.detach().zero_() # zero init suggested by @Grad62304977

    def forward(self, x: Tensor, ve: Tensor | None, block_mask: BlockMask):
        B, T = x.size(0), x.size(1) # batch size, sequence length
        assert B == 1, "Must use batch size = 1 for FlexAttention"
        q, k, v = F.linear(x, self.qkv_w.flatten(end_dim=1).type_as(x)).view(B, T, 3 * self.num_heads, self.head_dim).chunk(3, dim=-2)
        q, k = norm(q), norm(k) # QK norm @Grad62304977
        q, k = self.rotary(q), self.rotary(k)
        if ve is not None:
            v = self.lambdas[0] * v + self.lambdas[1] * ve.view_as(v) # @KoszarskyB & @Grad62304977
        else: # skip mid-layers token value embeddings by @YouJiacheng
            v = self.lambdas[0] * v
        # scale the attention logits by given constant, instead of the default head_dim**-0.5, by @leloykun
        # inspired by learnable scalars used by @brendanh0gan https://x.com/hi_tysam/status/1879693583898591283
        y = flex_attention(q.transpose(1, 2), k.transpose(1, 2), v.transpose(1, 2), block_mask=block_mask, scale=15/self.head_dim).transpose(1, 2)
        y = y.contiguous().view(B, T, self.num_heads * self.head_dim) # re-assemble all head outputs side by side
        y = self.c_proj(y)
        return y

class MLP(nn.Module):
    def __init__(self, dim: int):
        super().__init__()
        hdim = 4 * dim
        self.c_fc = CastedLinear(dim, hdim)
        self.c_proj = CastedLinear(hdim, dim)
        self.c_proj.weight.detach().zero_() # zero init suggested by @Grad62304977

    def forward(self, x: Tensor):
        x = self.c_fc(x)
        x = F.relu(x).square() # https://arxiv.org/abs/2109.08668v2; ~1-2% better than GELU; suggested by @SKYLINEZ007 and @Grad62304977
        x = self.c_proj(x)
        return x

class Block(nn.Module):
    def __init__(self, dim: int, num_heads: int, max_seq_len: int, layer_idx: int):
        super().__init__()
        # skip attention of blocks.7 (the 8th layer) by @YouJiacheng
        self.attn = CausalSelfAttention(dim, num_heads, max_seq_len) if layer_idx != 7 else None
        self.mlp = MLP(dim)
        self.lambdas = nn.Parameter(torch.tensor([1., 0.]))

    def forward(self, x: Tensor, ve: Tensor | None, x0: Tensor, block_mask: BlockMask):
        x = self.lambdas[0] * x + self.lambdas[1] * x0
        if self.attn is not None:
            x = x + self.attn(norm(x), ve, block_mask)
        x = x + self.mlp(norm(x))
        return x

# -----------------------------------------------------------------------------
# The main model

def next_multiple_of_n(v: float | int, *, n: int):
    return next(x for x in range(n, int(v) + 1 + n, n) if x >= v)

class GPT(nn.Module):
    def __init__(self, vocab_size: int, num_layers: int, num_heads: int, model_dim: int, max_seq_len: int):
        super().__init__()
        self.embed = nn.Embedding(vocab_size, model_dim)
        # token value embeddings by @KoszarskyB - inspired by @Grad62304977's value residual implementation following https://arxiv.org/abs/2410.17897
        # value embedding code simplification inspired by @ragulpr https://github.com/KellerJordan/modded-nanogpt/pull/78
        self.value_embeds = nn.ModuleList([nn.Embedding(vocab_size, model_dim) for _ in range(3)])
        self.blocks = nn.ModuleList([Block(model_dim, num_heads, max_seq_len, i) for i in range(num_layers)])
        # there are only 50257 unique GPT-2 tokens; we extend to nearest multiple of 128 for efficiency.
        # suggested to me by @Grad62304977. this originates from Karpathy's experiments.
        self.lm_head = CastedLinear(model_dim, next_multiple_of_n(vocab_size, n=128), use_fp8=True, x_s=(768**0.5)/448, w_s=2**-9, grad_s=1/448)
        self.lm_head.weight.detach().zero_() # @Grad62304977
        # Add learnable skip connection weights for decoder layers
        assert num_layers % 2 == 0
        self.skip_weights = nn.Parameter(torch.ones(num_layers//2))

    def create_blockmasks(self, input_seq: Tensor, sliding_window_num_blocks: Tensor):
        BLOCK_SIZE = 128
        docs = (input_seq == 50256).cumsum(0)

        def document_causal(b, h, q_idx, kv_idx):
            causal_mask = q_idx >= kv_idx
            document_mask = docs[q_idx] == docs[kv_idx]
            return causal_mask & document_mask

        def dense_to_ordered(dense_blockmask: Tensor):
            num_blocks = dense_blockmask.sum(dim=-1, dtype=torch.int32)
            indices = dense_blockmask.argsort(dim=-1, descending=False, stable=True).flip(-1).to(torch.int32)
            return num_blocks[None, None].contiguous(), indices[None, None].contiguous()

        # manual block mask creation by @YouJiacheng
        assert len(input_seq) % BLOCK_SIZE == 0
        NUM_BLOCKS = len(input_seq) // BLOCK_SIZE
        block_idx = torch.arange(NUM_BLOCKS, dtype=torch.int32, device="cuda")
        causal_blockmask_any = block_idx[:, None] >= block_idx
        causal_blockmask_all = block_idx[:, None] > block_idx
        docs_low = docs.view(-1, BLOCK_SIZE)[:, 0].contiguous()
        docs_high = docs.view(-1, BLOCK_SIZE)[:, -1].contiguous()
        document_blockmask_any = (docs_low[:, None] <= docs_high) & (docs_high[:, None] >= docs_low)
        document_blockmask_all = (docs_low[:, None] == docs_high) & (docs_high[:, None] == docs_low)
        blockmask_any = causal_blockmask_any & document_blockmask_any
        blockmask_all = causal_blockmask_all & document_blockmask_all
        partial_kv_num_blocks, partial_kv_indices = dense_to_ordered(blockmask_any & ~blockmask_all)
        full_kv_num_blocks, full_kv_indices = dense_to_ordered(blockmask_all)
        def build_bm(window_size_blocks: Tensor) -> BlockMask:
            return BlockMask.from_kv_blocks(
                torch.clamp_max(partial_kv_num_blocks, torch.clamp_min(window_size_blocks - full_kv_num_blocks, 1)),
                partial_kv_indices,
                torch.clamp_max(full_kv_num_blocks, window_size_blocks - 1),
                full_kv_indices,
                BLOCK_SIZE=BLOCK_SIZE,
                mask_mod=document_causal,
            )
        # Long-short SWA block masks by @leloykun & @YouJiacheng, adapated from suggestion by @Grad62304977, following Gemma 2 paper
        return build_bm(sliding_window_num_blocks), build_bm(sliding_window_num_blocks // 2)

    def forward(self, input_seq: Tensor, target_seq: Tensor, sliding_window_num_blocks: Tensor):
        assert input_seq.ndim == 1

        ve = [value_embed(input_seq) for value_embed in self.value_embeds]
        # 012 ... 012 structure on token value embeddings by @YouJiacheng, improved on @leloykun's U-net structure
        ve = [ve[0], ve[1], ve[2]] + [None] * (len(self.blocks) - 6) + [ve[0], ve[1], ve[2]]
        assert len(ve) == len(self.blocks)

        long_bm, short_bm = self.create_blockmasks(input_seq, sliding_window_num_blocks)
        block_masks = [long_bm, short_bm, short_bm, short_bm, long_bm, short_bm, short_bm, long_bm, short_bm, short_bm, short_bm, long_bm]
        assert len(block_masks) == len(self.blocks)

        x = x0 = norm(self.embed(input_seq)[None]) # use of norm here by @Grad62304977

        # U-net design by @brendanh0gan
        skip_connections = []
        n = len(self.skip_weights)
        for i in range(len(self.blocks)):
            if i >= n:
                x = x + self.skip_weights[i - n] * skip_connections.pop()
            x = self.blocks[i](x, ve[i], x0, block_masks[i])
            if i < n:
                skip_connections.append(x)

        x = norm(x)
        logits = self.lm_head(x).float()
        # @Grad62304977 added tanh softcapping following Gemma 2 paper, @KoszarskyB reduced it from 30 to 15, @YouJiacheng shifted it by +15 (2*sigmoid(2*x)=tanh(x)+1)
        logits = 30 * torch.sigmoid(logits / 7.5)
        loss = F.cross_entropy(logits.view(-1, logits.size(-1)), target_seq, reduction='sum' if self.training else 'mean')
        return loss

# -----------------------------------------------------------------------------
# Our own simple Distributed Data Loader

def _load_data_shard(file: Path):
    header = torch.from_file(str(file), False, 256, dtype=torch.int32) # header is 256 int32
    assert header[0] == 20240520, "magic number mismatch in the data .bin file"
    assert header[1] == 1, "unsupported version"
    num_tokens = int(header[2]) # number of tokens (claimed)
    with file.open("rb", buffering=0) as f:
        tokens = torch.empty(num_tokens, dtype=torch.uint16, pin_memory=True) # avoid pin_memory copy by @YouJiacheng
        f.seek(256 * 4)
        nbytes = f.readinto(tokens.numpy()) # avoid bytes->array copy by @YouJiacheng
        assert nbytes == 2 * num_tokens, "number of tokens read does not match header"
    return tokens

def distributed_data_generator(filename_pattern: str, batch_size: int, rank : int, world_size : int):
    files = [Path(file) for file in sorted(glob.glob(filename_pattern))]
    assert batch_size % world_size == 0
    local_batch_size = batch_size // world_size
    file_iter = iter(files) # use itertools.cycle(files) instead if you want to do multi-epoch training
    tokens, pos = _load_data_shard(next(file_iter)), 0
    while True:
        if pos + batch_size + 1 >= len(tokens):
            tokens, pos = _load_data_shard(next(file_iter)), 0
        buf = tokens[pos + rank * local_batch_size:][:local_batch_size + 1]
        inputs = buf[:-1].to(device="cuda", dtype=torch.int32, non_blocking=True) # no sync on host side;
        targets = buf[1:].to(device="cuda", dtype=torch.int64, non_blocking=True) # H2D in another stream isn't helpful.
        pos += batch_size
        yield inputs, targets

# -----------------------------------------------------------------------------
# int main

@dataclass
class Hyperparameters:
    # data
    train_files = "data/fineweb10B/fineweb_train_*.bin" # input .bin to train on
    val_files = "data/fineweb10B/fineweb_val_*.bin" # input .bin to eval validation loss on
    val_tokens = 10485760 # how many tokens of validation data? it's important to keep this fixed for consistent comparisons
    train_seq_len = 48*1024 # FlexAttention sequence length
    val_seq_len = 4*64*1024 # FlexAttention sequence length for validation
    # optimization
    num_iterations = 1770 # number of iterations to run
    cooldown_frac = 0.4 # fraction of training spent cooling down the learning rate
    # architecture
    vocab_size = 50257
    # evaluation and logging
    val_loss_every = 125 # every how many steps to evaluate val loss? 0 for only at the end
    save_checkpoint = False
args = Hyperparameters()

# torchrun sets these env variables
rank = int(os.environ["RANK"])
world_size = int(os.environ["WORLD_SIZE"])
assert world_size == 8 # this code is designed for 8xH100
assert torch.cuda.is_available()
device = torch.device("cuda", int(os.environ["LOCAL_RANK"]))
torch.cuda.set_device(device)
dist.init_process_group(backend="nccl", device_id=device)
dist.barrier()
master_process = (rank == 0) # this process will do logging, checkpointing etc.

# begin logging
logfile = None
if master_process:
    run_id = uuid.uuid4()
    os.makedirs("logs", exist_ok=True)
    logfile = f"logs/{run_id}.txt"
    print(logfile)
def print0(s, console=False):
    if master_process:
        with open(logfile, "a") as f:
            if console:
                print(s)
            print(s, file=f)

# begin by printing this file (the Python code)
print0(code)
print0("="*100)
# log information about the hardware/software environment this is running on
print0(f"Running Python {sys.version}")
print0(f"Running PyTorch {torch.version.__version__} compiled for CUDA {torch.version.cuda}")
def nvidia_smi():
    import subprocess  # avoid top level import
    return subprocess.run(["nvidia-smi"], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True).stdout
print0(nvidia_smi())
print0("="*100)

########################################
#    Construct model and optimizer     #
########################################

model: nn.Module = GPT(vocab_size=args.vocab_size, num_layers=12, num_heads=6, model_dim=768,
                       max_seq_len=max(args.train_seq_len, args.val_seq_len)).cuda()
for m in model.modules():
    if isinstance(m, nn.Embedding):
        m.bfloat16()
for param in model.parameters():
    dist.broadcast(param.detach(), 0)

# collect the parameters to optimize
hidden_matrix_params = [p for n, p in model.blocks.named_parameters() if p.ndim >= 2 and "embed" not in n]
embed_params = [p for n, p in model.named_parameters() if "embed" in n]
scalar_params = [p for p in model.parameters() if p.ndim < 2]
head_params = [model.lm_head.weight]

# init the optimizer(s)
adam_params = [dict(params=head_params, lr=0.22/768**0.5), dict(params=embed_params, lr=0.6), dict(params=scalar_params, lr=0.04)]
# small adam epsilon by @YouJiacheng. this is an alternate method of fixing the world_size dependence
# discovered by @fernbear.bsky.social https://x.com/hi_tysam/status/1879692937589875094
optimizer1 = torch.optim.Adam(adam_params, betas=(0.8, 0.95), eps=1e-10, fused=True)
optimizer2 = Muon(hidden_matrix_params, lr=0.05, momentum=0.95, rank=rank, world_size=world_size)
optimizers = [optimizer1, optimizer2]
for opt in optimizers:
    for group in opt.param_groups:
        group["initial_lr"] = group["lr"]

# learning rate schedule: stable then decay
def get_lr(step: int):
    x = step / args.num_iterations # progress in training
    assert 0 <= x < 1
    if x < 1 - args.cooldown_frac:
        return 1.0
    else:
        w = (1 - x) / args.cooldown_frac
        return w * 1.0 + (1 - w) * 0.1

# attention window size schedule: linearly increase
@lru_cache(1)
def get_window_size_blocks_helper(window_size: int):
    return torch.tensor(window_size // 128, dtype=torch.int32, pin_memory=True).cuda(non_blocking=True)
def get_window_size_blocks(step: int):
    x = step / args.num_iterations # progress in training
    assert 0 <= x <= 1
    # Linearly increase the block-wise sliding window size over training 128 -> 1792
    # increase by @fernbear.bsky.social; block-wise by @YouJiacheng
    window_size = next_multiple_of_n(1728 * x, n=128)
    return get_window_size_blocks_helper(window_size)

model: nn.Module = torch.compile(model, dynamic=False)

########################################
#            Warmup kernels            #
########################################

# Warmup the training kernels, then re-initialize the state so we aren't cheating
warmup_steps = 10
initial_state = dict(model=copy.deepcopy(model.state_dict()),
                     optimizers=[copy.deepcopy(opt.state_dict()) for opt in optimizers]) # save the initial state
for _ in range(warmup_steps):
    inputs = targets = torch.randint(0, args.vocab_size, size=(args.train_seq_len,), device="cuda")
    model(inputs.to(torch.int32), targets, get_window_size_blocks(0)).backward()
    for param in model.parameters():
        dist.all_reduce(param.grad, op=dist.ReduceOp.AVG)
    for opt in optimizers:
        opt.step()
    model.zero_grad(set_to_none=True)
model.load_state_dict(initial_state["model"])
for opt, opt_state in zip(optimizers, initial_state["optimizers"]):
    opt.load_state_dict(opt_state)
del initial_state

########################################
#        Training and validation       #
########################################

train_loader = distributed_data_generator(args.train_files, world_size * args.train_seq_len, rank, world_size)
training_time_ms = 0
# start the clock
torch.cuda.synchronize()
t0 = time.perf_counter()
# begin training
train_steps = args.num_iterations
for step in range(train_steps + 1):
    last_step = (step == train_steps)

    # --------------- VALIDATION SECTION -----------------
    if last_step or (args.val_loss_every > 0 and step % args.val_loss_every == 0):
        # stop the clock
        torch.cuda.synchronize()
        training_time_ms += 1000 * (time.perf_counter() - t0)
        model.eval()
        val_batch_size = world_size * args.val_seq_len
        assert args.val_tokens % val_batch_size == 0
        val_steps = args.val_tokens // val_batch_size
        val_loader = distributed_data_generator(args.val_files, val_batch_size, rank, world_size)
        val_loss = 0
        with torch.no_grad():
            for _ in range(val_steps):
                inputs, targets = next(val_loader)
                val_loss += model(inputs, targets, get_window_size_blocks(step))
        val_loss /= val_steps
        del val_loader
        dist.all_reduce(val_loss, op=dist.ReduceOp.AVG)
        print0(f"step:{step}/{train_steps} val_loss:{val_loss:.4f} train_time:{training_time_ms:.0f}ms step_avg:{training_time_ms/max(step, 1):.2f}ms", console=True)
        model.train()
        # start the clock again
        torch.cuda.synchronize()
        t0 = time.perf_counter()

    if last_step:
        if master_process and args.save_checkpoint:
            log = dict(step=step, code=code, model=model.state_dict(), optimizers=[opt.state_dict() for opt in optimizers])
            os.makedirs(f"logs/{run_id}", exist_ok=True)
            torch.save(log, f"logs/{run_id}/state_step{step:06d}.pt")
        # the last step only has the validation loop, so break to avoid training
        break

    # --------------- TRAINING SECTION -----------------
    inputs, targets = next(train_loader)
    model(inputs, targets, get_window_size_blocks(step)).backward()
    for param in model.parameters():
        dist.all_reduce(param.grad, op=dist.ReduceOp.AVG)
    # set optimization hyperparameters
    for opt in optimizers:
        for group in opt.param_groups:
            group["lr"] = group["initial_lr"] * get_lr(step)
    for group in optimizer2.param_groups:
        frac = min(step / 300, 1) # momentum warmup for muon
        group["momentum"] = (1 - frac) * 0.85 + frac * 0.95
    # step the optimizers
    for opt in optimizers:
        opt.step()
    # null the gradients
    model.zero_grad(set_to_none=True)
    # logging
    approx_training_time_ms = training_time_ms + 1000 * (time.perf_counter() - t0)
    print0(f"step:{step+1}/{train_steps} train_time:{approx_training_time_ms:.0f}ms step_avg:{approx_training_time_ms/(step + 1):.2f}ms", console=True)

print0(f"peak memory allocated: {torch.cuda.max_memory_allocated() // 1024 // 1024} MiB "
       f"reserved: {torch.cuda.max_memory_reserved() // 1024 // 1024} MiB", console=True)
dist.destroy_process_group()

====================================================================================================
Running Python 3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]
Running PyTorch 2.7.0.dev20250125+cu126 compiled for CUDA 12.6
Sun Feb 16 06:56:04 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA H100 80GB HBM3          On  |   00000000:19:00.0 Off |                    0 |
| N/A   34C    P0            113W /  700W |    7714MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA H100 80GB HBM3          On  |   00000000:3B:00.0 Off |                    0 |
| N/A   28C    P0            109W /  700W |    3452MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA H100 80GB HBM3          On  |   00000000:4C:00.0 Off |                    0 |
| N/A   27C    P0            110W /  700W |    3452MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA H100 80GB HBM3          On  |   00000000:5D:00.0 Off |                    0 |
| N/A   33C    P0            115W /  700W |    3452MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   4  NVIDIA H100 80GB HBM3          On  |   00000000:9B:00.0 Off |                    0 |
| N/A   33C    P0            114W /  700W |    3452MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   5  NVIDIA H100 80GB HBM3          On  |   00000000:BB:00.0 Off |                    0 |
| N/A   28C    P0            109W /  700W |    3452MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   6  NVIDIA H100 80GB HBM3          On  |   00000000:CB:00.0 Off |                    0 |
| N/A   34C    P0            114W /  700W |    3452MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   7  NVIDIA H100 80GB HBM3          On  |   00000000:DB:00.0 Off |                    0 |
| N/A   27C    P0            111W /  700W |    3212MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
+-----------------------------------------------------------------------------------------+

====================================================================================================
step:0/1770 val_loss:10.8258 train_time:0ms step_avg:0.02ms
step:1/1770 train_time:60ms step_avg:59.64ms
step:2/1770 train_time:135ms step_avg:67.35ms
step:3/1770 train_time:227ms step_avg:75.71ms
step:4/1770 train_time:323ms step_avg:80.73ms
step:5/1770 train_time:419ms step_avg:83.73ms
step:6/1770 train_time:515ms step_avg:85.76ms
step:7/1770 train_time:611ms step_avg:87.25ms
step:8/1770 train_time:707ms step_avg:88.35ms
step:9/1770 train_time:802ms step_avg:89.15ms
step:10/1770 train_time:899ms step_avg:89.85ms
step:11/1770 train_time:995ms step_avg:90.45ms
step:12/1770 train_time:1091ms step_avg:90.88ms
step:13/1770 train_time:1187ms step_avg:91.33ms
step:14/1770 train_time:1284ms step_avg:91.69ms
step:15/1770 train_time:1380ms step_avg:91.98ms
step:16/1770 train_time:1476ms step_avg:92.24ms
step:17/1770 train_time:1572ms step_avg:92.47ms
step:18/1770 train_time:1669ms step_avg:92.70ms
step:19/1770 train_time:1765ms step_avg:92.88ms
step:20/1770 train_time:1861ms step_avg:93.04ms
step:21/1770 train_time:1957ms step_avg:93.20ms
step:22/1770 train_time:2053ms step_avg:93.32ms
step:23/1770 train_time:2149ms step_avg:93.45ms
step:24/1770 train_time:2246ms step_avg:93.57ms
step:25/1770 train_time:2342ms step_avg:93.66ms
step:26/1770 train_time:2438ms step_avg:93.77ms
step:27/1770 train_time:2534ms step_avg:93.85ms
step:28/1770 train_time:2631ms step_avg:93.95ms
step:29/1770 train_time:2727ms step_avg:94.02ms
step:30/1770 train_time:2823ms step_avg:94.11ms
step:31/1770 train_time:2919ms step_avg:94.18ms
step:32/1770 train_time:3015ms step_avg:94.23ms
step:33/1770 train_time:3113ms step_avg:94.33ms
step:34/1770 train_time:3208ms step_avg:94.35ms
step:35/1770 train_time:3304ms step_avg:94.41ms
step:36/1770 train_time:3401ms step_avg:94.46ms
step:37/1770 train_time:3496ms step_avg:94.50ms
step:38/1770 train_time:3592ms step_avg:94.53ms
step:39/1770 train_time:3688ms step_avg:94.57ms
step:40/1770 train_time:3785ms step_avg:94.62ms
step:41/1770 train_time:3881ms step_avg:94.66ms
step:42/1770 train_time:3977ms step_avg:94.69ms
step:43/1770 train_time:4074ms step_avg:94.74ms
step:44/1770 train_time:4170ms step_avg:94.76ms
step:45/1770 train_time:4266ms step_avg:94.79ms
step:46/1770 train_time:4363ms step_avg:94.84ms
step:47/1770 train_time:4459ms step_avg:94.86ms
step:48/1770 train_time:4554ms step_avg:94.88ms
step:49/1770 train_time:4650ms step_avg:94.91ms
step:50/1770 train_time:4747ms step_avg:94.93ms
step:51/1770 train_time:4842ms step_avg:94.94ms
step:52/1770 train_time:4938ms step_avg:94.97ms
step:53/1770 train_time:5034ms step_avg:94.98ms
step:54/1770 train_time:5131ms step_avg:95.02ms
step:55/1770 train_time:5227ms step_avg:95.04ms
step:56/1770 train_time:5323ms step_avg:95.06ms
step:57/1770 train_time:5419ms step_avg:95.07ms
step:58/1770 train_time:5515ms step_avg:95.09ms
step:59/1770 train_time:5611ms step_avg:95.10ms
step:60/1770 train_time:5707ms step_avg:95.12ms
step:61/1770 train_time:5803ms step_avg:95.14ms
step:62/1770 train_time:5899ms step_avg:95.15ms
step:63/1770 train_time:5995ms step_avg:95.16ms
step:64/1770 train_time:6091ms step_avg:95.16ms
step:65/1770 train_time:6186ms step_avg:95.17ms
step:66/1770 train_time:6282ms step_avg:95.19ms
step:67/1770 train_time:6378ms step_avg:95.20ms
step:68/1770 train_time:6475ms step_avg:95.21ms
step:69/1770 train_time:6571ms step_avg:95.23ms
step:70/1770 train_time:6667ms step_avg:95.25ms
step:71/1770 train_time:6764ms step_avg:95.26ms
step:72/1770 train_time:6860ms step_avg:95.28ms
step:73/1770 train_time:6956ms step_avg:95.29ms
step:74/1770 train_time:7052ms step_avg:95.30ms
step:75/1770 train_time:7148ms step_avg:95.31ms
step:76/1770 train_time:7245ms step_avg:95.32ms
step:77/1770 train_time:7341ms step_avg:95.34ms
step:78/1770 train_time:7437ms step_avg:95.35ms
step:79/1770 train_time:7533ms step_avg:95.36ms
step:80/1770 train_time:7629ms step_avg:95.37ms
step:81/1770 train_time:7726ms step_avg:95.38ms
step:82/1770 train_time:7822ms step_avg:95.39ms
step:83/1770 train_time:7918ms step_avg:95.40ms
step:84/1770 train_time:8014ms step_avg:95.41ms
step:85/1770 train_time:8110ms step_avg:95.41ms
step:86/1770 train_time:8206ms step_avg:95.42ms
step:87/1770 train_time:8303ms step_avg:95.44ms
step:88/1770 train_time:8399ms step_avg:95.44ms
step:89/1770 train_time:8495ms step_avg:95.45ms
step:90/1770 train_time:8591ms step_avg:95.45ms
step:91/1770 train_time:8687ms step_avg:95.46ms
step:92/1770 train_time:8783ms step_avg:95.47ms
step:93/1770 train_time:8879ms step_avg:95.48ms
step:94/1770 train_time:8975ms step_avg:95.48ms
step:95/1770 train_time:9071ms step_avg:95.48ms
step:96/1770 train_time:9167ms step_avg:95.49ms
step:97/1770 train_time:9263ms step_avg:95.50ms
step:98/1770 train_time:9359ms step_avg:95.50ms
step:99/1770 train_time:9455ms step_avg:95.50ms
step:100/1770 train_time:9550ms step_avg:95.50ms
step:101/1770 train_time:9647ms step_avg:95.51ms
step:102/1770 train_time:9744ms step_avg:95.53ms
step:103/1770 train_time:9838ms step_avg:95.52ms
step:104/1770 train_time:9935ms step_avg:95.53ms
step:105/1770 train_time:10031ms step_avg:95.53ms
step:106/1770 train_time:10127ms step_avg:95.54ms
step:107/1770 train_time:10223ms step_avg:95.55ms
step:108/1770 train_time:10319ms step_avg:95.55ms
step:109/1770 train_time:10415ms step_avg:95.55ms
step:110/1770 train_time:10511ms step_avg:95.56ms
step:111/1770 train_time:10607ms step_avg:95.56ms
step:112/1770 train_time:10704ms step_avg:95.57ms
step:113/1770 train_time:10800ms step_avg:95.58ms
step:114/1770 train_time:10896ms step_avg:95.58ms
step:115/1770 train_time:10991ms step_avg:95.58ms
step:116/1770 train_time:11088ms step_avg:95.58ms
step:117/1770 train_time:11184ms step_avg:95.59ms
step:118/1770 train_time:11280ms step_avg:95.59ms
step:119/1770 train_time:11376ms step_avg:95.60ms
step:120/1770 train_time:11472ms step_avg:95.60ms
step:121/1770 train_time:11568ms step_avg:95.60ms
step:122/1770 train_time:11664ms step_avg:95.61ms
step:123/1770 train_time:11760ms step_avg:95.61ms
step:124/1770 train_time:11856ms step_avg:95.61ms
step:125/1770 train_time:11952ms step_avg:95.62ms
step:125/1770 val_loss:4.6303 train_time:12042ms step_avg:96.34ms
step:126/1770 train_time:12064ms step_avg:95.75ms
step:127/1770 train_time:12153ms step_avg:95.69ms
step:128/1770 train_time:12257ms step_avg:95.76ms
step:129/1770 train_time:12354ms step_avg:95.77ms
step:130/1770 train_time:12451ms step_avg:95.78ms
step:131/1770 train_time:12546ms step_avg:95.77ms
step:132/1770 train_time:12641ms step_avg:95.77ms
step:133/1770 train_time:12737ms step_avg:95.77ms
step:134/1770 train_time:12834ms step_avg:95.78ms
step:135/1770 train_time:12931ms step_avg:95.78ms
step:136/1770 train_time:13027ms step_avg:95.79ms
step:137/1770 train_time:13123ms step_avg:95.79ms
step:138/1770 train_time:13220ms step_avg:95.79ms
step:139/1770 train_time:13316ms step_avg:95.80ms
step:140/1770 train_time:13413ms step_avg:95.81ms
step:141/1770 train_time:13510ms step_avg:95.81ms
step:142/1770 train_time:13606ms step_avg:95.82ms
step:143/1770 train_time:13703ms step_avg:95.82ms
step:144/1770 train_time:13799ms step_avg:95.83ms
step:145/1770 train_time:13896ms step_avg:95.83ms
step:146/1770 train_time:13993ms step_avg:95.84ms
step:147/1770 train_time:14089ms step_avg:95.85ms
step:148/1770 train_time:14186ms step_avg:95.85ms
step:149/1770 train_time:14283ms step_avg:95.86ms
step:150/1770 train_time:14379ms step_avg:95.86ms
step:151/1770 train_time:14476ms step_avg:95.87ms
step:152/1770 train_time:14573ms step_avg:95.88ms
step:153/1770 train_time:14670ms step_avg:95.88ms
step:154/1770 train_time:14769ms step_avg:95.90ms
step:155/1770 train_time:14866ms step_avg:95.91ms
step:156/1770 train_time:14962ms step_avg:95.91ms
step:157/1770 train_time:15059ms step_avg:95.91ms
step:158/1770 train_time:15155ms step_avg:95.92ms
step:159/1770 train_time:15252ms step_avg:95.92ms
step:160/1770 train_time:15348ms step_avg:95.93ms
step:161/1770 train_time:15445ms step_avg:95.93ms
step:162/1770 train_time:15541ms step_avg:95.93ms
step:163/1770 train_time:15638ms step_avg:95.94ms
step:164/1770 train_time:15735ms step_avg:95.94ms
step:165/1770 train_time:15831ms step_avg:95.95ms
step:166/1770 train_time:15928ms step_avg:95.95ms
step:167/1770 train_time:16025ms step_avg:95.96ms
step:168/1770 train_time:16122ms step_avg:95.96ms
step:169/1770 train_time:16218ms step_avg:95.96ms
step:170/1770 train_time:16315ms step_avg:95.97ms
step:171/1770 train_time:16411ms step_avg:95.97ms
step:172/1770 train_time:16508ms step_avg:95.98ms
step:173/1770 train_time:16605ms step_avg:95.98ms
step:174/1770 train_time:16702ms step_avg:95.99ms
step:175/1770 train_time:16799ms step_avg:95.99ms
step:176/1770 train_time:16895ms step_avg:95.99ms
step:177/1770 train_time:16992ms step_avg:96.00ms
step:178/1770 train_time:17090ms step_avg:96.01ms
step:179/1770 train_time:17188ms step_avg:96.02ms
step:180/1770 train_time:17284ms step_avg:96.02ms
step:181/1770 train_time:17381ms step_avg:96.03ms
step:182/1770 train_time:17477ms step_avg:96.03ms
step:183/1770 train_time:17574ms step_avg:96.03ms
step:184/1770 train_time:17671ms step_avg:96.04ms
step:185/1770 train_time:17769ms step_avg:96.05ms
step:186/1770 train_time:17865ms step_avg:96.05ms
step:187/1770 train_time:17962ms step_avg:96.05ms
step:188/1770 train_time:18058ms step_avg:96.05ms
step:189/1770 train_time:18155ms step_avg:96.06ms
step:190/1770 train_time:18252ms step_avg:96.06ms
step:191/1770 train_time:18349ms step_avg:96.07ms
step:192/1770 train_time:18445ms step_avg:96.07ms
step:193/1770 train_time:18542ms step_avg:96.07ms
step:194/1770 train_time:18638ms step_avg:96.07ms
step:195/1770 train_time:18735ms step_avg:96.08ms
step:196/1770 train_time:18832ms step_avg:96.08ms
step:197/1770 train_time:18928ms step_avg:96.08ms
step:198/1770 train_time:19025ms step_avg:96.09ms
step:199/1770 train_time:19122ms step_avg:96.09ms
step:200/1770 train_time:19218ms step_avg:96.09ms
step:201/1770 train_time:19315ms step_avg:96.10ms
step:202/1770 train_time:19412ms step_avg:96.10ms
step:203/1770 train_time:19509ms step_avg:96.10ms
step:204/1770 train_time:19605ms step_avg:96.10ms
step:205/1770 train_time:19702ms step_avg:96.11ms
step:206/1770 train_time:19798ms step_avg:96.11ms
step:207/1770 train_time:19895ms step_avg:96.11ms
step:208/1770 train_time:19993ms step_avg:96.12ms
step:209/1770 train_time:20089ms step_avg:96.12ms
step:210/1770 train_time:20187ms step_avg:96.13ms
step:211/1770 train_time:20283ms step_avg:96.13ms
step:212/1770 train_time:20379ms step_avg:96.13ms
step:213/1770 train_time:20476ms step_avg:96.13ms
step:214/1770 train_time:20574ms step_avg:96.14ms
step:215/1770 train_time:20671ms step_avg:96.14ms
step:216/1770 train_time:20768ms step_avg:96.15ms
step:217/1770 train_time:20864ms step_avg:96.15ms
step:218/1770 train_time:20960ms step_avg:96.15ms
step:219/1770 train_time:21057ms step_avg:96.15ms
step:220/1770 train_time:21154ms step_avg:96.15ms
step:221/1770 train_time:21250ms step_avg:96.16ms
step:222/1770 train_time:21347ms step_avg:96.16ms
step:223/1770 train_time:21445ms step_avg:96.16ms
step:224/1770 train_time:21541ms step_avg:96.17ms
step:225/1770 train_time:21638ms step_avg:96.17ms
step:226/1770 train_time:21735ms step_avg:96.17ms
step:227/1770 train_time:21832ms step_avg:96.18ms
step:228/1770 train_time:21929ms step_avg:96.18ms
step:229/1770 train_time:22027ms step_avg:96.19ms
step:230/1770 train_time:22123ms step_avg:96.19ms
step:231/1770 train_time:22219ms step_avg:96.19ms
step:232/1770 train_time:22316ms step_avg:96.19ms
step:233/1770 train_time:22413ms step_avg:96.19ms
step:234/1770 train_time:22510ms step_avg:96.20ms
step:235/1770 train_time:22607ms step_avg:96.20ms
step:236/1770 train_time:22704ms step_avg:96.20ms
step:237/1770 train_time:22800ms step_avg:96.20ms
step:238/1770 train_time:22897ms step_avg:96.20ms
step:239/1770 train_time:22994ms step_avg:96.21ms
step:240/1770 train_time:23090ms step_avg:96.21ms
step:241/1770 train_time:23188ms step_avg:96.21ms
step:242/1770 train_time:23609ms step_avg:97.56ms
step:243/1770 train_time:23696ms step_avg:97.52ms
step:244/1770 train_time:23792ms step_avg:97.51ms
step:245/1770 train_time:23889ms step_avg:97.51ms
step:246/1770 train_time:23985ms step_avg:97.50ms
step:247/1770 train_time:24082ms step_avg:97.50ms
step:248/1770 train_time:24178ms step_avg:97.49ms
step:249/1770 train_time:24275ms step_avg:97.49ms
step:250/1770 train_time:24372ms step_avg:97.49ms
step:250/1770 val_loss:4.0952 train_time:24463ms step_avg:97.85ms
step:251/1770 train_time:24483ms step_avg:97.54ms
step:252/1770 train_time:24572ms step_avg:97.51ms
step:253/1770 train_time:24671ms step_avg:97.52ms
step:254/1770 train_time:24768ms step_avg:97.51ms
step:255/1770 train_time:24865ms step_avg:97.51ms
step:256/1770 train_time:24961ms step_avg:97.51ms
step:257/1770 train_time:25057ms step_avg:97.50ms
step:258/1770 train_time:25153ms step_avg:97.49ms
step:259/1770 train_time:25249ms step_avg:97.49ms
step:260/1770 train_time:25346ms step_avg:97.48ms
step:261/1770 train_time:25444ms step_avg:97.49ms
step:262/1770 train_time:25541ms step_avg:97.48ms
step:263/1770 train_time:25639ms step_avg:97.49ms
step:264/1770 train_time:25736ms step_avg:97.49ms
step:265/1770 train_time:25833ms step_avg:97.48ms
step:266/1770 train_time:25931ms step_avg:97.48ms
step:267/1770 train_time:26028ms step_avg:97.48ms
step:268/1770 train_time:26125ms step_avg:97.48ms
step:269/1770 train_time:26223ms step_avg:97.48ms
step:270/1770 train_time:26320ms step_avg:97.48ms
step:271/1770 train_time:26417ms step_avg:97.48ms
step:272/1770 train_time:26514ms step_avg:97.48ms
step:273/1770 train_time:26611ms step_avg:97.48ms
step:274/1770 train_time:26708ms step_avg:97.47ms
step:275/1770 train_time:26805ms step_avg:97.47ms
step:276/1770 train_time:26903ms step_avg:97.47ms
step:277/1770 train_time:27001ms step_avg:97.48ms
step:278/1770 train_time:27099ms step_avg:97.48ms
step:279/1770 train_time:27198ms step_avg:97.48ms
step:280/1770 train_time:27295ms step_avg:97.48ms
step:281/1770 train_time:27392ms step_avg:97.48ms
step:282/1770 train_time:27488ms step_avg:97.48ms
step:283/1770 train_time:27585ms step_avg:97.47ms
step:284/1770 train_time:27682ms step_avg:97.47ms
step:285/1770 train_time:27780ms step_avg:97.47ms
step:286/1770 train_time:27878ms step_avg:97.48ms
step:287/1770 train_time:27976ms step_avg:97.48ms
step:288/1770 train_time:28073ms step_avg:97.47ms
step:289/1770 train_time:28169ms step_avg:97.47ms
step:290/1770 train_time:28266ms step_avg:97.47ms
step:291/1770 train_time:28364ms step_avg:97.47ms
step:292/1770 train_time:28462ms step_avg:97.47ms
step:293/1770 train_time:28559ms step_avg:97.47ms
step:294/1770 train_time:28656ms step_avg:97.47ms
step:295/1770 train_time:28753ms step_avg:97.47ms
step:296/1770 train_time:28849ms step_avg:97.46ms
step:297/1770 train_time:28946ms step_avg:97.46ms
step:298/1770 train_time:29044ms step_avg:97.46ms
step:299/1770 train_time:29141ms step_avg:97.46ms
step:300/1770 train_time:29239ms step_avg:97.46ms
step:301/1770 train_time:29337ms step_avg:97.46ms
step:302/1770 train_time:29435ms step_avg:97.47ms
step:303/1770 train_time:29532ms step_avg:97.47ms
step:304/1770 train_time:29629ms step_avg:97.46ms
step:305/1770 train_time:29726ms step_avg:97.46ms
step:306/1770 train_time:29823ms step_avg:97.46ms
step:307/1770 train_time:29920ms step_avg:97.46ms
step:308/1770 train_time:30018ms step_avg:97.46ms
step:309/1770 train_time:30114ms step_avg:97.46ms
step:310/1770 train_time:30211ms step_avg:97.46ms
step:311/1770 train_time:30309ms step_avg:97.46ms
step:312/1770 train_time:30406ms step_avg:97.46ms
step:313/1770 train_time:30505ms step_avg:97.46ms
step:314/1770 train_time:30602ms step_avg:97.46ms
step:315/1770 train_time:30700ms step_avg:97.46ms
step:316/1770 train_time:30798ms step_avg:97.46ms
step:317/1770 train_time:30895ms step_avg:97.46ms
step:318/1770 train_time:30993ms step_avg:97.46ms
step:319/1770 train_time:31089ms step_avg:97.46ms
step:320/1770 train_time:31186ms step_avg:97.46ms
step:321/1770 train_time:31284ms step_avg:97.46ms
step:322/1770 train_time:31381ms step_avg:97.46ms
step:323/1770 train_time:31478ms step_avg:97.45ms
step:324/1770 train_time:31575ms step_avg:97.45ms
step:325/1770 train_time:31672ms step_avg:97.45ms
step:326/1770 train_time:31770ms step_avg:97.45ms
step:327/1770 train_time:31866ms step_avg:97.45ms
step:328/1770 train_time:31964ms step_avg:97.45ms
step:329/1770 train_time:32061ms step_avg:97.45ms
step:330/1770 train_time:32159ms step_avg:97.45ms
step:331/1770 train_time:32256ms step_avg:97.45ms
step:332/1770 train_time:32352ms step_avg:97.45ms
step:333/1770 train_time:32449ms step_avg:97.44ms
step:334/1770 train_time:32546ms step_avg:97.44ms
step:335/1770 train_time:32644ms step_avg:97.44ms
step:336/1770 train_time:32741ms step_avg:97.44ms
step:337/1770 train_time:32840ms step_avg:97.45ms
step:338/1770 train_time:32938ms step_avg:97.45ms
step:339/1770 train_time:33036ms step_avg:97.45ms
step:340/1770 train_time:33132ms step_avg:97.45ms
step:341/1770 train_time:33229ms step_avg:97.45ms
step:342/1770 train_time:33326ms step_avg:97.44ms
step:343/1770 train_time:33424ms step_avg:97.45ms
step:344/1770 train_time:33521ms step_avg:97.45ms
step:345/1770 train_time:33618ms step_avg:97.44ms
step:346/1770 train_time:33715ms step_avg:97.44ms
step:347/1770 train_time:33812ms step_avg:97.44ms
step:348/1770 train_time:33909ms step_avg:97.44ms
step:349/1770 train_time:34007ms step_avg:97.44ms
step:350/1770 train_time:34106ms step_avg:97.45ms
step:351/1770 train_time:34204ms step_avg:97.45ms
step:352/1770 train_time:34302ms step_avg:97.45ms
step:353/1770 train_time:34399ms step_avg:97.45ms
step:354/1770 train_time:34496ms step_avg:97.45ms
step:355/1770 train_time:34593ms step_avg:97.44ms
step:356/1770 train_time:34690ms step_avg:97.44ms
step:357/1770 train_time:34787ms step_avg:97.44ms
step:358/1770 train_time:34886ms step_avg:97.45ms
step:359/1770 train_time:34983ms step_avg:97.45ms
step:360/1770 train_time:35081ms step_avg:97.45ms
step:361/1770 train_time:35178ms step_avg:97.45ms
step:362/1770 train_time:35275ms step_avg:97.45ms
step:363/1770 train_time:35372ms step_avg:97.44ms
step:364/1770 train_time:35469ms step_avg:97.44ms
step:365/1770 train_time:35567ms step_avg:97.44ms
step:366/1770 train_time:35665ms step_avg:97.44ms
step:367/1770 train_time:35762ms step_avg:97.44ms
step:368/1770 train_time:35860ms step_avg:97.45ms
step:369/1770 train_time:35958ms step_avg:97.45ms
step:370/1770 train_time:36054ms step_avg:97.44ms
step:371/1770 train_time:36151ms step_avg:97.44ms
step:372/1770 train_time:36248ms step_avg:97.44ms
step:373/1770 train_time:36345ms step_avg:97.44ms
step:374/1770 train_time:36443ms step_avg:97.44ms
step:375/1770 train_time:36541ms step_avg:97.44ms
step:375/1770 val_loss:3.8915 train_time:36633ms step_avg:97.69ms
step:376/1770 train_time:36655ms step_avg:97.49ms
step:377/1770 train_time:36742ms step_avg:97.46ms
step:378/1770 train_time:36841ms step_avg:97.46ms
step:379/1770 train_time:36938ms step_avg:97.46ms
step:380/1770 train_time:37035ms step_avg:97.46ms
step:381/1770 train_time:37132ms step_avg:97.46ms
step:382/1770 train_time:37229ms step_avg:97.46ms
step:383/1770 train_time:37326ms step_avg:97.46ms
step:384/1770 train_time:37423ms step_avg:97.46ms
step:385/1770 train_time:37520ms step_avg:97.45ms
step:386/1770 train_time:37617ms step_avg:97.45ms
step:387/1770 train_time:37714ms step_avg:97.45ms
step:388/1770 train_time:37810ms step_avg:97.45ms
step:389/1770 train_time:37908ms step_avg:97.45ms
step:390/1770 train_time:38006ms step_avg:97.45ms
step:391/1770 train_time:38104ms step_avg:97.45ms
step:392/1770 train_time:38202ms step_avg:97.45ms
step:393/1770 train_time:38298ms step_avg:97.45ms
step:394/1770 train_time:38395ms step_avg:97.45ms
step:395/1770 train_time:38491ms step_avg:97.45ms
step:396/1770 train_time:38591ms step_avg:97.45ms
step:397/1770 train_time:38690ms step_avg:97.46ms
step:398/1770 train_time:38789ms step_avg:97.46ms
step:399/1770 train_time:38888ms step_avg:97.46ms
step:400/1770 train_time:38988ms step_avg:97.47ms
step:401/1770 train_time:39088ms step_avg:97.48ms
step:402/1770 train_time:39187ms step_avg:97.48ms
step:403/1770 train_time:39286ms step_avg:97.48ms
step:404/1770 train_time:39386ms step_avg:97.49ms
step:405/1770 train_time:39487ms step_avg:97.50ms
step:406/1770 train_time:39585ms step_avg:97.50ms
step:407/1770 train_time:39685ms step_avg:97.51ms
step:408/1770 train_time:39784ms step_avg:97.51ms
step:409/1770 train_time:39883ms step_avg:97.51ms
step:410/1770 train_time:39983ms step_avg:97.52ms
step:411/1770 train_time:40083ms step_avg:97.53ms
step:412/1770 train_time:40183ms step_avg:97.53ms
step:413/1770 train_time:40282ms step_avg:97.54ms
step:414/1770 train_time:40381ms step_avg:97.54ms
step:415/1770 train_time:40481ms step_avg:97.54ms
step:416/1770 train_time:40579ms step_avg:97.55ms
step:417/1770 train_time:40679ms step_avg:97.55ms
step:418/1770 train_time:40779ms step_avg:97.56ms
step:419/1770 train_time:40879ms step_avg:97.56ms
step:420/1770 train_time:40979ms step_avg:97.57ms
step:421/1770 train_time:41078ms step_avg:97.57ms
step:422/1770 train_time:41177ms step_avg:97.58ms
step:423/1770 train_time:41277ms step_avg:97.58ms
step:424/1770 train_time:41376ms step_avg:97.58ms
step:425/1770 train_time:41474ms step_avg:97.59ms
step:426/1770 train_time:41573ms step_avg:97.59ms
step:427/1770 train_time:41673ms step_avg:97.59ms
step:428/1770 train_time:41772ms step_avg:97.60ms
step:429/1770 train_time:41871ms step_avg:97.60ms
step:430/1770 train_time:41970ms step_avg:97.61ms
step:431/1770 train_time:42070ms step_avg:97.61ms
step:432/1770 train_time:42170ms step_avg:97.62ms
step:433/1770 train_time:42270ms step_avg:97.62ms
step:434/1770 train_time:42370ms step_avg:97.63ms
step:435/1770 train_time:42470ms step_avg:97.63ms
step:436/1770 train_time:42570ms step_avg:97.64ms
step:437/1770 train_time:42670ms step_avg:97.64ms
step:438/1770 train_time:42769ms step_avg:97.65ms
step:439/1770 train_time:42869ms step_avg:97.65ms
step:440/1770 train_time:42968ms step_avg:97.66ms
step:441/1770 train_time:43068ms step_avg:97.66ms
step:442/1770 train_time:43166ms step_avg:97.66ms
step:443/1770 train_time:43265ms step_avg:97.66ms
step:444/1770 train_time:43365ms step_avg:97.67ms
step:445/1770 train_time:43464ms step_avg:97.67ms
step:446/1770 train_time:43564ms step_avg:97.68ms
step:447/1770 train_time:43665ms step_avg:97.68ms
step:448/1770 train_time:43765ms step_avg:97.69ms
step:449/1770 train_time:43865ms step_avg:97.69ms
step:450/1770 train_time:43965ms step_avg:97.70ms
step:451/1770 train_time:44065ms step_avg:97.70ms
step:452/1770 train_time:44163ms step_avg:97.71ms
step:453/1770 train_time:44262ms step_avg:97.71ms
step:454/1770 train_time:44361ms step_avg:97.71ms
step:455/1770 train_time:44460ms step_avg:97.71ms
step:456/1770 train_time:44558ms step_avg:97.72ms
step:457/1770 train_time:44658ms step_avg:97.72ms
step:458/1770 train_time:44757ms step_avg:97.72ms
step:459/1770 train_time:44856ms step_avg:97.72ms
step:460/1770 train_time:44954ms step_avg:97.73ms
step:461/1770 train_time:45053ms step_avg:97.73ms
step:462/1770 train_time:45152ms step_avg:97.73ms
step:463/1770 train_time:45252ms step_avg:97.74ms
step:464/1770 train_time:45351ms step_avg:97.74ms
step:465/1770 train_time:45451ms step_avg:97.74ms
step:466/1770 train_time:45550ms step_avg:97.75ms
step:467/1770 train_time:45650ms step_avg:97.75ms
step:468/1770 train_time:45751ms step_avg:97.76ms
step:469/1770 train_time:45851ms step_avg:97.76ms
step:470/1770 train_time:45951ms step_avg:97.77ms
step:471/1770 train_time:46051ms step_avg:97.77ms
step:472/1770 train_time:46151ms step_avg:97.78ms
step:473/1770 train_time:46250ms step_avg:97.78ms
step:474/1770 train_time:46350ms step_avg:97.78ms
step:475/1770 train_time:46449ms step_avg:97.79ms
step:476/1770 train_time:46549ms step_avg:97.79ms
step:477/1770 train_time:46649ms step_avg:97.80ms
step:478/1770 train_time:46749ms step_avg:97.80ms
step:479/1770 train_time:46849ms step_avg:97.81ms
step:480/1770 train_time:46949ms step_avg:97.81ms
step:481/1770 train_time:47049ms step_avg:97.81ms
step:482/1770 train_time:47148ms step_avg:97.82ms
step:483/1770 train_time:47249ms step_avg:97.82ms
step:484/1770 train_time:47348ms step_avg:97.83ms
step:485/1770 train_time:47448ms step_avg:97.83ms
step:486/1770 train_time:47547ms step_avg:97.83ms
step:487/1770 train_time:47646ms step_avg:97.84ms
step:488/1770 train_time:47745ms step_avg:97.84ms
step:489/1770 train_time:47845ms step_avg:97.84ms
step:490/1770 train_time:47944ms step_avg:97.85ms
step:491/1770 train_time:48044ms step_avg:97.85ms
step:492/1770 train_time:48143ms step_avg:97.85ms
step:493/1770 train_time:48242ms step_avg:97.85ms
step:494/1770 train_time:48341ms step_avg:97.86ms
step:495/1770 train_time:48441ms step_avg:97.86ms
step:496/1770 train_time:48541ms step_avg:97.86ms
step:497/1770 train_time:48640ms step_avg:97.87ms
step:498/1770 train_time:48739ms step_avg:97.87ms
step:499/1770 train_time:48838ms step_avg:97.87ms
step:500/1770 train_time:48937ms step_avg:97.87ms
step:500/1770 val_loss:3.7446 train_time:49030ms step_avg:98.06ms
step:501/1770 train_time:49052ms step_avg:97.91ms
step:502/1770 train_time:49141ms step_avg:97.89ms
step:503/1770 train_time:49243ms step_avg:97.90ms
step:504/1770 train_time:49343ms step_avg:97.90ms
step:505/1770 train_time:49443ms step_avg:97.91ms
step:506/1770 train_time:49543ms step_avg:97.91ms
step:507/1770 train_time:49642ms step_avg:97.91ms
step:508/1770 train_time:49741ms step_avg:97.92ms
step:509/1770 train_time:49841ms step_avg:97.92ms
step:510/1770 train_time:49940ms step_avg:97.92ms
step:511/1770 train_time:50039ms step_avg:97.92ms
step:512/1770 train_time:50139ms step_avg:97.93ms
step:513/1770 train_time:50240ms step_avg:97.93ms
step:514/1770 train_time:50340ms step_avg:97.94ms
step:515/1770 train_time:50440ms step_avg:97.94ms
step:516/1770 train_time:50540ms step_avg:97.95ms
step:517/1770 train_time:50639ms step_avg:97.95ms
step:518/1770 train_time:50739ms step_avg:97.95ms
step:519/1770 train_time:50838ms step_avg:97.95ms
step:520/1770 train_time:50937ms step_avg:97.96ms
step:521/1770 train_time:51036ms step_avg:97.96ms
step:522/1770 train_time:51135ms step_avg:97.96ms
step:523/1770 train_time:51234ms step_avg:97.96ms
step:524/1770 train_time:51335ms step_avg:97.97ms
step:525/1770 train_time:51433ms step_avg:97.97ms
step:526/1770 train_time:51533ms step_avg:97.97ms
step:527/1770 train_time:51632ms step_avg:97.97ms
step:528/1770 train_time:51731ms step_avg:97.98ms
step:529/1770 train_time:51831ms step_avg:97.98ms
step:530/1770 train_time:51931ms step_avg:97.98ms
step:531/1770 train_time:52030ms step_avg:97.99ms
step:532/1770 train_time:52130ms step_avg:97.99ms
step:533/1770 train_time:52229ms step_avg:97.99ms
step:534/1770 train_time:52328ms step_avg:97.99ms
step:535/1770 train_time:52428ms step_avg:98.00ms
step:536/1770 train_time:52528ms step_avg:98.00ms
step:537/1770 train_time:52627ms step_avg:98.00ms
step:538/1770 train_time:52727ms step_avg:98.01ms
step:539/1770 train_time:52826ms step_avg:98.01ms
step:540/1770 train_time:52926ms step_avg:98.01ms
step:541/1770 train_time:53025ms step_avg:98.01ms
step:542/1770 train_time:53124ms step_avg:98.02ms
step:543/1770 train_time:53224ms step_avg:98.02ms
step:544/1770 train_time:53324ms step_avg:98.02ms
step:545/1770 train_time:53423ms step_avg:98.02ms
step:546/1770 train_time:53523ms step_avg:98.03ms
step:547/1770 train_time:53623ms step_avg:98.03ms
step:548/1770 train_time:53723ms step_avg:98.03ms
step:549/1770 train_time:53822ms step_avg:98.04ms
step:550/1770 train_time:53923ms step_avg:98.04ms
step:551/1770 train_time:54023ms step_avg:98.04ms
step:552/1770 train_time:54123ms step_avg:98.05ms
step:553/1770 train_time:54223ms step_avg:98.05ms
step:554/1770 train_time:54323ms step_avg:98.06ms
step:555/1770 train_time:54423ms step_avg:98.06ms
step:556/1770 train_time:54523ms step_avg:98.06ms
step:557/1770 train_time:54623ms step_avg:98.07ms
step:558/1770 train_time:54723ms step_avg:98.07ms
step:559/1770 train_time:54822ms step_avg:98.07ms
step:560/1770 train_time:54923ms step_avg:98.08ms
step:561/1770 train_time:55022ms step_avg:98.08ms
step:562/1770 train_time:55122ms step_avg:98.08ms
step:563/1770 train_time:55221ms step_avg:98.08ms
step:564/1770 train_time:55321ms step_avg:98.09ms
step:565/1770 train_time:55420ms step_avg:98.09ms
step:566/1770 train_time:55520ms step_avg:98.09ms
step:567/1770 train_time:55619ms step_avg:98.09ms
step:568/1770 train_time:55720ms step_avg:98.10ms
step:569/1770 train_time:55820ms step_avg:98.10ms
step:570/1770 train_time:55920ms step_avg:98.10ms
step:571/1770 train_time:56020ms step_avg:98.11ms
step:572/1770 train_time:56120ms step_avg:98.11ms
step:573/1770 train_time:56219ms step_avg:98.11ms
step:574/1770 train_time:56319ms step_avg:98.12ms
step:575/1770 train_time:56419ms step_avg:98.12ms
step:576/1770 train_time:56519ms step_avg:98.12ms
step:577/1770 train_time:56619ms step_avg:98.13ms
step:578/1770 train_time:56719ms step_avg:98.13ms
step:579/1770 train_time:56820ms step_avg:98.13ms
step:580/1770 train_time:56920ms step_avg:98.14ms
step:581/1770 train_time:57021ms step_avg:98.14ms
step:582/1770 train_time:57122ms step_avg:98.15ms
step:583/1770 train_time:57222ms step_avg:98.15ms
step:584/1770 train_time:57322ms step_avg:98.15ms
step:585/1770 train_time:57422ms step_avg:98.16ms
step:586/1770 train_time:57522ms step_avg:98.16ms
step:587/1770 train_time:57622ms step_avg:98.16ms
step:588/1770 train_time:57722ms step_avg:98.17ms
step:589/1770 train_time:57822ms step_avg:98.17ms
step:590/1770 train_time:57923ms step_avg:98.17ms
step:591/1770 train_time:58023ms step_avg:98.18ms
step:592/1770 train_time:58123ms step_avg:98.18ms
step:593/1770 train_time:58223ms step_avg:98.18ms
step:594/1770 train_time:58323ms step_avg:98.19ms
step:595/1770 train_time:58422ms step_avg:98.19ms
step:596/1770 train_time:58523ms step_avg:98.19ms
step:597/1770 train_time:58623ms step_avg:98.20ms
step:598/1770 train_time:58723ms step_avg:98.20ms
step:599/1770 train_time:58822ms step_avg:98.20ms
step:600/1770 train_time:58923ms step_avg:98.20ms
step:601/1770 train_time:59023ms step_avg:98.21ms
step:602/1770 train_time:59123ms step_avg:98.21ms
step:603/1770 train_time:59223ms step_avg:98.21ms
step:604/1770 train_time:59323ms step_avg:98.22ms
step:605/1770 train_time:59423ms step_avg:98.22ms
step:606/1770 train_time:59522ms step_avg:98.22ms
step:607/1770 train_time:59623ms step_avg:98.22ms
step:608/1770 train_time:59723ms step_avg:98.23ms
step:609/1770 train_time:59823ms step_avg:98.23ms
step:610/1770 train_time:59923ms step_avg:98.23ms
step:611/1770 train_time:60023ms step_avg:98.24ms
step:612/1770 train_time:60123ms step_avg:98.24ms
step:613/1770 train_time:60222ms step_avg:98.24ms
step:614/1770 train_time:60322ms step_avg:98.24ms
step:615/1770 train_time:60423ms step_avg:98.25ms
step:616/1770 train_time:60523ms step_avg:98.25ms
step:617/1770 train_time:60623ms step_avg:98.25ms
step:618/1770 train_time:60723ms step_avg:98.26ms
step:619/1770 train_time:60823ms step_avg:98.26ms
step:620/1770 train_time:60923ms step_avg:98.26ms
step:621/1770 train_time:61023ms step_avg:98.27ms
step:622/1770 train_time:61123ms step_avg:98.27ms
step:623/1770 train_time:61223ms step_avg:98.27ms
step:624/1770 train_time:61322ms step_avg:98.27ms
step:625/1770 train_time:61423ms step_avg:98.28ms
step:625/1770 val_loss:3.6596 train_time:61517ms step_avg:98.43ms
step:626/1770 train_time:61538ms step_avg:98.30ms
step:627/1770 train_time:61627ms step_avg:98.29ms
step:628/1770 train_time:61728ms step_avg:98.29ms
step:629/1770 train_time:61828ms step_avg:98.30ms
step:630/1770 train_time:61928ms step_avg:98.30ms
step:631/1770 train_time:62028ms step_avg:98.30ms
step:632/1770 train_time:62127ms step_avg:98.30ms
step:633/1770 train_time:62226ms step_avg:98.30ms
step:634/1770 train_time:62326ms step_avg:98.31ms
step:635/1770 train_time:62426ms step_avg:98.31ms
step:636/1770 train_time:62527ms step_avg:98.31ms
step:637/1770 train_time:62628ms step_avg:98.32ms
step:638/1770 train_time:62728ms step_avg:98.32ms
step:639/1770 train_time:62828ms step_avg:98.32ms
step:640/1770 train_time:62928ms step_avg:98.32ms
step:641/1770 train_time:63027ms step_avg:98.33ms
step:642/1770 train_time:63127ms step_avg:98.33ms
step:643/1770 train_time:63226ms step_avg:98.33ms
step:644/1770 train_time:63326ms step_avg:98.33ms
step:645/1770 train_time:63425ms step_avg:98.33ms
step:646/1770 train_time:63525ms step_avg:98.34ms
step:647/1770 train_time:63626ms step_avg:98.34ms
step:648/1770 train_time:63727ms step_avg:98.34ms
step:649/1770 train_time:63828ms step_avg:98.35ms
step:650/1770 train_time:63928ms step_avg:98.35ms
step:651/1770 train_time:64028ms step_avg:98.35ms
step:652/1770 train_time:64127ms step_avg:98.35ms
step:653/1770 train_time:64227ms step_avg:98.36ms
step:654/1770 train_time:64327ms step_avg:98.36ms
step:655/1770 train_time:64427ms step_avg:98.36ms
step:656/1770 train_time:64527ms step_avg:98.36ms
step:657/1770 train_time:64627ms step_avg:98.37ms
step:658/1770 train_time:64729ms step_avg:98.37ms
step:659/1770 train_time:64830ms step_avg:98.38ms
step:660/1770 train_time:64932ms step_avg:98.38ms
step:661/1770 train_time:65033ms step_avg:98.39ms
step:662/1770 train_time:65134ms step_avg:98.39ms
step:663/1770 train_time:65234ms step_avg:98.39ms
step:664/1770 train_time:65335ms step_avg:98.40ms
step:665/1770 train_time:65437ms step_avg:98.40ms
step:666/1770 train_time:65539ms step_avg:98.41ms
step:667/1770 train_time:65640ms step_avg:98.41ms
step:668/1770 train_time:65741ms step_avg:98.42ms
step:669/1770 train_time:65843ms step_avg:98.42ms
step:670/1770 train_time:65944ms step_avg:98.42ms
step:671/1770 train_time:66046ms step_avg:98.43ms
step:672/1770 train_time:66148ms step_avg:98.43ms
step:673/1770 train_time:66249ms step_avg:98.44ms
step:674/1770 train_time:66351ms step_avg:98.44ms
step:675/1770 train_time:66452ms step_avg:98.45ms
step:676/1770 train_time:66553ms step_avg:98.45ms
step:677/1770 train_time:66654ms step_avg:98.45ms
step:678/1770 train_time:66754ms step_avg:98.46ms
step:679/1770 train_time:66855ms step_avg:98.46ms
step:680/1770 train_time:66956ms step_avg:98.46ms
step:681/1770 train_time:67057ms step_avg:98.47ms
step:682/1770 train_time:67158ms step_avg:98.47ms
step:683/1770 train_time:67261ms step_avg:98.48ms
step:684/1770 train_time:67363ms step_avg:98.48ms
step:685/1770 train_time:67465ms step_avg:98.49ms
step:686/1770 train_time:67565ms step_avg:98.49ms
step:687/1770 train_time:67667ms step_avg:98.50ms
step:688/1770 train_time:67768ms step_avg:98.50ms
step:689/1770 train_time:67870ms step_avg:98.50ms
step:690/1770 train_time:67970ms step_avg:98.51ms
step:691/1770 train_time:68072ms step_avg:98.51ms
step:692/1770 train_time:68172ms step_avg:98.51ms
step:693/1770 train_time:68272ms step_avg:98.52ms
step:694/1770 train_time:68373ms step_avg:98.52ms
step:695/1770 train_time:68474ms step_avg:98.52ms
step:696/1770 train_time:68574ms step_avg:98.53ms
step:697/1770 train_time:68676ms step_avg:98.53ms
step:698/1770 train_time:68778ms step_avg:98.54ms
step:699/1770 train_time:68879ms step_avg:98.54ms
step:700/1770 train_time:68982ms step_avg:98.55ms
step:701/1770 train_time:69084ms step_avg:98.55ms
step:702/1770 train_time:69185ms step_avg:98.55ms
step:703/1770 train_time:69287ms step_avg:98.56ms
step:704/1770 train_time:69388ms step_avg:98.56ms
step:705/1770 train_time:69489ms step_avg:98.57ms
step:706/1770 train_time:69591ms step_avg:98.57ms
step:707/1770 train_time:69692ms step_avg:98.57ms
step:708/1770 train_time:69793ms step_avg:98.58ms
step:709/1770 train_time:69893ms step_avg:98.58ms
step:710/1770 train_time:69994ms step_avg:98.58ms
step:711/1770 train_time:70095ms step_avg:98.59ms
step:712/1770 train_time:70196ms step_avg:98.59ms
step:713/1770 train_time:70297ms step_avg:98.59ms
step:714/1770 train_time:70398ms step_avg:98.60ms
step:715/1770 train_time:70498ms step_avg:98.60ms
step:716/1770 train_time:70599ms step_avg:98.60ms
step:717/1770 train_time:70700ms step_avg:98.61ms
step:718/1770 train_time:70803ms step_avg:98.61ms
step:719/1770 train_time:70906ms step_avg:98.62ms
step:720/1770 train_time:71008ms step_avg:98.62ms
step:721/1770 train_time:71109ms step_avg:98.63ms
step:722/1770 train_time:71210ms step_avg:98.63ms
step:723/1770 train_time:71312ms step_avg:98.63ms
step:724/1770 train_time:71413ms step_avg:98.64ms
step:725/1770 train_time:71514ms step_avg:98.64ms
step:726/1770 train_time:71615ms step_avg:98.64ms
step:727/1770 train_time:71717ms step_avg:98.65ms
step:728/1770 train_time:71817ms step_avg:98.65ms
step:729/1770 train_time:71919ms step_avg:98.65ms
step:730/1770 train_time:72020ms step_avg:98.66ms
step:731/1770 train_time:72122ms step_avg:98.66ms
step:732/1770 train_time:72223ms step_avg:98.67ms
step:733/1770 train_time:72325ms step_avg:98.67ms
step:734/1770 train_time:72427ms step_avg:98.67ms
step:735/1770 train_time:72528ms step_avg:98.68ms
step:736/1770 train_time:72629ms step_avg:98.68ms
step:737/1770 train_time:72730ms step_avg:98.68ms
step:738/1770 train_time:72832ms step_avg:98.69ms
step:739/1770 train_time:72933ms step_avg:98.69ms
step:740/1770 train_time:73033ms step_avg:98.69ms
step:741/1770 train_time:73134ms step_avg:98.70ms
step:742/1770 train_time:73235ms step_avg:98.70ms
step:743/1770 train_time:73337ms step_avg:98.70ms
step:744/1770 train_time:73438ms step_avg:98.71ms
step:745/1770 train_time:73539ms step_avg:98.71ms
step:746/1770 train_time:73639ms step_avg:98.71ms
step:747/1770 train_time:73741ms step_avg:98.72ms
step:748/1770 train_time:73843ms step_avg:98.72ms
step:749/1770 train_time:73944ms step_avg:98.72ms
step:750/1770 train_time:74046ms step_avg:98.73ms
step:750/1770 val_loss:3.5946 train_time:74141ms step_avg:98.85ms
step:751/1770 train_time:74163ms step_avg:98.75ms
step:752/1770 train_time:74254ms step_avg:98.74ms
step:753/1770 train_time:74357ms step_avg:98.75ms
step:754/1770 train_time:74457ms step_avg:98.75ms
step:755/1770 train_time:74558ms step_avg:98.75ms
step:756/1770 train_time:74659ms step_avg:98.76ms
step:757/1770 train_time:74760ms step_avg:98.76ms
step:758/1770 train_time:74861ms step_avg:98.76ms
step:759/1770 train_time:74962ms step_avg:98.76ms
step:760/1770 train_time:75063ms step_avg:98.77ms
step:761/1770 train_time:75166ms step_avg:98.77ms
step:762/1770 train_time:75268ms step_avg:98.78ms
step:763/1770 train_time:75370ms step_avg:98.78ms
step:764/1770 train_time:75470ms step_avg:98.78ms
step:765/1770 train_time:75571ms step_avg:98.79ms
step:766/1770 train_time:75671ms step_avg:98.79ms
step:767/1770 train_time:75773ms step_avg:98.79ms
step:768/1770 train_time:75874ms step_avg:98.79ms
step:769/1770 train_time:75977ms step_avg:98.80ms
step:770/1770 train_time:76079ms step_avg:98.80ms
step:771/1770 train_time:76180ms step_avg:98.81ms
step:772/1770 train_time:76282ms step_avg:98.81ms
step:773/1770 train_time:76383ms step_avg:98.81ms
step:774/1770 train_time:76485ms step_avg:98.82ms
step:775/1770 train_time:76586ms step_avg:98.82ms
step:776/1770 train_time:76687ms step_avg:98.82ms
step:777/1770 train_time:76788ms step_avg:98.83ms
step:778/1770 train_time:76889ms step_avg:98.83ms
step:779/1770 train_time:76989ms step_avg:98.83ms
step:780/1770 train_time:77090ms step_avg:98.83ms
step:781/1770 train_time:77191ms step_avg:98.84ms
step:782/1770 train_time:77293ms step_avg:98.84ms
step:783/1770 train_time:77393ms step_avg:98.84ms
step:784/1770 train_time:77494ms step_avg:98.84ms
step:785/1770 train_time:77596ms step_avg:98.85ms
step:786/1770 train_time:77699ms step_avg:98.85ms
step:787/1770 train_time:77800ms step_avg:98.86ms
step:788/1770 train_time:77901ms step_avg:98.86ms
step:789/1770 train_time:78003ms step_avg:98.86ms
step:790/1770 train_time:78104ms step_avg:98.87ms
step:791/1770 train_time:78206ms step_avg:98.87ms
step:792/1770 train_time:78308ms step_avg:98.87ms
step:793/1770 train_time:78409ms step_avg:98.88ms
step:794/1770 train_time:78510ms step_avg:98.88ms
step:795/1770 train_time:78611ms step_avg:98.88ms
step:796/1770 train_time:78712ms step_avg:98.88ms
step:797/1770 train_time:78812ms step_avg:98.89ms
step:798/1770 train_time:78914ms step_avg:98.89ms
step:799/1770 train_time:79016ms step_avg:98.89ms
step:800/1770 train_time:79118ms step_avg:98.90ms
step:801/1770 train_time:79219ms step_avg:98.90ms
step:802/1770 train_time:79321ms step_avg:98.90ms
step:803/1770 train_time:79423ms step_avg:98.91ms
step:804/1770 train_time:79524ms step_avg:98.91ms
step:805/1770 train_time:79626ms step_avg:98.91ms
step:806/1770 train_time:79727ms step_avg:98.92ms
step:807/1770 train_time:79828ms step_avg:98.92ms
step:808/1770 train_time:79930ms step_avg:98.92ms
step:809/1770 train_time:80031ms step_avg:98.93ms
step:810/1770 train_time:80132ms step_avg:98.93ms
step:811/1770 train_time:80234ms step_avg:98.93ms
step:812/1770 train_time:80335ms step_avg:98.93ms
step:813/1770 train_time:80437ms step_avg:98.94ms
step:814/1770 train_time:80540ms step_avg:98.94ms
step:815/1770 train_time:80641ms step_avg:98.95ms
step:816/1770 train_time:80742ms step_avg:98.95ms
step:817/1770 train_time:80844ms step_avg:98.95ms
step:818/1770 train_time:80945ms step_avg:98.95ms
step:819/1770 train_time:81047ms step_avg:98.96ms
step:820/1770 train_time:81149ms step_avg:98.96ms
step:821/1770 train_time:81250ms step_avg:98.96ms
step:822/1770 train_time:81352ms step_avg:98.97ms
step:823/1770 train_time:81453ms step_avg:98.97ms
step:824/1770 train_time:81556ms step_avg:98.98ms
step:825/1770 train_time:81656ms step_avg:98.98ms
step:826/1770 train_time:81760ms step_avg:98.98ms
step:827/1770 train_time:81861ms step_avg:98.99ms
step:828/1770 train_time:81963ms step_avg:98.99ms
step:829/1770 train_time:82065ms step_avg:98.99ms
step:830/1770 train_time:82166ms step_avg:99.00ms
step:831/1770 train_time:82268ms step_avg:99.00ms
step:832/1770 train_time:82369ms step_avg:99.00ms
step:833/1770 train_time:82470ms step_avg:99.00ms
step:834/1770 train_time:82572ms step_avg:99.01ms
step:835/1770 train_time:82673ms step_avg:99.01ms
step:836/1770 train_time:82774ms step_avg:99.01ms
step:837/1770 train_time:82875ms step_avg:99.01ms
step:838/1770 train_time:82977ms step_avg:99.02ms
step:839/1770 train_time:83080ms step_avg:99.02ms
step:840/1770 train_time:83182ms step_avg:99.03ms
step:841/1770 train_time:83284ms step_avg:99.03ms
step:842/1770 train_time:83385ms step_avg:99.03ms
step:843/1770 train_time:83486ms step_avg:99.03ms
step:844/1770 train_time:83587ms step_avg:99.04ms
step:845/1770 train_time:83688ms step_avg:99.04ms
step:846/1770 train_time:83789ms step_avg:99.04ms
step:847/1770 train_time:83890ms step_avg:99.04ms
step:848/1770 train_time:83991ms step_avg:99.05ms
step:849/1770 train_time:84092ms step_avg:99.05ms
step:850/1770 train_time:84194ms step_avg:99.05ms
step:851/1770 train_time:84295ms step_avg:99.05ms
step:852/1770 train_time:84397ms step_avg:99.06ms
step:853/1770 train_time:84499ms step_avg:99.06ms
step:854/1770 train_time:84601ms step_avg:99.06ms
step:855/1770 train_time:84703ms step_avg:99.07ms
step:856/1770 train_time:84805ms step_avg:99.07ms
step:857/1770 train_time:84906ms step_avg:99.07ms
step:858/1770 train_time:85007ms step_avg:99.08ms
step:859/1770 train_time:85108ms step_avg:99.08ms
step:860/1770 train_time:85209ms step_avg:99.08ms
step:861/1770 train_time:85310ms step_avg:99.08ms
step:862/1770 train_time:85411ms step_avg:99.08ms
step:863/1770 train_time:85513ms step_avg:99.09ms
step:864/1770 train_time:85614ms step_avg:99.09ms
step:865/1770 train_time:85716ms step_avg:99.09ms
step:866/1770 train_time:85817ms step_avg:99.10ms
step:867/1770 train_time:85920ms step_avg:99.10ms
step:868/1770 train_time:86022ms step_avg:99.10ms
step:869/1770 train_time:86123ms step_avg:99.11ms
step:870/1770 train_time:86225ms step_avg:99.11ms
step:871/1770 train_time:86326ms step_avg:99.11ms
step:872/1770 train_time:86428ms step_avg:99.11ms
step:873/1770 train_time:86529ms step_avg:99.12ms
step:874/1770 train_time:86631ms step_avg:99.12ms
step:875/1770 train_time:86733ms step_avg:99.12ms
step:875/1770 val_loss:3.5471 train_time:86828ms step_avg:99.23ms
step:876/1770 train_time:86849ms step_avg:99.14ms
step:877/1770 train_time:86942ms step_avg:99.14ms
step:878/1770 train_time:87044ms step_avg:99.14ms
step:879/1770 train_time:87146ms step_avg:99.14ms
step:880/1770 train_time:87247ms step_avg:99.14ms
step:881/1770 train_time:87349ms step_avg:99.15ms
step:882/1770 train_time:87449ms step_avg:99.15ms
step:883/1770 train_time:87551ms step_avg:99.15ms
step:884/1770 train_time:87652ms step_avg:99.15ms
step:885/1770 train_time:87753ms step_avg:99.16ms
step:886/1770 train_time:87855ms step_avg:99.16ms
step:887/1770 train_time:87957ms step_avg:99.16ms
step:888/1770 train_time:88059ms step_avg:99.17ms
step:889/1770 train_time:88161ms step_avg:99.17ms
step:890/1770 train_time:88262ms step_avg:99.17ms
step:891/1770 train_time:88363ms step_avg:99.17ms
step:892/1770 train_time:88464ms step_avg:99.17ms
step:893/1770 train_time:88565ms step_avg:99.18ms
step:894/1770 train_time:88667ms step_avg:99.18ms
step:895/1770 train_time:88768ms step_avg:99.18ms
step:896/1770 train_time:88870ms step_avg:99.18ms
step:897/1770 train_time:88972ms step_avg:99.19ms
step:898/1770 train_time:89074ms step_avg:99.19ms
step:899/1770 train_time:89176ms step_avg:99.19ms
step:900/1770 train_time:89277ms step_avg:99.20ms
step:901/1770 train_time:89378ms step_avg:99.20ms
step:902/1770 train_time:89480ms step_avg:99.20ms
step:903/1770 train_time:89581ms step_avg:99.20ms
step:904/1770 train_time:89682ms step_avg:99.21ms
step:905/1770 train_time:89783ms step_avg:99.21ms
step:906/1770 train_time:89885ms step_avg:99.21ms
step:907/1770 train_time:89986ms step_avg:99.21ms
step:908/1770 train_time:90087ms step_avg:99.21ms
step:909/1770 train_time:90189ms step_avg:99.22ms
step:910/1770 train_time:90291ms step_avg:99.22ms
step:911/1770 train_time:90393ms step_avg:99.22ms
step:912/1770 train_time:90495ms step_avg:99.23ms
step:913/1770 train_time:90597ms step_avg:99.23ms
step:914/1770 train_time:90699ms step_avg:99.23ms
step:915/1770 train_time:90800ms step_avg:99.24ms
step:916/1770 train_time:90902ms step_avg:99.24ms
step:917/1770 train_time:91003ms step_avg:99.24ms
step:918/1770 train_time:91104ms step_avg:99.24ms
step:919/1770 train_time:91205ms step_avg:99.24ms
step:920/1770 train_time:91308ms step_avg:99.25ms
step:921/1770 train_time:91411ms step_avg:99.25ms
step:922/1770 train_time:91515ms step_avg:99.26ms
step:923/1770 train_time:91618ms step_avg:99.26ms
step:924/1770 train_time:91721ms step_avg:99.26ms
step:925/1770 train_time:91823ms step_avg:99.27ms
step:926/1770 train_time:91926ms step_avg:99.27ms
step:927/1770 train_time:92030ms step_avg:99.28ms
step:928/1770 train_time:92133ms step_avg:99.28ms
step:929/1770 train_time:92236ms step_avg:99.28ms
step:930/1770 train_time:92339ms step_avg:99.29ms
step:931/1770 train_time:92441ms step_avg:99.29ms
step:932/1770 train_time:92543ms step_avg:99.30ms
step:933/1770 train_time:92645ms step_avg:99.30ms
step:934/1770 train_time:92749ms step_avg:99.30ms
step:935/1770 train_time:92851ms step_avg:99.31ms
step:936/1770 train_time:92954ms step_avg:99.31ms
step:937/1770 train_time:93057ms step_avg:99.31ms
step:938/1770 train_time:93160ms step_avg:99.32ms
step:939/1770 train_time:93262ms step_avg:99.32ms
step:940/1770 train_time:93365ms step_avg:99.32ms
step:941/1770 train_time:93468ms step_avg:99.33ms
step:942/1770 train_time:93571ms step_avg:99.33ms
step:943/1770 train_time:93673ms step_avg:99.34ms
step:944/1770 train_time:93776ms step_avg:99.34ms
step:945/1770 train_time:93879ms step_avg:99.34ms
step:946/1770 train_time:93982ms step_avg:99.35ms
step:947/1770 train_time:94085ms step_avg:99.35ms
step:948/1770 train_time:94186ms step_avg:99.35ms
step:949/1770 train_time:94290ms step_avg:99.36ms
step:950/1770 train_time:94393ms step_avg:99.36ms
step:951/1770 train_time:94495ms step_avg:99.36ms
step:952/1770 train_time:94598ms step_avg:99.37ms
step:953/1770 train_time:94701ms step_avg:99.37ms
step:954/1770 train_time:94804ms step_avg:99.38ms
step:955/1770 train_time:94907ms step_avg:99.38ms
step:956/1770 train_time:95009ms step_avg:99.38ms
step:957/1770 train_time:95113ms step_avg:99.39ms
step:958/1770 train_time:95215ms step_avg:99.39ms
step:959/1770 train_time:95319ms step_avg:99.39ms
step:960/1770 train_time:95421ms step_avg:99.40ms
step:961/1770 train_time:95523ms step_avg:99.40ms
step:962/1770 train_time:95626ms step_avg:99.40ms
step:963/1770 train_time:95729ms step_avg:99.41ms
step:964/1770 train_time:95832ms step_avg:99.41ms
step:965/1770 train_time:95935ms step_avg:99.41ms
step:966/1770 train_time:96038ms step_avg:99.42ms
step:967/1770 train_time:96141ms step_avg:99.42ms
step:968/1770 train_time:96244ms step_avg:99.43ms
step:969/1770 train_time:96347ms step_avg:99.43ms
step:970/1770 train_time:96449ms step_avg:99.43ms
step:971/1770 train_time:96553ms step_avg:99.44ms
step:972/1770 train_time:96655ms step_avg:99.44ms
step:973/1770 train_time:96759ms step_avg:99.44ms
step:974/1770 train_time:96861ms step_avg:99.45ms
step:975/1770 train_time:96964ms step_avg:99.45ms
step:976/1770 train_time:97067ms step_avg:99.45ms
step:977/1770 train_time:97169ms step_avg:99.46ms
step:978/1770 train_time:97272ms step_avg:99.46ms
step:979/1770 train_time:97375ms step_avg:99.46ms
step:980/1770 train_time:97479ms step_avg:99.47ms
step:981/1770 train_time:97581ms step_avg:99.47ms
step:982/1770 train_time:97683ms step_avg:99.47ms
step:983/1770 train_time:97785ms step_avg:99.48ms
step:984/1770 train_time:97887ms step_avg:99.48ms
step:985/1770 train_time:97991ms step_avg:99.48ms
step:986/1770 train_time:98093ms step_avg:99.49ms
step:987/1770 train_time:98196ms step_avg:99.49ms
step:988/1770 train_time:98298ms step_avg:99.49ms
step:989/1770 train_time:98402ms step_avg:99.50ms
step:990/1770 train_time:98505ms step_avg:99.50ms
step:991/1770 train_time:98607ms step_avg:99.50ms
step:992/1770 train_time:98710ms step_avg:99.51ms
step:993/1770 train_time:98813ms step_avg:99.51ms
step:994/1770 train_time:98915ms step_avg:99.51ms
step:995/1770 train_time:99018ms step_avg:99.52ms
step:996/1770 train_time:99121ms step_avg:99.52ms
step:997/1770 train_time:99224ms step_avg:99.52ms
step:998/1770 train_time:99327ms step_avg:99.53ms
step:999/1770 train_time:99429ms step_avg:99.53ms
step:1000/1770 train_time:99531ms step_avg:99.53ms
step:1000/1770 val_loss:3.5096 train_time:99629ms step_avg:99.63ms
step:1001/1770 train_time:99649ms step_avg:99.55ms
step:1002/1770 train_time:99745ms step_avg:99.55ms
step:1003/1770 train_time:99849ms step_avg:99.55ms
step:1004/1770 train_time:99952ms step_avg:99.55ms
step:1005/1770 train_time:100054ms step_avg:99.56ms
step:1006/1770 train_time:100157ms step_avg:99.56ms
step:1007/1770 train_time:100259ms step_avg:99.56ms
step:1008/1770 train_time:100362ms step_avg:99.57ms
step:1009/1770 train_time:100464ms step_avg:99.57ms
step:1010/1770 train_time:100566ms step_avg:99.57ms
step:1011/1770 train_time:100670ms step_avg:99.57ms
step:1012/1770 train_time:100774ms step_avg:99.58ms
step:1013/1770 train_time:100877ms step_avg:99.58ms
step:1014/1770 train_time:100980ms step_avg:99.59ms
step:1015/1770 train_time:101083ms step_avg:99.59ms
step:1016/1770 train_time:101185ms step_avg:99.59ms
step:1017/1770 train_time:101289ms step_avg:99.60ms
step:1018/1770 train_time:101390ms step_avg:99.60ms
step:1019/1770 train_time:101493ms step_avg:99.60ms
step:1020/1770 train_time:101596ms step_avg:99.60ms
step:1021/1770 train_time:101698ms step_avg:99.61ms
step:1022/1770 train_time:101801ms step_avg:99.61ms
step:1023/1770 train_time:101904ms step_avg:99.61ms
step:1024/1770 train_time:102007ms step_avg:99.62ms
step:1025/1770 train_time:102109ms step_avg:99.62ms
step:1026/1770 train_time:102214ms step_avg:99.62ms
step:1027/1770 train_time:102318ms step_avg:99.63ms
step:1028/1770 train_time:102421ms step_avg:99.63ms
step:1029/1770 train_time:102523ms step_avg:99.63ms
step:1030/1770 train_time:102626ms step_avg:99.64ms
step:1031/1770 train_time:102728ms step_avg:99.64ms
step:1032/1770 train_time:102831ms step_avg:99.64ms
step:1033/1770 train_time:102934ms step_avg:99.65ms
step:1034/1770 train_time:103036ms step_avg:99.65ms
step:1035/1770 train_time:103139ms step_avg:99.65ms
step:1036/1770 train_time:103241ms step_avg:99.65ms
step:1037/1770 train_time:103344ms step_avg:99.66ms
step:1038/1770 train_time:103447ms step_avg:99.66ms
step:1039/1770 train_time:103550ms step_avg:99.66ms
step:1040/1770 train_time:103653ms step_avg:99.67ms
step:1041/1770 train_time:103756ms step_avg:99.67ms
step:1042/1770 train_time:103859ms step_avg:99.67ms
step:1043/1770 train_time:103962ms step_avg:99.68ms
step:1044/1770 train_time:104064ms step_avg:99.68ms
step:1045/1770 train_time:104166ms step_avg:99.68ms
step:1046/1770 train_time:104269ms step_avg:99.68ms
step:1047/1770 train_time:104372ms step_avg:99.69ms
step:1048/1770 train_time:104475ms step_avg:99.69ms
step:1049/1770 train_time:104578ms step_avg:99.69ms
step:1050/1770 train_time:104681ms step_avg:99.70ms
step:1051/1770 train_time:104784ms step_avg:99.70ms
step:1052/1770 train_time:104887ms step_avg:99.70ms
step:1053/1770 train_time:104989ms step_avg:99.71ms
step:1054/1770 train_time:105092ms step_avg:99.71ms
step:1055/1770 train_time:105196ms step_avg:99.71ms
step:1056/1770 train_time:105298ms step_avg:99.71ms
step:1057/1770 train_time:105401ms step_avg:99.72ms
step:1058/1770 train_time:105505ms step_avg:99.72ms
step:1059/1770 train_time:105607ms step_avg:99.72ms
step:1060/1770 train_time:105710ms step_avg:99.73ms
step:1061/1770 train_time:105813ms step_avg:99.73ms
step:1062/1770 train_time:105920ms step_avg:99.74ms
step:1063/1770 train_time:106024ms step_avg:99.74ms
step:1064/1770 train_time:106127ms step_avg:99.74ms
step:1065/1770 train_time:106229ms step_avg:99.75ms
step:1066/1770 train_time:106334ms step_avg:99.75ms
step:1067/1770 train_time:106437ms step_avg:99.75ms
step:1068/1770 train_time:106542ms step_avg:99.76ms
step:1069/1770 train_time:106645ms step_avg:99.76ms
step:1070/1770 train_time:106748ms step_avg:99.76ms
step:1071/1770 train_time:106850ms step_avg:99.77ms
step:1072/1770 train_time:106953ms step_avg:99.77ms
step:1073/1770 train_time:107056ms step_avg:99.77ms
step:1074/1770 train_time:107159ms step_avg:99.78ms
step:1075/1770 train_time:107262ms step_avg:99.78ms
step:1076/1770 train_time:107365ms step_avg:99.78ms
step:1077/1770 train_time:107468ms step_avg:99.78ms
step:1078/1770 train_time:107570ms step_avg:99.79ms
step:1079/1770 train_time:107673ms step_avg:99.79ms
step:1080/1770 train_time:107776ms step_avg:99.79ms
step:1081/1770 train_time:107879ms step_avg:99.80ms
step:1082/1770 train_time:107982ms step_avg:99.80ms
step:1083/1770 train_time:108084ms step_avg:99.80ms
step:1084/1770 train_time:108187ms step_avg:99.80ms
step:1085/1770 train_time:108289ms step_avg:99.81ms
step:1086/1770 train_time:108392ms step_avg:99.81ms
step:1087/1770 train_time:108495ms step_avg:99.81ms
step:1088/1770 train_time:108597ms step_avg:99.81ms
step:1089/1770 train_time:108700ms step_avg:99.82ms
step:1090/1770 train_time:108804ms step_avg:99.82ms
step:1091/1770 train_time:108906ms step_avg:99.82ms
step:1092/1770 train_time:109009ms step_avg:99.83ms
step:1093/1770 train_time:109113ms step_avg:99.83ms
step:1094/1770 train_time:109217ms step_avg:99.83ms
step:1095/1770 train_time:109321ms step_avg:99.84ms
step:1096/1770 train_time:109424ms step_avg:99.84ms
step:1097/1770 train_time:109527ms step_avg:99.84ms
step:1098/1770 train_time:109629ms step_avg:99.84ms
step:1099/1770 train_time:109732ms step_avg:99.85ms
step:1100/1770 train_time:109834ms step_avg:99.85ms
step:1101/1770 train_time:109937ms step_avg:99.85ms
step:1102/1770 train_time:110040ms step_avg:99.86ms
step:1103/1770 train_time:110144ms step_avg:99.86ms
step:1104/1770 train_time:110247ms step_avg:99.86ms
step:1105/1770 train_time:110350ms step_avg:99.86ms
step:1106/1770 train_time:110454ms step_avg:99.87ms
step:1107/1770 train_time:110556ms step_avg:99.87ms
step:1108/1770 train_time:110659ms step_avg:99.87ms
step:1109/1770 train_time:110762ms step_avg:99.88ms
step:1110/1770 train_time:110865ms step_avg:99.88ms
step:1111/1770 train_time:110967ms step_avg:99.88ms
step:1112/1770 train_time:111071ms step_avg:99.88ms
step:1113/1770 train_time:111174ms step_avg:99.89ms
step:1114/1770 train_time:111277ms step_avg:99.89ms
step:1115/1770 train_time:111381ms step_avg:99.89ms
step:1116/1770 train_time:111483ms step_avg:99.90ms
step:1117/1770 train_time:111587ms step_avg:99.90ms
step:1118/1770 train_time:111688ms step_avg:99.90ms
step:1119/1770 train_time:111792ms step_avg:99.90ms
step:1120/1770 train_time:111895ms step_avg:99.91ms
step:1121/1770 train_time:111998ms step_avg:99.91ms
step:1122/1770 train_time:112101ms step_avg:99.91ms
step:1123/1770 train_time:112203ms step_avg:99.91ms
step:1124/1770 train_time:112306ms step_avg:99.92ms
step:1125/1770 train_time:112408ms step_avg:99.92ms
step:1125/1770 val_loss:3.4688 train_time:112506ms step_avg:100.01ms
step:1126/1770 train_time:112526ms step_avg:99.93ms
step:1127/1770 train_time:112621ms step_avg:99.93ms
step:1128/1770 train_time:112725ms step_avg:99.93ms
step:1129/1770 train_time:112828ms step_avg:99.94ms
step:1130/1770 train_time:112931ms step_avg:99.94ms
step:1131/1770 train_time:113033ms step_avg:99.94ms
step:1132/1770 train_time:113136ms step_avg:99.94ms
step:1133/1770 train_time:113239ms step_avg:99.95ms
step:1134/1770 train_time:113341ms step_avg:99.95ms
step:1135/1770 train_time:113444ms step_avg:99.95ms
step:1136/1770 train_time:113547ms step_avg:99.95ms
step:1137/1770 train_time:113654ms step_avg:99.96ms
step:1138/1770 train_time:113757ms step_avg:99.96ms
step:1139/1770 train_time:113860ms step_avg:99.97ms
step:1140/1770 train_time:113962ms step_avg:99.97ms
step:1141/1770 train_time:114065ms step_avg:99.97ms
step:1142/1770 train_time:114167ms step_avg:99.97ms
step:1143/1770 train_time:114270ms step_avg:99.97ms
step:1144/1770 train_time:114373ms step_avg:99.98ms
step:1145/1770 train_time:114476ms step_avg:99.98ms
step:1146/1770 train_time:114580ms step_avg:99.98ms
step:1147/1770 train_time:114684ms step_avg:99.99ms
step:1148/1770 train_time:114787ms step_avg:99.99ms
step:1149/1770 train_time:114890ms step_avg:99.99ms
step:1150/1770 train_time:114993ms step_avg:99.99ms
step:1151/1770 train_time:115097ms step_avg:100.00ms
step:1152/1770 train_time:115200ms step_avg:100.00ms
step:1153/1770 train_time:115303ms step_avg:100.00ms
step:1154/1770 train_time:115405ms step_avg:100.00ms
step:1155/1770 train_time:115508ms step_avg:100.01ms
step:1156/1770 train_time:115611ms step_avg:100.01ms
step:1157/1770 train_time:115717ms step_avg:100.01ms
step:1158/1770 train_time:115820ms step_avg:100.02ms
step:1159/1770 train_time:115922ms step_avg:100.02ms
step:1160/1770 train_time:116025ms step_avg:100.02ms
step:1161/1770 train_time:116128ms step_avg:100.02ms
step:1162/1770 train_time:116234ms step_avg:100.03ms
step:1163/1770 train_time:116337ms step_avg:100.03ms
step:1164/1770 train_time:116440ms step_avg:100.03ms
step:1165/1770 train_time:116542ms step_avg:100.04ms
step:1166/1770 train_time:116645ms step_avg:100.04ms
step:1167/1770 train_time:116748ms step_avg:100.04ms
step:1168/1770 train_time:116851ms step_avg:100.04ms
step:1169/1770 train_time:116953ms step_avg:100.05ms
step:1170/1770 train_time:117057ms step_avg:100.05ms
step:1171/1770 train_time:117160ms step_avg:100.05ms
step:1172/1770 train_time:117263ms step_avg:100.05ms
step:1173/1770 train_time:117366ms step_avg:100.06ms
step:1174/1770 train_time:117469ms step_avg:100.06ms
step:1175/1770 train_time:117572ms step_avg:100.06ms
step:1176/1770 train_time:117675ms step_avg:100.06ms
step:1177/1770 train_time:117778ms step_avg:100.07ms
step:1178/1770 train_time:117880ms step_avg:100.07ms
step:1179/1770 train_time:117983ms step_avg:100.07ms
step:1180/1770 train_time:118085ms step_avg:100.07ms
step:1181/1770 train_time:118188ms step_avg:100.07ms
step:1182/1770 train_time:118291ms step_avg:100.08ms
step:1183/1770 train_time:118396ms step_avg:100.08ms
step:1184/1770 train_time:118501ms step_avg:100.09ms
step:1185/1770 train_time:118604ms step_avg:100.09ms
step:1186/1770 train_time:118709ms step_avg:100.09ms
step:1187/1770 train_time:118816ms step_avg:100.10ms
step:1188/1770 train_time:118920ms step_avg:100.10ms
step:1189/1770 train_time:119025ms step_avg:100.11ms
step:1190/1770 train_time:119128ms step_avg:100.11ms
step:1191/1770 train_time:119233ms step_avg:100.11ms
step:1192/1770 train_time:119338ms step_avg:100.12ms
step:1193/1770 train_time:119442ms step_avg:100.12ms
step:1194/1770 train_time:119546ms step_avg:100.12ms
step:1195/1770 train_time:119651ms step_avg:100.13ms
step:1196/1770 train_time:119755ms step_avg:100.13ms
step:1197/1770 train_time:119859ms step_avg:100.13ms
step:1198/1770 train_time:119963ms step_avg:100.14ms
step:1199/1770 train_time:120067ms step_avg:100.14ms
step:1200/1770 train_time:120172ms step_avg:100.14ms
step:1201/1770 train_time:120277ms step_avg:100.15ms
step:1202/1770 train_time:120380ms step_avg:100.15ms
step:1203/1770 train_time:120485ms step_avg:100.15ms
step:1204/1770 train_time:120588ms step_avg:100.16ms
step:1205/1770 train_time:120692ms step_avg:100.16ms
step:1206/1770 train_time:120797ms step_avg:100.16ms
step:1207/1770 train_time:120901ms step_avg:100.17ms
step:1208/1770 train_time:121005ms step_avg:100.17ms
step:1209/1770 train_time:121109ms step_avg:100.17ms
step:1210/1770 train_time:121212ms step_avg:100.18ms
step:1211/1770 train_time:121316ms step_avg:100.18ms
step:1212/1770 train_time:121423ms step_avg:100.18ms
step:1213/1770 train_time:121527ms step_avg:100.19ms
step:1214/1770 train_time:121630ms step_avg:100.19ms
step:1215/1770 train_time:121733ms step_avg:100.19ms
step:1216/1770 train_time:121839ms step_avg:100.20ms
step:1217/1770 train_time:121943ms step_avg:100.20ms
step:1218/1770 train_time:122047ms step_avg:100.20ms
step:1219/1770 train_time:122150ms step_avg:100.21ms
step:1220/1770 train_time:122254ms step_avg:100.21ms
step:1221/1770 train_time:122359ms step_avg:100.21ms
step:1222/1770 train_time:122465ms step_avg:100.22ms
step:1223/1770 train_time:122568ms step_avg:100.22ms
step:1224/1770 train_time:122673ms step_avg:100.22ms
step:1225/1770 train_time:122777ms step_avg:100.23ms
step:1226/1770 train_time:122882ms step_avg:100.23ms
step:1227/1770 train_time:122989ms step_avg:100.24ms
step:1228/1770 train_time:123095ms step_avg:100.24ms
step:1229/1770 train_time:123198ms step_avg:100.24ms
step:1230/1770 train_time:123304ms step_avg:100.25ms
step:1231/1770 train_time:123408ms step_avg:100.25ms
step:1232/1770 train_time:123512ms step_avg:100.25ms
step:1233/1770 train_time:123616ms step_avg:100.26ms
step:1234/1770 train_time:123720ms step_avg:100.26ms
step:1235/1770 train_time:123824ms step_avg:100.26ms
step:1236/1770 train_time:123929ms step_avg:100.27ms
step:1237/1770 train_time:124033ms step_avg:100.27ms
step:1238/1770 train_time:124138ms step_avg:100.27ms
step:1239/1770 train_time:124242ms step_avg:100.28ms
step:1240/1770 train_time:124345ms step_avg:100.28ms
step:1241/1770 train_time:124450ms step_avg:100.28ms
step:1242/1770 train_time:124554ms step_avg:100.28ms
step:1243/1770 train_time:124659ms step_avg:100.29ms
step:1244/1770 train_time:124763ms step_avg:100.29ms
step:1245/1770 train_time:124867ms step_avg:100.29ms
step:1246/1770 train_time:124972ms step_avg:100.30ms
step:1247/1770 train_time:125076ms step_avg:100.30ms
step:1248/1770 train_time:125181ms step_avg:100.31ms
step:1249/1770 train_time:125285ms step_avg:100.31ms
step:1250/1770 train_time:125388ms step_avg:100.31ms
step:1250/1770 val_loss:3.4216 train_time:125488ms step_avg:100.39ms
step:1251/1770 train_time:125508ms step_avg:100.33ms
step:1252/1770 train_time:125604ms step_avg:100.32ms
step:1253/1770 train_time:125709ms step_avg:100.33ms
step:1254/1770 train_time:125812ms step_avg:100.33ms
step:1255/1770 train_time:125918ms step_avg:100.33ms
step:1256/1770 train_time:126022ms step_avg:100.34ms
step:1257/1770 train_time:126126ms step_avg:100.34ms
step:1258/1770 train_time:126230ms step_avg:100.34ms
step:1259/1770 train_time:126335ms step_avg:100.35ms
step:1260/1770 train_time:126439ms step_avg:100.35ms
step:1261/1770 train_time:126544ms step_avg:100.35ms
step:1262/1770 train_time:126649ms step_avg:100.36ms
step:1263/1770 train_time:126753ms step_avg:100.36ms
step:1264/1770 train_time:126859ms step_avg:100.36ms
step:1265/1770 train_time:126963ms step_avg:100.37ms
step:1266/1770 train_time:127068ms step_avg:100.37ms
step:1267/1770 train_time:127172ms step_avg:100.37ms
step:1268/1770 train_time:127276ms step_avg:100.38ms
step:1269/1770 train_time:127380ms step_avg:100.38ms
step:1270/1770 train_time:127484ms step_avg:100.38ms
step:1271/1770 train_time:127588ms step_avg:100.38ms
step:1272/1770 train_time:127691ms step_avg:100.39ms
step:1273/1770 train_time:127796ms step_avg:100.39ms
step:1274/1770 train_time:127899ms step_avg:100.39ms
step:1275/1770 train_time:128004ms step_avg:100.40ms
step:1276/1770 train_time:128108ms step_avg:100.40ms
step:1277/1770 train_time:128211ms step_avg:100.40ms
step:1278/1770 train_time:128316ms step_avg:100.40ms
step:1279/1770 train_time:128420ms step_avg:100.41ms
step:1280/1770 train_time:128527ms step_avg:100.41ms
step:1281/1770 train_time:128631ms step_avg:100.41ms
step:1282/1770 train_time:128736ms step_avg:100.42ms
step:1283/1770 train_time:128840ms step_avg:100.42ms
step:1284/1770 train_time:128944ms step_avg:100.42ms
step:1285/1770 train_time:129049ms step_avg:100.43ms
step:1286/1770 train_time:129154ms step_avg:100.43ms
step:1287/1770 train_time:129259ms step_avg:100.43ms
step:1288/1770 train_time:129364ms step_avg:100.44ms
step:1289/1770 train_time:129469ms step_avg:100.44ms
step:1290/1770 train_time:129572ms step_avg:100.44ms
step:1291/1770 train_time:129676ms step_avg:100.45ms
step:1292/1770 train_time:129780ms step_avg:100.45ms
step:1293/1770 train_time:129885ms step_avg:100.45ms
step:1294/1770 train_time:129988ms step_avg:100.45ms
step:1295/1770 train_time:130092ms step_avg:100.46ms
step:1296/1770 train_time:130196ms step_avg:100.46ms
step:1297/1770 train_time:130300ms step_avg:100.46ms
step:1298/1770 train_time:130405ms step_avg:100.47ms
step:1299/1770 train_time:130509ms step_avg:100.47ms
step:1300/1770 train_time:130613ms step_avg:100.47ms
step:1301/1770 train_time:130717ms step_avg:100.47ms
step:1302/1770 train_time:130822ms step_avg:100.48ms
step:1303/1770 train_time:130926ms step_avg:100.48ms
step:1304/1770 train_time:131030ms step_avg:100.48ms
step:1305/1770 train_time:131133ms step_avg:100.49ms
step:1306/1770 train_time:131237ms step_avg:100.49ms
step:1307/1770 train_time:131341ms step_avg:100.49ms
step:1308/1770 train_time:131445ms step_avg:100.49ms
step:1309/1770 train_time:131550ms step_avg:100.50ms
step:1310/1770 train_time:131654ms step_avg:100.50ms
step:1311/1770 train_time:131758ms step_avg:100.50ms
step:1312/1770 train_time:131862ms step_avg:100.50ms
step:1313/1770 train_time:131966ms step_avg:100.51ms
step:1314/1770 train_time:132070ms step_avg:100.51ms
step:1315/1770 train_time:132174ms step_avg:100.51ms
step:1316/1770 train_time:132278ms step_avg:100.52ms
step:1317/1770 train_time:132382ms step_avg:100.52ms
step:1318/1770 train_time:132491ms step_avg:100.52ms
step:1319/1770 train_time:132595ms step_avg:100.53ms
step:1320/1770 train_time:132699ms step_avg:100.53ms
step:1321/1770 train_time:132804ms step_avg:100.53ms
step:1322/1770 train_time:132908ms step_avg:100.54ms
step:1323/1770 train_time:133013ms step_avg:100.54ms
step:1324/1770 train_time:133117ms step_avg:100.54ms
step:1325/1770 train_time:133224ms step_avg:100.55ms
step:1326/1770 train_time:133327ms step_avg:100.55ms
step:1327/1770 train_time:133434ms step_avg:100.55ms
step:1328/1770 train_time:133538ms step_avg:100.56ms
step:1329/1770 train_time:133641ms step_avg:100.56ms
step:1330/1770 train_time:133745ms step_avg:100.56ms
step:1331/1770 train_time:133848ms step_avg:100.56ms
step:1332/1770 train_time:133952ms step_avg:100.56ms
step:1333/1770 train_time:134055ms step_avg:100.57ms
step:1334/1770 train_time:134160ms step_avg:100.57ms
step:1335/1770 train_time:134264ms step_avg:100.57ms
step:1336/1770 train_time:134368ms step_avg:100.57ms
step:1337/1770 train_time:134472ms step_avg:100.58ms
step:1338/1770 train_time:134576ms step_avg:100.58ms
step:1339/1770 train_time:134681ms step_avg:100.58ms
step:1340/1770 train_time:134786ms step_avg:100.59ms
step:1341/1770 train_time:134890ms step_avg:100.59ms
step:1342/1770 train_time:134995ms step_avg:100.59ms
step:1343/1770 train_time:135099ms step_avg:100.60ms
step:1344/1770 train_time:135204ms step_avg:100.60ms
step:1345/1770 train_time:135308ms step_avg:100.60ms
step:1346/1770 train_time:135413ms step_avg:100.60ms
step:1347/1770 train_time:135516ms step_avg:100.61ms
step:1348/1770 train_time:135622ms step_avg:100.61ms
step:1349/1770 train_time:135727ms step_avg:100.61ms
step:1350/1770 train_time:135831ms step_avg:100.62ms
step:1351/1770 train_time:135935ms step_avg:100.62ms
step:1352/1770 train_time:136038ms step_avg:100.62ms
step:1353/1770 train_time:136144ms step_avg:100.62ms
step:1354/1770 train_time:136248ms step_avg:100.63ms
step:1355/1770 train_time:136352ms step_avg:100.63ms
step:1356/1770 train_time:136455ms step_avg:100.63ms
step:1357/1770 train_time:136560ms step_avg:100.63ms
step:1358/1770 train_time:136666ms step_avg:100.64ms
step:1359/1770 train_time:136770ms step_avg:100.64ms
step:1360/1770 train_time:136875ms step_avg:100.64ms
step:1361/1770 train_time:136979ms step_avg:100.65ms
step:1362/1770 train_time:137084ms step_avg:100.65ms
step:1363/1770 train_time:137189ms step_avg:100.65ms
step:1364/1770 train_time:137292ms step_avg:100.65ms
step:1365/1770 train_time:137395ms step_avg:100.66ms
step:1366/1770 train_time:137499ms step_avg:100.66ms
step:1367/1770 train_time:137606ms step_avg:100.66ms
step:1368/1770 train_time:137709ms step_avg:100.66ms
step:1369/1770 train_time:137814ms step_avg:100.67ms
step:1370/1770 train_time:137918ms step_avg:100.67ms
step:1371/1770 train_time:138024ms step_avg:100.67ms
step:1372/1770 train_time:138127ms step_avg:100.68ms
step:1373/1770 train_time:138231ms step_avg:100.68ms
step:1374/1770 train_time:138337ms step_avg:100.68ms
step:1375/1770 train_time:138441ms step_avg:100.68ms
step:1375/1770 val_loss:3.3782 train_time:138540ms step_avg:100.76ms
step:1376/1770 train_time:138560ms step_avg:100.70ms
step:1377/1770 train_time:138655ms step_avg:100.69ms
step:1378/1770 train_time:138758ms step_avg:100.70ms
step:1379/1770 train_time:138862ms step_avg:100.70ms
step:1380/1770 train_time:138966ms step_avg:100.70ms
step:1381/1770 train_time:139071ms step_avg:100.70ms
step:1382/1770 train_time:139174ms step_avg:100.70ms
step:1383/1770 train_time:139279ms step_avg:100.71ms
step:1384/1770 train_time:139383ms step_avg:100.71ms
step:1385/1770 train_time:139489ms step_avg:100.71ms
step:1386/1770 train_time:139594ms step_avg:100.72ms
step:1387/1770 train_time:139698ms step_avg:100.72ms
step:1388/1770 train_time:139802ms step_avg:100.72ms
step:1389/1770 train_time:139906ms step_avg:100.72ms
step:1390/1770 train_time:140011ms step_avg:100.73ms
step:1391/1770 train_time:140114ms step_avg:100.73ms
step:1392/1770 train_time:140218ms step_avg:100.73ms
step:1393/1770 train_time:140322ms step_avg:100.73ms
step:1394/1770 train_time:140426ms step_avg:100.74ms
step:1395/1770 train_time:140531ms step_avg:100.74ms
step:1396/1770 train_time:140636ms step_avg:100.74ms
step:1397/1770 train_time:140741ms step_avg:100.75ms
step:1398/1770 train_time:140845ms step_avg:100.75ms
step:1399/1770 train_time:140950ms step_avg:100.75ms
step:1400/1770 train_time:141054ms step_avg:100.75ms
step:1401/1770 train_time:141159ms step_avg:100.76ms
step:1402/1770 train_time:141263ms step_avg:100.76ms
step:1403/1770 train_time:141368ms step_avg:100.76ms
step:1404/1770 train_time:141472ms step_avg:100.76ms
step:1405/1770 train_time:141576ms step_avg:100.77ms
step:1406/1770 train_time:141681ms step_avg:100.77ms
step:1407/1770 train_time:141785ms step_avg:100.77ms
step:1408/1770 train_time:141889ms step_avg:100.77ms
step:1409/1770 train_time:141993ms step_avg:100.78ms
step:1410/1770 train_time:142097ms step_avg:100.78ms
step:1411/1770 train_time:142201ms step_avg:100.78ms
step:1412/1770 train_time:142305ms step_avg:100.78ms
step:1413/1770 train_time:142410ms step_avg:100.79ms
step:1414/1770 train_time:142514ms step_avg:100.79ms
step:1415/1770 train_time:142619ms step_avg:100.79ms
step:1416/1770 train_time:142723ms step_avg:100.79ms
step:1417/1770 train_time:142827ms step_avg:100.80ms
step:1418/1770 train_time:142931ms step_avg:100.80ms
step:1419/1770 train_time:143035ms step_avg:100.80ms
step:1420/1770 train_time:143139ms step_avg:100.80ms
step:1421/1770 train_time:143243ms step_avg:100.80ms
step:1422/1770 train_time:143347ms step_avg:100.81ms
step:1423/1770 train_time:143452ms step_avg:100.81ms
step:1424/1770 train_time:143556ms step_avg:100.81ms
step:1425/1770 train_time:143660ms step_avg:100.81ms
step:1426/1770 train_time:143767ms step_avg:100.82ms
step:1427/1770 train_time:143871ms step_avg:100.82ms
step:1428/1770 train_time:143976ms step_avg:100.82ms
step:1429/1770 train_time:144080ms step_avg:100.83ms
step:1430/1770 train_time:144185ms step_avg:100.83ms
step:1431/1770 train_time:144290ms step_avg:100.83ms
step:1432/1770 train_time:144394ms step_avg:100.83ms
step:1433/1770 train_time:144498ms step_avg:100.84ms
step:1434/1770 train_time:144602ms step_avg:100.84ms
step:1435/1770 train_time:144706ms step_avg:100.84ms
step:1436/1770 train_time:144813ms step_avg:100.84ms
step:1437/1770 train_time:144917ms step_avg:100.85ms
step:1438/1770 train_time:145021ms step_avg:100.85ms
step:1439/1770 train_time:145125ms step_avg:100.85ms
step:1440/1770 train_time:145229ms step_avg:100.85ms
step:1441/1770 train_time:145336ms step_avg:100.86ms
step:1442/1770 train_time:145440ms step_avg:100.86ms
step:1443/1770 train_time:145544ms step_avg:100.86ms
step:1444/1770 train_time:145649ms step_avg:100.87ms
step:1445/1770 train_time:145754ms step_avg:100.87ms
step:1446/1770 train_time:145859ms step_avg:100.87ms
step:1447/1770 train_time:145964ms step_avg:100.87ms
step:1448/1770 train_time:146070ms step_avg:100.88ms
step:1449/1770 train_time:146177ms step_avg:100.88ms
step:1450/1770 train_time:146282ms step_avg:100.88ms
step:1451/1770 train_time:146389ms step_avg:100.89ms
step:1452/1770 train_time:146495ms step_avg:100.89ms
step:1453/1770 train_time:146601ms step_avg:100.90ms
step:1454/1770 train_time:146706ms step_avg:100.90ms
step:1455/1770 train_time:146813ms step_avg:100.90ms
step:1456/1770 train_time:146919ms step_avg:100.91ms
step:1457/1770 train_time:147025ms step_avg:100.91ms
step:1458/1770 train_time:147130ms step_avg:100.91ms
step:1459/1770 train_time:147237ms step_avg:100.92ms
step:1460/1770 train_time:147342ms step_avg:100.92ms
step:1461/1770 train_time:147447ms step_avg:100.92ms
step:1462/1770 train_time:147553ms step_avg:100.93ms
step:1463/1770 train_time:147658ms step_avg:100.93ms
step:1464/1770 train_time:147765ms step_avg:100.93ms
step:1465/1770 train_time:147870ms step_avg:100.94ms
step:1466/1770 train_time:147977ms step_avg:100.94ms
step:1467/1770 train_time:148084ms step_avg:100.94ms
step:1468/1770 train_time:148191ms step_avg:100.95ms
step:1469/1770 train_time:148296ms step_avg:100.95ms
step:1470/1770 train_time:148401ms step_avg:100.95ms
step:1471/1770 train_time:148507ms step_avg:100.96ms
step:1472/1770 train_time:148612ms step_avg:100.96ms
step:1473/1770 train_time:148719ms step_avg:100.96ms
step:1474/1770 train_time:148825ms step_avg:100.97ms
step:1475/1770 train_time:148931ms step_avg:100.97ms
step:1476/1770 train_time:149036ms step_avg:100.97ms
step:1477/1770 train_time:149142ms step_avg:100.98ms
step:1478/1770 train_time:149248ms step_avg:100.98ms
step:1479/1770 train_time:149353ms step_avg:100.98ms
step:1480/1770 train_time:149458ms step_avg:100.99ms
step:1481/1770 train_time:149566ms step_avg:100.99ms
step:1482/1770 train_time:149671ms step_avg:100.99ms
step:1483/1770 train_time:149776ms step_avg:101.00ms
step:1484/1770 train_time:149882ms step_avg:101.00ms
step:1485/1770 train_time:149987ms step_avg:101.00ms
step:1486/1770 train_time:150092ms step_avg:101.00ms
step:1487/1770 train_time:150197ms step_avg:101.01ms
step:1488/1770 train_time:150303ms step_avg:101.01ms
step:1489/1770 train_time:150409ms step_avg:101.01ms
step:1490/1770 train_time:150515ms step_avg:101.02ms
step:1491/1770 train_time:150621ms step_avg:101.02ms
step:1492/1770 train_time:150727ms step_avg:101.02ms
step:1493/1770 train_time:150835ms step_avg:101.03ms
step:1494/1770 train_time:150945ms step_avg:101.03ms
step:1495/1770 train_time:151050ms step_avg:101.04ms
step:1496/1770 train_time:151154ms step_avg:101.04ms
step:1497/1770 train_time:151260ms step_avg:101.04ms
step:1498/1770 train_time:151364ms step_avg:101.04ms
step:1499/1770 train_time:151469ms step_avg:101.05ms
step:1500/1770 train_time:151573ms step_avg:101.05ms
step:1500/1770 val_loss:3.3399 train_time:151673ms step_avg:101.12ms
step:1501/1770 train_time:151693ms step_avg:101.06ms
step:1502/1770 train_time:151792ms step_avg:101.06ms
step:1503/1770 train_time:151896ms step_avg:101.06ms
step:1504/1770 train_time:152002ms step_avg:101.07ms
step:1505/1770 train_time:152109ms step_avg:101.07ms
step:1506/1770 train_time:152215ms step_avg:101.07ms
step:1507/1770 train_time:152319ms step_avg:101.07ms
step:1508/1770 train_time:152426ms step_avg:101.08ms
step:1509/1770 train_time:152531ms step_avg:101.08ms
step:1510/1770 train_time:152635ms step_avg:101.08ms
step:1511/1770 train_time:152741ms step_avg:101.09ms
step:1512/1770 train_time:152847ms step_avg:101.09ms
step:1513/1770 train_time:152951ms step_avg:101.09ms
step:1514/1770 train_time:153057ms step_avg:101.09ms
step:1515/1770 train_time:153164ms step_avg:101.10ms
step:1516/1770 train_time:153270ms step_avg:101.10ms
step:1517/1770 train_time:153375ms step_avg:101.10ms
step:1518/1770 train_time:153483ms step_avg:101.11ms
step:1519/1770 train_time:153587ms step_avg:101.11ms
step:1520/1770 train_time:153693ms step_avg:101.11ms
step:1521/1770 train_time:153798ms step_avg:101.12ms
step:1522/1770 train_time:153903ms step_avg:101.12ms
step:1523/1770 train_time:154010ms step_avg:101.12ms
step:1524/1770 train_time:154115ms step_avg:101.13ms
step:1525/1770 train_time:154221ms step_avg:101.13ms
step:1526/1770 train_time:154326ms step_avg:101.13ms
step:1527/1770 train_time:154431ms step_avg:101.13ms
step:1528/1770 train_time:154538ms step_avg:101.14ms
step:1529/1770 train_time:154643ms step_avg:101.14ms
step:1530/1770 train_time:154748ms step_avg:101.14ms
step:1531/1770 train_time:154854ms step_avg:101.15ms
step:1532/1770 train_time:154958ms step_avg:101.15ms
step:1533/1770 train_time:155065ms step_avg:101.15ms
step:1534/1770 train_time:155171ms step_avg:101.15ms
step:1535/1770 train_time:155276ms step_avg:101.16ms
step:1536/1770 train_time:155381ms step_avg:101.16ms
step:1537/1770 train_time:155487ms step_avg:101.16ms
step:1538/1770 train_time:155594ms step_avg:101.17ms
step:1539/1770 train_time:155700ms step_avg:101.17ms
step:1540/1770 train_time:155809ms step_avg:101.17ms
step:1541/1770 train_time:155916ms step_avg:101.18ms
step:1542/1770 train_time:156021ms step_avg:101.18ms
step:1543/1770 train_time:156127ms step_avg:101.18ms
step:1544/1770 train_time:156233ms step_avg:101.19ms
step:1545/1770 train_time:156339ms step_avg:101.19ms
step:1546/1770 train_time:156444ms step_avg:101.19ms
step:1547/1770 train_time:156550ms step_avg:101.20ms
step:1548/1770 train_time:156655ms step_avg:101.20ms
step:1549/1770 train_time:156760ms step_avg:101.20ms
step:1550/1770 train_time:156866ms step_avg:101.20ms
step:1551/1770 train_time:156971ms step_avg:101.21ms
step:1552/1770 train_time:157078ms step_avg:101.21ms
step:1553/1770 train_time:157184ms step_avg:101.21ms
step:1554/1770 train_time:157289ms step_avg:101.22ms
step:1555/1770 train_time:157395ms step_avg:101.22ms
step:1556/1770 train_time:157499ms step_avg:101.22ms
step:1557/1770 train_time:157605ms step_avg:101.22ms
step:1558/1770 train_time:157710ms step_avg:101.23ms
step:1559/1770 train_time:157815ms step_avg:101.23ms
step:1560/1770 train_time:157919ms step_avg:101.23ms
step:1561/1770 train_time:158026ms step_avg:101.23ms
step:1562/1770 train_time:158132ms step_avg:101.24ms
step:1563/1770 train_time:158238ms step_avg:101.24ms
step:1564/1770 train_time:158344ms step_avg:101.24ms
step:1565/1770 train_time:158449ms step_avg:101.25ms
step:1566/1770 train_time:158554ms step_avg:101.25ms
step:1567/1770 train_time:158660ms step_avg:101.25ms
step:1568/1770 train_time:158765ms step_avg:101.25ms
step:1569/1770 train_time:158874ms step_avg:101.26ms
step:1570/1770 train_time:158979ms step_avg:101.26ms
step:1571/1770 train_time:159085ms step_avg:101.26ms
step:1572/1770 train_time:159190ms step_avg:101.27ms
step:1573/1770 train_time:159299ms step_avg:101.27ms
step:1574/1770 train_time:159403ms step_avg:101.27ms
step:1575/1770 train_time:159509ms step_avg:101.28ms
step:1576/1770 train_time:159614ms step_avg:101.28ms
step:1577/1770 train_time:159719ms step_avg:101.28ms
step:1578/1770 train_time:159826ms step_avg:101.28ms
step:1579/1770 train_time:159931ms step_avg:101.29ms
step:1580/1770 train_time:160037ms step_avg:101.29ms
step:1581/1770 train_time:160145ms step_avg:101.29ms
step:1582/1770 train_time:160252ms step_avg:101.30ms
step:1583/1770 train_time:160357ms step_avg:101.30ms
step:1584/1770 train_time:160463ms step_avg:101.30ms
step:1585/1770 train_time:160568ms step_avg:101.30ms
step:1586/1770 train_time:160677ms step_avg:101.31ms
step:1587/1770 train_time:160784ms step_avg:101.31ms
step:1588/1770 train_time:160889ms step_avg:101.32ms
step:1589/1770 train_time:160996ms step_avg:101.32ms
step:1590/1770 train_time:161101ms step_avg:101.32ms
step:1591/1770 train_time:161206ms step_avg:101.32ms
step:1592/1770 train_time:161312ms step_avg:101.33ms
step:1593/1770 train_time:161417ms step_avg:101.33ms
step:1594/1770 train_time:161524ms step_avg:101.33ms
step:1595/1770 train_time:161629ms step_avg:101.33ms
step:1596/1770 train_time:161736ms step_avg:101.34ms
step:1597/1770 train_time:161841ms step_avg:101.34ms
step:1598/1770 train_time:161947ms step_avg:101.34ms
step:1599/1770 train_time:162055ms step_avg:101.35ms
step:1600/1770 train_time:162161ms step_avg:101.35ms
step:1601/1770 train_time:162268ms step_avg:101.35ms
step:1602/1770 train_time:162373ms step_avg:101.36ms
step:1603/1770 train_time:162478ms step_avg:101.36ms
step:1604/1770 train_time:162583ms step_avg:101.36ms
step:1605/1770 train_time:162688ms step_avg:101.36ms
step:1606/1770 train_time:162793ms step_avg:101.37ms
step:1607/1770 train_time:162902ms step_avg:101.37ms
step:1608/1770 train_time:163009ms step_avg:101.37ms
step:1609/1770 train_time:163114ms step_avg:101.38ms
step:1610/1770 train_time:163220ms step_avg:101.38ms
step:1611/1770 train_time:163327ms step_avg:101.38ms
step:1612/1770 train_time:163433ms step_avg:101.39ms
step:1613/1770 train_time:163538ms step_avg:101.39ms
step:1614/1770 train_time:163645ms step_avg:101.39ms
step:1615/1770 train_time:163751ms step_avg:101.39ms
step:1616/1770 train_time:163857ms step_avg:101.40ms
step:1617/1770 train_time:163964ms step_avg:101.40ms
step:1618/1770 train_time:164071ms step_avg:101.40ms
step:1619/1770 train_time:164177ms step_avg:101.41ms
step:1620/1770 train_time:164283ms step_avg:101.41ms
step:1621/1770 train_time:164389ms step_avg:101.41ms
step:1622/1770 train_time:164495ms step_avg:101.41ms
step:1623/1770 train_time:164604ms step_avg:101.42ms
step:1624/1770 train_time:164709ms step_avg:101.42ms
step:1625/1770 train_time:164813ms step_avg:101.42ms
step:1625/1770 val_loss:3.3055 train_time:164914ms step_avg:101.49ms
step:1626/1770 train_time:164933ms step_avg:101.44ms
step:1627/1770 train_time:165029ms step_avg:101.43ms
step:1628/1770 train_time:165133ms step_avg:101.43ms
step:1629/1770 train_time:165238ms step_avg:101.44ms
step:1630/1770 train_time:165343ms step_avg:101.44ms
step:1631/1770 train_time:165448ms step_avg:101.44ms
step:1632/1770 train_time:165553ms step_avg:101.44ms
step:1633/1770 train_time:165660ms step_avg:101.44ms
step:1634/1770 train_time:165764ms step_avg:101.45ms
step:1635/1770 train_time:165869ms step_avg:101.45ms
step:1636/1770 train_time:165976ms step_avg:101.45ms
step:1637/1770 train_time:166082ms step_avg:101.46ms
step:1638/1770 train_time:166187ms step_avg:101.46ms
step:1639/1770 train_time:166293ms step_avg:101.46ms
step:1640/1770 train_time:166399ms step_avg:101.46ms
step:1641/1770 train_time:166505ms step_avg:101.47ms
step:1642/1770 train_time:166609ms step_avg:101.47ms
step:1643/1770 train_time:166715ms step_avg:101.47ms
step:1644/1770 train_time:166822ms step_avg:101.47ms
step:1645/1770 train_time:166926ms step_avg:101.47ms
step:1646/1770 train_time:167034ms step_avg:101.48ms
step:1647/1770 train_time:167141ms step_avg:101.48ms
step:1648/1770 train_time:167246ms step_avg:101.48ms
step:1649/1770 train_time:167351ms step_avg:101.49ms
step:1650/1770 train_time:167457ms step_avg:101.49ms
step:1651/1770 train_time:167563ms step_avg:101.49ms
step:1652/1770 train_time:167668ms step_avg:101.49ms
step:1653/1770 train_time:167773ms step_avg:101.50ms
step:1654/1770 train_time:167881ms step_avg:101.50ms
step:1655/1770 train_time:167989ms step_avg:101.50ms
step:1656/1770 train_time:168094ms step_avg:101.51ms
step:1657/1770 train_time:168202ms step_avg:101.51ms
step:1658/1770 train_time:168307ms step_avg:101.51ms
step:1659/1770 train_time:168413ms step_avg:101.51ms
step:1660/1770 train_time:168519ms step_avg:101.52ms
step:1661/1770 train_time:168625ms step_avg:101.52ms
step:1662/1770 train_time:168731ms step_avg:101.52ms
step:1663/1770 train_time:168836ms step_avg:101.52ms
step:1664/1770 train_time:168941ms step_avg:101.53ms
step:1665/1770 train_time:169046ms step_avg:101.53ms
step:1666/1770 train_time:169151ms step_avg:101.53ms
step:1667/1770 train_time:169256ms step_avg:101.53ms
step:1668/1770 train_time:169362ms step_avg:101.54ms
step:1669/1770 train_time:169466ms step_avg:101.54ms
step:1670/1770 train_time:169571ms step_avg:101.54ms
step:1671/1770 train_time:169678ms step_avg:101.54ms
step:1672/1770 train_time:169783ms step_avg:101.54ms
step:1673/1770 train_time:169889ms step_avg:101.55ms
step:1674/1770 train_time:169994ms step_avg:101.55ms
step:1675/1770 train_time:170099ms step_avg:101.55ms
step:1676/1770 train_time:170205ms step_avg:101.55ms
step:1677/1770 train_time:170314ms step_avg:101.56ms
step:1678/1770 train_time:170419ms step_avg:101.56ms
step:1679/1770 train_time:170524ms step_avg:101.56ms
step:1680/1770 train_time:170629ms step_avg:101.56ms
step:1681/1770 train_time:170734ms step_avg:101.57ms
step:1682/1770 train_time:170842ms step_avg:101.57ms
step:1683/1770 train_time:170947ms step_avg:101.57ms
step:1684/1770 train_time:171052ms step_avg:101.57ms
step:1685/1770 train_time:171157ms step_avg:101.58ms
step:1686/1770 train_time:171263ms step_avg:101.58ms
step:1687/1770 train_time:171372ms step_avg:101.58ms
step:1688/1770 train_time:171478ms step_avg:101.59ms
step:1689/1770 train_time:171584ms step_avg:101.59ms
step:1690/1770 train_time:171689ms step_avg:101.59ms
step:1691/1770 train_time:171794ms step_avg:101.59ms
step:1692/1770 train_time:171900ms step_avg:101.60ms
step:1693/1770 train_time:172007ms step_avg:101.60ms
step:1694/1770 train_time:172112ms step_avg:101.60ms
step:1695/1770 train_time:172218ms step_avg:101.60ms
step:1696/1770 train_time:172324ms step_avg:101.61ms
step:1697/1770 train_time:172432ms step_avg:101.61ms
step:1698/1770 train_time:172538ms step_avg:101.61ms
step:1699/1770 train_time:172643ms step_avg:101.61ms
step:1700/1770 train_time:172748ms step_avg:101.62ms
step:1701/1770 train_time:172853ms step_avg:101.62ms
step:1702/1770 train_time:172959ms step_avg:101.62ms
step:1703/1770 train_time:173065ms step_avg:101.62ms
step:1704/1770 train_time:173171ms step_avg:101.63ms
step:1705/1770 train_time:173276ms step_avg:101.63ms
step:1706/1770 train_time:173381ms step_avg:101.63ms
step:1707/1770 train_time:173488ms step_avg:101.63ms
step:1708/1770 train_time:173594ms step_avg:101.64ms
step:1709/1770 train_time:173701ms step_avg:101.64ms
step:1710/1770 train_time:173812ms step_avg:101.64ms
step:1711/1770 train_time:173920ms step_avg:101.65ms
step:1712/1770 train_time:174026ms step_avg:101.65ms
step:1713/1770 train_time:174132ms step_avg:101.65ms
step:1714/1770 train_time:174238ms step_avg:101.66ms
step:1715/1770 train_time:174344ms step_avg:101.66ms
step:1716/1770 train_time:174451ms step_avg:101.66ms
step:1717/1770 train_time:174556ms step_avg:101.66ms
step:1718/1770 train_time:174663ms step_avg:101.67ms
step:1719/1770 train_time:174770ms step_avg:101.67ms
step:1720/1770 train_time:174877ms step_avg:101.67ms
step:1721/1770 train_time:174983ms step_avg:101.68ms
step:1722/1770 train_time:175093ms step_avg:101.68ms
step:1723/1770 train_time:175201ms step_avg:101.68ms
step:1724/1770 train_time:175309ms step_avg:101.69ms
step:1725/1770 train_time:175418ms step_avg:101.69ms
step:1726/1770 train_time:175526ms step_avg:101.70ms
step:1727/1770 train_time:175633ms step_avg:101.70ms
step:1728/1770 train_time:175742ms step_avg:101.70ms
step:1729/1770 train_time:175848ms step_avg:101.71ms
step:1730/1770 train_time:175955ms step_avg:101.71ms
step:1731/1770 train_time:176063ms step_avg:101.71ms
step:1732/1770 train_time:176169ms step_avg:101.71ms
step:1733/1770 train_time:176277ms step_avg:101.72ms
step:1734/1770 train_time:176383ms step_avg:101.72ms
step:1735/1770 train_time:176490ms step_avg:101.72ms
step:1736/1770 train_time:176596ms step_avg:101.73ms
step:1737/1770 train_time:176703ms step_avg:101.73ms
step:1738/1770 train_time:176809ms step_avg:101.73ms
step:1739/1770 train_time:176915ms step_avg:101.73ms
step:1740/1770 train_time:177021ms step_avg:101.74ms
step:1741/1770 train_time:177129ms step_avg:101.74ms
step:1742/1770 train_time:177240ms step_avg:101.75ms
step:1743/1770 train_time:177348ms step_avg:101.75ms
step:1744/1770 train_time:177453ms step_avg:101.75ms
step:1745/1770 train_time:177559ms step_avg:101.75ms
step:1746/1770 train_time:177668ms step_avg:101.76ms
step:1747/1770 train_time:177774ms step_avg:101.76ms
step:1748/1770 train_time:177882ms step_avg:101.76ms
step:1749/1770 train_time:177989ms step_avg:101.77ms
step:1750/1770 train_time:178095ms step_avg:101.77ms
step:1750/1770 val_loss:3.2785 train_time:178196ms step_avg:101.83ms
step:1751/1770 train_time:178216ms step_avg:101.78ms
step:1752/1770 train_time:178315ms step_avg:101.78ms
step:1753/1770 train_time:178421ms step_avg:101.78ms
step:1754/1770 train_time:178527ms step_avg:101.78ms
step:1755/1770 train_time:178634ms step_avg:101.79ms
step:1756/1770 train_time:178741ms step_avg:101.79ms
step:1757/1770 train_time:178847ms step_avg:101.79ms
step:1758/1770 train_time:178953ms step_avg:101.79ms
step:1759/1770 train_time:179059ms step_avg:101.80ms
step:1760/1770 train_time:179166ms step_avg:101.80ms
step:1761/1770 train_time:179276ms step_avg:101.80ms
step:1762/1770 train_time:179384ms step_avg:101.81ms
step:1763/1770 train_time:179490ms step_avg:101.81ms
step:1764/1770 train_time:179597ms step_avg:101.81ms
step:1765/1770 train_time:179703ms step_avg:101.81ms
step:1766/1770 train_time:179813ms step_avg:101.82ms
step:1767/1770 train_time:179917ms step_avg:101.82ms
step:1768/1770 train_time:180024ms step_avg:101.82ms
step:1769/1770 train_time:180130ms step_avg:101.83ms
step:1770/1770 train_time:180235ms step_avg:101.83ms
step:1770/1770 val_loss:3.2756 train_time:180337ms step_avg:101.89ms
peak memory allocated: 30724 MiB reserved: 45392 MiB
