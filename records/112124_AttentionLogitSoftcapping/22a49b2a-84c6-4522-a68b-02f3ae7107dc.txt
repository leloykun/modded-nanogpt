====================================================================================================
import os
import sys
with open(sys.argv[0]) as f:
    code = f.read() # read the code of this file ASAP, for logging
import uuid
import glob
import time
from dataclasses import dataclass

import numpy as np
import torch
from torch import nn
import torch.nn.functional as F
import torch.distributed as dist
import torch._inductor.config as config
from torch.nn.parallel import DistributedDataParallel as DDP
# Use of FlexAttention contributed by @KoszarskyB
from torch.nn.attention.flex_attention import flex_attention, create_block_mask, BlockMask, _score_mod_signature
from torch._inductor.lowering import make_pointwise, register_lowering
# Some internal torch.compile details
from torch._inductor.virtualized import ops
from functools import partial
flex_attention = torch.compile(flex_attention, dynamic=False)
create_block_mask = torch.compile(create_block_mask, dynamic=False)

# -----------------------------------------------------------------------------
# Muon optimizer

def zeropower_via_svd(G, steps=None):
    U, S, V = G.svd()
    return U @ V.T

@torch.compile
def zeropower_via_newtonschulz5(G, steps=10, eps=1e-7):
    """
    Newton-Schulz iteration to compute the zeroth power / orthogonalization of G. We opt to use a
    quintic iteration whose coefficients are selected to maximize the slope at zero. For the purpose
    of minimizing steps, it turns out to be empirically effective to keep increasing the slope at
    zero even beyond the point where the iteration no longer converges all the way to one everywhere
    on the interval. This iteration therefore does not produce UV^T but rather something like US'V^T
    where S' is diagonal with S_{ii}' ~ Uniform(0.5, 1.5), which turns out not to hurt model
    performance at all relative to UV^T, where USV^T = G is the SVD.
    """
    assert len(G.shape) == 2
    a, b, c = (3.4445, -4.7750,  2.0315)
    X = G.bfloat16()
    X /= (X.norm() + eps) # ensure top singular value <= 1
    if G.size(0) > G.size(1):
        X = X.T
    for _ in range(steps):
        A = X @ X.T
        B = b * A + c * A @ A # adapted from suggestion by @jxbz, @leloykun, and @YouJiacheng
        X = a * X + B @ X
    if G.size(0) > G.size(1):
        X = X.T
    return X

zeropower_backends = dict(svd=zeropower_via_svd, newtonschulz5=zeropower_via_newtonschulz5)

class Muon(torch.optim.Optimizer):
    """
    Muon - MomentUm Orthogonalized by Newton-schulz

    Muon internally runs standard SGD-momentum, and then performs an orthogonalization post-
    processing step, in which each 2D parameter's update is replaced with the nearest orthogonal
    matrix. To efficiently orthogonalize each update, we use a Newton-Schulz iteration, which has
    the advantage that it can be stably run in bfloat16 on the GPU.

    Some warnings:
    - This optimizer assumes that all parameters passed in are 2D.
    - It should not be used for the embedding layer, the final fully connected layer, or any {0,1}-D
    parameters; those should all be optimized by a standard method (e.g., AdamW).
    - To use it with 4D convolutional filters, it works well to just flatten their last 3 dimensions.
    - We believe it is unlikely to work well for training with small batch size.
    - We believe it may not work well for finetuning pretrained models, but we haven't tested this.
    - We have not yet tried this optimizer for training scenarios larger than NanoGPT (124M).

    Arguments:
        lr: The learning rate used by the internal SGD.
        momentum: The momentum used by the internal SGD.
        nesterov: Whether to use Nesterov-style momentum in the internal SGD. (recommended)
        backend: The chosen backend for the orthogonalization step. (recommended: 'newtonschulz5')
        backend_steps: The number of iteration steps to use in the backend, if it is iterative.
    """
    def __init__(self, params, lr=0.02, momentum=0.95, nesterov=True,
                 backend='newtonschulz5', backend_steps=5):
        defaults = dict(lr=lr, momentum=momentum, nesterov=nesterov, backend=backend, backend_steps=backend_steps)
        super().__init__(params, defaults)

    def step(self):

        for group in self.param_groups:

            lr = group['lr']
            momentum = group['momentum']
            zeropower_backend = zeropower_backends[group['backend']]

            # generate weight updates in distributed fashion
            total_params = sum(p.numel() for p in group['params'])
            updates_flat = torch.zeros(total_params, device='cuda', dtype=torch.bfloat16)
            curr_idx = 0
            for i, p in enumerate(group['params']):
                # luckily this will perfectly distribute a transformer with multiple of 4 layers to 8 GPUs
                if i % int(os.environ['WORLD_SIZE']) == int(os.environ['RANK']):
                    g = p.grad
                    assert g is not None
                    state = self.state[p]
                    if 'momentum_buffer' not in state:
                        state['momentum_buffer'] = torch.zeros_like(g)
                    buf = state['momentum_buffer']
                    buf.mul_(momentum).add_(g)
                    if group['nesterov']:
                        g = g.add(buf, alpha=momentum)
                    g = zeropower_backend(g, steps=group['backend_steps'])
                    g *= max(1, g.size(0)/g.size(1))**0.5
                    updates_flat[curr_idx:curr_idx+p.numel()] = g.flatten()
                curr_idx += p.numel()

            # sync updates across devices. we are not memory-constrained so can do this simple deserialization
            dist.all_reduce(updates_flat, op=dist.ReduceOp.SUM)

            # deserialize and apply updates
            curr_idx = 0
            for p in group['params']:
                g = updates_flat[curr_idx:curr_idx+p.numel()].view_as(p.data).type_as(p.data)
                p.data.add_(g, alpha=-lr)
                curr_idx += p.numel()

# -----------------------------------------------------------------------------
# Attention Tanh softcapping

@torch.library.custom_op("approx::tanh", mutates_args=())
def _tanh_approx(inp: torch.Tensor) -> torch.Tensor:
    return torch.tanh(inp)

@_tanh_approx.register_fake
def _(inp: torch.Tensor) -> torch.Tensor:
    return torch.tanh(inp)

def _tanh_approx_lowering(inp):
    fn = partial(ops.inline_asm_elementwise, asm="tanh.approx.f32 $0, $1;")
    return make_pointwise(fn)(inp)

register_lowering(torch.ops.approx.tanh)(_tanh_approx_lowering)

class _TanhApprox(torch.autograd.Function):
    @staticmethod
    def forward(x):
        return torch.ops.approx.tanh(x)

    @staticmethod
    def setup_context(ctx, inputs, output):
        (x,) = inputs
        result = output
        ctx.save_for_backward(result)

    @staticmethod
    def backward(ctx, grad_output):
        (result,) = ctx.saved_tensors
        return grad_output * (1 - result * result)

    @staticmethod
    def vmap(info, in_dims, x):
        return torch.tanh(x), 0

_tanh_approx = _TanhApprox.apply

def generate_tanh_softcap(soft_cap: int, approx: bool=True) -> _score_mod_signature:
    tanh = _tanh_approx if approx else torch.tanh

    def tanh_softcap(score, b, h, q_idx, kv_idx):
        return soft_cap * tanh(score / soft_cap)

    prefix = "tanh_softcap_approx" if approx else "tanh_softcap"
    tanh_softcap.__name__ = f"{prefix}_{soft_cap}"

    return tanh_softcap

# -----------------------------------------------------------------------------
# PyTorch nn.Module definitions for the GPT-2 model

class Rotary(torch.nn.Module):

    def __init__(self, dim, base=10000):
        super().__init__()
        self.dim = dim
        self.base = base
        self.inv_freq = None
        self.seq_len_cached = None
        self.cos_cached = None
        self.sin_cached = None

    def forward(self, x):
        seq_len = x.shape[1]
        if seq_len != self.seq_len_cached:
            self.inv_freq = 1.0 / (self.base ** (torch.arange(0, self.dim, 2, device=x.device).float() / self.dim))
            self.seq_len_cached = seq_len
            t = torch.arange(seq_len, device=x.device).type_as(self.inv_freq)
            freqs = torch.outer(t, self.inv_freq)
            self.cos_cached = freqs.cos().bfloat16()
            self.sin_cached = freqs.sin().bfloat16()
        return self.cos_cached[None, :, None, :], self.sin_cached[None, :, None, :]

def apply_rotary_emb(x, cos, sin):
    assert x.ndim == 4 # multihead attention
    d = x.shape[3]//2
    x1 = x[..., :d]
    x2 = x[..., d:]
    y1 = x1 * cos + x2 * sin
    y2 = x1 * (-sin) + x2 * cos
    return torch.cat([y1, y2], 3).type_as(x)

class CastedLinear(nn.Linear):
    def forward(self, x):
        return F.linear(x, self.weight.to(x.dtype))

class CausalSelfAttention(nn.Module):

    def __init__(self, config):
        super().__init__()
        self.n_head = config.n_head
        self.n_embd = config.n_embd
        self.head_dim = self.n_embd // self.n_head
        assert self.n_embd % self.n_head == 0
        self.c_q = CastedLinear(self.n_embd, self.n_embd, bias=False)
        self.c_k = CastedLinear(self.n_embd, self.n_embd, bias=False)
        self.c_v = CastedLinear(self.n_embd, self.n_embd, bias=False)
        # output projection
        self.c_proj = CastedLinear(self.n_embd, self.n_embd, bias=False)
        self.c_proj.weight.data.zero_() # zero init suggested by @Grad62304977
        self.rotary = Rotary(self.head_dim)
        self.lamb = nn.Parameter(torch.tensor(0.5)) # @Grad62304977

    def forward(self, x, v1, block_mask: BlockMask, score_mod: _score_mod_signature):
        B, T, C = x.size() # batch size, sequence length, embedding dimensionality (n_embd)
        q = self.c_q(x).view(B, T, self.n_head, self.head_dim)
        k = self.c_k(x).view(B, T, self.n_head, self.head_dim)
        v = self.c_v(x).view(B, T, self.n_head, self.head_dim)
        if v1 is None:
            v1 = v # This happens if we are in the first block. v needs to be accessed by subsequent blocks
        v = (1 - self.lamb) * v + self.lamb * v1.view_as(v) # @Grad62304977
        cos, sin = self.rotary(q)
        q, k = F.rms_norm(q, (q.size(-1),)), F.rms_norm(k, (k.size(-1),)) # QK norm suggested by @Grad62304977
        q, k = apply_rotary_emb(q, cos, sin), apply_rotary_emb(k, cos, sin)
        y = flex_attention(q.transpose(1, 2), k.transpose(1, 2), v.transpose(1, 2), score_mod=score_mod, block_mask=block_mask)
        y = y.transpose(1, 2).contiguous().view_as(x) # re-assemble all head outputs side by side
        y = self.c_proj(y)
        return y, v1

class MLP(nn.Module):

    def __init__(self, config):
        super().__init__()
        self.c_fc    = CastedLinear(config.n_embd, 4 * config.n_embd, bias=False)
        self.c_proj  = CastedLinear(4 * config.n_embd, config.n_embd, bias=False)
        self.c_proj.weight.data.zero_() # zero init suggested by @Grad62304977

    def forward(self, x):
        x = self.c_fc(x)
        x = F.relu(x).square() # https://arxiv.org/abs/2109.08668v2; ~1-2% better than GELU; suggested by @SKYLINEZ007 and @Grad62304977
        x = self.c_proj(x)
        return x

class Block(nn.Module):

    def __init__(self, config):
        super().__init__()
        self.attn = CausalSelfAttention(config)
        self.mlp = MLP(config)
        self.lambdas = nn.Parameter(torch.tensor([1., 0.]))

    def forward(self, x, v1, x0, block_mask: BlockMask, score_mod: _score_mod_signature):
        x = self.lambdas[0] * x + self.lambdas[1] * x0
        x1, v1 = self.attn(F.rms_norm(x, (x.size(-1),)), v1, block_mask, score_mod)
        x = x + x1
        x = x + self.mlp(F.rms_norm(x, (x.size(-1),)))
        return x, v1

# -----------------------------------------------------------------------------
# The main GPT-2 model

@dataclass
class GPTConfig:
    vocab_size : int = 50304
    n_layer : int = 12
    n_head : int = 6 # head dim 128 suggested by @Grad62304977
    n_embd : int = 768
    attention_soft_cap : int = 50
    lm_head_soft_cap : int = 30

class GPT(nn.Module):

    def __init__(self, config: GPTConfig):
        super().__init__()
        self.attention_soft_cap = config.attention_soft_cap
        self.lm_head_soft_cap = config.lm_head_soft_cap

        # U-net design by @brendanh0gan
        self.num_encoder_layers = config.n_layer // 2 # Half of the layers for encoder
        self.num_decoder_layers = config.n_layer - self.num_encoder_layers # Remaining for decoder
        # Add learnable skip connection weights for decoder layers
        self.skip_weights = nn.Parameter(torch.ones(self.num_decoder_layers))

        self.transformer = nn.ModuleDict(dict(
            wte = nn.Embedding(config.vocab_size, config.n_embd),
            h = nn.ModuleList([Block(config) for _ in range(config.n_layer)]),
        ))
        self.lm_head = CastedLinear(config.n_embd, config.vocab_size, bias=False)
        self.lm_head.weight.data.zero_() # @Grad62304977

    def forward(self, idx, target):

        docs = (idx == 50256).cumsum(0)
        def document_causal_mask(b, h, q_idx, kv_idx):
            causal_mask = q_idx >= kv_idx
            document_mask = docs[q_idx] == docs[kv_idx]
            window_mask = q_idx - kv_idx < 1024
            return causal_mask & document_mask & window_mask

        softcap_mod = generate_tanh_softcap(self.attention_soft_cap, approx=True)  # @leloykun

        S = len(idx)
        block_mask = create_block_mask(document_causal_mask, None, None, S, S, device="cuda", _compile=True)

        # forward the GPT model itself
        x = self.transformer.wte(idx[None]) # token embeddings of shape (b, t, n_embd)
        x = F.rms_norm(x, (x.size(-1),)) # @Grad62304977
        x0 = x
        v1 = None

        # Store outputs for U-Net skip connections
        skip_connections = []
        # Encoder pass - process only the first half of the blocks
        for i in range(self.num_encoder_layers):
            x, v1 = self.transformer.h[i](x, v1, x0, block_mask, softcap_mod)
            skip_connections.append(x)
        # Decoder pass - process the remaining blocks with weighted skip connections
        for i in range(self.num_decoder_layers):
            x = x + self.skip_weights[i] * skip_connections.pop()
            x, v1 = self.transformer.h[self.num_encoder_layers + i](x, v1, x0, block_mask, softcap_mod)

        x = F.rms_norm(x, (x.size(-1),))
        logits = self.lm_head(x)
        logits = self.lm_head_soft_cap * torch.tanh(logits / self.lm_head_soft_cap) # @Grad62304977
        logits = logits.float()
        loss = F.cross_entropy(logits.view(-1, logits.size(-1)), target.view(-1))
        return loss

# -----------------------------------------------------------------------------
# Our own simple Distributed Data Loader

def _peek_data_shard(filename):
    # only reads the header, returns header data
    with open(filename, "rb") as f:
        # first read the header, which is 256 int32 integers (4 bytes each)
        header = np.frombuffer(f.read(256*4), dtype=np.int32)
    if header[0] != 20240520:
        print("ERROR: magic number mismatch in the data .bin file!")
        print("---> HINT: Are you passing in a correct file with --input_bin?")
        print("---> HINT: Dataset encoding changed recently, re-run data prepro or refer again to README")
        print("---> HINT: For example re-run: `python dev/data/tinyshakespeare.py`, then re-try")
        exit(1)
    assert header[1] == 1, "unsupported version"
    ntok = header[2] # number of tokens (claimed)
    return ntok # for now just return the number of tokens

def _load_data_shard(filename):
    with open(filename, "rb") as f:
        # first read the header, which is 256 int32 integers (4 bytes each)
        header = np.frombuffer(f.read(256*4), dtype=np.int32)
        assert header[0] == 20240520, "magic number mismatch in the data .bin file"
        assert header[1] == 1, "unsupported version"
        ntok = header[2] # number of tokens (claimed)
        # the rest of it are tokens, stored as uint16
        tokens = np.frombuffer(f.read(), dtype=np.uint16)
    assert len(tokens) == ntok, "number of tokens read does not match header?"
    return tokens

class DistributedDataLoader:
    def __init__(self, filename_pattern, B, T, process_rank, num_processes):
        self.process_rank = process_rank
        self.num_processes = num_processes
        self.B = B
        self.T = T

        # glob files that match the pattern
        self.files = sorted(glob.glob(filename_pattern))
        assert len(self.files) > 0, f"did not find any files that match the pattern {filename_pattern}"

        # load and validate all data shards, count number of tokens in total
        ntok_total = 0
        for fname in self.files:
            shard_ntok = _peek_data_shard(fname)
            assert shard_ntok >= num_processes * B * T + 1
            ntok_total += int(shard_ntok)
        self.ntok_total = ntok_total

        self.reset()

    def reset(self):
        self.current_shard = -1
        self.advance()

    def advance(self): # advance to next data shard
        self.current_shard = (self.current_shard + 1) % len(self.files)
        self.current_position = self.process_rank * self.B * self.T
        self.tokens = _load_data_shard(self.files[self.current_shard])

    def next_batch(self):
        batch_size = self.B * self.T * self.num_processes
        buf = self.tokens[self.current_position:self.current_position+self.B*self.T+1]
        buf = torch.tensor(buf.astype(np.int32), dtype=torch.long)
        x = buf[:-1] # inputs
        y = buf[1:] # targets
        # advance current position and load next shard if necessary
        self.current_position += batch_size
        if self.current_position + batch_size >= len(self.tokens):
            self.advance()
        return x.cuda(), y.cuda()

# -----------------------------------------------------------------------------
# int main

@dataclass
class Hyperparameters:
    # data hyperparams
    input_bin : str = 'data/fineweb10B/fineweb_train_*.bin' # input .bin to train on
    input_val_bin : str = 'data/fineweb10B/fineweb_val_*.bin' # input .bin to eval validation loss on
    # optimization hyperparams
    batch_size : int = 8 # batch size, in sequences, across all devices
    device_batch_size : int = 1 # batch size, in sequences, per device
    sequence_length : int = 64*1024 # sequence length, in tokens
    num_iterations : int = 1875 # number of iterations to run
    warmup_iters : int = 0
    warmdown_iters : int = 562 # number of iterations of linear warmup/warmdown for triangular or trapezoidal schedule
    weight_decay : float = 0
    # evaluation and logging hyperparams
    val_loss_every : int = 125 # every how many steps to evaluate val loss? 0 for only at the end
    val_tokens : int = 10485760 # how many tokens of validation data? it's important to keep this fixed for consistent comparisons
    save_every : int = 0 # every how many steps to save the checkpoint? 0 for only at the end
args = Hyperparameters()

# set up DDP (distributed data parallel). torchrun sets this env variable
assert torch.cuda.is_available()
dist.init_process_group(backend='nccl')
ddp_rank = int(os.environ['RANK'])
ddp_local_rank = int(os.environ['LOCAL_RANK'])
ddp_world_size = int(os.environ['WORLD_SIZE'])
device = f'cuda:{ddp_local_rank}'
torch.cuda.set_device(device)
print(f"using device: {device}")
master_process = (ddp_rank == 0) # this process will do logging, checkpointing etc.

# begin logging
logfile = None
if master_process:
    run_id = str(uuid.uuid4())
    logdir = 'logs/%s/' % run_id
    os.makedirs(logdir, exist_ok=True)
    logfile = 'logs/%s.txt' % run_id
    # create the log file
    with open(logfile, "w") as f:
        # begin the log by printing this file (the Python code)
        f.write('='*100 + '\n')
        f.write(code)
        f.write('='*100 + '\n')
def print0(s, logonly=False):
    if master_process:
        with open(logfile, "a") as f:
            if not logonly:
                print(s)
            f.write(s+'\n')
# log information about the hardware/software environment this is running on
# and print the full `nvidia-smi` to file
print0(f"Running pytorch {torch.version.__version__} compiled for CUDA {torch.version.cuda}\nnvidia-smi:")
import subprocess
result = subprocess.run(['nvidia-smi'], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
print0(f'{result.stdout}', logonly=True)
print0('='*100, logonly=True)

# convenience variables
B, T = args.device_batch_size, args.sequence_length
# calculate the number of steps to take in the val loop.
assert args.val_tokens % (B * T * ddp_world_size) == 0
val_steps = args.val_tokens // (B * T * ddp_world_size)
# calculate the steps of gradient accumulation required to attain the desired global batch size.
assert args.batch_size % (B * ddp_world_size) == 0
train_accumulation_steps = args.batch_size // (B * ddp_world_size)

# load tokens
train_loader = DistributedDataLoader(args.input_bin, B, T, ddp_rank, ddp_world_size)
val_loader = DistributedDataLoader(args.input_val_bin, B, T, ddp_rank, ddp_world_size)
print0(f"Training DataLoader: total number of tokens: {train_loader.ntok_total} across {len(train_loader.files)} files")
print0(f"Validation DataLoader: total number of tokens: {val_loader.ntok_total} across {len(val_loader.files)} files")
print0('='*100, logonly=True)
x, y = train_loader.next_batch()

# there are only 50257 unique GPT-2 tokens; we extend to nearest multiple of 128 for efficiency. suggested to me by @Grad62304977.
# this originates from Karpathy's experiments.
num_vocab = 50304
model = GPT(GPTConfig(vocab_size=num_vocab, n_layer=12, n_head=6, n_embd=768))
model = model.cuda().bfloat16()
for m in model.modules():
    if isinstance(m, CastedLinear):
        m.float()
if hasattr(config, "coordinate_descent_tuning"):
    config.coordinate_descent_tuning = True # suggested by @Chillee
model = torch.compile(model)
# here we wrap model into DDP container
model = DDP(model, device_ids=[ddp_local_rank])
raw_model = model.module # always contains the "raw" unwrapped model

# CUDNN attention is ~4ms faster than Flash, but doesn't get selected by default in PyTorch 2.5.1
from torch.backends.cuda import enable_cudnn_sdp, enable_flash_sdp, enable_math_sdp, enable_mem_efficient_sdp
enable_cudnn_sdp(True)
enable_flash_sdp(False)
enable_mem_efficient_sdp(False)
enable_math_sdp(False)

# init the optimizer(s)
optimizer1 = torch.optim.Adam([raw_model.transformer.wte.weight], lr=0.6,   betas=(0.9, 0.95), fused=True)
optimizer2 = torch.optim.Adam([raw_model.lm_head.weight],         lr=0.008, betas=(0.9, 0.95), fused=True)
params = list(raw_model.transformer.h.parameters())
matrix_params = [p for p in params if p.ndim == 2]
scalar_params = [p for p in params if p.ndim < 2] + [raw_model.skip_weights]
# optimizer3 = Muon(matrix_params, lr=0.04, momentum=0.95)
optimizer3 = torch.optim.AdamW(matrix_params, lr=0.0018, betas=(0.9, 0.95),
                               weight_decay=args.weight_decay, fused=True)
optimizer4 = torch.optim.Adam(scalar_params, lr=0.04, betas=(0.9, 0.95), fused=True) # note that this learning rate is neither sensitive nor tuned
optimizers = [optimizer1, optimizer2, optimizer3, optimizer4]
# learning rate decay scheduler (linear warmup and warmdown)
def get_lr(it):
    assert it <= args.num_iterations
    # 1) linear warmup for warmup_iters steps
    if it < args.warmup_iters:
        return (it+1) / args.warmup_iters
    # 2) constant lr for a while
    elif it < args.num_iterations - args.warmdown_iters:
        return 1.0
    # 3) linear warmdown
    else:
        decay_ratio = (args.num_iterations - it) / args.warmdown_iters
        return decay_ratio
schedulers = [torch.optim.lr_scheduler.LambdaLR(opt, get_lr) for opt in optimizers]

# Start training loop
training_time_ms = 0
# start the clock
torch.cuda.synchronize()
t0 = time.time()
# begin training
for step in range(args.num_iterations + 1):
    last_step = (step == args.num_iterations)
    # This effectively ignores timing first 10 steps, which are slower for weird reasons.
    # Alternately, and slightly more correctly in terms of benchmarking, we could do 10
    # steps with dummy data first, and then re-initialize the model and reset the loader.
    if step == 10:
        training_time_ms = 0
        t0 = time.time()
    timed_steps = float('nan') if step <= 11 else (step - 10) + 1 # <= 11 to avoid bug in val

    # once in a while evaluate the validation dataset
    if (last_step or (args.val_loss_every > 0 and step % args.val_loss_every == 0)):
        # stop the clock
        torch.cuda.synchronize()
        training_time_ms += 1000 * (time.time() - t0)
        # run validation batches
        model.eval()
        val_loader.reset()
        val_loss = 0.0
        for _ in range(val_steps):
            with torch.no_grad():
                x_val, y_val = val_loader.next_batch()
                val_loss += model(x_val, y_val)
        dist.all_reduce(val_loss, op=dist.ReduceOp.AVG)
        val_loss /= val_steps
        # log val loss to console and to logfile
        print0(f'step:{step}/{args.num_iterations} val_loss:{val_loss:.4f} train_time:{training_time_ms:.0f}ms step_avg:{training_time_ms/(timed_steps-1):.2f}ms')
        if master_process:
            with open(logfile, "a") as f:
                print("============== Weight norms: ==============")
                f.write("============== Weight norms: ==============\n")
                for name, p in model.named_parameters():
                    if p.ndim != 2:
                        continue
                    if "c_q" not in name and "c_k" not in name:
                        continue
                    fro_norm = torch.linalg.norm(p.data.float(), ord="fro").item()
                    spectral_norm = torch.linalg.matrix_norm(p.data.float(), ord=2).item()
                    nuclear_norm = torch.linalg.matrix_norm(p.data.float(), ord="nuc").item()
                    print(f"{name = } | {fro_norm = :.5f} | {spectral_norm = :.5f} | {nuclear_norm = :.5f}")
                    f.write(f"{name = } | {fro_norm = :.5f} | {spectral_norm = :.5f} | {nuclear_norm = :.5f}\n")
                f.write("===========================================\n")
                print("===========================================")
        # start the clock again
        torch.cuda.synchronize()
        t0 = time.time()

    if master_process and (last_step or (args.save_every > 0 and step % args.save_every == 0)):
        # stop the clock
        torch.cuda.synchronize()
        training_time_ms += 1000 * (time.time() - t0)
        # save the state of the training process
        log = dict(step=step, code=code, model=raw_model.state_dict(), optimizers=[opt.state_dict() for opt in optimizers])
        torch.save(log, 'logs/%s/state_step%06d.pt' % (run_id, step))
        # start the clock again
        torch.cuda.synchronize()
        t0 = time.time()

    # bit confusing: we want to make sure to eval on 0th iteration
    # but also after the very last iteration. so we loop for step <= num_iterations
    # instead of just < num_iterations (one extra due to <=), only to do
    # the validation/sampling one last time, and then we break right here as we're done.
    if last_step:
        break

    # --------------- TRAINING SECTION BEGIN -----------------
    model.train()
    for i in range(1, train_accumulation_steps+1):
        # forward pass
        loss = model(x, y)
        train_loss = loss.detach()
        # advance the dataset for the next batch
        x, y = train_loader.next_batch()
        # backward pass
        if i < train_accumulation_steps:
            with model.no_sync(): # there's no need to sync gradients every accumulation step
                loss.backward()
        else:
            loss.backward() # just sync on the last step
    for p in model.parameters():
        p.grad /= train_accumulation_steps
    # momentum warmup for Muon
    frac = min(step/500, 1)
    optimizer3.param_groups[0]['momentum'] = (1 - frac) * 0.85 + frac * 0.95
    # step the optimizers and schedulers
    for opt, sched in zip(optimizers, schedulers):
        opt.step()
        sched.step()
    # null the gradients
    model.zero_grad(set_to_none=True)
    # --------------- TRAINING SECTION END -------------------
    # everything that follows now is just diagnostics, prints, logging, etc.

    #dist.all_reduce(train_loss, op=dist.ReduceOp.AVG) # all-reducing the training loss would be more correct in terms of logging, but slower
    approx_time = training_time_ms + 1000 * (time.time() - t0)
    print0(f"step:{step+1}/{args.num_iterations} train_loss:{train_loss.item():.4f} train_time:{approx_time:.0f}ms step_avg:{approx_time/timed_steps:.2f}ms")

if master_process:
    print(f"peak memory consumption: {torch.cuda.max_memory_allocated() // 1024 // 1024} MiB")

# -------------------------------------------------------------------------
# clean up nice
dist.destroy_process_group()
====================================================================================================
Running pytorch 2.6.0.dev20241122+cu124 compiled for CUDA 12.4
nvidia-smi:
Fri Nov 22 14:04:15 2024       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA A100-SXM4-80GB          On  |   00000000:48:00.0 Off |                    0 |
| N/A   31C    P0             63W /  400W |       3MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA A100-SXM4-80GB          On  |   00000000:4E:00.0 Off |                    0 |
| N/A   28C    P0             66W /  400W |      33MiB /  81920MiB |      1%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA A100-SXM4-80GB          On  |   00000000:9B:00.0 Off |                    0 |
| N/A   28C    P0             69W /  400W |      21MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA A100-SXM4-80GB          On  |   00000000:A1:00.0 Off |                    0 |
| N/A   32C    P0             70W /  400W |      20MiB /  81920MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
+-----------------------------------------------------------------------------------------+

====================================================================================================
Training DataLoader: total number of tokens: 1100000000 across 11 files
Validation DataLoader: total number of tokens: 100000000 across 1 files
====================================================================================================
step:0/1875 val_loss:10.8258 train_time:0ms step_avg:nanms
============== Weight norms: ==============
name = 'module._orig_mod.transformer.h.0.attn.c_q.weight' | fro_norm = 15.99847 | spectral_norm = 1.16534 | nuclear_norm = 376.29724
name = 'module._orig_mod.transformer.h.0.attn.c_k.weight' | fro_norm = 15.99505 | spectral_norm = 1.15186 | nuclear_norm = 376.29730
name = 'module._orig_mod.transformer.h.1.attn.c_q.weight' | fro_norm = 16.00463 | spectral_norm = 1.15223 | nuclear_norm = 376.58557
name = 'module._orig_mod.transformer.h.1.attn.c_k.weight' | fro_norm = 15.99930 | spectral_norm = 1.15217 | nuclear_norm = 376.36963
name = 'module._orig_mod.transformer.h.2.attn.c_q.weight' | fro_norm = 15.99753 | spectral_norm = 1.14926 | nuclear_norm = 376.51947
name = 'module._orig_mod.transformer.h.2.attn.c_k.weight' | fro_norm = 16.00445 | spectral_norm = 1.15155 | nuclear_norm = 376.59891
name = 'module._orig_mod.transformer.h.3.attn.c_q.weight' | fro_norm = 16.01145 | spectral_norm = 1.14129 | nuclear_norm = 376.71167
name = 'module._orig_mod.transformer.h.3.attn.c_k.weight' | fro_norm = 16.00063 | spectral_norm = 1.14317 | nuclear_norm = 376.68054
name = 'module._orig_mod.transformer.h.4.attn.c_q.weight' | fro_norm = 15.99358 | spectral_norm = 1.14911 | nuclear_norm = 376.34760
name = 'module._orig_mod.transformer.h.4.attn.c_k.weight' | fro_norm = 16.00392 | spectral_norm = 1.14222 | nuclear_norm = 376.63022
name = 'module._orig_mod.transformer.h.5.attn.c_q.weight' | fro_norm = 15.99448 | spectral_norm = 1.14217 | nuclear_norm = 376.21909
name = 'module._orig_mod.transformer.h.5.attn.c_k.weight' | fro_norm = 16.00333 | spectral_norm = 1.15123 | nuclear_norm = 376.63000
name = 'module._orig_mod.transformer.h.6.attn.c_q.weight' | fro_norm = 15.98668 | spectral_norm = 1.14864 | nuclear_norm = 375.86887
name = 'module._orig_mod.transformer.h.6.attn.c_k.weight' | fro_norm = 16.00849 | spectral_norm = 1.14682 | nuclear_norm = 376.83209
name = 'module._orig_mod.transformer.h.7.attn.c_q.weight' | fro_norm = 15.99991 | spectral_norm = 1.15905 | nuclear_norm = 376.43063
name = 'module._orig_mod.transformer.h.7.attn.c_k.weight' | fro_norm = 16.00302 | spectral_norm = 1.14766 | nuclear_norm = 376.57452
name = 'module._orig_mod.transformer.h.8.attn.c_q.weight' | fro_norm = 15.99436 | spectral_norm = 1.14572 | nuclear_norm = 376.23465
name = 'module._orig_mod.transformer.h.8.attn.c_k.weight' | fro_norm = 16.00057 | spectral_norm = 1.15091 | nuclear_norm = 376.20615
name = 'module._orig_mod.transformer.h.9.attn.c_q.weight' | fro_norm = 16.00970 | spectral_norm = 1.14591 | nuclear_norm = 376.77161
name = 'module._orig_mod.transformer.h.9.attn.c_k.weight' | fro_norm = 15.99335 | spectral_norm = 1.13905 | nuclear_norm = 376.35657
name = 'module._orig_mod.transformer.h.10.attn.c_q.weight' | fro_norm = 15.99399 | spectral_norm = 1.14912 | nuclear_norm = 376.25226
name = 'module._orig_mod.transformer.h.10.attn.c_k.weight' | fro_norm = 16.00160 | spectral_norm = 1.14780 | nuclear_norm = 376.64703
name = 'module._orig_mod.transformer.h.11.attn.c_q.weight' | fro_norm = 16.00640 | spectral_norm = 1.15530 | nuclear_norm = 376.30139
name = 'module._orig_mod.transformer.h.11.attn.c_k.weight' | fro_norm = 15.99306 | spectral_norm = 1.14592 | nuclear_norm = 376.06042
===========================================
step:1/1875 train_loss:10.8258 train_time:24946ms step_avg:nanms
step:2/1875 train_loss:10.1269 train_time:25434ms step_avg:nanms
step:3/1875 train_loss:9.3287 train_time:26145ms step_avg:nanms
step:4/1875 train_loss:7.8149 train_time:26873ms step_avg:nanms
step:5/1875 train_loss:7.3357 train_time:27595ms step_avg:nanms
step:6/1875 train_loss:7.1932 train_time:28307ms step_avg:nanms
step:7/1875 train_loss:7.7024 train_time:29032ms step_avg:nanms
step:8/1875 train_loss:7.0647 train_time:29753ms step_avg:nanms
step:9/1875 train_loss:7.7489 train_time:30487ms step_avg:nanms
step:10/1875 train_loss:7.1272 train_time:31211ms step_avg:nanms
step:11/1875 train_loss:7.2630 train_time:493ms step_avg:nanms
step:12/1875 train_loss:7.2751 train_time:1209ms step_avg:nanms
step:13/1875 train_loss:7.0363 train_time:1956ms step_avg:652.11ms
step:14/1875 train_loss:8.4767 train_time:2679ms step_avg:669.75ms
step:15/1875 train_loss:7.3837 train_time:3401ms step_avg:680.13ms
step:16/1875 train_loss:6.9228 train_time:4115ms step_avg:685.84ms
step:17/1875 train_loss:6.7512 train_time:4837ms step_avg:690.99ms
step:18/1875 train_loss:7.3263 train_time:5559ms step_avg:694.86ms
step:19/1875 train_loss:6.7378 train_time:6294ms step_avg:699.33ms
step:20/1875 train_loss:6.9144 train_time:7015ms step_avg:701.51ms
step:21/1875 train_loss:6.7394 train_time:7736ms step_avg:703.25ms
step:22/1875 train_loss:6.5717 train_time:8454ms step_avg:704.48ms
step:23/1875 train_loss:6.5653 train_time:9184ms step_avg:706.46ms
step:24/1875 train_loss:6.5399 train_time:9908ms step_avg:707.75ms
step:25/1875 train_loss:6.3502 train_time:10624ms step_avg:708.29ms
step:26/1875 train_loss:6.4828 train_time:11353ms step_avg:709.55ms
step:27/1875 train_loss:6.4017 train_time:12086ms step_avg:710.94ms
step:28/1875 train_loss:6.3946 train_time:12805ms step_avg:711.39ms
step:29/1875 train_loss:6.3837 train_time:13522ms step_avg:711.68ms
step:30/1875 train_loss:6.3971 train_time:14235ms step_avg:711.76ms
step:31/1875 train_loss:6.8581 train_time:14967ms step_avg:712.73ms
step:32/1875 train_loss:6.2557 train_time:15697ms step_avg:713.51ms
step:33/1875 train_loss:6.1244 train_time:16422ms step_avg:713.99ms
step:34/1875 train_loss:6.1517 train_time:17139ms step_avg:714.13ms
step:35/1875 train_loss:6.3729 train_time:17872ms step_avg:714.87ms
step:36/1875 train_loss:6.3112 train_time:18597ms step_avg:715.26ms
step:37/1875 train_loss:6.2925 train_time:19327ms step_avg:715.81ms
step:38/1875 train_loss:6.1153 train_time:20058ms step_avg:716.36ms
step:39/1875 train_loss:6.2244 train_time:20782ms step_avg:716.62ms
step:40/1875 train_loss:6.0391 train_time:21516ms step_avg:717.19ms
step:41/1875 train_loss:6.2091 train_time:22243ms step_avg:717.51ms
step:42/1875 train_loss:6.1054 train_time:22961ms step_avg:717.54ms
step:43/1875 train_loss:6.1068 train_time:23676ms step_avg:717.46ms
step:44/1875 train_loss:6.0394 train_time:24397ms step_avg:717.57ms
step:45/1875 train_loss:5.9198 train_time:25127ms step_avg:717.93ms
step:46/1875 train_loss:6.0141 train_time:25864ms step_avg:718.45ms
step:47/1875 train_loss:5.9333 train_time:26573ms step_avg:718.19ms
step:48/1875 train_loss:6.1009 train_time:27305ms step_avg:718.54ms
step:49/1875 train_loss:5.9090 train_time:28054ms step_avg:719.35ms
step:50/1875 train_loss:6.0254 train_time:28771ms step_avg:719.27ms
step:51/1875 train_loss:6.0898 train_time:29499ms step_avg:719.49ms
step:52/1875 train_loss:6.0921 train_time:30237ms step_avg:719.93ms
step:53/1875 train_loss:5.9960 train_time:30961ms step_avg:720.02ms
step:54/1875 train_loss:6.0072 train_time:31659ms step_avg:719.53ms
step:55/1875 train_loss:5.9261 train_time:32389ms step_avg:719.75ms
step:56/1875 train_loss:5.9196 train_time:33130ms step_avg:720.22ms
step:57/1875 train_loss:5.9452 train_time:33845ms step_avg:720.11ms
step:58/1875 train_loss:5.9624 train_time:34562ms step_avg:720.04ms
step:59/1875 train_loss:6.0403 train_time:35289ms step_avg:720.18ms
step:60/1875 train_loss:5.8735 train_time:36024ms step_avg:720.48ms
step:61/1875 train_loss:6.0070 train_time:36733ms step_avg:720.26ms
step:62/1875 train_loss:5.9972 train_time:37456ms step_avg:720.31ms
step:63/1875 train_loss:5.9480 train_time:38187ms step_avg:720.50ms
step:64/1875 train_loss:5.9037 train_time:38921ms step_avg:720.76ms
step:65/1875 train_loss:5.7405 train_time:39648ms step_avg:720.87ms
step:66/1875 train_loss:5.7647 train_time:40375ms step_avg:720.98ms
step:67/1875 train_loss:5.9572 train_time:41097ms step_avg:721.00ms
step:68/1875 train_loss:5.9194 train_time:41833ms step_avg:721.26ms
step:69/1875 train_loss:5.9437 train_time:42556ms step_avg:721.29ms
step:70/1875 train_loss:5.8307 train_time:43289ms step_avg:721.48ms
step:71/1875 train_loss:5.9195 train_time:44011ms step_avg:721.49ms
step:72/1875 train_loss:5.8861 train_time:44748ms step_avg:721.75ms
step:73/1875 train_loss:5.9158 train_time:45489ms step_avg:722.05ms
step:74/1875 train_loss:5.6707 train_time:46223ms step_avg:722.23ms
step:75/1875 train_loss:5.7638 train_time:46948ms step_avg:722.27ms
step:76/1875 train_loss:5.7208 train_time:47680ms step_avg:722.43ms
step:77/1875 train_loss:5.8944 train_time:48410ms step_avg:722.54ms
step:78/1875 train_loss:5.7812 train_time:49135ms step_avg:722.57ms
step:79/1875 train_loss:5.4763 train_time:49877ms step_avg:722.86ms
step:80/1875 train_loss:5.8100 train_time:50604ms step_avg:722.91ms
step:81/1875 train_loss:5.8286 train_time:51321ms step_avg:722.84ms
step:82/1875 train_loss:5.7615 train_time:52050ms step_avg:722.91ms
step:83/1875 train_loss:5.8277 train_time:52782ms step_avg:723.04ms
step:84/1875 train_loss:5.7148 train_time:53498ms step_avg:722.94ms
step:85/1875 train_loss:5.7824 train_time:54225ms step_avg:723.01ms
step:86/1875 train_loss:5.7510 train_time:54952ms step_avg:723.06ms
step:87/1875 train_loss:5.8229 train_time:55674ms step_avg:723.03ms
step:88/1875 train_loss:5.6503 train_time:56404ms step_avg:723.12ms
step:89/1875 train_loss:5.6395 train_time:57129ms step_avg:723.15ms
step:90/1875 train_loss:5.5208 train_time:57870ms step_avg:723.38ms
step:91/1875 train_loss:5.7154 train_time:58586ms step_avg:723.28ms
step:92/1875 train_loss:5.6943 train_time:59312ms step_avg:723.32ms
step:93/1875 train_loss:5.9063 train_time:60042ms step_avg:723.40ms
step:94/1875 train_loss:5.8074 train_time:60761ms step_avg:723.34ms
step:95/1875 train_loss:5.5799 train_time:61490ms step_avg:723.41ms
step:96/1875 train_loss:5.6164 train_time:62209ms step_avg:723.36ms
step:97/1875 train_loss:5.7414 train_time:62931ms step_avg:723.35ms
step:98/1875 train_loss:5.5710 train_time:63658ms step_avg:723.39ms
step:99/1875 train_loss:5.5613 train_time:64390ms step_avg:723.48ms
step:100/1875 train_loss:5.5805 train_time:65115ms step_avg:723.50ms
step:101/1875 train_loss:5.4524 train_time:65874ms step_avg:723.89ms
step:102/1875 train_loss:5.6152 train_time:66598ms step_avg:723.89ms
step:103/1875 train_loss:5.4660 train_time:67326ms step_avg:723.94ms
step:104/1875 train_loss:5.6284 train_time:68064ms step_avg:724.08ms
step:105/1875 train_loss:5.6586 train_time:68786ms step_avg:724.06ms
step:106/1875 train_loss:5.7728 train_time:69514ms step_avg:724.11ms
step:107/1875 train_loss:5.5852 train_time:70240ms step_avg:724.12ms
step:108/1875 train_loss:5.4588 train_time:70965ms step_avg:724.13ms
step:109/1875 train_loss:5.7465 train_time:71684ms step_avg:724.08ms
step:110/1875 train_loss:5.6383 train_time:72408ms step_avg:724.08ms
step:111/1875 train_loss:5.5072 train_time:73136ms step_avg:724.12ms
step:112/1875 train_loss:5.6366 train_time:73865ms step_avg:724.16ms
step:113/1875 train_loss:5.3928 train_time:74590ms step_avg:724.17ms
step:114/1875 train_loss:5.5809 train_time:75316ms step_avg:724.19ms
step:115/1875 train_loss:5.4691 train_time:76035ms step_avg:724.14ms
step:116/1875 train_loss:5.6250 train_time:76768ms step_avg:724.22ms
step:117/1875 train_loss:5.4014 train_time:77483ms step_avg:724.14ms
step:118/1875 train_loss:5.5179 train_time:78213ms step_avg:724.19ms
step:119/1875 train_loss:5.4895 train_time:78929ms step_avg:724.12ms
step:120/1875 train_loss:5.5503 train_time:79651ms step_avg:724.10ms
step:121/1875 train_loss:5.5093 train_time:80370ms step_avg:724.05ms
step:122/1875 train_loss:5.4103 train_time:81096ms step_avg:724.07ms
step:123/1875 train_loss:5.4879 train_time:81820ms step_avg:724.07ms
step:124/1875 train_loss:5.3638 train_time:82542ms step_avg:724.05ms
step:125/1875 train_loss:5.2744 train_time:83264ms step_avg:724.03ms
step:125/1875 val_loss:5.4381 train_time:83490ms step_avg:726.00ms
============== Weight norms: ==============
name = 'module._orig_mod.transformer.h.0.attn.c_q.weight' | fro_norm = 20.53424 | spectral_norm = 7.21741 | nuclear_norm = 425.92395
name = 'module._orig_mod.transformer.h.0.attn.c_k.weight' | fro_norm = 20.55343 | spectral_norm = 6.39106 | nuclear_norm = 426.00635
name = 'module._orig_mod.transformer.h.1.attn.c_q.weight' | fro_norm = 21.83314 | spectral_norm = 7.31222 | nuclear_norm = 437.79129
name = 'module._orig_mod.transformer.h.1.attn.c_k.weight' | fro_norm = 21.12227 | spectral_norm = 6.83913 | nuclear_norm = 431.50275
name = 'module._orig_mod.transformer.h.2.attn.c_q.weight' | fro_norm = 19.71000 | spectral_norm = 7.67934 | nuclear_norm = 410.58270
name = 'module._orig_mod.transformer.h.2.attn.c_k.weight' | fro_norm = 19.19725 | spectral_norm = 6.54618 | nuclear_norm = 410.47757
name = 'module._orig_mod.transformer.h.3.attn.c_q.weight' | fro_norm = 18.92976 | spectral_norm = 6.22705 | nuclear_norm = 406.14041
name = 'module._orig_mod.transformer.h.3.attn.c_k.weight' | fro_norm = 18.70712 | spectral_norm = 5.46188 | nuclear_norm = 408.21649
name = 'module._orig_mod.transformer.h.4.attn.c_q.weight' | fro_norm = 18.40897 | spectral_norm = 6.17992 | nuclear_norm = 403.34055
name = 'module._orig_mod.transformer.h.4.attn.c_k.weight' | fro_norm = 18.26756 | spectral_norm = 5.51251 | nuclear_norm = 404.00610
name = 'module._orig_mod.transformer.h.5.attn.c_q.weight' | fro_norm = 19.55389 | spectral_norm = 7.47005 | nuclear_norm = 410.05096
name = 'module._orig_mod.transformer.h.5.attn.c_k.weight' | fro_norm = 19.12211 | spectral_norm = 5.98649 | nuclear_norm = 409.10135
name = 'module._orig_mod.transformer.h.6.attn.c_q.weight' | fro_norm = 19.13877 | spectral_norm = 6.81276 | nuclear_norm = 404.86011
name = 'module._orig_mod.transformer.h.6.attn.c_k.weight' | fro_norm = 18.85597 | spectral_norm = 6.33997 | nuclear_norm = 404.92963
name = 'module._orig_mod.transformer.h.7.attn.c_q.weight' | fro_norm = 18.39569 | spectral_norm = 5.90356 | nuclear_norm = 400.05042
name = 'module._orig_mod.transformer.h.7.attn.c_k.weight' | fro_norm = 18.23016 | spectral_norm = 5.29442 | nuclear_norm = 400.52698
name = 'module._orig_mod.transformer.h.8.attn.c_q.weight' | fro_norm = 18.59102 | spectral_norm = 5.82355 | nuclear_norm = 402.53586
name = 'module._orig_mod.transformer.h.8.attn.c_k.weight' | fro_norm = 18.34882 | spectral_norm = 5.35952 | nuclear_norm = 402.60071
name = 'module._orig_mod.transformer.h.9.attn.c_q.weight' | fro_norm = 18.21250 | spectral_norm = 6.66784 | nuclear_norm = 395.43710
name = 'module._orig_mod.transformer.h.9.attn.c_k.weight' | fro_norm = 18.10193 | spectral_norm = 4.96374 | nuclear_norm = 398.78589
name = 'module._orig_mod.transformer.h.10.attn.c_q.weight' | fro_norm = 18.19053 | spectral_norm = 5.81050 | nuclear_norm = 400.42487
name = 'module._orig_mod.transformer.h.10.attn.c_k.weight' | fro_norm = 17.89595 | spectral_norm = 5.29968 | nuclear_norm = 396.57767
name = 'module._orig_mod.transformer.h.11.attn.c_q.weight' | fro_norm = 19.05525 | spectral_norm = 5.91822 | nuclear_norm = 404.38712
name = 'module._orig_mod.transformer.h.11.attn.c_k.weight' | fro_norm = 18.39681 | spectral_norm = 5.70934 | nuclear_norm = 399.11383
===========================================
step:126/1875 train_loss:5.3091 train_time:83992ms step_avg:724.07ms
step:127/1875 train_loss:5.4636 train_time:84714ms step_avg:724.05ms
step:128/1875 train_loss:5.4709 train_time:85432ms step_avg:724.00ms
step:129/1875 train_loss:5.4382 train_time:86161ms step_avg:724.04ms
step:130/1875 train_loss:5.5059 train_time:86898ms step_avg:724.15ms
step:131/1875 train_loss:5.5635 train_time:87628ms step_avg:724.20ms
step:132/1875 train_loss:5.3342 train_time:88344ms step_avg:724.13ms
step:133/1875 train_loss:5.3152 train_time:89073ms step_avg:724.17ms
step:134/1875 train_loss:5.4241 train_time:89797ms step_avg:724.17ms
step:135/1875 train_loss:5.2909 train_time:90518ms step_avg:724.14ms
step:136/1875 train_loss:5.2649 train_time:91242ms step_avg:724.15ms
step:137/1875 train_loss:5.4065 train_time:91975ms step_avg:724.21ms
step:138/1875 train_loss:5.3403 train_time:92697ms step_avg:724.20ms
step:139/1875 train_loss:5.3786 train_time:93415ms step_avg:724.15ms
step:140/1875 train_loss:5.2748 train_time:94141ms step_avg:724.16ms
step:141/1875 train_loss:5.2731 train_time:94876ms step_avg:724.25ms
step:142/1875 train_loss:5.2723 train_time:95599ms step_avg:724.23ms
step:143/1875 train_loss:5.4103 train_time:96330ms step_avg:724.29ms
step:144/1875 train_loss:5.8349 train_time:97050ms step_avg:724.25ms
step:145/1875 train_loss:5.2946 train_time:97770ms step_avg:724.22ms
step:146/1875 train_loss:5.3196 train_time:98500ms step_avg:724.27ms
step:147/1875 train_loss:5.3200 train_time:99218ms step_avg:724.22ms
step:148/1875 train_loss:5.1154 train_time:99936ms step_avg:724.18ms
step:149/1875 train_loss:5.5158 train_time:100669ms step_avg:724.24ms
step:150/1875 train_loss:5.4010 train_time:101402ms step_avg:724.30ms
step:151/1875 train_loss:5.2646 train_time:102123ms step_avg:724.28ms
step:152/1875 train_loss:5.3777 train_time:102855ms step_avg:724.33ms
step:153/1875 train_loss:5.2952 train_time:103592ms step_avg:724.42ms
step:154/1875 train_loss:5.1801 train_time:104314ms step_avg:724.41ms
step:155/1875 train_loss:5.2238 train_time:105032ms step_avg:724.36ms
step:156/1875 train_loss:5.3477 train_time:105764ms step_avg:724.41ms
step:157/1875 train_loss:5.2931 train_time:106500ms step_avg:724.49ms
step:158/1875 train_loss:5.2874 train_time:107217ms step_avg:724.44ms
step:159/1875 train_loss:5.1696 train_time:107937ms step_avg:724.41ms
step:160/1875 train_loss:5.1483 train_time:108657ms step_avg:724.38ms
step:161/1875 train_loss:5.2018 train_time:109383ms step_avg:724.39ms
step:162/1875 train_loss:5.2544 train_time:110102ms step_avg:724.35ms
step:163/1875 train_loss:5.2184 train_time:110823ms step_avg:724.33ms
step:164/1875 train_loss:5.1309 train_time:111547ms step_avg:724.33ms
step:165/1875 train_loss:5.1913 train_time:112276ms step_avg:724.36ms
step:166/1875 train_loss:5.2733 train_time:113002ms step_avg:724.37ms
step:167/1875 train_loss:5.2168 train_time:113725ms step_avg:724.36ms
step:168/1875 train_loss:5.1580 train_time:114452ms step_avg:724.38ms
step:169/1875 train_loss:5.2033 train_time:115176ms step_avg:724.38ms
step:170/1875 train_loss:5.1509 train_time:115921ms step_avg:724.51ms
step:171/1875 train_loss:4.6622 train_time:116668ms step_avg:724.64ms
step:172/1875 train_loss:5.0901 train_time:117406ms step_avg:724.73ms
step:173/1875 train_loss:5.0943 train_time:118129ms step_avg:724.72ms
step:174/1875 train_loss:5.3016 train_time:118848ms step_avg:724.68ms
step:175/1875 train_loss:5.2378 train_time:119572ms step_avg:724.68ms
step:176/1875 train_loss:5.1625 train_time:120297ms step_avg:724.68ms
step:177/1875 train_loss:5.3050 train_time:121019ms step_avg:724.66ms
step:178/1875 train_loss:5.1293 train_time:121740ms step_avg:724.64ms
step:179/1875 train_loss:5.1216 train_time:122465ms step_avg:724.65ms
step:180/1875 train_loss:5.1666 train_time:123187ms step_avg:724.63ms
step:181/1875 train_loss:5.0717 train_time:123908ms step_avg:724.61ms
step:182/1875 train_loss:5.0158 train_time:124626ms step_avg:724.57ms
step:183/1875 train_loss:5.1264 train_time:125353ms step_avg:724.58ms
step:184/1875 train_loss:5.3324 train_time:126075ms step_avg:724.57ms
step:185/1875 train_loss:5.0559 train_time:126787ms step_avg:724.50ms
step:186/1875 train_loss:5.1612 train_time:127513ms step_avg:724.51ms
step:187/1875 train_loss:5.1023 train_time:128251ms step_avg:724.58ms
step:188/1875 train_loss:5.1319 train_time:128986ms step_avg:724.64ms
step:189/1875 train_loss:4.7632 train_time:129710ms step_avg:724.64ms
step:190/1875 train_loss:4.9943 train_time:130640ms step_avg:725.78ms
step:191/1875 train_loss:5.0213 train_time:131376ms step_avg:725.84ms
step:192/1875 train_loss:4.9616 train_time:132108ms step_avg:725.87ms
step:193/1875 train_loss:5.1595 train_time:132843ms step_avg:725.92ms
step:194/1875 train_loss:5.0992 train_time:133582ms step_avg:725.99ms
step:195/1875 train_loss:5.2914 train_time:134308ms step_avg:725.99ms
step:196/1875 train_loss:5.1719 train_time:135027ms step_avg:725.95ms
step:197/1875 train_loss:5.0191 train_time:135750ms step_avg:725.94ms
step:198/1875 train_loss:5.0418 train_time:136494ms step_avg:726.03ms
step:199/1875 train_loss:4.9549 train_time:137209ms step_avg:725.97ms
step:200/1875 train_loss:5.0143 train_time:137933ms step_avg:725.96ms
step:201/1875 train_loss:4.9352 train_time:138666ms step_avg:726.00ms
step:202/1875 train_loss:5.1587 train_time:139396ms step_avg:726.02ms
step:203/1875 train_loss:5.0778 train_time:140122ms step_avg:726.02ms
step:204/1875 train_loss:5.0151 train_time:140845ms step_avg:726.00ms
step:205/1875 train_loss:5.1910 train_time:141573ms step_avg:726.02ms
step:206/1875 train_loss:4.8616 train_time:142301ms step_avg:726.03ms
step:207/1875 train_loss:4.9976 train_time:143027ms step_avg:726.02ms
step:208/1875 train_loss:4.9570 train_time:143754ms step_avg:726.03ms
step:209/1875 train_loss:5.1054 train_time:144475ms step_avg:726.00ms
step:210/1875 train_loss:5.0730 train_time:145211ms step_avg:726.05ms
step:211/1875 train_loss:4.9263 train_time:145942ms step_avg:726.08ms
step:212/1875 train_loss:5.1002 train_time:146653ms step_avg:726.01ms
step:213/1875 train_loss:4.8973 train_time:147395ms step_avg:726.08ms
step:214/1875 train_loss:4.9790 train_time:148126ms step_avg:726.11ms
step:215/1875 train_loss:4.8575 train_time:148851ms step_avg:726.10ms
step:216/1875 train_loss:5.0039 train_time:149578ms step_avg:726.11ms
step:217/1875 train_loss:4.9512 train_time:150294ms step_avg:726.06ms
step:218/1875 train_loss:4.9460 train_time:151018ms step_avg:726.05ms
step:219/1875 train_loss:4.9634 train_time:151723ms step_avg:725.95ms
step:220/1875 train_loss:4.9735 train_time:152454ms step_avg:725.97ms
step:221/1875 train_loss:5.0087 train_time:153185ms step_avg:726.00ms
step:222/1875 train_loss:4.9386 train_time:153920ms step_avg:726.04ms
step:223/1875 train_loss:4.9813 train_time:154640ms step_avg:726.01ms
step:224/1875 train_loss:5.0660 train_time:155369ms step_avg:726.02ms
step:225/1875 train_loss:4.8404 train_time:156093ms step_avg:726.01ms
step:226/1875 train_loss:4.8284 train_time:156814ms step_avg:725.99ms
step:227/1875 train_loss:4.8215 train_time:157533ms step_avg:725.96ms
step:228/1875 train_loss:4.9937 train_time:158253ms step_avg:725.93ms
step:229/1875 train_loss:4.8566 train_time:158976ms step_avg:725.92ms
step:230/1875 train_loss:4.9566 train_time:159714ms step_avg:725.97ms
step:231/1875 train_loss:4.8244 train_time:160439ms step_avg:725.97ms
step:232/1875 train_loss:4.7933 train_time:161162ms step_avg:725.96ms
step:233/1875 train_loss:5.0001 train_time:161887ms step_avg:725.95ms
step:234/1875 train_loss:4.8279 train_time:162622ms step_avg:725.99ms
step:235/1875 train_loss:4.7691 train_time:163361ms step_avg:726.05ms
step:236/1875 train_loss:5.0386 train_time:164089ms step_avg:726.06ms
step:237/1875 train_loss:4.8926 train_time:164822ms step_avg:726.09ms
step:238/1875 train_loss:4.8097 train_time:165548ms step_avg:726.09ms
step:239/1875 train_loss:4.9532 train_time:166284ms step_avg:726.13ms
step:240/1875 train_loss:4.9339 train_time:167006ms step_avg:726.11ms
step:241/1875 train_loss:4.8345 train_time:167751ms step_avg:726.20ms
step:242/1875 train_loss:4.9987 train_time:168478ms step_avg:726.20ms
step:243/1875 train_loss:4.8381 train_time:169206ms step_avg:726.20ms
step:244/1875 train_loss:4.8952 train_time:169929ms step_avg:726.19ms
step:245/1875 train_loss:4.9323 train_time:170662ms step_avg:726.22ms
step:246/1875 train_loss:4.8756 train_time:171372ms step_avg:726.15ms
step:247/1875 train_loss:4.8360 train_time:172102ms step_avg:726.17ms
step:248/1875 train_loss:4.9942 train_time:172833ms step_avg:726.19ms
step:249/1875 train_loss:4.7357 train_time:173558ms step_avg:726.18ms
step:250/1875 train_loss:4.7670 train_time:174277ms step_avg:726.16ms
step:250/1875 val_loss:4.8293 train_time:174493ms step_avg:727.05ms
============== Weight norms: ==============
name = 'module._orig_mod.transformer.h.0.attn.c_q.weight' | fro_norm = 23.35171 | spectral_norm = 9.06616 | nuclear_norm = 469.18890
name = 'module._orig_mod.transformer.h.0.attn.c_k.weight' | fro_norm = 22.73975 | spectral_norm = 7.08505 | nuclear_norm = 462.73270
name = 'module._orig_mod.transformer.h.1.attn.c_q.weight' | fro_norm = 25.60565 | spectral_norm = 7.01106 | nuclear_norm = 503.01859
name = 'module._orig_mod.transformer.h.1.attn.c_k.weight' | fro_norm = 23.77850 | spectral_norm = 6.30028 | nuclear_norm = 482.77380
name = 'module._orig_mod.transformer.h.2.attn.c_q.weight' | fro_norm = 24.27587 | spectral_norm = 5.89241 | nuclear_norm = 476.95316
name = 'module._orig_mod.transformer.h.2.attn.c_k.weight' | fro_norm = 22.66661 | spectral_norm = 5.27026 | nuclear_norm = 462.03171
name = 'module._orig_mod.transformer.h.3.attn.c_q.weight' | fro_norm = 22.23501 | spectral_norm = 5.47117 | nuclear_norm = 456.96469
name = 'module._orig_mod.transformer.h.3.attn.c_k.weight' | fro_norm = 21.23330 | spectral_norm = 4.88821 | nuclear_norm = 449.09729
name = 'module._orig_mod.transformer.h.4.attn.c_q.weight' | fro_norm = 20.18895 | spectral_norm = 5.89637 | nuclear_norm = 432.66986
name = 'module._orig_mod.transformer.h.4.attn.c_k.weight' | fro_norm = 19.66496 | spectral_norm = 5.20816 | nuclear_norm = 427.69043
name = 'module._orig_mod.transformer.h.5.attn.c_q.weight' | fro_norm = 22.84097 | spectral_norm = 6.88021 | nuclear_norm = 456.89816
name = 'module._orig_mod.transformer.h.5.attn.c_k.weight' | fro_norm = 21.78947 | spectral_norm = 6.03426 | nuclear_norm = 447.60645
name = 'module._orig_mod.transformer.h.6.attn.c_q.weight' | fro_norm = 22.30102 | spectral_norm = 5.88305 | nuclear_norm = 451.25992
name = 'module._orig_mod.transformer.h.6.attn.c_k.weight' | fro_norm = 21.74710 | spectral_norm = 5.88378 | nuclear_norm = 449.14706
name = 'module._orig_mod.transformer.h.7.attn.c_q.weight' | fro_norm = 20.67142 | spectral_norm = 5.80121 | nuclear_norm = 435.23486
name = 'module._orig_mod.transformer.h.7.attn.c_k.weight' | fro_norm = 20.14845 | spectral_norm = 5.27481 | nuclear_norm = 429.86188
name = 'module._orig_mod.transformer.h.8.attn.c_q.weight' | fro_norm = 20.00599 | spectral_norm = 5.81161 | nuclear_norm = 423.09436
name = 'module._orig_mod.transformer.h.8.attn.c_k.weight' | fro_norm = 19.60210 | spectral_norm = 5.40248 | nuclear_norm = 420.11722
name = 'module._orig_mod.transformer.h.9.attn.c_q.weight' | fro_norm = 18.71152 | spectral_norm = 6.67638 | nuclear_norm = 404.09314
name = 'module._orig_mod.transformer.h.9.attn.c_k.weight' | fro_norm = 18.47440 | spectral_norm = 5.06352 | nuclear_norm = 404.59344
name = 'module._orig_mod.transformer.h.10.attn.c_q.weight' | fro_norm = 18.31532 | spectral_norm = 5.82599 | nuclear_norm = 402.89752
name = 'module._orig_mod.transformer.h.10.attn.c_k.weight' | fro_norm = 18.01706 | spectral_norm = 5.37031 | nuclear_norm = 398.65491
name = 'module._orig_mod.transformer.h.11.attn.c_q.weight' | fro_norm = 20.95410 | spectral_norm = 6.24961 | nuclear_norm = 431.77994
name = 'module._orig_mod.transformer.h.11.attn.c_k.weight' | fro_norm = 19.71012 | spectral_norm = 5.52746 | nuclear_norm = 419.49249
===========================================
step:251/1875 train_loss:4.8930 train_time:174990ms step_avg:726.10ms
step:252/1875 train_loss:4.9029 train_time:175708ms step_avg:726.07ms
step:253/1875 train_loss:4.7729 train_time:176435ms step_avg:726.07ms
step:254/1875 train_loss:4.7650 train_time:177147ms step_avg:726.01ms
step:255/1875 train_loss:4.8941 train_time:177881ms step_avg:726.04ms
step:256/1875 train_loss:4.8645 train_time:178601ms step_avg:726.02ms
step:257/1875 train_loss:4.8223 train_time:179325ms step_avg:726.01ms
step:258/1875 train_loss:4.7458 train_time:180054ms step_avg:726.02ms
step:259/1875 train_loss:4.7633 train_time:180783ms step_avg:726.04ms
step:260/1875 train_loss:4.8340 train_time:181507ms step_avg:726.03ms
step:261/1875 train_loss:4.8437 train_time:182229ms step_avg:726.01ms
step:262/1875 train_loss:4.7542 train_time:182978ms step_avg:726.10ms
step:263/1875 train_loss:4.6931 train_time:183696ms step_avg:726.07ms
step:264/1875 train_loss:4.7432 train_time:184433ms step_avg:726.11ms
step:265/1875 train_loss:4.6125 train_time:185155ms step_avg:726.10ms
step:266/1875 train_loss:4.6681 train_time:185875ms step_avg:726.08ms
step:267/1875 train_loss:4.6921 train_time:186612ms step_avg:726.12ms
step:268/1875 train_loss:4.6675 train_time:187346ms step_avg:726.15ms
step:269/1875 train_loss:4.6198 train_time:188073ms step_avg:726.15ms
step:270/1875 train_loss:4.8353 train_time:188789ms step_avg:726.11ms
step:271/1875 train_loss:4.7644 train_time:189510ms step_avg:726.09ms
step:272/1875 train_loss:4.6319 train_time:190231ms step_avg:726.07ms
step:273/1875 train_loss:4.6617 train_time:190953ms step_avg:726.06ms
step:274/1875 train_loss:4.7968 train_time:191680ms step_avg:726.06ms
step:275/1875 train_loss:4.8021 train_time:192411ms step_avg:726.08ms
step:276/1875 train_loss:4.9837 train_time:193132ms step_avg:726.06ms
step:277/1875 train_loss:4.7358 train_time:193862ms step_avg:726.07ms
step:278/1875 train_loss:4.8880 train_time:194579ms step_avg:726.04ms
step:279/1875 train_loss:4.7158 train_time:195304ms step_avg:726.04ms
step:280/1875 train_loss:4.7272 train_time:196032ms step_avg:726.05ms
step:281/1875 train_loss:4.6795 train_time:196772ms step_avg:726.10ms
step:282/1875 train_loss:4.7514 train_time:197518ms step_avg:726.17ms
step:283/1875 train_loss:4.6068 train_time:198257ms step_avg:726.22ms
step:284/1875 train_loss:4.7511 train_time:198976ms step_avg:726.19ms
step:285/1875 train_loss:4.7371 train_time:199707ms step_avg:726.21ms
step:286/1875 train_loss:4.7669 train_time:200430ms step_avg:726.20ms
step:287/1875 train_loss:4.6206 train_time:201160ms step_avg:726.21ms
step:288/1875 train_loss:4.7046 train_time:201881ms step_avg:726.19ms
step:289/1875 train_loss:4.5613 train_time:202612ms step_avg:726.21ms
step:290/1875 train_loss:4.5499 train_time:203336ms step_avg:726.20ms
step:291/1875 train_loss:4.6578 train_time:204063ms step_avg:726.20ms
step:292/1875 train_loss:4.5593 train_time:204785ms step_avg:726.19ms
step:293/1875 train_loss:4.5859 train_time:205502ms step_avg:726.16ms
step:294/1875 train_loss:4.6304 train_time:206236ms step_avg:726.18ms
step:295/1875 train_loss:4.5376 train_time:206949ms step_avg:726.14ms
step:296/1875 train_loss:4.5127 train_time:207692ms step_avg:726.19ms
step:297/1875 train_loss:4.5333 train_time:208421ms step_avg:726.21ms
step:298/1875 train_loss:4.6127 train_time:209150ms step_avg:726.22ms
step:299/1875 train_loss:4.5037 train_time:209887ms step_avg:726.25ms
step:300/1875 train_loss:4.6402 train_time:210617ms step_avg:726.27ms
step:301/1875 train_loss:4.6308 train_time:211336ms step_avg:726.24ms
step:302/1875 train_loss:4.5616 train_time:212061ms step_avg:726.24ms
step:303/1875 train_loss:4.6266 train_time:212776ms step_avg:726.20ms
step:304/1875 train_loss:4.5926 train_time:213496ms step_avg:726.18ms
step:305/1875 train_loss:5.0435 train_time:214216ms step_avg:726.16ms
step:306/1875 train_loss:4.5681 train_time:214921ms step_avg:726.08ms
step:307/1875 train_loss:4.4526 train_time:215666ms step_avg:726.15ms
step:308/1875 train_loss:4.6279 train_time:216402ms step_avg:726.18ms
step:309/1875 train_loss:4.4435 train_time:217120ms step_avg:726.15ms
step:310/1875 train_loss:4.6662 train_time:217846ms step_avg:726.15ms
step:311/1875 train_loss:4.5430 train_time:218569ms step_avg:726.14ms
step:312/1875 train_loss:4.4920 train_time:219281ms step_avg:726.10ms
step:313/1875 train_loss:4.5781 train_time:220016ms step_avg:726.13ms
step:314/1875 train_loss:4.6970 train_time:220741ms step_avg:726.12ms
step:315/1875 train_loss:4.5565 train_time:221473ms step_avg:726.14ms
step:316/1875 train_loss:4.4179 train_time:222191ms step_avg:726.11ms
step:317/1875 train_loss:4.4787 train_time:222922ms step_avg:726.13ms
step:318/1875 train_loss:4.5060 train_time:223649ms step_avg:726.13ms
step:319/1875 train_loss:4.4592 train_time:224382ms step_avg:726.16ms
step:320/1875 train_loss:4.5452 train_time:225114ms step_avg:726.17ms
step:321/1875 train_loss:4.5389 train_time:225839ms step_avg:726.17ms
step:322/1875 train_loss:4.4858 train_time:226571ms step_avg:726.19ms
step:323/1875 train_loss:4.5635 train_time:227293ms step_avg:726.18ms
step:324/1875 train_loss:4.5357 train_time:228016ms step_avg:726.17ms
step:325/1875 train_loss:4.6301 train_time:228745ms step_avg:726.18ms
step:326/1875 train_loss:4.4591 train_time:229463ms step_avg:726.15ms
step:327/1875 train_loss:4.9397 train_time:230193ms step_avg:726.16ms
step:328/1875 train_loss:4.6232 train_time:230925ms step_avg:726.18ms
step:329/1875 train_loss:4.4145 train_time:231694ms step_avg:726.31ms
step:330/1875 train_loss:4.3530 train_time:232419ms step_avg:726.31ms
step:331/1875 train_loss:4.5315 train_time:233148ms step_avg:726.32ms
step:332/1875 train_loss:4.4494 train_time:233871ms step_avg:726.31ms
step:333/1875 train_loss:4.4603 train_time:234590ms step_avg:726.28ms
step:334/1875 train_loss:4.4003 train_time:235311ms step_avg:726.27ms
step:335/1875 train_loss:4.5746 train_time:236041ms step_avg:726.28ms
step:336/1875 train_loss:4.5204 train_time:236762ms step_avg:726.26ms
step:337/1875 train_loss:4.9416 train_time:237500ms step_avg:726.30ms
step:338/1875 train_loss:4.5064 train_time:238233ms step_avg:726.32ms
step:339/1875 train_loss:4.4472 train_time:238969ms step_avg:726.35ms
step:340/1875 train_loss:4.4779 train_time:239689ms step_avg:726.33ms
step:341/1875 train_loss:4.4077 train_time:240425ms step_avg:726.36ms
step:342/1875 train_loss:4.3686 train_time:241138ms step_avg:726.32ms
step:343/1875 train_loss:4.4231 train_time:241854ms step_avg:726.29ms
step:344/1875 train_loss:4.5490 train_time:242584ms step_avg:726.30ms
step:345/1875 train_loss:4.3992 train_time:243314ms step_avg:726.31ms
step:346/1875 train_loss:4.3209 train_time:244041ms step_avg:726.31ms
step:347/1875 train_loss:4.3606 train_time:244777ms step_avg:726.34ms
step:348/1875 train_loss:4.4026 train_time:245507ms step_avg:726.35ms
step:349/1875 train_loss:4.3522 train_time:246228ms step_avg:726.34ms
step:350/1875 train_loss:4.0650 train_time:246969ms step_avg:726.38ms
step:351/1875 train_loss:4.3329 train_time:247697ms step_avg:726.39ms
step:352/1875 train_loss:4.7050 train_time:248425ms step_avg:726.39ms
step:353/1875 train_loss:4.1958 train_time:249154ms step_avg:726.40ms
step:354/1875 train_loss:4.4533 train_time:249879ms step_avg:726.39ms
step:355/1875 train_loss:4.3193 train_time:250610ms step_avg:726.40ms
step:356/1875 train_loss:4.4208 train_time:251332ms step_avg:726.39ms
step:357/1875 train_loss:4.3508 train_time:252052ms step_avg:726.37ms
step:358/1875 train_loss:4.3589 train_time:252785ms step_avg:726.39ms
step:359/1875 train_loss:4.3588 train_time:253521ms step_avg:726.42ms
step:360/1875 train_loss:4.0250 train_time:254260ms step_avg:726.46ms
step:361/1875 train_loss:4.5412 train_time:254999ms step_avg:726.49ms
step:362/1875 train_loss:4.4384 train_time:255726ms step_avg:726.50ms
step:363/1875 train_loss:4.3498 train_time:256456ms step_avg:726.50ms
step:364/1875 train_loss:4.2734 train_time:257184ms step_avg:726.51ms
step:365/1875 train_loss:4.4112 train_time:257910ms step_avg:726.51ms
step:366/1875 train_loss:4.3864 train_time:258653ms step_avg:726.55ms
step:367/1875 train_loss:4.3586 train_time:259369ms step_avg:726.52ms
step:368/1875 train_loss:4.3643 train_time:260106ms step_avg:726.55ms
step:369/1875 train_loss:4.2408 train_time:260828ms step_avg:726.54ms
step:370/1875 train_loss:4.4119 train_time:261550ms step_avg:726.53ms
step:371/1875 train_loss:4.2751 train_time:262259ms step_avg:726.48ms
step:372/1875 train_loss:4.1907 train_time:262989ms step_avg:726.49ms
step:373/1875 train_loss:4.4111 train_time:263714ms step_avg:726.48ms
step:374/1875 train_loss:4.3380 train_time:264419ms step_avg:726.42ms
step:375/1875 train_loss:4.3169 train_time:265139ms step_avg:726.41ms
step:375/1875 val_loss:4.3435 train_time:265369ms step_avg:727.04ms
============== Weight norms: ==============
name = 'module._orig_mod.transformer.h.0.attn.c_q.weight' | fro_norm = 25.88870 | spectral_norm = 10.68229 | nuclear_norm = 510.28186
name = 'module._orig_mod.transformer.h.0.attn.c_k.weight' | fro_norm = 24.89926 | spectral_norm = 9.18582 | nuclear_norm = 495.29395
name = 'module._orig_mod.transformer.h.1.attn.c_q.weight' | fro_norm = 27.94675 | spectral_norm = 7.27814 | nuclear_norm = 549.05389
name = 'module._orig_mod.transformer.h.1.attn.c_k.weight' | fro_norm = 25.78087 | spectral_norm = 6.53043 | nuclear_norm = 521.97394
name = 'module._orig_mod.transformer.h.2.attn.c_q.weight' | fro_norm = 26.60446 | spectral_norm = 5.46082 | nuclear_norm = 506.69745
name = 'module._orig_mod.transformer.h.2.attn.c_k.weight' | fro_norm = 25.05745 | spectral_norm = 4.88400 | nuclear_norm = 497.93137
name = 'module._orig_mod.transformer.h.3.attn.c_q.weight' | fro_norm = 24.63564 | spectral_norm = 5.48137 | nuclear_norm = 499.05069
name = 'module._orig_mod.transformer.h.3.attn.c_k.weight' | fro_norm = 23.25421 | spectral_norm = 4.91809 | nuclear_norm = 485.70258
name = 'module._orig_mod.transformer.h.4.attn.c_q.weight' | fro_norm = 23.45129 | spectral_norm = 5.61422 | nuclear_norm = 486.01544
name = 'module._orig_mod.transformer.h.4.attn.c_k.weight' | fro_norm = 22.38248 | spectral_norm = 5.02846 | nuclear_norm = 474.34961
name = 'module._orig_mod.transformer.h.5.attn.c_q.weight' | fro_norm = 25.52238 | spectral_norm = 6.79482 | nuclear_norm = 501.28268
name = 'module._orig_mod.transformer.h.5.attn.c_k.weight' | fro_norm = 24.33190 | spectral_norm = 6.25434 | nuclear_norm = 489.32562
name = 'module._orig_mod.transformer.h.6.attn.c_q.weight' | fro_norm = 24.91992 | spectral_norm = 5.94032 | nuclear_norm = 494.78006
name = 'module._orig_mod.transformer.h.6.attn.c_k.weight' | fro_norm = 24.21603 | spectral_norm = 5.34433 | nuclear_norm = 492.55399
name = 'module._orig_mod.transformer.h.7.attn.c_q.weight' | fro_norm = 24.07887 | spectral_norm = 5.56723 | nuclear_norm = 493.06818
name = 'module._orig_mod.transformer.h.7.attn.c_k.weight' | fro_norm = 22.91466 | spectral_norm = 5.11748 | nuclear_norm = 476.30292
name = 'module._orig_mod.transformer.h.8.attn.c_q.weight' | fro_norm = 22.73144 | spectral_norm = 5.74099 | nuclear_norm = 465.71790
name = 'module._orig_mod.transformer.h.8.attn.c_k.weight' | fro_norm = 22.12336 | spectral_norm = 5.58498 | nuclear_norm = 460.43018
name = 'module._orig_mod.transformer.h.9.attn.c_q.weight' | fro_norm = 21.98449 | spectral_norm = 6.60958 | nuclear_norm = 455.95160
name = 'module._orig_mod.transformer.h.9.attn.c_k.weight' | fro_norm = 20.84085 | spectral_norm = 5.74059 | nuclear_norm = 440.28998
name = 'module._orig_mod.transformer.h.10.attn.c_q.weight' | fro_norm = 20.45549 | spectral_norm = 5.86486 | nuclear_norm = 436.86526
name = 'module._orig_mod.transformer.h.10.attn.c_k.weight' | fro_norm = 19.62251 | spectral_norm = 5.67848 | nuclear_norm = 423.56693
name = 'module._orig_mod.transformer.h.11.attn.c_q.weight' | fro_norm = 23.69152 | spectral_norm = 6.31594 | nuclear_norm = 475.84122
name = 'module._orig_mod.transformer.h.11.attn.c_k.weight' | fro_norm = 22.14583 | spectral_norm = 5.97764 | nuclear_norm = 459.06009
===========================================
step:376/1875 train_loss:4.3902 train_time:265858ms step_avg:726.39ms
step:377/1875 train_loss:4.2906 train_time:266605ms step_avg:726.44ms
step:378/1875 train_loss:4.3432 train_time:267356ms step_avg:726.51ms
step:379/1875 train_loss:4.4102 train_time:268079ms step_avg:726.50ms
step:380/1875 train_loss:4.4311 train_time:269016ms step_avg:727.07ms
step:381/1875 train_loss:4.2106 train_time:269934ms step_avg:727.59ms
step:382/1875 train_loss:4.2816 train_time:270677ms step_avg:727.63ms
step:383/1875 train_loss:4.2710 train_time:271417ms step_avg:727.66ms
step:384/1875 train_loss:4.3665 train_time:272142ms step_avg:727.65ms
step:385/1875 train_loss:4.1807 train_time:272870ms step_avg:727.65ms
step:386/1875 train_loss:4.3664 train_time:273592ms step_avg:727.64ms
step:387/1875 train_loss:4.2678 train_time:274333ms step_avg:727.67ms
step:388/1875 train_loss:4.4220 train_time:275041ms step_avg:727.62ms
step:389/1875 train_loss:4.2936 train_time:275776ms step_avg:727.64ms
step:390/1875 train_loss:4.3434 train_time:276506ms step_avg:727.65ms
step:391/1875 train_loss:4.2138 train_time:277242ms step_avg:727.67ms
step:392/1875 train_loss:4.2910 train_time:277962ms step_avg:727.65ms
step:393/1875 train_loss:4.2976 train_time:278687ms step_avg:727.64ms
step:394/1875 train_loss:4.2765 train_time:279405ms step_avg:727.62ms
step:395/1875 train_loss:4.2874 train_time:280139ms step_avg:727.63ms
step:396/1875 train_loss:4.2478 train_time:280866ms step_avg:727.63ms
step:397/1875 train_loss:4.0552 train_time:281594ms step_avg:727.63ms
step:398/1875 train_loss:4.2922 train_time:282318ms step_avg:727.62ms
step:399/1875 train_loss:4.2528 train_time:283042ms step_avg:727.61ms
step:400/1875 train_loss:4.1828 train_time:283764ms step_avg:727.60ms
step:401/1875 train_loss:4.3120 train_time:284490ms step_avg:727.59ms
step:402/1875 train_loss:4.1696 train_time:285213ms step_avg:727.58ms
step:403/1875 train_loss:4.4601 train_time:285930ms step_avg:727.56ms
step:404/1875 train_loss:4.3387 train_time:286674ms step_avg:727.60ms
step:405/1875 train_loss:4.3424 train_time:287394ms step_avg:727.58ms
step:406/1875 train_loss:4.3370 train_time:288116ms step_avg:727.57ms
step:407/1875 train_loss:4.2790 train_time:288842ms step_avg:727.56ms
step:408/1875 train_loss:4.2006 train_time:289565ms step_avg:727.55ms
step:409/1875 train_loss:4.2758 train_time:290291ms step_avg:727.55ms
step:410/1875 train_loss:4.2292 train_time:291012ms step_avg:727.53ms
step:411/1875 train_loss:4.2755 train_time:291736ms step_avg:727.52ms
step:412/1875 train_loss:4.2662 train_time:292453ms step_avg:727.50ms
step:413/1875 train_loss:4.2292 train_time:293181ms step_avg:727.50ms
step:414/1875 train_loss:4.3342 train_time:293911ms step_avg:727.50ms
step:415/1875 train_loss:4.1916 train_time:294631ms step_avg:727.48ms
step:416/1875 train_loss:4.2591 train_time:295360ms step_avg:727.49ms
step:417/1875 train_loss:4.3289 train_time:296080ms step_avg:727.47ms
step:418/1875 train_loss:4.1272 train_time:296809ms step_avg:727.47ms
step:419/1875 train_loss:4.3869 train_time:297531ms step_avg:727.46ms
step:420/1875 train_loss:4.4262 train_time:298249ms step_avg:727.44ms
step:421/1875 train_loss:4.2237 train_time:298975ms step_avg:727.43ms
step:422/1875 train_loss:4.3669 train_time:299693ms step_avg:727.41ms
step:423/1875 train_loss:4.0607 train_time:300421ms step_avg:727.41ms
step:424/1875 train_loss:4.2187 train_time:301147ms step_avg:727.41ms
step:425/1875 train_loss:4.0974 train_time:301876ms step_avg:727.41ms
step:426/1875 train_loss:4.2940 train_time:302609ms step_avg:727.43ms
step:427/1875 train_loss:4.2831 train_time:303333ms step_avg:727.42ms
step:428/1875 train_loss:4.1826 train_time:304062ms step_avg:727.42ms
step:429/1875 train_loss:4.3204 train_time:304789ms step_avg:727.42ms
step:430/1875 train_loss:4.1590 train_time:305524ms step_avg:727.44ms
step:431/1875 train_loss:4.0826 train_time:306262ms step_avg:727.46ms
step:432/1875 train_loss:4.2791 train_time:306982ms step_avg:727.45ms
step:433/1875 train_loss:4.3052 train_time:307695ms step_avg:727.41ms
step:434/1875 train_loss:4.3031 train_time:308427ms step_avg:727.42ms
step:435/1875 train_loss:4.1918 train_time:309146ms step_avg:727.40ms
step:436/1875 train_loss:4.2749 train_time:309874ms step_avg:727.40ms
step:437/1875 train_loss:4.2984 train_time:310592ms step_avg:727.38ms
step:438/1875 train_loss:4.2371 train_time:311320ms step_avg:727.38ms
step:439/1875 train_loss:4.2958 train_time:312043ms step_avg:727.37ms
step:440/1875 train_loss:4.1374 train_time:312770ms step_avg:727.37ms
step:441/1875 train_loss:4.2185 train_time:313494ms step_avg:727.36ms
step:442/1875 train_loss:4.1873 train_time:314205ms step_avg:727.33ms
step:443/1875 train_loss:4.0528 train_time:314942ms step_avg:727.35ms
step:444/1875 train_loss:4.2042 train_time:315673ms step_avg:727.36ms
step:445/1875 train_loss:4.4109 train_time:316394ms step_avg:727.34ms
step:446/1875 train_loss:4.0996 train_time:317125ms step_avg:727.35ms
step:447/1875 train_loss:4.2744 train_time:317848ms step_avg:727.34ms
step:448/1875 train_loss:4.2782 train_time:318578ms step_avg:727.35ms
step:449/1875 train_loss:4.1531 train_time:319308ms step_avg:727.35ms
step:450/1875 train_loss:4.1290 train_time:320045ms step_avg:727.37ms
step:451/1875 train_loss:4.1408 train_time:320774ms step_avg:727.38ms
step:452/1875 train_loss:4.4996 train_time:321501ms step_avg:727.38ms
step:453/1875 train_loss:4.3736 train_time:322214ms step_avg:727.35ms
step:454/1875 train_loss:4.2254 train_time:322961ms step_avg:727.39ms
step:455/1875 train_loss:4.1386 train_time:323686ms step_avg:727.38ms
step:456/1875 train_loss:4.2707 train_time:324412ms step_avg:727.38ms
step:457/1875 train_loss:4.2068 train_time:325135ms step_avg:727.37ms
step:458/1875 train_loss:4.1812 train_time:325856ms step_avg:727.36ms
step:459/1875 train_loss:4.2821 train_time:326577ms step_avg:727.34ms
step:460/1875 train_loss:4.1107 train_time:327303ms step_avg:727.34ms
step:461/1875 train_loss:4.2124 train_time:328045ms step_avg:727.37ms
step:462/1875 train_loss:4.1530 train_time:328767ms step_avg:727.36ms
step:463/1875 train_loss:4.0081 train_time:329497ms step_avg:727.37ms
step:464/1875 train_loss:4.1624 train_time:330212ms step_avg:727.34ms
step:465/1875 train_loss:4.2630 train_time:330922ms step_avg:727.30ms
step:466/1875 train_loss:4.1207 train_time:331659ms step_avg:727.32ms
step:467/1875 train_loss:4.1518 train_time:332386ms step_avg:727.32ms
step:468/1875 train_loss:4.1172 train_time:333117ms step_avg:727.33ms
step:469/1875 train_loss:4.3157 train_time:333835ms step_avg:727.31ms
step:470/1875 train_loss:4.1868 train_time:334551ms step_avg:727.29ms
step:471/1875 train_loss:4.0243 train_time:335287ms step_avg:727.30ms
step:472/1875 train_loss:4.2360 train_time:336015ms step_avg:727.30ms
step:473/1875 train_loss:4.1061 train_time:336731ms step_avg:727.28ms
step:474/1875 train_loss:4.2242 train_time:337456ms step_avg:727.28ms
step:475/1875 train_loss:4.2759 train_time:338179ms step_avg:727.27ms
step:476/1875 train_loss:4.4239 train_time:338898ms step_avg:727.25ms
step:477/1875 train_loss:4.2261 train_time:339623ms step_avg:727.24ms
step:478/1875 train_loss:4.2092 train_time:340352ms step_avg:727.25ms
step:479/1875 train_loss:4.1329 train_time:341068ms step_avg:727.22ms
step:480/1875 train_loss:4.0900 train_time:341809ms step_avg:727.25ms
step:481/1875 train_loss:4.1456 train_time:342544ms step_avg:727.27ms
step:482/1875 train_loss:4.2456 train_time:343263ms step_avg:727.25ms
step:483/1875 train_loss:4.1800 train_time:343987ms step_avg:727.24ms
step:484/1875 train_loss:4.2318 train_time:344716ms step_avg:727.25ms
step:485/1875 train_loss:4.1824 train_time:345439ms step_avg:727.24ms
step:486/1875 train_loss:4.0121 train_time:346169ms step_avg:727.25ms
step:487/1875 train_loss:4.1474 train_time:346903ms step_avg:727.26ms
step:488/1875 train_loss:4.1594 train_time:347624ms step_avg:727.25ms
step:489/1875 train_loss:4.1530 train_time:348350ms step_avg:727.24ms
step:490/1875 train_loss:4.3394 train_time:349067ms step_avg:727.22ms
step:491/1875 train_loss:4.1129 train_time:349797ms step_avg:727.23ms
step:492/1875 train_loss:4.0614 train_time:350519ms step_avg:727.22ms
step:493/1875 train_loss:4.2035 train_time:351235ms step_avg:727.19ms
step:494/1875 train_loss:3.9613 train_time:351962ms step_avg:727.19ms
step:495/1875 train_loss:4.1442 train_time:352697ms step_avg:727.21ms
step:496/1875 train_loss:4.3020 train_time:353428ms step_avg:727.22ms
step:497/1875 train_loss:4.1398 train_time:354168ms step_avg:727.24ms
step:498/1875 train_loss:4.1191 train_time:354903ms step_avg:727.26ms
step:499/1875 train_loss:4.1003 train_time:355624ms step_avg:727.25ms
step:500/1875 train_loss:4.2035 train_time:356350ms step_avg:727.24ms
step:500/1875 val_loss:4.1114 train_time:356562ms step_avg:727.68ms
============== Weight norms: ==============
name = 'module._orig_mod.transformer.h.0.attn.c_q.weight' | fro_norm = 28.31298 | spectral_norm = 11.71941 | nuclear_norm = 552.68884
name = 'module._orig_mod.transformer.h.0.attn.c_k.weight' | fro_norm = 27.04755 | spectral_norm = 10.69262 | nuclear_norm = 528.26556
name = 'module._orig_mod.transformer.h.1.attn.c_q.weight' | fro_norm = 29.95274 | spectral_norm = 7.78120 | nuclear_norm = 586.89044
name = 'module._orig_mod.transformer.h.1.attn.c_k.weight' | fro_norm = 27.66018 | spectral_norm = 6.96013 | nuclear_norm = 557.27148
name = 'module._orig_mod.transformer.h.2.attn.c_q.weight' | fro_norm = 28.63523 | spectral_norm = 5.43267 | nuclear_norm = 540.77277
name = 'module._orig_mod.transformer.h.2.attn.c_k.weight' | fro_norm = 27.03201 | spectral_norm = 4.89065 | nuclear_norm = 533.66467
name = 'module._orig_mod.transformer.h.3.attn.c_q.weight' | fro_norm = 26.98744 | spectral_norm = 5.87322 | nuclear_norm = 540.61768
name = 'module._orig_mod.transformer.h.3.attn.c_k.weight' | fro_norm = 25.31894 | spectral_norm = 5.09685 | nuclear_norm = 523.30200
name = 'module._orig_mod.transformer.h.4.attn.c_q.weight' | fro_norm = 26.33710 | spectral_norm = 5.46452 | nuclear_norm = 537.25012
name = 'module._orig_mod.transformer.h.4.attn.c_k.weight' | fro_norm = 24.88379 | spectral_norm = 5.17447 | nuclear_norm = 519.67950
name = 'module._orig_mod.transformer.h.5.attn.c_q.weight' | fro_norm = 27.94607 | spectral_norm = 6.93263 | nuclear_norm = 544.93042
name = 'module._orig_mod.transformer.h.5.attn.c_k.weight' | fro_norm = 26.56347 | spectral_norm = 6.14008 | nuclear_norm = 529.80688
name = 'module._orig_mod.transformer.h.6.attn.c_q.weight' | fro_norm = 27.22153 | spectral_norm = 6.22009 | nuclear_norm = 535.82025
name = 'module._orig_mod.transformer.h.6.attn.c_k.weight' | fro_norm = 26.43109 | spectral_norm = 5.36711 | nuclear_norm = 534.90076
name = 'module._orig_mod.transformer.h.7.attn.c_q.weight' | fro_norm = 26.78142 | spectral_norm = 5.40606 | nuclear_norm = 544.41858
name = 'module._orig_mod.transformer.h.7.attn.c_k.weight' | fro_norm = 25.29791 | spectral_norm = 4.95221 | nuclear_norm = 523.06396
name = 'module._orig_mod.transformer.h.8.attn.c_q.weight' | fro_norm = 25.62543 | spectral_norm = 5.79538 | nuclear_norm = 514.78156
name = 'module._orig_mod.transformer.h.8.attn.c_k.weight' | fro_norm = 24.76125 | spectral_norm = 5.74254 | nuclear_norm = 506.59241
name = 'module._orig_mod.transformer.h.9.attn.c_q.weight' | fro_norm = 25.14488 | spectral_norm = 6.50352 | nuclear_norm = 507.75037
name = 'module._orig_mod.transformer.h.9.attn.c_k.weight' | fro_norm = 23.34174 | spectral_norm = 6.09292 | nuclear_norm = 481.16794
name = 'module._orig_mod.transformer.h.10.attn.c_q.weight' | fro_norm = 24.14820 | spectral_norm = 5.92396 | nuclear_norm = 498.86719
name = 'module._orig_mod.transformer.h.10.attn.c_k.weight' | fro_norm = 22.62379 | spectral_norm = 5.69704 | nuclear_norm = 474.01471
name = 'module._orig_mod.transformer.h.11.attn.c_q.weight' | fro_norm = 26.18807 | spectral_norm = 6.42411 | nuclear_norm = 519.28870
name = 'module._orig_mod.transformer.h.11.attn.c_k.weight' | fro_norm = 24.47673 | spectral_norm = 6.17664 | nuclear_norm = 499.80270
===========================================
step:501/1875 train_loss:4.1182 train_time:357066ms step_avg:727.22ms
step:502/1875 train_loss:4.0435 train_time:357804ms step_avg:727.24ms
step:503/1875 train_loss:4.1510 train_time:358524ms step_avg:727.23ms
step:504/1875 train_loss:4.0122 train_time:359247ms step_avg:727.22ms
step:505/1875 train_loss:4.4075 train_time:359963ms step_avg:727.20ms
step:506/1875 train_loss:4.0984 train_time:360684ms step_avg:727.18ms
step:507/1875 train_loss:4.1747 train_time:361414ms step_avg:727.19ms
step:508/1875 train_loss:4.3368 train_time:362135ms step_avg:727.18ms
step:509/1875 train_loss:4.0305 train_time:362872ms step_avg:727.20ms
step:510/1875 train_loss:4.1435 train_time:363589ms step_avg:727.18ms
step:511/1875 train_loss:4.1548 train_time:364329ms step_avg:727.20ms
step:512/1875 train_loss:3.9608 train_time:365049ms step_avg:727.19ms
step:513/1875 train_loss:3.9369 train_time:365778ms step_avg:727.19ms
step:514/1875 train_loss:4.2099 train_time:366506ms step_avg:727.19ms
step:515/1875 train_loss:4.2875 train_time:367234ms step_avg:727.20ms
step:516/1875 train_loss:4.1909 train_time:367971ms step_avg:727.22ms
step:517/1875 train_loss:4.0250 train_time:368693ms step_avg:727.21ms
step:518/1875 train_loss:4.1977 train_time:369414ms step_avg:727.19ms
step:519/1875 train_loss:3.9361 train_time:370148ms step_avg:727.21ms
step:520/1875 train_loss:4.1758 train_time:370874ms step_avg:727.20ms
step:521/1875 train_loss:4.0665 train_time:371597ms step_avg:727.20ms
step:522/1875 train_loss:3.9601 train_time:372325ms step_avg:727.20ms
step:523/1875 train_loss:4.1968 train_time:373048ms step_avg:727.19ms
step:524/1875 train_loss:3.9955 train_time:373783ms step_avg:727.20ms
step:525/1875 train_loss:4.0516 train_time:374507ms step_avg:727.20ms
step:526/1875 train_loss:4.1060 train_time:375221ms step_avg:727.17ms
step:527/1875 train_loss:4.3480 train_time:375943ms step_avg:727.16ms
step:528/1875 train_loss:4.0692 train_time:376675ms step_avg:727.17ms
step:529/1875 train_loss:4.0369 train_time:377392ms step_avg:727.15ms
step:530/1875 train_loss:4.0645 train_time:378131ms step_avg:727.17ms
step:531/1875 train_loss:4.1713 train_time:378857ms step_avg:727.17ms
step:532/1875 train_loss:4.1192 train_time:379578ms step_avg:727.16ms
step:533/1875 train_loss:4.1146 train_time:380322ms step_avg:727.19ms
step:534/1875 train_loss:4.1974 train_time:381051ms step_avg:727.20ms
step:535/1875 train_loss:4.1453 train_time:381789ms step_avg:727.22ms
step:536/1875 train_loss:4.0202 train_time:382515ms step_avg:727.22ms
step:537/1875 train_loss:4.0865 train_time:383243ms step_avg:727.22ms
step:538/1875 train_loss:4.0246 train_time:383971ms step_avg:727.22ms
step:539/1875 train_loss:3.9983 train_time:384695ms step_avg:727.21ms
step:540/1875 train_loss:4.0827 train_time:385447ms step_avg:727.26ms
step:541/1875 train_loss:4.0324 train_time:386181ms step_avg:727.27ms
step:542/1875 train_loss:4.0296 train_time:386907ms step_avg:727.27ms
step:543/1875 train_loss:4.1072 train_time:387633ms step_avg:727.27ms
step:544/1875 train_loss:4.0876 train_time:388362ms step_avg:727.27ms
step:545/1875 train_loss:4.1100 train_time:389098ms step_avg:727.29ms
step:546/1875 train_loss:4.1465 train_time:389819ms step_avg:727.27ms
step:547/1875 train_loss:3.9860 train_time:390546ms step_avg:727.27ms
step:548/1875 train_loss:4.2219 train_time:391285ms step_avg:727.30ms
step:549/1875 train_loss:3.5996 train_time:392018ms step_avg:727.31ms
step:550/1875 train_loss:4.1255 train_time:392747ms step_avg:727.31ms
step:551/1875 train_loss:4.1158 train_time:393480ms step_avg:727.32ms
step:552/1875 train_loss:4.0327 train_time:394206ms step_avg:727.32ms
step:553/1875 train_loss:4.1412 train_time:394930ms step_avg:727.31ms
step:554/1875 train_loss:4.0791 train_time:395663ms step_avg:727.32ms
step:555/1875 train_loss:4.0381 train_time:396388ms step_avg:727.32ms
step:556/1875 train_loss:4.1608 train_time:397111ms step_avg:727.31ms
step:557/1875 train_loss:4.0812 train_time:397829ms step_avg:727.29ms
step:558/1875 train_loss:3.9923 train_time:398557ms step_avg:727.29ms
step:559/1875 train_loss:4.1017 train_time:399275ms step_avg:727.28ms
step:560/1875 train_loss:4.0036 train_time:399997ms step_avg:727.27ms
step:561/1875 train_loss:4.0649 train_time:400719ms step_avg:727.26ms
step:562/1875 train_loss:4.0652 train_time:401442ms step_avg:727.25ms
step:563/1875 train_loss:3.8689 train_time:402162ms step_avg:727.24ms
step:564/1875 train_loss:4.1210 train_time:402879ms step_avg:727.22ms
step:565/1875 train_loss:3.9846 train_time:403601ms step_avg:727.21ms
step:566/1875 train_loss:4.0171 train_time:404336ms step_avg:727.22ms
step:567/1875 train_loss:4.1123 train_time:405070ms step_avg:727.23ms
step:568/1875 train_loss:4.0243 train_time:405792ms step_avg:727.23ms
step:569/1875 train_loss:4.3259 train_time:406511ms step_avg:727.21ms
step:570/1875 train_loss:4.0605 train_time:407424ms step_avg:727.54ms
step:571/1875 train_loss:4.0417 train_time:408159ms step_avg:727.56ms
step:572/1875 train_loss:4.1350 train_time:408888ms step_avg:727.56ms
step:573/1875 train_loss:4.0707 train_time:409619ms step_avg:727.56ms
step:574/1875 train_loss:4.0793 train_time:410341ms step_avg:727.55ms
step:575/1875 train_loss:4.1449 train_time:411084ms step_avg:727.58ms
step:576/1875 train_loss:4.1119 train_time:411815ms step_avg:727.59ms
step:577/1875 train_loss:4.1232 train_time:412535ms step_avg:727.58ms
step:578/1875 train_loss:4.0631 train_time:413255ms step_avg:727.56ms
step:579/1875 train_loss:4.0304 train_time:413981ms step_avg:727.56ms
step:580/1875 train_loss:4.0391 train_time:414705ms step_avg:727.55ms
step:581/1875 train_loss:3.9778 train_time:415427ms step_avg:727.54ms
step:582/1875 train_loss:4.0195 train_time:416155ms step_avg:727.54ms
step:583/1875 train_loss:4.2377 train_time:416890ms step_avg:727.56ms
step:584/1875 train_loss:4.0254 train_time:417613ms step_avg:727.55ms
step:585/1875 train_loss:3.9595 train_time:418344ms step_avg:727.55ms
step:586/1875 train_loss:4.1551 train_time:419064ms step_avg:727.54ms
step:587/1875 train_loss:3.8872 train_time:419799ms step_avg:727.55ms
step:588/1875 train_loss:4.0343 train_time:420527ms step_avg:727.56ms
step:589/1875 train_loss:4.0344 train_time:421249ms step_avg:727.55ms
step:590/1875 train_loss:4.3718 train_time:421978ms step_avg:727.55ms
step:591/1875 train_loss:4.1332 train_time:422708ms step_avg:727.55ms
step:592/1875 train_loss:3.8919 train_time:423417ms step_avg:727.52ms
step:593/1875 train_loss:3.9075 train_time:424157ms step_avg:727.54ms
step:594/1875 train_loss:3.8845 train_time:424881ms step_avg:727.54ms
step:595/1875 train_loss:3.9128 train_time:425612ms step_avg:727.54ms
step:596/1875 train_loss:4.2866 train_time:426349ms step_avg:727.56ms
step:597/1875 train_loss:4.0138 train_time:427068ms step_avg:727.54ms
step:598/1875 train_loss:3.9630 train_time:427810ms step_avg:727.57ms
step:599/1875 train_loss:4.0315 train_time:428530ms step_avg:727.56ms
step:600/1875 train_loss:3.8443 train_time:429253ms step_avg:727.55ms
step:601/1875 train_loss:3.9790 train_time:429981ms step_avg:727.55ms
step:602/1875 train_loss:4.0046 train_time:430699ms step_avg:727.53ms
step:603/1875 train_loss:4.0213 train_time:431417ms step_avg:727.52ms
step:604/1875 train_loss:4.1319 train_time:432158ms step_avg:727.54ms
step:605/1875 train_loss:3.9904 train_time:432887ms step_avg:727.54ms
step:606/1875 train_loss:3.9821 train_time:433615ms step_avg:727.54ms
step:607/1875 train_loss:3.9081 train_time:434339ms step_avg:727.54ms
step:608/1875 train_loss:4.1646 train_time:435073ms step_avg:727.55ms
step:609/1875 train_loss:4.0172 train_time:435790ms step_avg:727.53ms
step:610/1875 train_loss:3.9618 train_time:436513ms step_avg:727.52ms
step:611/1875 train_loss:4.0747 train_time:437232ms step_avg:727.51ms
step:612/1875 train_loss:3.9777 train_time:437964ms step_avg:727.51ms
step:613/1875 train_loss:3.9171 train_time:438682ms step_avg:727.50ms
step:614/1875 train_loss:4.1178 train_time:439407ms step_avg:727.50ms
step:615/1875 train_loss:4.0726 train_time:440133ms step_avg:727.49ms
step:616/1875 train_loss:4.0591 train_time:440851ms step_avg:727.48ms
step:617/1875 train_loss:3.9977 train_time:441582ms step_avg:727.48ms
step:618/1875 train_loss:3.9059 train_time:442302ms step_avg:727.47ms
step:619/1875 train_loss:4.0325 train_time:443024ms step_avg:727.46ms
step:620/1875 train_loss:3.9200 train_time:443757ms step_avg:727.47ms
step:621/1875 train_loss:3.9364 train_time:444485ms step_avg:727.47ms
step:622/1875 train_loss:4.2442 train_time:445208ms step_avg:727.46ms
step:623/1875 train_loss:3.9309 train_time:445933ms step_avg:727.46ms
step:624/1875 train_loss:3.9757 train_time:446665ms step_avg:727.47ms
step:625/1875 train_loss:4.0490 train_time:447397ms step_avg:727.48ms
step:625/1875 val_loss:3.9786 train_time:447621ms step_avg:727.84ms
============== Weight norms: ==============
name = 'module._orig_mod.transformer.h.0.attn.c_q.weight' | fro_norm = 30.62276 | spectral_norm = 12.49537 | nuclear_norm = 595.68164
name = 'module._orig_mod.transformer.h.0.attn.c_k.weight' | fro_norm = 29.13922 | spectral_norm = 11.77167 | nuclear_norm = 563.14935
name = 'module._orig_mod.transformer.h.1.attn.c_q.weight' | fro_norm = 31.87708 | spectral_norm = 8.32843 | nuclear_norm = 622.59332
name = 'module._orig_mod.transformer.h.1.attn.c_k.weight' | fro_norm = 29.48112 | spectral_norm = 7.52136 | nuclear_norm = 590.62384
name = 'module._orig_mod.transformer.h.2.attn.c_q.weight' | fro_norm = 30.64594 | spectral_norm = 5.62823 | nuclear_norm = 576.33655
name = 'module._orig_mod.transformer.h.2.attn.c_k.weight' | fro_norm = 28.95158 | spectral_norm = 5.05858 | nuclear_norm = 568.65387
name = 'module._orig_mod.transformer.h.3.attn.c_q.weight' | fro_norm = 29.33786 | spectral_norm = 6.14522 | nuclear_norm = 584.52417
name = 'module._orig_mod.transformer.h.3.attn.c_k.weight' | fro_norm = 27.39467 | spectral_norm = 5.30557 | nuclear_norm = 561.86670
name = 'module._orig_mod.transformer.h.4.attn.c_q.weight' | fro_norm = 28.91335 | spectral_norm = 5.55542 | nuclear_norm = 584.41858
name = 'module._orig_mod.transformer.h.4.attn.c_k.weight' | fro_norm = 27.16195 | spectral_norm = 5.49116 | nuclear_norm = 561.85083
name = 'module._orig_mod.transformer.h.5.attn.c_q.weight' | fro_norm = 30.28364 | spectral_norm = 7.05392 | nuclear_norm = 588.20532
name = 'module._orig_mod.transformer.h.5.attn.c_k.weight' | fro_norm = 28.71996 | spectral_norm = 6.10592 | nuclear_norm = 570.36304
name = 'module._orig_mod.transformer.h.6.attn.c_q.weight' | fro_norm = 29.50092 | spectral_norm = 6.49752 | nuclear_norm = 578.32635
name = 'module._orig_mod.transformer.h.6.attn.c_k.weight' | fro_norm = 28.58706 | spectral_norm = 5.51963 | nuclear_norm = 577.01501
name = 'module._orig_mod.transformer.h.7.attn.c_q.weight' | fro_norm = 29.24078 | spectral_norm = 5.35463 | nuclear_norm = 593.60699
name = 'module._orig_mod.transformer.h.7.attn.c_k.weight' | fro_norm = 27.55979 | spectral_norm = 5.08372 | nuclear_norm = 569.13354
name = 'module._orig_mod.transformer.h.8.attn.c_q.weight' | fro_norm = 28.19155 | spectral_norm = 6.14552 | nuclear_norm = 560.16626
name = 'module._orig_mod.transformer.h.8.attn.c_k.weight' | fro_norm = 27.17330 | spectral_norm = 5.97926 | nuclear_norm = 550.62512
name = 'module._orig_mod.transformer.h.9.attn.c_q.weight' | fro_norm = 27.84690 | spectral_norm = 6.58123 | nuclear_norm = 553.07831
name = 'module._orig_mod.transformer.h.9.attn.c_k.weight' | fro_norm = 25.65849 | spectral_norm = 6.20567 | nuclear_norm = 519.84796
name = 'module._orig_mod.transformer.h.10.attn.c_q.weight' | fro_norm = 27.28297 | spectral_norm = 6.06382 | nuclear_norm = 554.22241
name = 'module._orig_mod.transformer.h.10.attn.c_k.weight' | fro_norm = 25.32501 | spectral_norm = 5.66685 | nuclear_norm = 522.75769
name = 'module._orig_mod.transformer.h.11.attn.c_q.weight' | fro_norm = 28.48654 | spectral_norm = 6.54230 | nuclear_norm = 561.52856
name = 'module._orig_mod.transformer.h.11.attn.c_k.weight' | fro_norm = 26.55948 | spectral_norm = 6.31106 | nuclear_norm = 537.90649
===========================================
step:626/1875 train_loss:4.0564 train_time:448122ms step_avg:727.47ms
step:627/1875 train_loss:4.1021 train_time:448853ms step_avg:727.48ms
step:628/1875 train_loss:4.0836 train_time:449576ms step_avg:727.47ms
step:629/1875 train_loss:4.1341 train_time:450298ms step_avg:727.46ms
step:630/1875 train_loss:3.9542 train_time:451017ms step_avg:727.45ms
step:631/1875 train_loss:4.0671 train_time:451733ms step_avg:727.43ms
step:632/1875 train_loss:4.1044 train_time:452460ms step_avg:727.43ms
step:633/1875 train_loss:4.0174 train_time:453186ms step_avg:727.42ms
step:634/1875 train_loss:3.9457 train_time:453907ms step_avg:727.41ms
step:635/1875 train_loss:4.0525 train_time:454639ms step_avg:727.42ms
step:636/1875 train_loss:4.3067 train_time:455366ms step_avg:727.42ms
step:637/1875 train_loss:3.8925 train_time:456096ms step_avg:727.43ms
step:638/1875 train_loss:3.6855 train_time:456817ms step_avg:727.41ms
step:639/1875 train_loss:3.9388 train_time:457542ms step_avg:727.41ms
step:640/1875 train_loss:3.9765 train_time:458271ms step_avg:727.41ms
step:641/1875 train_loss:3.9427 train_time:458993ms step_avg:727.41ms
step:642/1875 train_loss:3.9257 train_time:459715ms step_avg:727.40ms
step:643/1875 train_loss:3.9758 train_time:460439ms step_avg:727.39ms
step:644/1875 train_loss:3.9889 train_time:461159ms step_avg:727.38ms
step:645/1875 train_loss:3.9109 train_time:461880ms step_avg:727.37ms
step:646/1875 train_loss:4.1268 train_time:462605ms step_avg:727.37ms
step:647/1875 train_loss:4.0408 train_time:463335ms step_avg:727.37ms
step:648/1875 train_loss:3.9972 train_time:464061ms step_avg:727.37ms
step:649/1875 train_loss:4.0450 train_time:464803ms step_avg:727.39ms
step:650/1875 train_loss:4.1053 train_time:465532ms step_avg:727.39ms
step:651/1875 train_loss:3.9622 train_time:466263ms step_avg:727.40ms
step:652/1875 train_loss:4.1144 train_time:466990ms step_avg:727.40ms
step:653/1875 train_loss:3.9460 train_time:467715ms step_avg:727.39ms
step:654/1875 train_loss:4.0201 train_time:468440ms step_avg:727.39ms
step:655/1875 train_loss:3.7796 train_time:469163ms step_avg:727.38ms
step:656/1875 train_loss:3.9276 train_time:469881ms step_avg:727.37ms
step:657/1875 train_loss:3.9314 train_time:470606ms step_avg:727.37ms
step:658/1875 train_loss:3.8489 train_time:471333ms step_avg:727.37ms
step:659/1875 train_loss:4.0391 train_time:472060ms step_avg:727.37ms
step:660/1875 train_loss:3.9402 train_time:472792ms step_avg:727.37ms
step:661/1875 train_loss:4.0101 train_time:473516ms step_avg:727.37ms
step:662/1875 train_loss:4.0950 train_time:474243ms step_avg:727.37ms
step:663/1875 train_loss:4.0145 train_time:474975ms step_avg:727.37ms
step:664/1875 train_loss:3.8990 train_time:475695ms step_avg:727.36ms
step:665/1875 train_loss:3.9625 train_time:476429ms step_avg:727.37ms
step:666/1875 train_loss:3.8335 train_time:477166ms step_avg:727.39ms
step:667/1875 train_loss:4.1266 train_time:477891ms step_avg:727.38ms
step:668/1875 train_loss:3.9740 train_time:478620ms step_avg:727.39ms
step:669/1875 train_loss:3.9814 train_time:479347ms step_avg:727.39ms
step:670/1875 train_loss:3.8322 train_time:480085ms step_avg:727.40ms
step:671/1875 train_loss:3.9374 train_time:480806ms step_avg:727.39ms
step:672/1875 train_loss:3.8992 train_time:481541ms step_avg:727.40ms
step:673/1875 train_loss:3.9197 train_time:482268ms step_avg:727.40ms
step:674/1875 train_loss:4.1787 train_time:482988ms step_avg:727.39ms
step:675/1875 train_loss:3.9765 train_time:483711ms step_avg:727.38ms
step:676/1875 train_loss:4.0611 train_time:484436ms step_avg:727.38ms
step:677/1875 train_loss:3.8169 train_time:485165ms step_avg:727.38ms
step:678/1875 train_loss:3.9347 train_time:485887ms step_avg:727.38ms
step:679/1875 train_loss:3.8803 train_time:486603ms step_avg:727.36ms
step:680/1875 train_loss:4.0010 train_time:487337ms step_avg:727.37ms
step:681/1875 train_loss:3.9409 train_time:488081ms step_avg:727.39ms
step:682/1875 train_loss:3.9563 train_time:488804ms step_avg:727.39ms
step:683/1875 train_loss:3.9849 train_time:489525ms step_avg:727.38ms
step:684/1875 train_loss:4.0869 train_time:490267ms step_avg:727.40ms
step:685/1875 train_loss:3.9826 train_time:491006ms step_avg:727.42ms
step:686/1875 train_loss:4.0547 train_time:491735ms step_avg:727.42ms
step:687/1875 train_loss:3.9701 train_time:492454ms step_avg:727.41ms
step:688/1875 train_loss:4.0140 train_time:493190ms step_avg:727.42ms
step:689/1875 train_loss:3.6389 train_time:493939ms step_avg:727.45ms
step:690/1875 train_loss:3.7531 train_time:494667ms step_avg:727.45ms
step:691/1875 train_loss:3.8893 train_time:495393ms step_avg:727.45ms
step:692/1875 train_loss:3.7600 train_time:496116ms step_avg:727.44ms
step:693/1875 train_loss:3.9774 train_time:496841ms step_avg:727.44ms
step:694/1875 train_loss:3.9952 train_time:497559ms step_avg:727.42ms
step:695/1875 train_loss:3.8930 train_time:498281ms step_avg:727.42ms
step:696/1875 train_loss:3.8686 train_time:498999ms step_avg:727.40ms
step:697/1875 train_loss:4.1824 train_time:499732ms step_avg:727.41ms
step:698/1875 train_loss:3.9254 train_time:500459ms step_avg:727.41ms
step:699/1875 train_loss:3.9689 train_time:501181ms step_avg:727.40ms
step:700/1875 train_loss:4.1089 train_time:501907ms step_avg:727.40ms
step:701/1875 train_loss:3.9032 train_time:502630ms step_avg:727.40ms
step:702/1875 train_loss:3.8643 train_time:503352ms step_avg:727.39ms
step:703/1875 train_loss:3.8484 train_time:504082ms step_avg:727.39ms
step:704/1875 train_loss:3.8173 train_time:504808ms step_avg:727.39ms
step:705/1875 train_loss:3.9080 train_time:505555ms step_avg:727.42ms
step:706/1875 train_loss:3.8803 train_time:506280ms step_avg:727.41ms
step:707/1875 train_loss:3.9279 train_time:507006ms step_avg:727.41ms
step:708/1875 train_loss:3.9834 train_time:507739ms step_avg:727.42ms
step:709/1875 train_loss:3.9282 train_time:508463ms step_avg:727.42ms
step:710/1875 train_loss:3.9052 train_time:509203ms step_avg:727.43ms
step:711/1875 train_loss:3.8840 train_time:509946ms step_avg:727.45ms
step:712/1875 train_loss:3.9179 train_time:510672ms step_avg:727.45ms
step:713/1875 train_loss:3.9889 train_time:511408ms step_avg:727.46ms
step:714/1875 train_loss:3.9773 train_time:512136ms step_avg:727.47ms
step:715/1875 train_loss:3.8938 train_time:512867ms step_avg:727.47ms
step:716/1875 train_loss:3.9217 train_time:513601ms step_avg:727.48ms
step:717/1875 train_loss:3.9316 train_time:514320ms step_avg:727.47ms
step:718/1875 train_loss:4.0297 train_time:515041ms step_avg:727.46ms
step:719/1875 train_loss:3.9370 train_time:515765ms step_avg:727.45ms
step:720/1875 train_loss:4.0076 train_time:516486ms step_avg:727.44ms
step:721/1875 train_loss:4.1344 train_time:517222ms step_avg:727.46ms
step:722/1875 train_loss:3.8059 train_time:517946ms step_avg:727.45ms
step:723/1875 train_loss:4.0580 train_time:518684ms step_avg:727.47ms
step:724/1875 train_loss:4.1042 train_time:519400ms step_avg:727.45ms
step:725/1875 train_loss:3.8911 train_time:520119ms step_avg:727.44ms
step:726/1875 train_loss:3.9833 train_time:520860ms step_avg:727.46ms
step:727/1875 train_loss:3.8840 train_time:521593ms step_avg:727.47ms
step:728/1875 train_loss:3.8874 train_time:522319ms step_avg:727.46ms
step:729/1875 train_loss:4.0574 train_time:523046ms step_avg:727.46ms
step:730/1875 train_loss:3.9909 train_time:523768ms step_avg:727.46ms
step:731/1875 train_loss:3.9951 train_time:524504ms step_avg:727.47ms
step:732/1875 train_loss:3.9058 train_time:525237ms step_avg:727.47ms
step:733/1875 train_loss:3.9269 train_time:525954ms step_avg:727.46ms
step:734/1875 train_loss:4.1494 train_time:526679ms step_avg:727.46ms
step:735/1875 train_loss:3.8863 train_time:527394ms step_avg:727.44ms
step:736/1875 train_loss:3.9361 train_time:528131ms step_avg:727.45ms
step:737/1875 train_loss:4.0603 train_time:528861ms step_avg:727.46ms
step:738/1875 train_loss:3.9917 train_time:529584ms step_avg:727.45ms
step:739/1875 train_loss:3.9145 train_time:530306ms step_avg:727.44ms
step:740/1875 train_loss:3.8336 train_time:531029ms step_avg:727.44ms
step:741/1875 train_loss:4.4431 train_time:531756ms step_avg:727.44ms
step:742/1875 train_loss:3.8332 train_time:532493ms step_avg:727.45ms
step:743/1875 train_loss:3.8948 train_time:533228ms step_avg:727.46ms
step:744/1875 train_loss:3.8952 train_time:533956ms step_avg:727.46ms
step:745/1875 train_loss:3.9663 train_time:534700ms step_avg:727.48ms
step:746/1875 train_loss:3.9177 train_time:535433ms step_avg:727.49ms
step:747/1875 train_loss:3.9210 train_time:536156ms step_avg:727.48ms
step:748/1875 train_loss:3.9683 train_time:536878ms step_avg:727.48ms
step:749/1875 train_loss:3.8945 train_time:537600ms step_avg:727.47ms
step:750/1875 train_loss:3.8897 train_time:538334ms step_avg:727.48ms
step:750/1875 val_loss:3.8944 train_time:538571ms step_avg:727.80ms
============== Weight norms: ==============
name = 'module._orig_mod.transformer.h.0.attn.c_q.weight' | fro_norm = 32.86757 | spectral_norm = 13.26360 | nuclear_norm = 638.27472
name = 'module._orig_mod.transformer.h.0.attn.c_k.weight' | fro_norm = 31.24687 | spectral_norm = 12.62394 | nuclear_norm = 601.21057
name = 'module._orig_mod.transformer.h.1.attn.c_q.weight' | fro_norm = 33.74340 | spectral_norm = 8.83720 | nuclear_norm = 656.47302
name = 'module._orig_mod.transformer.h.1.attn.c_k.weight' | fro_norm = 31.26024 | spectral_norm = 8.11620 | nuclear_norm = 623.35907
name = 'module._orig_mod.transformer.h.2.attn.c_q.weight' | fro_norm = 32.60705 | spectral_norm = 5.80544 | nuclear_norm = 611.58575
name = 'module._orig_mod.transformer.h.2.attn.c_k.weight' | fro_norm = 30.81677 | spectral_norm = 5.27276 | nuclear_norm = 602.58997
name = 'module._orig_mod.transformer.h.3.attn.c_q.weight' | fro_norm = 31.59288 | spectral_norm = 6.48157 | nuclear_norm = 627.84485
name = 'module._orig_mod.transformer.h.3.attn.c_k.weight' | fro_norm = 29.44826 | spectral_norm = 5.59481 | nuclear_norm = 600.46649
name = 'module._orig_mod.transformer.h.4.attn.c_q.weight' | fro_norm = 31.29995 | spectral_norm = 5.81314 | nuclear_norm = 628.13373
name = 'module._orig_mod.transformer.h.4.attn.c_k.weight' | fro_norm = 29.31855 | spectral_norm = 5.80412 | nuclear_norm = 602.53644
name = 'module._orig_mod.transformer.h.5.attn.c_q.weight' | fro_norm = 32.58303 | spectral_norm = 7.17413 | nuclear_norm = 631.68390
name = 'module._orig_mod.transformer.h.5.attn.c_k.weight' | fro_norm = 30.84684 | spectral_norm = 6.23809 | nuclear_norm = 610.25482
name = 'module._orig_mod.transformer.h.6.attn.c_q.weight' | fro_norm = 31.77592 | spectral_norm = 6.75630 | nuclear_norm = 622.28760
name = 'module._orig_mod.transformer.h.6.attn.c_k.weight' | fro_norm = 30.70197 | spectral_norm = 5.80764 | nuclear_norm = 618.92426
name = 'module._orig_mod.transformer.h.7.attn.c_q.weight' | fro_norm = 31.64996 | spectral_norm = 5.49199 | nuclear_norm = 642.11389
name = 'module._orig_mod.transformer.h.7.attn.c_k.weight' | fro_norm = 29.80368 | spectral_norm = 5.22793 | nuclear_norm = 615.16663
name = 'module._orig_mod.transformer.h.8.attn.c_q.weight' | fro_norm = 30.69822 | spectral_norm = 6.55046 | nuclear_norm = 606.85388
name = 'module._orig_mod.transformer.h.8.attn.c_k.weight' | fro_norm = 29.60864 | spectral_norm = 6.24464 | nuclear_norm = 596.80737
name = 'module._orig_mod.transformer.h.9.attn.c_q.weight' | fro_norm = 30.27304 | spectral_norm = 6.89997 | nuclear_norm = 595.04535
name = 'module._orig_mod.transformer.h.9.attn.c_k.weight' | fro_norm = 27.75792 | spectral_norm = 6.49729 | nuclear_norm = 556.12451
name = 'module._orig_mod.transformer.h.10.attn.c_q.weight' | fro_norm = 30.10342 | spectral_norm = 6.20617 | nuclear_norm = 605.22607
name = 'module._orig_mod.transformer.h.10.attn.c_k.weight' | fro_norm = 27.88924 | spectral_norm = 5.77530 | nuclear_norm = 570.09882
name = 'module._orig_mod.transformer.h.11.attn.c_q.weight' | fro_norm = 30.68200 | spectral_norm = 6.85454 | nuclear_norm = 603.23724
name = 'module._orig_mod.transformer.h.11.attn.c_k.weight' | fro_norm = 28.55537 | spectral_norm = 6.44181 | nuclear_norm = 575.82672
===========================================
step:751/1875 train_loss:3.9443 train_time:539077ms step_avg:727.50ms
step:752/1875 train_loss:3.9061 train_time:539799ms step_avg:727.49ms
step:753/1875 train_loss:3.9316 train_time:540526ms step_avg:727.49ms
step:754/1875 train_loss:3.9450 train_time:541251ms step_avg:727.49ms
step:755/1875 train_loss:3.9119 train_time:541973ms step_avg:727.48ms
step:756/1875 train_loss:3.9942 train_time:542689ms step_avg:727.46ms
step:757/1875 train_loss:3.7954 train_time:543428ms step_avg:727.48ms
step:758/1875 train_loss:4.0261 train_time:544174ms step_avg:727.51ms
step:759/1875 train_loss:3.9755 train_time:544892ms step_avg:727.49ms
step:760/1875 train_loss:3.9082 train_time:545805ms step_avg:727.74ms
step:761/1875 train_loss:4.0202 train_time:546523ms step_avg:727.73ms
step:762/1875 train_loss:3.9284 train_time:547469ms step_avg:728.02ms
step:763/1875 train_loss:3.7572 train_time:548193ms step_avg:728.01ms
step:764/1875 train_loss:3.7381 train_time:548930ms step_avg:728.02ms
step:765/1875 train_loss:3.8677 train_time:549656ms step_avg:728.02ms
step:766/1875 train_loss:3.8776 train_time:550382ms step_avg:728.02ms
step:767/1875 train_loss:4.8784 train_time:551113ms step_avg:728.02ms
step:768/1875 train_loss:3.8840 train_time:551845ms step_avg:728.03ms
step:769/1875 train_loss:3.9454 train_time:552579ms step_avg:728.04ms
step:770/1875 train_loss:4.0118 train_time:553300ms step_avg:728.03ms
step:771/1875 train_loss:4.4995 train_time:554023ms step_avg:728.02ms
step:772/1875 train_loss:3.9306 train_time:554744ms step_avg:728.01ms
step:773/1875 train_loss:3.9292 train_time:555479ms step_avg:728.02ms
step:774/1875 train_loss:3.9289 train_time:556203ms step_avg:728.01ms
step:775/1875 train_loss:4.0218 train_time:556927ms step_avg:728.01ms
step:776/1875 train_loss:3.8291 train_time:557650ms step_avg:728.00ms
step:777/1875 train_loss:3.9539 train_time:558370ms step_avg:727.99ms
step:778/1875 train_loss:3.9476 train_time:559105ms step_avg:728.00ms
step:779/1875 train_loss:3.9120 train_time:559837ms step_avg:728.01ms
step:780/1875 train_loss:3.9083 train_time:560562ms step_avg:728.00ms
step:781/1875 train_loss:3.7790 train_time:561292ms step_avg:728.01ms
step:782/1875 train_loss:3.9426 train_time:562012ms step_avg:728.00ms
step:783/1875 train_loss:3.8980 train_time:562742ms step_avg:728.00ms
step:784/1875 train_loss:3.8574 train_time:563474ms step_avg:728.00ms
step:785/1875 train_loss:3.8572 train_time:564196ms step_avg:727.99ms
step:786/1875 train_loss:3.8838 train_time:564916ms step_avg:727.98ms
step:787/1875 train_loss:3.8333 train_time:565635ms step_avg:727.97ms
step:788/1875 train_loss:3.8878 train_time:566363ms step_avg:727.97ms
step:789/1875 train_loss:3.8531 train_time:567084ms step_avg:727.96ms
step:790/1875 train_loss:3.8240 train_time:567823ms step_avg:727.98ms
step:791/1875 train_loss:3.8452 train_time:568545ms step_avg:727.97ms
step:792/1875 train_loss:3.9267 train_time:569277ms step_avg:727.98ms
step:793/1875 train_loss:3.9290 train_time:570002ms step_avg:727.97ms
step:794/1875 train_loss:3.9377 train_time:570723ms step_avg:727.96ms
step:795/1875 train_loss:3.8871 train_time:571465ms step_avg:727.98ms
step:796/1875 train_loss:3.9881 train_time:572193ms step_avg:727.98ms
step:797/1875 train_loss:3.9045 train_time:572929ms step_avg:727.99ms
step:798/1875 train_loss:3.7173 train_time:573662ms step_avg:728.00ms
step:799/1875 train_loss:3.7865 train_time:574384ms step_avg:727.99ms
step:800/1875 train_loss:4.3549 train_time:575115ms step_avg:727.99ms
step:801/1875 train_loss:3.9965 train_time:575857ms step_avg:728.01ms
step:802/1875 train_loss:3.8857 train_time:576574ms step_avg:728.00ms
step:803/1875 train_loss:3.9205 train_time:577311ms step_avg:728.01ms
step:804/1875 train_loss:3.9081 train_time:578047ms step_avg:728.02ms
step:805/1875 train_loss:3.8559 train_time:578775ms step_avg:728.02ms
step:806/1875 train_loss:3.8106 train_time:579495ms step_avg:728.01ms
step:807/1875 train_loss:3.8756 train_time:580229ms step_avg:728.02ms
step:808/1875 train_loss:3.9380 train_time:580943ms step_avg:728.00ms
step:809/1875 train_loss:4.1292 train_time:581676ms step_avg:728.01ms
step:810/1875 train_loss:3.9856 train_time:582395ms step_avg:727.99ms
step:811/1875 train_loss:3.8058 train_time:583115ms step_avg:727.98ms
step:812/1875 train_loss:3.9158 train_time:583839ms step_avg:727.98ms
step:813/1875 train_loss:3.9188 train_time:584562ms step_avg:727.97ms
step:814/1875 train_loss:3.8860 train_time:585285ms step_avg:727.97ms
step:815/1875 train_loss:3.7235 train_time:586015ms step_avg:727.97ms
step:816/1875 train_loss:4.0627 train_time:586733ms step_avg:727.96ms
step:817/1875 train_loss:3.8837 train_time:587454ms step_avg:727.95ms
step:818/1875 train_loss:3.8409 train_time:588183ms step_avg:727.95ms
step:819/1875 train_loss:3.8421 train_time:588909ms step_avg:727.95ms
step:820/1875 train_loss:3.8583 train_time:589632ms step_avg:727.94ms
step:821/1875 train_loss:3.7134 train_time:590359ms step_avg:727.94ms
step:822/1875 train_loss:3.8619 train_time:591085ms step_avg:727.94ms
step:823/1875 train_loss:3.9529 train_time:591806ms step_avg:727.93ms
step:824/1875 train_loss:3.6844 train_time:592528ms step_avg:727.92ms
step:825/1875 train_loss:3.8888 train_time:593251ms step_avg:727.92ms
step:826/1875 train_loss:4.0030 train_time:593976ms step_avg:727.91ms
step:827/1875 train_loss:3.7403 train_time:594710ms step_avg:727.92ms
step:828/1875 train_loss:3.8110 train_time:595449ms step_avg:727.93ms
step:829/1875 train_loss:3.8181 train_time:596176ms step_avg:727.93ms
step:830/1875 train_loss:3.9113 train_time:596882ms step_avg:727.91ms
step:831/1875 train_loss:3.7636 train_time:597624ms step_avg:727.92ms
step:832/1875 train_loss:3.9033 train_time:598355ms step_avg:727.93ms
step:833/1875 train_loss:3.9129 train_time:599076ms step_avg:727.92ms
step:834/1875 train_loss:3.9170 train_time:599809ms step_avg:727.92ms
step:835/1875 train_loss:3.7651 train_time:600540ms step_avg:727.93ms
step:836/1875 train_loss:3.9817 train_time:601269ms step_avg:727.93ms
step:837/1875 train_loss:3.7685 train_time:601998ms step_avg:727.93ms
step:838/1875 train_loss:3.6868 train_time:602716ms step_avg:727.92ms
step:839/1875 train_loss:3.9226 train_time:603443ms step_avg:727.92ms
step:840/1875 train_loss:3.8571 train_time:604159ms step_avg:727.90ms
step:841/1875 train_loss:3.9162 train_time:604877ms step_avg:727.89ms
step:842/1875 train_loss:3.8051 train_time:605607ms step_avg:727.89ms
step:843/1875 train_loss:3.8670 train_time:606334ms step_avg:727.89ms
step:844/1875 train_loss:3.8311 train_time:607061ms step_avg:727.89ms
step:845/1875 train_loss:3.8390 train_time:607774ms step_avg:727.87ms
step:846/1875 train_loss:3.8621 train_time:608512ms step_avg:727.89ms
step:847/1875 train_loss:3.9014 train_time:609236ms step_avg:727.88ms
step:848/1875 train_loss:3.8361 train_time:609960ms step_avg:727.88ms
step:849/1875 train_loss:3.6848 train_time:610698ms step_avg:727.89ms
step:850/1875 train_loss:3.8939 train_time:611422ms step_avg:727.88ms
step:851/1875 train_loss:3.7719 train_time:612141ms step_avg:727.87ms
step:852/1875 train_loss:3.8935 train_time:612870ms step_avg:727.87ms
step:853/1875 train_loss:3.6563 train_time:613600ms step_avg:727.88ms
step:854/1875 train_loss:3.9629 train_time:614318ms step_avg:727.87ms
step:855/1875 train_loss:3.8747 train_time:615039ms step_avg:727.86ms
step:856/1875 train_loss:3.6626 train_time:615767ms step_avg:727.86ms
step:857/1875 train_loss:3.9570 train_time:616487ms step_avg:727.85ms
step:858/1875 train_loss:3.9682 train_time:617225ms step_avg:727.86ms
step:859/1875 train_loss:3.6674 train_time:617955ms step_avg:727.86ms
step:860/1875 train_loss:3.8570 train_time:618693ms step_avg:727.87ms
step:861/1875 train_loss:3.9266 train_time:619422ms step_avg:727.88ms
step:862/1875 train_loss:3.7150 train_time:620141ms step_avg:727.87ms
step:863/1875 train_loss:3.8077 train_time:620877ms step_avg:727.87ms
step:864/1875 train_loss:4.1005 train_time:621613ms step_avg:727.88ms
step:865/1875 train_loss:4.0368 train_time:622340ms step_avg:727.88ms
step:866/1875 train_loss:3.8715 train_time:623090ms step_avg:727.91ms
step:867/1875 train_loss:3.8119 train_time:623816ms step_avg:727.91ms
step:868/1875 train_loss:4.0141 train_time:624546ms step_avg:727.91ms
step:869/1875 train_loss:3.7480 train_time:625278ms step_avg:727.91ms
step:870/1875 train_loss:3.7004 train_time:626005ms step_avg:727.91ms
step:871/1875 train_loss:3.8798 train_time:626727ms step_avg:727.91ms
step:872/1875 train_loss:3.8442 train_time:627451ms step_avg:727.90ms
step:873/1875 train_loss:3.7687 train_time:628176ms step_avg:727.90ms
step:874/1875 train_loss:3.9028 train_time:628885ms step_avg:727.88ms
step:875/1875 train_loss:3.8182 train_time:629618ms step_avg:727.88ms
step:875/1875 val_loss:3.8255 train_time:629838ms step_avg:728.14ms
============== Weight norms: ==============
name = 'module._orig_mod.transformer.h.0.attn.c_q.weight' | fro_norm = 35.02970 | spectral_norm = 13.98599 | nuclear_norm = 680.73547
name = 'module._orig_mod.transformer.h.0.attn.c_k.weight' | fro_norm = 33.30676 | spectral_norm = 13.45059 | nuclear_norm = 639.01001
name = 'module._orig_mod.transformer.h.1.attn.c_q.weight' | fro_norm = 35.59547 | spectral_norm = 9.33716 | nuclear_norm = 690.08240
name = 'module._orig_mod.transformer.h.1.attn.c_k.weight' | fro_norm = 33.03326 | spectral_norm = 8.66185 | nuclear_norm = 655.32812
name = 'module._orig_mod.transformer.h.2.attn.c_q.weight' | fro_norm = 34.52852 | spectral_norm = 5.96917 | nuclear_norm = 646.43536
name = 'module._orig_mod.transformer.h.2.attn.c_k.weight' | fro_norm = 32.66582 | spectral_norm = 5.54611 | nuclear_norm = 636.24158
name = 'module._orig_mod.transformer.h.3.attn.c_q.weight' | fro_norm = 33.87325 | spectral_norm = 6.75043 | nuclear_norm = 671.62775
name = 'module._orig_mod.transformer.h.3.attn.c_k.weight' | fro_norm = 31.54177 | spectral_norm = 5.89328 | nuclear_norm = 640.16052
name = 'module._orig_mod.transformer.h.4.attn.c_q.weight' | fro_norm = 33.64389 | spectral_norm = 6.18595 | nuclear_norm = 671.57751
name = 'module._orig_mod.transformer.h.4.attn.c_k.weight' | fro_norm = 31.44436 | spectral_norm = 6.16943 | nuclear_norm = 642.48206
name = 'module._orig_mod.transformer.h.5.attn.c_q.weight' | fro_norm = 34.89676 | spectral_norm = 7.40257 | nuclear_norm = 674.52502
name = 'module._orig_mod.transformer.h.5.attn.c_k.weight' | fro_norm = 32.92518 | spectral_norm = 6.47583 | nuclear_norm = 649.91827
name = 'module._orig_mod.transformer.h.6.attn.c_q.weight' | fro_norm = 34.08241 | spectral_norm = 7.05294 | nuclear_norm = 666.08618
name = 'module._orig_mod.transformer.h.6.attn.c_k.weight' | fro_norm = 32.84733 | spectral_norm = 6.10766 | nuclear_norm = 660.93420
name = 'module._orig_mod.transformer.h.7.attn.c_q.weight' | fro_norm = 34.05757 | spectral_norm = 5.68636 | nuclear_norm = 691.20813
name = 'module._orig_mod.transformer.h.7.attn.c_k.weight' | fro_norm = 32.02647 | spectral_norm = 5.42740 | nuclear_norm = 660.43597
name = 'module._orig_mod.transformer.h.8.attn.c_q.weight' | fro_norm = 33.13001 | spectral_norm = 6.87684 | nuclear_norm = 653.08270
name = 'module._orig_mod.transformer.h.8.attn.c_k.weight' | fro_norm = 31.96960 | spectral_norm = 6.53032 | nuclear_norm = 642.47314
name = 'module._orig_mod.transformer.h.9.attn.c_q.weight' | fro_norm = 32.65906 | spectral_norm = 7.20502 | nuclear_norm = 637.26343
name = 'module._orig_mod.transformer.h.9.attn.c_k.weight' | fro_norm = 29.90159 | spectral_norm = 6.80218 | nuclear_norm = 593.45007
name = 'module._orig_mod.transformer.h.10.attn.c_q.weight' | fro_norm = 32.75818 | spectral_norm = 6.53736 | nuclear_norm = 653.56323
name = 'module._orig_mod.transformer.h.10.attn.c_k.weight' | fro_norm = 30.33430 | spectral_norm = 6.01630 | nuclear_norm = 615.42627
name = 'module._orig_mod.transformer.h.11.attn.c_q.weight' | fro_norm = 32.88831 | spectral_norm = 7.14481 | nuclear_norm = 646.03149
name = 'module._orig_mod.transformer.h.11.attn.c_k.weight' | fro_norm = 30.57260 | spectral_norm = 6.60134 | nuclear_norm = 615.27979
===========================================
step:876/1875 train_loss:3.9231 train_time:630357ms step_avg:727.89ms
step:877/1875 train_loss:3.6858 train_time:631074ms step_avg:727.88ms
step:878/1875 train_loss:3.9377 train_time:631805ms step_avg:727.89ms
step:879/1875 train_loss:3.7946 train_time:632524ms step_avg:727.88ms
step:880/1875 train_loss:4.1457 train_time:633246ms step_avg:727.87ms
step:881/1875 train_loss:3.8729 train_time:633967ms step_avg:727.86ms
step:882/1875 train_loss:3.6781 train_time:634684ms step_avg:727.85ms
step:883/1875 train_loss:4.0024 train_time:635405ms step_avg:727.84ms
step:884/1875 train_loss:3.7159 train_time:636130ms step_avg:727.84ms
step:885/1875 train_loss:3.9480 train_time:636851ms step_avg:727.83ms
step:886/1875 train_loss:3.8217 train_time:637577ms step_avg:727.83ms
step:887/1875 train_loss:3.9206 train_time:638313ms step_avg:727.84ms
step:888/1875 train_loss:3.8777 train_time:639040ms step_avg:727.84ms
step:889/1875 train_loss:3.9119 train_time:639767ms step_avg:727.83ms
step:890/1875 train_loss:3.8685 train_time:640510ms step_avg:727.85ms
step:891/1875 train_loss:3.7160 train_time:641231ms step_avg:727.84ms
step:892/1875 train_loss:3.8779 train_time:641948ms step_avg:727.83ms
step:893/1875 train_loss:3.7839 train_time:642672ms step_avg:727.83ms
step:894/1875 train_loss:3.8504 train_time:643399ms step_avg:727.83ms
step:895/1875 train_loss:3.6711 train_time:644121ms step_avg:727.82ms
step:896/1875 train_loss:3.6025 train_time:644852ms step_avg:727.82ms
step:897/1875 train_loss:3.7626 train_time:645591ms step_avg:727.84ms
step:898/1875 train_loss:3.9412 train_time:646318ms step_avg:727.84ms
step:899/1875 train_loss:3.8225 train_time:647049ms step_avg:727.84ms
step:900/1875 train_loss:3.8643 train_time:647776ms step_avg:727.84ms
step:901/1875 train_loss:4.0226 train_time:648500ms step_avg:727.83ms
step:902/1875 train_loss:3.7936 train_time:649219ms step_avg:727.82ms
step:903/1875 train_loss:3.7390 train_time:649954ms step_avg:727.83ms
step:904/1875 train_loss:3.9712 train_time:650686ms step_avg:727.84ms
step:905/1875 train_loss:3.9187 train_time:651408ms step_avg:727.83ms
step:906/1875 train_loss:3.7650 train_time:652131ms step_avg:727.83ms
step:907/1875 train_loss:3.7682 train_time:652857ms step_avg:727.82ms
step:908/1875 train_loss:4.0765 train_time:653582ms step_avg:727.82ms
step:909/1875 train_loss:3.7762 train_time:654329ms step_avg:727.84ms
step:910/1875 train_loss:3.9427 train_time:655050ms step_avg:727.83ms
step:911/1875 train_loss:4.1655 train_time:655779ms step_avg:727.83ms
step:912/1875 train_loss:3.6316 train_time:656515ms step_avg:727.84ms
step:913/1875 train_loss:3.9325 train_time:657231ms step_avg:727.83ms
step:914/1875 train_loss:3.8119 train_time:657950ms step_avg:727.82ms
step:915/1875 train_loss:3.8632 train_time:658694ms step_avg:727.84ms
step:916/1875 train_loss:3.9956 train_time:659428ms step_avg:727.85ms
step:917/1875 train_loss:3.7749 train_time:660154ms step_avg:727.84ms
step:918/1875 train_loss:3.7456 train_time:660873ms step_avg:727.83ms
step:919/1875 train_loss:3.8378 train_time:661613ms step_avg:727.85ms
step:920/1875 train_loss:3.7378 train_time:662351ms step_avg:727.86ms
step:921/1875 train_loss:3.8008 train_time:663082ms step_avg:727.86ms
step:922/1875 train_loss:3.7625 train_time:663810ms step_avg:727.86ms
step:923/1875 train_loss:3.8965 train_time:664531ms step_avg:727.85ms
step:924/1875 train_loss:3.8107 train_time:665256ms step_avg:727.85ms
step:925/1875 train_loss:3.7682 train_time:665972ms step_avg:727.84ms
step:926/1875 train_loss:3.8793 train_time:666702ms step_avg:727.84ms
step:927/1875 train_loss:3.7588 train_time:667430ms step_avg:727.84ms
step:928/1875 train_loss:3.9560 train_time:668159ms step_avg:727.84ms
step:929/1875 train_loss:3.8236 train_time:668880ms step_avg:727.83ms
step:930/1875 train_loss:3.6398 train_time:669604ms step_avg:727.83ms
step:931/1875 train_loss:3.9887 train_time:670327ms step_avg:727.82ms
step:932/1875 train_loss:3.6582 train_time:671051ms step_avg:727.82ms
step:933/1875 train_loss:3.6653 train_time:671780ms step_avg:727.82ms
step:934/1875 train_loss:3.8698 train_time:672506ms step_avg:727.82ms
step:935/1875 train_loss:3.8376 train_time:673224ms step_avg:727.81ms
step:936/1875 train_loss:3.6826 train_time:673963ms step_avg:727.82ms
step:937/1875 train_loss:3.6272 train_time:674675ms step_avg:727.81ms
step:938/1875 train_loss:3.7961 train_time:675411ms step_avg:727.81ms
step:939/1875 train_loss:3.5901 train_time:676129ms step_avg:727.80ms
step:940/1875 train_loss:3.8773 train_time:676862ms step_avg:727.81ms
step:941/1875 train_loss:3.7107 train_time:677604ms step_avg:727.82ms
step:942/1875 train_loss:3.7010 train_time:678335ms step_avg:727.83ms
step:943/1875 train_loss:3.8357 train_time:679070ms step_avg:727.83ms
step:944/1875 train_loss:3.7115 train_time:679779ms step_avg:727.81ms
step:945/1875 train_loss:3.7459 train_time:680510ms step_avg:727.82ms
step:946/1875 train_loss:3.9251 train_time:681241ms step_avg:727.82ms
step:947/1875 train_loss:3.7999 train_time:681968ms step_avg:727.82ms
step:948/1875 train_loss:3.8794 train_time:682708ms step_avg:727.83ms
step:949/1875 train_loss:4.0307 train_time:683435ms step_avg:727.83ms
step:950/1875 train_loss:3.6659 train_time:684384ms step_avg:728.07ms
step:951/1875 train_loss:3.7482 train_time:685100ms step_avg:728.05ms
step:952/1875 train_loss:3.9902 train_time:685855ms step_avg:728.08ms
step:953/1875 train_loss:3.6964 train_time:686617ms step_avg:728.12ms
step:954/1875 train_loss:3.7564 train_time:687358ms step_avg:728.13ms
step:955/1875 train_loss:3.8549 train_time:688092ms step_avg:728.14ms
step:956/1875 train_loss:3.7186 train_time:688832ms step_avg:728.15ms
step:957/1875 train_loss:3.7627 train_time:689549ms step_avg:728.14ms
step:958/1875 train_loss:3.7297 train_time:690274ms step_avg:728.14ms
step:959/1875 train_loss:3.8005 train_time:691016ms step_avg:728.15ms
step:960/1875 train_loss:3.7948 train_time:691754ms step_avg:728.16ms
step:961/1875 train_loss:3.7998 train_time:692471ms step_avg:728.15ms
step:962/1875 train_loss:3.6848 train_time:693205ms step_avg:728.16ms
step:963/1875 train_loss:3.9315 train_time:693946ms step_avg:728.17ms
step:964/1875 train_loss:3.8969 train_time:694670ms step_avg:728.17ms
step:965/1875 train_loss:3.6947 train_time:695393ms step_avg:728.16ms
step:966/1875 train_loss:3.7153 train_time:696123ms step_avg:728.16ms
step:967/1875 train_loss:3.7778 train_time:696848ms step_avg:728.16ms
step:968/1875 train_loss:4.0044 train_time:697577ms step_avg:728.16ms
step:969/1875 train_loss:3.8174 train_time:698298ms step_avg:728.15ms
step:970/1875 train_loss:3.8156 train_time:699016ms step_avg:728.14ms
step:971/1875 train_loss:3.8548 train_time:699745ms step_avg:728.14ms
step:972/1875 train_loss:3.6585 train_time:700466ms step_avg:728.14ms
step:973/1875 train_loss:3.8268 train_time:701200ms step_avg:728.14ms
step:974/1875 train_loss:3.8010 train_time:701920ms step_avg:728.13ms
step:975/1875 train_loss:3.8349 train_time:702636ms step_avg:728.12ms
step:976/1875 train_loss:3.8923 train_time:703366ms step_avg:728.12ms
step:977/1875 train_loss:3.7573 train_time:704077ms step_avg:728.10ms
step:978/1875 train_loss:3.9549 train_time:704815ms step_avg:728.11ms
step:979/1875 train_loss:3.8566 train_time:705535ms step_avg:728.11ms
step:980/1875 train_loss:3.6597 train_time:706257ms step_avg:728.10ms
step:981/1875 train_loss:3.9277 train_time:706979ms step_avg:728.09ms
step:982/1875 train_loss:3.7139 train_time:707709ms step_avg:728.10ms
step:983/1875 train_loss:3.8628 train_time:708425ms step_avg:728.08ms
step:984/1875 train_loss:3.8361 train_time:709142ms step_avg:728.07ms
step:985/1875 train_loss:3.8167 train_time:709871ms step_avg:728.07ms
step:986/1875 train_loss:3.7906 train_time:710611ms step_avg:728.08ms
step:987/1875 train_loss:3.8751 train_time:711336ms step_avg:728.08ms
step:988/1875 train_loss:3.6972 train_time:712056ms step_avg:728.07ms
step:989/1875 train_loss:3.7771 train_time:712774ms step_avg:728.06ms
step:990/1875 train_loss:3.7858 train_time:713507ms step_avg:728.07ms
step:991/1875 train_loss:3.7259 train_time:714244ms step_avg:728.08ms
step:992/1875 train_loss:3.9399 train_time:714980ms step_avg:728.09ms
step:993/1875 train_loss:3.7684 train_time:715709ms step_avg:728.09ms
step:994/1875 train_loss:3.7423 train_time:716434ms step_avg:728.08ms
step:995/1875 train_loss:3.8099 train_time:717180ms step_avg:728.10ms
step:996/1875 train_loss:3.8911 train_time:717903ms step_avg:728.10ms
step:997/1875 train_loss:3.8399 train_time:718615ms step_avg:728.08ms
step:998/1875 train_loss:3.7461 train_time:719344ms step_avg:728.08ms
step:999/1875 train_loss:4.0734 train_time:720062ms step_avg:728.07ms
step:1000/1875 train_loss:3.7415 train_time:720787ms step_avg:728.07ms
step:1000/1875 val_loss:3.7665 train_time:720998ms step_avg:728.28ms
============== Weight norms: ==============
name = 'module._orig_mod.transformer.h.0.attn.c_q.weight' | fro_norm = 37.09477 | spectral_norm = 14.71735 | nuclear_norm = 721.67896
name = 'module._orig_mod.transformer.h.0.attn.c_k.weight' | fro_norm = 35.29515 | spectral_norm = 14.21870 | nuclear_norm = 676.35736
name = 'module._orig_mod.transformer.h.1.attn.c_q.weight' | fro_norm = 37.39467 | spectral_norm = 9.82010 | nuclear_norm = 722.45056
name = 'module._orig_mod.transformer.h.1.attn.c_k.weight' | fro_norm = 34.76788 | spectral_norm = 9.19290 | nuclear_norm = 687.23566
name = 'module._orig_mod.transformer.h.2.attn.c_q.weight' | fro_norm = 36.41158 | spectral_norm = 6.15144 | nuclear_norm = 681.27374
name = 'module._orig_mod.transformer.h.2.attn.c_k.weight' | fro_norm = 34.46964 | spectral_norm = 5.75263 | nuclear_norm = 669.71350
name = 'module._orig_mod.transformer.h.3.attn.c_q.weight' | fro_norm = 36.09810 | spectral_norm = 6.92033 | nuclear_norm = 714.69763
name = 'module._orig_mod.transformer.h.3.attn.c_k.weight' | fro_norm = 33.62186 | spectral_norm = 6.17975 | nuclear_norm = 680.78638
name = 'module._orig_mod.transformer.h.4.attn.c_q.weight' | fro_norm = 35.89295 | spectral_norm = 6.64655 | nuclear_norm = 713.66797
name = 'module._orig_mod.transformer.h.4.attn.c_k.weight' | fro_norm = 33.51027 | spectral_norm = 6.57616 | nuclear_norm = 682.21234
name = 'module._orig_mod.transformer.h.5.attn.c_q.weight' | fro_norm = 37.10085 | spectral_norm = 7.57908 | nuclear_norm = 717.20618
name = 'module._orig_mod.transformer.h.5.attn.c_k.weight' | fro_norm = 34.97564 | spectral_norm = 6.77850 | nuclear_norm = 689.56775
name = 'module._orig_mod.transformer.h.6.attn.c_q.weight' | fro_norm = 36.37527 | spectral_norm = 7.30455 | nuclear_norm = 710.30237
name = 'module._orig_mod.transformer.h.6.attn.c_k.weight' | fro_norm = 34.96906 | spectral_norm = 6.38823 | nuclear_norm = 702.70679
name = 'module._orig_mod.transformer.h.7.attn.c_q.weight' | fro_norm = 36.42698 | spectral_norm = 5.95035 | nuclear_norm = 740.17700
name = 'module._orig_mod.transformer.h.7.attn.c_k.weight' | fro_norm = 34.22540 | spectral_norm = 5.65352 | nuclear_norm = 706.11719
name = 'module._orig_mod.transformer.h.8.attn.c_q.weight' | fro_norm = 35.51893 | spectral_norm = 7.28709 | nuclear_norm = 699.30048
name = 'module._orig_mod.transformer.h.8.attn.c_k.weight' | fro_norm = 34.28662 | spectral_norm = 6.83355 | nuclear_norm = 687.65411
name = 'module._orig_mod.transformer.h.9.attn.c_q.weight' | fro_norm = 35.00088 | spectral_norm = 7.55859 | nuclear_norm = 679.16864
name = 'module._orig_mod.transformer.h.9.attn.c_k.weight' | fro_norm = 31.98787 | spectral_norm = 7.12171 | nuclear_norm = 631.06927
name = 'module._orig_mod.transformer.h.10.attn.c_q.weight' | fro_norm = 35.34001 | spectral_norm = 6.80444 | nuclear_norm = 701.41211
name = 'module._orig_mod.transformer.h.10.attn.c_k.weight' | fro_norm = 32.70960 | spectral_norm = 6.31477 | nuclear_norm = 660.44183
name = 'module._orig_mod.transformer.h.11.attn.c_q.weight' | fro_norm = 35.16499 | spectral_norm = 7.46789 | nuclear_norm = 690.85632
name = 'module._orig_mod.transformer.h.11.attn.c_k.weight' | fro_norm = 32.61048 | spectral_norm = 6.79660 | nuclear_norm = 655.82361
===========================================
step:1001/1875 train_loss:3.8687 train_time:721499ms step_avg:728.05ms
step:1002/1875 train_loss:3.7224 train_time:722219ms step_avg:728.04ms
step:1003/1875 train_loss:3.7983 train_time:722935ms step_avg:728.03ms
step:1004/1875 train_loss:3.6791 train_time:723663ms step_avg:728.03ms
step:1005/1875 train_loss:3.8508 train_time:724400ms step_avg:728.04ms
step:1006/1875 train_loss:3.9037 train_time:725131ms step_avg:728.04ms
step:1007/1875 train_loss:3.6906 train_time:725856ms step_avg:728.04ms
step:1008/1875 train_loss:3.7539 train_time:726583ms step_avg:728.04ms
step:1009/1875 train_loss:3.7406 train_time:727313ms step_avg:728.04ms
step:1010/1875 train_loss:3.8651 train_time:728036ms step_avg:728.04ms
step:1011/1875 train_loss:3.9554 train_time:728784ms step_avg:728.06ms
step:1012/1875 train_loss:3.8524 train_time:729515ms step_avg:728.06ms
step:1013/1875 train_loss:3.8136 train_time:730232ms step_avg:728.05ms
step:1014/1875 train_loss:3.6801 train_time:730958ms step_avg:728.05ms
step:1015/1875 train_loss:3.8247 train_time:731684ms step_avg:728.04ms
step:1016/1875 train_loss:3.9349 train_time:732404ms step_avg:728.04ms
step:1017/1875 train_loss:3.6254 train_time:733122ms step_avg:728.03ms
step:1018/1875 train_loss:3.7142 train_time:733857ms step_avg:728.03ms
step:1019/1875 train_loss:3.7273 train_time:734588ms step_avg:728.04ms
step:1020/1875 train_loss:3.6871 train_time:735318ms step_avg:728.04ms
step:1021/1875 train_loss:3.8174 train_time:736037ms step_avg:728.03ms
step:1022/1875 train_loss:3.7072 train_time:736758ms step_avg:728.02ms
step:1023/1875 train_loss:3.6562 train_time:737488ms step_avg:728.02ms
step:1024/1875 train_loss:3.7783 train_time:738217ms step_avg:728.02ms
step:1025/1875 train_loss:3.8205 train_time:738947ms step_avg:728.03ms
step:1026/1875 train_loss:3.7707 train_time:739678ms step_avg:728.03ms
step:1027/1875 train_loss:3.7960 train_time:740410ms step_avg:728.03ms
step:1028/1875 train_loss:3.9330 train_time:741135ms step_avg:728.03ms
step:1029/1875 train_loss:3.6286 train_time:741866ms step_avg:728.03ms
step:1030/1875 train_loss:3.6874 train_time:742598ms step_avg:728.04ms
step:1031/1875 train_loss:3.6300 train_time:743343ms step_avg:728.05ms
step:1032/1875 train_loss:3.8219 train_time:744063ms step_avg:728.05ms
step:1033/1875 train_loss:3.8124 train_time:744789ms step_avg:728.04ms
step:1034/1875 train_loss:3.9957 train_time:745516ms step_avg:728.04ms
step:1035/1875 train_loss:3.7903 train_time:746240ms step_avg:728.04ms
step:1036/1875 train_loss:3.7345 train_time:746967ms step_avg:728.04ms
step:1037/1875 train_loss:3.7415 train_time:747713ms step_avg:728.06ms
step:1038/1875 train_loss:3.7915 train_time:748436ms step_avg:728.05ms
step:1039/1875 train_loss:4.1054 train_time:749165ms step_avg:728.05ms
step:1040/1875 train_loss:3.9125 train_time:749883ms step_avg:728.04ms
step:1041/1875 train_loss:3.8081 train_time:750605ms step_avg:728.04ms
step:1042/1875 train_loss:3.7149 train_time:751326ms step_avg:728.03ms
step:1043/1875 train_loss:3.7809 train_time:752052ms step_avg:728.03ms
step:1044/1875 train_loss:3.8230 train_time:752789ms step_avg:728.04ms
step:1045/1875 train_loss:3.7279 train_time:753514ms step_avg:728.03ms
step:1046/1875 train_loss:3.7548 train_time:754231ms step_avg:728.02ms
step:1047/1875 train_loss:3.8167 train_time:754960ms step_avg:728.02ms
step:1048/1875 train_loss:3.7235 train_time:755684ms step_avg:728.02ms
step:1049/1875 train_loss:3.9468 train_time:756421ms step_avg:728.03ms
step:1050/1875 train_loss:3.8013 train_time:757158ms step_avg:728.04ms
step:1051/1875 train_loss:3.7241 train_time:757883ms step_avg:728.03ms
step:1052/1875 train_loss:3.7010 train_time:758602ms step_avg:728.02ms
step:1053/1875 train_loss:3.8124 train_time:759329ms step_avg:728.02ms
step:1054/1875 train_loss:3.6659 train_time:760054ms step_avg:728.02ms
step:1055/1875 train_loss:3.9893 train_time:760778ms step_avg:728.02ms
step:1056/1875 train_loss:3.8388 train_time:761502ms step_avg:728.01ms
step:1057/1875 train_loss:3.6793 train_time:762215ms step_avg:728.00ms
step:1058/1875 train_loss:3.8010 train_time:762953ms step_avg:728.01ms
step:1059/1875 train_loss:3.8815 train_time:763682ms step_avg:728.01ms
step:1060/1875 train_loss:3.6129 train_time:764403ms step_avg:728.00ms
step:1061/1875 train_loss:3.6733 train_time:765138ms step_avg:728.01ms
step:1062/1875 train_loss:3.7423 train_time:765873ms step_avg:728.02ms
step:1063/1875 train_loss:3.7230 train_time:766591ms step_avg:728.01ms
step:1064/1875 train_loss:3.6885 train_time:767318ms step_avg:728.01ms
step:1065/1875 train_loss:3.7787 train_time:768043ms step_avg:728.00ms
step:1066/1875 train_loss:3.7021 train_time:768768ms step_avg:728.00ms
step:1067/1875 train_loss:3.6520 train_time:769489ms step_avg:727.99ms
step:1068/1875 train_loss:3.7025 train_time:770221ms step_avg:728.00ms
step:1069/1875 train_loss:3.5897 train_time:770951ms step_avg:728.00ms
step:1070/1875 train_loss:3.7241 train_time:771674ms step_avg:727.99ms
step:1071/1875 train_loss:3.6508 train_time:772408ms step_avg:728.00ms
step:1072/1875 train_loss:3.8549 train_time:773129ms step_avg:727.99ms
step:1073/1875 train_loss:3.8033 train_time:773864ms step_avg:728.00ms
step:1074/1875 train_loss:3.7421 train_time:774587ms step_avg:728.00ms
step:1075/1875 train_loss:3.8332 train_time:775307ms step_avg:727.99ms
step:1076/1875 train_loss:3.7648 train_time:776028ms step_avg:727.98ms
step:1077/1875 train_loss:3.7145 train_time:776759ms step_avg:727.98ms
step:1078/1875 train_loss:4.0742 train_time:777479ms step_avg:727.98ms
step:1079/1875 train_loss:3.7628 train_time:778198ms step_avg:727.97ms
step:1080/1875 train_loss:3.4102 train_time:778933ms step_avg:727.97ms
step:1081/1875 train_loss:3.8273 train_time:779671ms step_avg:727.98ms
step:1082/1875 train_loss:3.7373 train_time:780399ms step_avg:727.98ms
step:1083/1875 train_loss:3.8192 train_time:781128ms step_avg:727.98ms
step:1084/1875 train_loss:3.8970 train_time:781867ms step_avg:728.00ms
step:1085/1875 train_loss:3.8082 train_time:782589ms step_avg:727.99ms
step:1086/1875 train_loss:3.7943 train_time:783309ms step_avg:727.98ms
step:1087/1875 train_loss:3.7260 train_time:784034ms step_avg:727.98ms
step:1088/1875 train_loss:3.9383 train_time:784773ms step_avg:727.99ms
step:1089/1875 train_loss:3.8277 train_time:785504ms step_avg:727.99ms
step:1090/1875 train_loss:3.6741 train_time:786227ms step_avg:727.99ms
step:1091/1875 train_loss:3.6864 train_time:786956ms step_avg:727.99ms
step:1092/1875 train_loss:3.7954 train_time:787688ms step_avg:727.99ms
step:1093/1875 train_loss:3.5825 train_time:788415ms step_avg:727.99ms
step:1094/1875 train_loss:3.7916 train_time:789136ms step_avg:727.99ms
step:1095/1875 train_loss:3.9127 train_time:789854ms step_avg:727.98ms
step:1096/1875 train_loss:3.7567 train_time:790577ms step_avg:727.97ms
step:1097/1875 train_loss:3.7260 train_time:791303ms step_avg:727.97ms
step:1098/1875 train_loss:3.7415 train_time:792039ms step_avg:727.98ms
step:1099/1875 train_loss:3.7922 train_time:792763ms step_avg:727.97ms
step:1100/1875 train_loss:3.8600 train_time:793495ms step_avg:727.98ms
step:1101/1875 train_loss:3.8282 train_time:794226ms step_avg:727.98ms
step:1102/1875 train_loss:3.7618 train_time:794960ms step_avg:727.99ms
step:1103/1875 train_loss:3.5950 train_time:795688ms step_avg:727.99ms
step:1104/1875 train_loss:3.6370 train_time:796411ms step_avg:727.98ms
step:1105/1875 train_loss:3.7657 train_time:797144ms step_avg:727.99ms
step:1106/1875 train_loss:3.6312 train_time:797878ms step_avg:727.99ms
step:1107/1875 train_loss:4.3461 train_time:798587ms step_avg:727.97ms
step:1108/1875 train_loss:3.5421 train_time:799322ms step_avg:727.98ms
step:1109/1875 train_loss:3.8718 train_time:800043ms step_avg:727.97ms
step:1110/1875 train_loss:3.6563 train_time:800780ms step_avg:727.98ms
step:1111/1875 train_loss:3.7970 train_time:801497ms step_avg:727.97ms
step:1112/1875 train_loss:3.7416 train_time:802217ms step_avg:727.96ms
step:1113/1875 train_loss:3.7878 train_time:802948ms step_avg:727.97ms
step:1114/1875 train_loss:3.8677 train_time:803676ms step_avg:727.97ms
step:1115/1875 train_loss:3.7562 train_time:804392ms step_avg:727.96ms
step:1116/1875 train_loss:3.6639 train_time:805115ms step_avg:727.95ms
step:1117/1875 train_loss:3.5468 train_time:805852ms step_avg:727.96ms
step:1118/1875 train_loss:3.7409 train_time:806579ms step_avg:727.96ms
step:1119/1875 train_loss:3.9023 train_time:807315ms step_avg:727.97ms
step:1120/1875 train_loss:3.9343 train_time:808050ms step_avg:727.97ms
step:1121/1875 train_loss:3.7835 train_time:808771ms step_avg:727.97ms
step:1122/1875 train_loss:3.8128 train_time:809490ms step_avg:727.96ms
step:1123/1875 train_loss:3.6960 train_time:810213ms step_avg:727.95ms
step:1124/1875 train_loss:3.7637 train_time:810931ms step_avg:727.95ms
step:1125/1875 train_loss:3.9026 train_time:811655ms step_avg:727.94ms
step:1125/1875 val_loss:3.7264 train_time:811879ms step_avg:728.14ms
============== Weight norms: ==============
name = 'module._orig_mod.transformer.h.0.attn.c_q.weight' | fro_norm = 39.09678 | spectral_norm = 15.44024 | nuclear_norm = 761.12048
name = 'module._orig_mod.transformer.h.0.attn.c_k.weight' | fro_norm = 37.25240 | spectral_norm = 14.99185 | nuclear_norm = 713.22241
name = 'module._orig_mod.transformer.h.1.attn.c_q.weight' | fro_norm = 39.19280 | spectral_norm = 10.27474 | nuclear_norm = 755.53162
name = 'module._orig_mod.transformer.h.1.attn.c_k.weight' | fro_norm = 36.50483 | spectral_norm = 9.71744 | nuclear_norm = 719.27148
name = 'module._orig_mod.transformer.h.2.attn.c_q.weight' | fro_norm = 38.26600 | spectral_norm = 6.36102 | nuclear_norm = 715.54321
name = 'module._orig_mod.transformer.h.2.attn.c_k.weight' | fro_norm = 36.25767 | spectral_norm = 5.99377 | nuclear_norm = 702.64539
name = 'module._orig_mod.transformer.h.3.attn.c_q.weight' | fro_norm = 38.25362 | spectral_norm = 7.11522 | nuclear_norm = 756.40686
name = 'module._orig_mod.transformer.h.3.attn.c_k.weight' | fro_norm = 35.64044 | spectral_norm = 6.47530 | nuclear_norm = 720.56543
name = 'module._orig_mod.transformer.h.4.attn.c_q.weight' | fro_norm = 38.05095 | spectral_norm = 7.02562 | nuclear_norm = 754.45465
name = 'module._orig_mod.transformer.h.4.attn.c_k.weight' | fro_norm = 35.50726 | spectral_norm = 6.95599 | nuclear_norm = 721.43140
name = 'module._orig_mod.transformer.h.5.attn.c_q.weight' | fro_norm = 39.26100 | spectral_norm = 7.80120 | nuclear_norm = 759.16870
name = 'module._orig_mod.transformer.h.5.attn.c_k.weight' | fro_norm = 36.96655 | spectral_norm = 7.02151 | nuclear_norm = 728.94763
name = 'module._orig_mod.transformer.h.6.attn.c_q.weight' | fro_norm = 38.63760 | spectral_norm = 7.59279 | nuclear_norm = 754.04041
name = 'module._orig_mod.transformer.h.6.attn.c_k.weight' | fro_norm = 37.02377 | spectral_norm = 6.68054 | nuclear_norm = 743.74805
name = 'module._orig_mod.transformer.h.7.attn.c_q.weight' | fro_norm = 38.74504 | spectral_norm = 6.19794 | nuclear_norm = 788.55396
name = 'module._orig_mod.transformer.h.7.attn.c_k.weight' | fro_norm = 36.36999 | spectral_norm = 5.87204 | nuclear_norm = 751.12268
name = 'module._orig_mod.transformer.h.8.attn.c_q.weight' | fro_norm = 37.89934 | spectral_norm = 7.58699 | nuclear_norm = 746.96826
name = 'module._orig_mod.transformer.h.8.attn.c_k.weight' | fro_norm = 36.62824 | spectral_norm = 7.04361 | nuclear_norm = 734.68463
name = 'module._orig_mod.transformer.h.9.attn.c_q.weight' | fro_norm = 37.23374 | spectral_norm = 7.89515 | nuclear_norm = 719.94940
name = 'module._orig_mod.transformer.h.9.attn.c_k.weight' | fro_norm = 34.01380 | spectral_norm = 7.53950 | nuclear_norm = 667.98499
name = 'module._orig_mod.transformer.h.10.attn.c_q.weight' | fro_norm = 37.79691 | spectral_norm = 7.14712 | nuclear_norm = 747.47992
name = 'module._orig_mod.transformer.h.10.attn.c_k.weight' | fro_norm = 34.97871 | spectral_norm = 6.58044 | nuclear_norm = 703.63562
name = 'module._orig_mod.transformer.h.11.attn.c_q.weight' | fro_norm = 37.38401 | spectral_norm = 7.84338 | nuclear_norm = 735.26892
name = 'module._orig_mod.transformer.h.11.attn.c_k.weight' | fro_norm = 34.63264 | spectral_norm = 6.96020 | nuclear_norm = 696.57214
===========================================
step:1126/1875 train_loss:3.6680 train_time:812390ms step_avg:727.95ms
step:1127/1875 train_loss:3.5335 train_time:813124ms step_avg:727.95ms
step:1128/1875 train_loss:3.7934 train_time:813858ms step_avg:727.96ms
step:1129/1875 train_loss:3.9990 train_time:814585ms step_avg:727.96ms
step:1130/1875 train_loss:3.5504 train_time:815315ms step_avg:727.96ms
step:1131/1875 train_loss:3.8742 train_time:816040ms step_avg:727.96ms
step:1132/1875 train_loss:3.7029 train_time:816759ms step_avg:727.95ms
step:1133/1875 train_loss:3.7119 train_time:817482ms step_avg:727.94ms
step:1134/1875 train_loss:3.6725 train_time:818204ms step_avg:727.94ms
step:1135/1875 train_loss:3.8218 train_time:818931ms step_avg:727.94ms
step:1136/1875 train_loss:3.7643 train_time:819670ms step_avg:727.95ms
step:1137/1875 train_loss:3.8271 train_time:820396ms step_avg:727.95ms
step:1138/1875 train_loss:3.8583 train_time:821123ms step_avg:727.95ms
step:1139/1875 train_loss:3.7792 train_time:821843ms step_avg:727.94ms
step:1140/1875 train_loss:3.6715 train_time:822799ms step_avg:728.14ms
step:1141/1875 train_loss:3.9825 train_time:823526ms step_avg:728.14ms
step:1142/1875 train_loss:3.7870 train_time:824246ms step_avg:728.13ms
step:1143/1875 train_loss:3.8386 train_time:825194ms step_avg:728.33ms
step:1144/1875 train_loss:3.8725 train_time:825910ms step_avg:728.32ms
step:1145/1875 train_loss:3.5079 train_time:826636ms step_avg:728.31ms
step:1146/1875 train_loss:3.8175 train_time:827369ms step_avg:728.32ms
step:1147/1875 train_loss:3.6595 train_time:828105ms step_avg:728.32ms
step:1148/1875 train_loss:3.7015 train_time:828822ms step_avg:728.31ms
step:1149/1875 train_loss:3.7800 train_time:829552ms step_avg:728.32ms
step:1150/1875 train_loss:3.8608 train_time:830271ms step_avg:728.31ms
step:1151/1875 train_loss:3.8113 train_time:830998ms step_avg:728.31ms
step:1152/1875 train_loss:3.7176 train_time:831727ms step_avg:728.31ms
step:1153/1875 train_loss:3.6686 train_time:832460ms step_avg:728.31ms
step:1154/1875 train_loss:3.8848 train_time:833191ms step_avg:728.31ms
step:1155/1875 train_loss:3.9012 train_time:833924ms step_avg:728.32ms
step:1156/1875 train_loss:3.6124 train_time:834646ms step_avg:728.31ms
step:1157/1875 train_loss:3.6055 train_time:835366ms step_avg:728.30ms
step:1158/1875 train_loss:3.7546 train_time:836105ms step_avg:728.31ms
step:1159/1875 train_loss:3.8113 train_time:836827ms step_avg:728.31ms
step:1160/1875 train_loss:3.5337 train_time:837557ms step_avg:728.31ms
step:1161/1875 train_loss:3.6083 train_time:838280ms step_avg:728.31ms
step:1162/1875 train_loss:3.6036 train_time:838985ms step_avg:728.29ms
step:1163/1875 train_loss:3.8142 train_time:839729ms step_avg:728.30ms
step:1164/1875 train_loss:3.6131 train_time:840457ms step_avg:728.30ms
step:1165/1875 train_loss:3.7524 train_time:841183ms step_avg:728.30ms
step:1166/1875 train_loss:3.7290 train_time:841915ms step_avg:728.30ms
step:1167/1875 train_loss:3.7280 train_time:842640ms step_avg:728.30ms
step:1168/1875 train_loss:3.6934 train_time:843364ms step_avg:728.29ms
step:1169/1875 train_loss:3.6934 train_time:844086ms step_avg:728.29ms
step:1170/1875 train_loss:3.9143 train_time:844804ms step_avg:728.28ms
step:1171/1875 train_loss:3.6871 train_time:845533ms step_avg:728.28ms
step:1172/1875 train_loss:3.7795 train_time:846260ms step_avg:728.28ms
step:1173/1875 train_loss:3.7334 train_time:846985ms step_avg:728.28ms
step:1174/1875 train_loss:3.6254 train_time:847715ms step_avg:728.28ms
step:1175/1875 train_loss:3.7332 train_time:848433ms step_avg:728.27ms
step:1176/1875 train_loss:4.0849 train_time:849173ms step_avg:728.28ms
step:1177/1875 train_loss:3.7076 train_time:849923ms step_avg:728.30ms
step:1178/1875 train_loss:3.6915 train_time:850650ms step_avg:728.30ms
step:1179/1875 train_loss:3.6118 train_time:851392ms step_avg:728.31ms
step:1180/1875 train_loss:3.7361 train_time:852124ms step_avg:728.31ms
step:1181/1875 train_loss:3.7532 train_time:852847ms step_avg:728.31ms
step:1182/1875 train_loss:3.6987 train_time:853571ms step_avg:728.30ms
step:1183/1875 train_loss:3.5960 train_time:854307ms step_avg:728.31ms
step:1184/1875 train_loss:3.7352 train_time:855036ms step_avg:728.31ms
step:1185/1875 train_loss:3.8388 train_time:855764ms step_avg:728.31ms
step:1186/1875 train_loss:4.0118 train_time:856486ms step_avg:728.30ms
step:1187/1875 train_loss:3.8508 train_time:857213ms step_avg:728.30ms
step:1188/1875 train_loss:3.7043 train_time:857946ms step_avg:728.31ms
step:1189/1875 train_loss:3.5413 train_time:858673ms step_avg:728.31ms
step:1190/1875 train_loss:3.6859 train_time:859418ms step_avg:728.32ms
step:1191/1875 train_loss:3.6984 train_time:860146ms step_avg:728.32ms
step:1192/1875 train_loss:3.7435 train_time:860873ms step_avg:728.32ms
step:1193/1875 train_loss:3.6574 train_time:861599ms step_avg:728.32ms
step:1194/1875 train_loss:3.8114 train_time:862329ms step_avg:728.32ms
step:1195/1875 train_loss:3.6629 train_time:863039ms step_avg:728.30ms
step:1196/1875 train_loss:3.6749 train_time:863778ms step_avg:728.31ms
step:1197/1875 train_loss:3.6553 train_time:864515ms step_avg:728.32ms
step:1198/1875 train_loss:3.7341 train_time:865244ms step_avg:728.32ms
step:1199/1875 train_loss:3.7132 train_time:865971ms step_avg:728.32ms
step:1200/1875 train_loss:3.6606 train_time:866705ms step_avg:728.32ms
step:1201/1875 train_loss:4.0777 train_time:867432ms step_avg:728.32ms
step:1202/1875 train_loss:3.6278 train_time:868180ms step_avg:728.34ms
step:1203/1875 train_loss:3.7096 train_time:868908ms step_avg:728.34ms
step:1204/1875 train_loss:3.7016 train_time:869629ms step_avg:728.33ms
step:1205/1875 train_loss:3.7900 train_time:870378ms step_avg:728.35ms
step:1206/1875 train_loss:3.7707 train_time:871112ms step_avg:728.35ms
step:1207/1875 train_loss:3.7441 train_time:871834ms step_avg:728.35ms
step:1208/1875 train_loss:3.6663 train_time:872566ms step_avg:728.35ms
step:1209/1875 train_loss:3.7249 train_time:873289ms step_avg:728.35ms
step:1210/1875 train_loss:3.6560 train_time:874013ms step_avg:728.34ms
step:1211/1875 train_loss:3.7425 train_time:874738ms step_avg:728.34ms
step:1212/1875 train_loss:3.9852 train_time:875473ms step_avg:728.35ms
step:1213/1875 train_loss:3.6411 train_time:876209ms step_avg:728.35ms
step:1214/1875 train_loss:3.8981 train_time:876925ms step_avg:728.34ms
step:1215/1875 train_loss:3.7183 train_time:877648ms step_avg:728.34ms
step:1216/1875 train_loss:3.7763 train_time:878373ms step_avg:728.34ms
step:1217/1875 train_loss:3.7260 train_time:879107ms step_avg:728.34ms
step:1218/1875 train_loss:3.7480 train_time:879823ms step_avg:728.33ms
step:1219/1875 train_loss:3.7778 train_time:880544ms step_avg:728.32ms
step:1220/1875 train_loss:3.6928 train_time:881263ms step_avg:728.32ms
step:1221/1875 train_loss:3.7413 train_time:881991ms step_avg:728.32ms
step:1222/1875 train_loss:3.7532 train_time:882714ms step_avg:728.31ms
step:1223/1875 train_loss:3.7771 train_time:883441ms step_avg:728.31ms
step:1224/1875 train_loss:3.7373 train_time:884173ms step_avg:728.31ms
step:1225/1875 train_loss:3.7126 train_time:884907ms step_avg:728.32ms
step:1226/1875 train_loss:3.6103 train_time:885639ms step_avg:728.32ms
step:1227/1875 train_loss:3.7568 train_time:886368ms step_avg:728.32ms
step:1228/1875 train_loss:3.5518 train_time:887092ms step_avg:728.32ms
step:1229/1875 train_loss:3.8665 train_time:887823ms step_avg:728.32ms
step:1230/1875 train_loss:3.6644 train_time:888558ms step_avg:728.33ms
step:1231/1875 train_loss:3.6705 train_time:889286ms step_avg:728.33ms
step:1232/1875 train_loss:3.8421 train_time:890026ms step_avg:728.34ms
step:1233/1875 train_loss:3.5673 train_time:890766ms step_avg:728.34ms
step:1234/1875 train_loss:3.6465 train_time:891486ms step_avg:728.34ms
step:1235/1875 train_loss:3.6978 train_time:892207ms step_avg:728.33ms
step:1236/1875 train_loss:3.7199 train_time:892930ms step_avg:728.33ms
step:1237/1875 train_loss:3.6879 train_time:893651ms step_avg:728.32ms
step:1238/1875 train_loss:3.6700 train_time:894384ms step_avg:728.33ms
step:1239/1875 train_loss:3.9012 train_time:895103ms step_avg:728.32ms
step:1240/1875 train_loss:3.6523 train_time:895828ms step_avg:728.32ms
step:1241/1875 train_loss:3.5276 train_time:896569ms step_avg:728.33ms
step:1242/1875 train_loss:3.8316 train_time:897300ms step_avg:728.33ms
step:1243/1875 train_loss:3.5271 train_time:898034ms step_avg:728.33ms
step:1244/1875 train_loss:3.7491 train_time:898757ms step_avg:728.33ms
step:1245/1875 train_loss:3.9638 train_time:899483ms step_avg:728.33ms
step:1246/1875 train_loss:3.6309 train_time:900204ms step_avg:728.32ms
step:1247/1875 train_loss:3.7151 train_time:900926ms step_avg:728.32ms
step:1248/1875 train_loss:3.8097 train_time:901646ms step_avg:728.31ms
step:1249/1875 train_loss:3.5553 train_time:902364ms step_avg:728.30ms
step:1250/1875 train_loss:3.6231 train_time:903095ms step_avg:728.30ms
step:1250/1875 val_loss:3.6903 train_time:903308ms step_avg:728.47ms
============== Weight norms: ==============
name = 'module._orig_mod.transformer.h.0.attn.c_q.weight' | fro_norm = 41.03319 | spectral_norm = 16.16331 | nuclear_norm = 799.39587
name = 'module._orig_mod.transformer.h.0.attn.c_k.weight' | fro_norm = 39.16010 | spectral_norm = 15.73254 | nuclear_norm = 748.88672
name = 'module._orig_mod.transformer.h.1.attn.c_q.weight' | fro_norm = 40.95579 | spectral_norm = 10.70624 | nuclear_norm = 787.94543
name = 'module._orig_mod.transformer.h.1.attn.c_k.weight' | fro_norm = 38.20248 | spectral_norm = 10.22392 | nuclear_norm = 750.94379
name = 'module._orig_mod.transformer.h.2.attn.c_q.weight' | fro_norm = 40.05909 | spectral_norm = 6.57686 | nuclear_norm = 748.89551
name = 'module._orig_mod.transformer.h.2.attn.c_k.weight' | fro_norm = 37.98526 | spectral_norm = 6.23924 | nuclear_norm = 734.91577
name = 'module._orig_mod.transformer.h.3.attn.c_q.weight' | fro_norm = 40.34868 | spectral_norm = 7.34748 | nuclear_norm = 797.38989
name = 'module._orig_mod.transformer.h.3.attn.c_k.weight' | fro_norm = 37.59687 | spectral_norm = 6.72386 | nuclear_norm = 758.95374
name = 'module._orig_mod.transformer.h.4.attn.c_q.weight' | fro_norm = 40.13238 | spectral_norm = 7.45520 | nuclear_norm = 794.27441
name = 'module._orig_mod.transformer.h.4.attn.c_k.weight' | fro_norm = 37.46499 | spectral_norm = 7.33348 | nuclear_norm = 759.34875
name = 'module._orig_mod.transformer.h.5.attn.c_q.weight' | fro_norm = 41.33445 | spectral_norm = 8.10328 | nuclear_norm = 800.05237
name = 'module._orig_mod.transformer.h.5.attn.c_k.weight' | fro_norm = 38.90033 | spectral_norm = 7.32580 | nuclear_norm = 767.06830
name = 'module._orig_mod.transformer.h.6.attn.c_q.weight' | fro_norm = 40.81229 | spectral_norm = 7.88926 | nuclear_norm = 795.84869
name = 'module._orig_mod.transformer.h.6.attn.c_k.weight' | fro_norm = 39.04748 | spectral_norm = 7.05551 | nuclear_norm = 783.74078
name = 'module._orig_mod.transformer.h.7.attn.c_q.weight' | fro_norm = 41.00905 | spectral_norm = 6.45523 | nuclear_norm = 835.75500
name = 'module._orig_mod.transformer.h.7.attn.c_k.weight' | fro_norm = 38.47709 | spectral_norm = 6.33155 | nuclear_norm = 795.32648
name = 'module._orig_mod.transformer.h.8.attn.c_q.weight' | fro_norm = 40.18388 | spectral_norm = 7.92192 | nuclear_norm = 793.80475
name = 'module._orig_mod.transformer.h.8.attn.c_k.weight' | fro_norm = 38.89795 | spectral_norm = 7.33928 | nuclear_norm = 780.67578
name = 'module._orig_mod.transformer.h.9.attn.c_q.weight' | fro_norm = 39.41087 | spectral_norm = 8.25113 | nuclear_norm = 759.41046
name = 'module._orig_mod.transformer.h.9.attn.c_k.weight' | fro_norm = 35.97995 | spectral_norm = 7.91292 | nuclear_norm = 703.61060
name = 'module._orig_mod.transformer.h.10.attn.c_q.weight' | fro_norm = 40.15547 | spectral_norm = 7.57842 | nuclear_norm = 792.84973
name = 'module._orig_mod.transformer.h.10.attn.c_k.weight' | fro_norm = 37.17925 | spectral_norm = 6.78541 | nuclear_norm = 746.12891
name = 'module._orig_mod.transformer.h.11.attn.c_q.weight' | fro_norm = 39.59785 | spectral_norm = 8.04765 | nuclear_norm = 780.24792
name = 'module._orig_mod.transformer.h.11.attn.c_k.weight' | fro_norm = 36.63129 | spectral_norm = 7.17318 | nuclear_norm = 736.82129
===========================================
step:1251/1875 train_loss:3.6427 train_time:903815ms step_avg:728.30ms
step:1252/1875 train_loss:3.5198 train_time:904532ms step_avg:728.29ms
step:1253/1875 train_loss:3.7773 train_time:905254ms step_avg:728.28ms
step:1254/1875 train_loss:3.8520 train_time:905999ms step_avg:728.30ms
step:1255/1875 train_loss:3.6196 train_time:906719ms step_avg:728.29ms
step:1256/1875 train_loss:3.8165 train_time:907440ms step_avg:728.28ms
step:1257/1875 train_loss:3.5616 train_time:908168ms step_avg:728.28ms
step:1258/1875 train_loss:3.7328 train_time:908900ms step_avg:728.28ms
step:1259/1875 train_loss:3.8324 train_time:909621ms step_avg:728.28ms
step:1260/1875 train_loss:3.6663 train_time:910341ms step_avg:728.27ms
step:1261/1875 train_loss:3.7267 train_time:911059ms step_avg:728.26ms
step:1262/1875 train_loss:3.8525 train_time:911806ms step_avg:728.28ms
step:1263/1875 train_loss:3.5291 train_time:912526ms step_avg:728.27ms
step:1264/1875 train_loss:3.7812 train_time:913256ms step_avg:728.27ms
step:1265/1875 train_loss:3.6976 train_time:913983ms step_avg:728.27ms
step:1266/1875 train_loss:3.6934 train_time:914709ms step_avg:728.27ms
step:1267/1875 train_loss:3.6203 train_time:915430ms step_avg:728.27ms
step:1268/1875 train_loss:3.6038 train_time:916152ms step_avg:728.26ms
step:1269/1875 train_loss:3.7170 train_time:916892ms step_avg:728.27ms
step:1270/1875 train_loss:3.6333 train_time:917620ms step_avg:728.27ms
step:1271/1875 train_loss:3.7283 train_time:918346ms step_avg:728.27ms
step:1272/1875 train_loss:3.6923 train_time:919075ms step_avg:728.27ms
step:1273/1875 train_loss:3.7202 train_time:919797ms step_avg:728.26ms
step:1274/1875 train_loss:3.6218 train_time:920521ms step_avg:728.26ms
step:1275/1875 train_loss:3.7458 train_time:921246ms step_avg:728.26ms
step:1276/1875 train_loss:3.6846 train_time:921967ms step_avg:728.25ms
step:1277/1875 train_loss:3.7726 train_time:922687ms step_avg:728.25ms
step:1278/1875 train_loss:3.7215 train_time:923405ms step_avg:728.24ms
step:1279/1875 train_loss:3.6390 train_time:924146ms step_avg:728.25ms
step:1280/1875 train_loss:3.5806 train_time:924884ms step_avg:728.26ms
step:1281/1875 train_loss:3.6834 train_time:925606ms step_avg:728.25ms
step:1282/1875 train_loss:3.6316 train_time:926335ms step_avg:728.25ms
step:1283/1875 train_loss:3.8205 train_time:927052ms step_avg:728.24ms
step:1284/1875 train_loss:3.6407 train_time:927775ms step_avg:728.24ms
step:1285/1875 train_loss:3.7902 train_time:928501ms step_avg:728.24ms
step:1286/1875 train_loss:3.6495 train_time:929228ms step_avg:728.24ms
step:1287/1875 train_loss:3.7373 train_time:929958ms step_avg:728.24ms
step:1288/1875 train_loss:3.7219 train_time:930661ms step_avg:728.22ms
step:1289/1875 train_loss:3.7027 train_time:931397ms step_avg:728.22ms
step:1290/1875 train_loss:3.7135 train_time:932134ms step_avg:728.23ms
step:1291/1875 train_loss:3.8485 train_time:932867ms step_avg:728.23ms
step:1292/1875 train_loss:3.6775 train_time:933596ms step_avg:728.23ms
step:1293/1875 train_loss:3.4584 train_time:934341ms step_avg:728.25ms
step:1294/1875 train_loss:3.7027 train_time:935058ms step_avg:728.24ms
step:1295/1875 train_loss:3.6952 train_time:935799ms step_avg:728.25ms
step:1296/1875 train_loss:3.7267 train_time:936535ms step_avg:728.25ms
step:1297/1875 train_loss:3.7600 train_time:937263ms step_avg:728.25ms
step:1298/1875 train_loss:3.7643 train_time:937981ms step_avg:728.25ms
step:1299/1875 train_loss:3.7463 train_time:938702ms step_avg:728.24ms
step:1300/1875 train_loss:3.6952 train_time:939427ms step_avg:728.24ms
step:1301/1875 train_loss:3.8394 train_time:940150ms step_avg:728.23ms
step:1302/1875 train_loss:3.7088 train_time:940870ms step_avg:728.23ms
step:1303/1875 train_loss:3.7623 train_time:941590ms step_avg:728.22ms
step:1304/1875 train_loss:3.6919 train_time:942312ms step_avg:728.22ms
step:1305/1875 train_loss:3.7917 train_time:943037ms step_avg:728.21ms
step:1306/1875 train_loss:3.8716 train_time:943777ms step_avg:728.22ms
step:1307/1875 train_loss:3.6553 train_time:944511ms step_avg:728.23ms
step:1308/1875 train_loss:3.6271 train_time:945238ms step_avg:728.23ms
step:1309/1875 train_loss:3.6459 train_time:945966ms step_avg:728.23ms
step:1310/1875 train_loss:3.6777 train_time:946682ms step_avg:728.22ms
step:1311/1875 train_loss:3.6174 train_time:947405ms step_avg:728.21ms
step:1312/1875 train_loss:3.8054 train_time:948134ms step_avg:728.21ms
step:1313/1875 train_loss:3.6886 train_time:948856ms step_avg:728.21ms
step:1314/1875 train_loss:3.7506 train_time:949573ms step_avg:728.20ms
step:1315/1875 train_loss:3.7257 train_time:950300ms step_avg:728.20ms
step:1316/1875 train_loss:3.7434 train_time:951024ms step_avg:728.20ms
step:1317/1875 train_loss:3.5796 train_time:951749ms step_avg:728.19ms
step:1318/1875 train_loss:3.8408 train_time:952487ms step_avg:728.20ms
step:1319/1875 train_loss:3.7812 train_time:953207ms step_avg:728.20ms
step:1320/1875 train_loss:3.6690 train_time:953935ms step_avg:728.20ms
step:1321/1875 train_loss:3.7565 train_time:954669ms step_avg:728.20ms
step:1322/1875 train_loss:3.7388 train_time:955386ms step_avg:728.19ms
step:1323/1875 train_loss:3.7062 train_time:956109ms step_avg:728.19ms
step:1324/1875 train_loss:3.8837 train_time:956832ms step_avg:728.18ms
step:1325/1875 train_loss:3.7672 train_time:957575ms step_avg:728.19ms
step:1326/1875 train_loss:3.8047 train_time:958311ms step_avg:728.20ms
step:1327/1875 train_loss:3.8384 train_time:959020ms step_avg:728.19ms
step:1328/1875 train_loss:3.5692 train_time:959754ms step_avg:728.19ms
step:1329/1875 train_loss:3.6484 train_time:960486ms step_avg:728.19ms
step:1330/1875 train_loss:3.7173 train_time:961428ms step_avg:728.35ms
step:1331/1875 train_loss:3.0470 train_time:962168ms step_avg:728.36ms
step:1332/1875 train_loss:3.7162 train_time:962914ms step_avg:728.38ms
step:1333/1875 train_loss:3.6917 train_time:963643ms step_avg:728.38ms
step:1334/1875 train_loss:3.6878 train_time:964361ms step_avg:728.37ms
step:1335/1875 train_loss:4.0682 train_time:965103ms step_avg:728.38ms
step:1336/1875 train_loss:3.7899 train_time:965831ms step_avg:728.38ms
step:1337/1875 train_loss:3.7015 train_time:966550ms step_avg:728.37ms
step:1338/1875 train_loss:3.6474 train_time:967275ms step_avg:728.37ms
step:1339/1875 train_loss:3.6202 train_time:968007ms step_avg:728.37ms
step:1340/1875 train_loss:3.8866 train_time:968739ms step_avg:728.38ms
step:1341/1875 train_loss:3.8352 train_time:969471ms step_avg:728.38ms
step:1342/1875 train_loss:3.6783 train_time:970197ms step_avg:728.38ms
step:1343/1875 train_loss:3.6226 train_time:970921ms step_avg:728.37ms
step:1344/1875 train_loss:3.9244 train_time:971642ms step_avg:728.37ms
step:1345/1875 train_loss:3.7021 train_time:972372ms step_avg:728.37ms
step:1346/1875 train_loss:3.6908 train_time:973089ms step_avg:728.36ms
step:1347/1875 train_loss:3.7393 train_time:973821ms step_avg:728.36ms
step:1348/1875 train_loss:3.7184 train_time:974545ms step_avg:728.36ms
step:1349/1875 train_loss:3.6310 train_time:975271ms step_avg:728.36ms
step:1350/1875 train_loss:3.5675 train_time:975987ms step_avg:728.35ms
step:1351/1875 train_loss:3.6573 train_time:976713ms step_avg:728.35ms
step:1352/1875 train_loss:3.6054 train_time:977458ms step_avg:728.36ms
step:1353/1875 train_loss:3.7277 train_time:978178ms step_avg:728.35ms
step:1354/1875 train_loss:3.5579 train_time:978898ms step_avg:728.35ms
step:1355/1875 train_loss:3.6308 train_time:979621ms step_avg:728.34ms
step:1356/1875 train_loss:3.7452 train_time:980341ms step_avg:728.34ms
step:1357/1875 train_loss:3.5860 train_time:981085ms step_avg:728.35ms
step:1358/1875 train_loss:3.5164 train_time:981812ms step_avg:728.35ms
step:1359/1875 train_loss:3.8468 train_time:982539ms step_avg:728.35ms
step:1360/1875 train_loss:3.7710 train_time:983261ms step_avg:728.34ms
step:1361/1875 train_loss:3.5031 train_time:983991ms step_avg:728.34ms
step:1362/1875 train_loss:3.7886 train_time:984722ms step_avg:728.34ms
step:1363/1875 train_loss:3.6835 train_time:985449ms step_avg:728.34ms
step:1364/1875 train_loss:3.5232 train_time:986178ms step_avg:728.34ms
step:1365/1875 train_loss:3.7159 train_time:986909ms step_avg:728.35ms
step:1366/1875 train_loss:3.6057 train_time:987647ms step_avg:728.35ms
step:1367/1875 train_loss:3.6433 train_time:988373ms step_avg:728.35ms
step:1368/1875 train_loss:3.6433 train_time:989097ms step_avg:728.35ms
step:1369/1875 train_loss:3.7585 train_time:989824ms step_avg:728.35ms
step:1370/1875 train_loss:3.7196 train_time:990542ms step_avg:728.34ms
step:1371/1875 train_loss:3.6944 train_time:991280ms step_avg:728.35ms
step:1372/1875 train_loss:3.5799 train_time:992005ms step_avg:728.34ms
step:1373/1875 train_loss:3.9262 train_time:992729ms step_avg:728.34ms
step:1374/1875 train_loss:3.6682 train_time:993452ms step_avg:728.34ms
step:1375/1875 train_loss:3.6947 train_time:994187ms step_avg:728.34ms
step:1375/1875 val_loss:3.6504 train_time:994403ms step_avg:728.50ms
============== Weight norms: ==============
name = 'module._orig_mod.transformer.h.0.attn.c_q.weight' | fro_norm = 42.87057 | spectral_norm = 16.76234 | nuclear_norm = 836.33423
name = 'module._orig_mod.transformer.h.0.attn.c_k.weight' | fro_norm = 40.99675 | spectral_norm = 16.40356 | nuclear_norm = 784.23608
name = 'module._orig_mod.transformer.h.1.attn.c_q.weight' | fro_norm = 42.60920 | spectral_norm = 11.14273 | nuclear_norm = 818.99878
name = 'module._orig_mod.transformer.h.1.attn.c_k.weight' | fro_norm = 39.82651 | spectral_norm = 10.68207 | nuclear_norm = 781.55896
name = 'module._orig_mod.transformer.h.2.attn.c_q.weight' | fro_norm = 41.71074 | spectral_norm = 6.76582 | nuclear_norm = 779.16870
name = 'module._orig_mod.transformer.h.2.attn.c_k.weight' | fro_norm = 39.61164 | spectral_norm = 6.46426 | nuclear_norm = 765.17902
name = 'module._orig_mod.transformer.h.3.attn.c_q.weight' | fro_norm = 42.28438 | spectral_norm = 7.54497 | nuclear_norm = 835.76288
name = 'module._orig_mod.transformer.h.3.attn.c_k.weight' | fro_norm = 39.44109 | spectral_norm = 6.98957 | nuclear_norm = 796.07654
name = 'module._orig_mod.transformer.h.4.attn.c_q.weight' | fro_norm = 42.03866 | spectral_norm = 7.82521 | nuclear_norm = 831.48071
name = 'module._orig_mod.transformer.h.4.attn.c_k.weight' | fro_norm = 39.26782 | spectral_norm = 7.61936 | nuclear_norm = 795.66174
name = 'module._orig_mod.transformer.h.5.attn.c_q.weight' | fro_norm = 43.28802 | spectral_norm = 8.36694 | nuclear_norm = 838.99933
name = 'module._orig_mod.transformer.h.5.attn.c_k.weight' | fro_norm = 40.72326 | spectral_norm = 7.56865 | nuclear_norm = 803.74524
name = 'module._orig_mod.transformer.h.6.attn.c_q.weight' | fro_norm = 42.84693 | spectral_norm = 8.13017 | nuclear_norm = 835.87573
name = 'module._orig_mod.transformer.h.6.attn.c_k.weight' | fro_norm = 40.94393 | spectral_norm = 7.41640 | nuclear_norm = 821.84827
name = 'module._orig_mod.transformer.h.7.attn.c_q.weight' | fro_norm = 43.11995 | spectral_norm = 6.70181 | nuclear_norm = 880.75214
name = 'module._orig_mod.transformer.h.7.attn.c_k.weight' | fro_norm = 40.44484 | spectral_norm = 6.80915 | nuclear_norm = 836.96582
name = 'module._orig_mod.transformer.h.8.attn.c_q.weight' | fro_norm = 42.31353 | spectral_norm = 8.18329 | nuclear_norm = 838.07526
name = 'module._orig_mod.transformer.h.8.attn.c_k.weight' | fro_norm = 40.98690 | spectral_norm = 7.55428 | nuclear_norm = 823.59772
name = 'module._orig_mod.transformer.h.9.attn.c_q.weight' | fro_norm = 41.44613 | spectral_norm = 8.51830 | nuclear_norm = 797.39197
name = 'module._orig_mod.transformer.h.9.attn.c_k.weight' | fro_norm = 37.84325 | spectral_norm = 8.20457 | nuclear_norm = 739.05505
name = 'module._orig_mod.transformer.h.10.attn.c_q.weight' | fro_norm = 42.33593 | spectral_norm = 7.97990 | nuclear_norm = 835.27716
name = 'module._orig_mod.transformer.h.10.attn.c_k.weight' | fro_norm = 39.24581 | spectral_norm = 7.04831 | nuclear_norm = 786.38678
name = 'module._orig_mod.transformer.h.11.attn.c_q.weight' | fro_norm = 41.70895 | spectral_norm = 8.28228 | nuclear_norm = 823.04175
name = 'module._orig_mod.transformer.h.11.attn.c_k.weight' | fro_norm = 38.52676 | spectral_norm = 7.31032 | nuclear_norm = 776.09143
===========================================
step:1376/1875 train_loss:3.6908 train_time:994900ms step_avg:728.33ms
step:1377/1875 train_loss:3.5011 train_time:995629ms step_avg:728.33ms
step:1378/1875 train_loss:3.8965 train_time:996358ms step_avg:728.33ms
step:1379/1875 train_loss:3.6732 train_time:997075ms step_avg:728.32ms
step:1380/1875 train_loss:3.8038 train_time:997803ms step_avg:728.32ms
step:1381/1875 train_loss:3.8348 train_time:998527ms step_avg:728.32ms
step:1382/1875 train_loss:3.4490 train_time:999244ms step_avg:728.31ms
step:1383/1875 train_loss:3.6497 train_time:999980ms step_avg:728.32ms
step:1384/1875 train_loss:4.0389 train_time:1000710ms step_avg:728.32ms
step:1385/1875 train_loss:3.5719 train_time:1001440ms step_avg:728.32ms
step:1386/1875 train_loss:3.7293 train_time:1002162ms step_avg:728.32ms
step:1387/1875 train_loss:3.8183 train_time:1002887ms step_avg:728.31ms
step:1388/1875 train_loss:3.7292 train_time:1003604ms step_avg:728.30ms
step:1389/1875 train_loss:3.7020 train_time:1004323ms step_avg:728.30ms
step:1390/1875 train_loss:3.5205 train_time:1005052ms step_avg:728.30ms
step:1391/1875 train_loss:3.6754 train_time:1005781ms step_avg:728.30ms
step:1392/1875 train_loss:3.6463 train_time:1006507ms step_avg:728.30ms
step:1393/1875 train_loss:3.9122 train_time:1007227ms step_avg:728.29ms
step:1394/1875 train_loss:3.6170 train_time:1007945ms step_avg:728.28ms
step:1395/1875 train_loss:3.6233 train_time:1008663ms step_avg:728.28ms
step:1396/1875 train_loss:3.5806 train_time:1009387ms step_avg:728.27ms
step:1397/1875 train_loss:3.8526 train_time:1010112ms step_avg:728.27ms
step:1398/1875 train_loss:3.7302 train_time:1010834ms step_avg:728.27ms
step:1399/1875 train_loss:3.7342 train_time:1011565ms step_avg:728.27ms
step:1400/1875 train_loss:3.6287 train_time:1012278ms step_avg:728.26ms
step:1401/1875 train_loss:3.5870 train_time:1012995ms step_avg:728.25ms
step:1402/1875 train_loss:3.6768 train_time:1013716ms step_avg:728.24ms
step:1403/1875 train_loss:3.6396 train_time:1014454ms step_avg:728.25ms
step:1404/1875 train_loss:3.6624 train_time:1015169ms step_avg:728.24ms
step:1405/1875 train_loss:3.6225 train_time:1015890ms step_avg:728.24ms
step:1406/1875 train_loss:3.8278 train_time:1016621ms step_avg:728.24ms
step:1407/1875 train_loss:3.5959 train_time:1017334ms step_avg:728.23ms
step:1408/1875 train_loss:3.6441 train_time:1018065ms step_avg:728.23ms
step:1409/1875 train_loss:3.6378 train_time:1018792ms step_avg:728.23ms
step:1410/1875 train_loss:3.5034 train_time:1019508ms step_avg:728.22ms
step:1411/1875 train_loss:3.6276 train_time:1020228ms step_avg:728.21ms
step:1412/1875 train_loss:3.6133 train_time:1020969ms step_avg:728.22ms
step:1413/1875 train_loss:3.6062 train_time:1021690ms step_avg:728.22ms
step:1414/1875 train_loss:3.6925 train_time:1022407ms step_avg:728.21ms
step:1415/1875 train_loss:3.6322 train_time:1023128ms step_avg:728.20ms
step:1416/1875 train_loss:3.6755 train_time:1023858ms step_avg:728.21ms
step:1417/1875 train_loss:3.6554 train_time:1024574ms step_avg:728.20ms
step:1418/1875 train_loss:3.7393 train_time:1025292ms step_avg:728.19ms
step:1419/1875 train_loss:3.5470 train_time:1026041ms step_avg:728.21ms
step:1420/1875 train_loss:3.6103 train_time:1026770ms step_avg:728.21ms
step:1421/1875 train_loss:3.7063 train_time:1027498ms step_avg:728.21ms
step:1422/1875 train_loss:3.6783 train_time:1028223ms step_avg:728.20ms
step:1423/1875 train_loss:3.6868 train_time:1028951ms step_avg:728.20ms
step:1424/1875 train_loss:3.6844 train_time:1029674ms step_avg:728.20ms
step:1425/1875 train_loss:3.6734 train_time:1030407ms step_avg:728.20ms
step:1426/1875 train_loss:3.6434 train_time:1031129ms step_avg:728.20ms
step:1427/1875 train_loss:3.6456 train_time:1031848ms step_avg:728.19ms
step:1428/1875 train_loss:3.5120 train_time:1032579ms step_avg:728.19ms
step:1429/1875 train_loss:3.6521 train_time:1033305ms step_avg:728.19ms
step:1430/1875 train_loss:3.5887 train_time:1034032ms step_avg:728.19ms
step:1431/1875 train_loss:3.6943 train_time:1034758ms step_avg:728.19ms
step:1432/1875 train_loss:3.6878 train_time:1035478ms step_avg:728.18ms
step:1433/1875 train_loss:3.5704 train_time:1036200ms step_avg:728.18ms
step:1434/1875 train_loss:3.6475 train_time:1036924ms step_avg:728.18ms
step:1435/1875 train_loss:3.6760 train_time:1037649ms step_avg:728.17ms
step:1436/1875 train_loss:3.4907 train_time:1038382ms step_avg:728.18ms
step:1437/1875 train_loss:3.6161 train_time:1039116ms step_avg:728.18ms
step:1438/1875 train_loss:3.4579 train_time:1039840ms step_avg:728.18ms
step:1439/1875 train_loss:3.5392 train_time:1040571ms step_avg:728.18ms
step:1440/1875 train_loss:3.7318 train_time:1041288ms step_avg:728.17ms
step:1441/1875 train_loss:3.6908 train_time:1042022ms step_avg:728.18ms
step:1442/1875 train_loss:3.6361 train_time:1042746ms step_avg:728.17ms
step:1443/1875 train_loss:3.4987 train_time:1043473ms step_avg:728.17ms
step:1444/1875 train_loss:3.6814 train_time:1044194ms step_avg:728.17ms
step:1445/1875 train_loss:3.7114 train_time:1044921ms step_avg:728.17ms
step:1446/1875 train_loss:3.7796 train_time:1045668ms step_avg:728.18ms
step:1447/1875 train_loss:3.7745 train_time:1046387ms step_avg:728.17ms
step:1448/1875 train_loss:3.6500 train_time:1047109ms step_avg:728.17ms
step:1449/1875 train_loss:3.5278 train_time:1047842ms step_avg:728.17ms
step:1450/1875 train_loss:3.6028 train_time:1048567ms step_avg:728.17ms
step:1451/1875 train_loss:3.6248 train_time:1049289ms step_avg:728.17ms
step:1452/1875 train_loss:3.7255 train_time:1049999ms step_avg:728.15ms
step:1453/1875 train_loss:3.7199 train_time:1050732ms step_avg:728.16ms
step:1454/1875 train_loss:3.5347 train_time:1051458ms step_avg:728.16ms
step:1455/1875 train_loss:3.6466 train_time:1052180ms step_avg:728.15ms
step:1456/1875 train_loss:3.5809 train_time:1052907ms step_avg:728.15ms
step:1457/1875 train_loss:3.6024 train_time:1053628ms step_avg:728.15ms
step:1458/1875 train_loss:3.6575 train_time:1054359ms step_avg:728.15ms
step:1459/1875 train_loss:3.5855 train_time:1055086ms step_avg:728.15ms
step:1460/1875 train_loss:3.4899 train_time:1055815ms step_avg:728.15ms
step:1461/1875 train_loss:3.7304 train_time:1056531ms step_avg:728.14ms
step:1462/1875 train_loss:3.5956 train_time:1057255ms step_avg:728.14ms
step:1463/1875 train_loss:3.6372 train_time:1057986ms step_avg:728.14ms
step:1464/1875 train_loss:3.7647 train_time:1058704ms step_avg:728.13ms
step:1465/1875 train_loss:3.5876 train_time:1059425ms step_avg:728.13ms
step:1466/1875 train_loss:3.7807 train_time:1060146ms step_avg:728.12ms
step:1467/1875 train_loss:3.6753 train_time:1060868ms step_avg:728.12ms
step:1468/1875 train_loss:3.6619 train_time:1061584ms step_avg:728.11ms
step:1469/1875 train_loss:3.5985 train_time:1062317ms step_avg:728.11ms
step:1470/1875 train_loss:3.7221 train_time:1063042ms step_avg:728.11ms
step:1471/1875 train_loss:3.6124 train_time:1063766ms step_avg:728.11ms
step:1472/1875 train_loss:3.5635 train_time:1064491ms step_avg:728.11ms
step:1473/1875 train_loss:3.6451 train_time:1065219ms step_avg:728.11ms
step:1474/1875 train_loss:3.5606 train_time:1065960ms step_avg:728.11ms
step:1475/1875 train_loss:3.5882 train_time:1066691ms step_avg:728.12ms
step:1476/1875 train_loss:3.7395 train_time:1067414ms step_avg:728.11ms
step:1477/1875 train_loss:3.6376 train_time:1068136ms step_avg:728.11ms
step:1478/1875 train_loss:3.4526 train_time:1068853ms step_avg:728.10ms
step:1479/1875 train_loss:3.5705 train_time:1069576ms step_avg:728.10ms
step:1480/1875 train_loss:3.5581 train_time:1070305ms step_avg:728.10ms
step:1481/1875 train_loss:3.6388 train_time:1071045ms step_avg:728.11ms
step:1482/1875 train_loss:3.7133 train_time:1071775ms step_avg:728.11ms
step:1483/1875 train_loss:3.5988 train_time:1072487ms step_avg:728.10ms
step:1484/1875 train_loss:3.7664 train_time:1073224ms step_avg:728.10ms
step:1485/1875 train_loss:3.6806 train_time:1073948ms step_avg:728.10ms
step:1486/1875 train_loss:3.6003 train_time:1074689ms step_avg:728.11ms
step:1487/1875 train_loss:3.5678 train_time:1075407ms step_avg:728.10ms
step:1488/1875 train_loss:3.5779 train_time:1076128ms step_avg:728.10ms
step:1489/1875 train_loss:3.5269 train_time:1076858ms step_avg:728.10ms
step:1490/1875 train_loss:3.6404 train_time:1077590ms step_avg:728.10ms
step:1491/1875 train_loss:3.5344 train_time:1078327ms step_avg:728.11ms
step:1492/1875 train_loss:3.6420 train_time:1079054ms step_avg:728.11ms
step:1493/1875 train_loss:3.5536 train_time:1079779ms step_avg:728.10ms
step:1494/1875 train_loss:3.4878 train_time:1080506ms step_avg:728.10ms
step:1495/1875 train_loss:3.5562 train_time:1081228ms step_avg:728.10ms
step:1496/1875 train_loss:3.7487 train_time:1081950ms step_avg:728.10ms
step:1497/1875 train_loss:3.6121 train_time:1082674ms step_avg:728.09ms
step:1498/1875 train_loss:3.3445 train_time:1083409ms step_avg:728.10ms
step:1499/1875 train_loss:3.6609 train_time:1084135ms step_avg:728.10ms
step:1500/1875 train_loss:3.6146 train_time:1084856ms step_avg:728.09ms
step:1500/1875 val_loss:3.5914 train_time:1085074ms step_avg:728.24ms
============== Weight norms: ==============
name = 'module._orig_mod.transformer.h.0.attn.c_q.weight' | fro_norm = 44.09142 | spectral_norm = 17.25242 | nuclear_norm = 860.86133
name = 'module._orig_mod.transformer.h.0.attn.c_k.weight' | fro_norm = 42.22100 | spectral_norm = 16.86588 | nuclear_norm = 808.66870
name = 'module._orig_mod.transformer.h.1.attn.c_q.weight' | fro_norm = 43.74232 | spectral_norm = 11.41162 | nuclear_norm = 840.47131
name = 'module._orig_mod.transformer.h.1.attn.c_k.weight' | fro_norm = 40.96823 | spectral_norm = 11.03128 | nuclear_norm = 803.34058
name = 'module._orig_mod.transformer.h.2.attn.c_q.weight' | fro_norm = 42.81912 | spectral_norm = 6.91886 | nuclear_norm = 799.26501
name = 'module._orig_mod.transformer.h.2.attn.c_k.weight' | fro_norm = 40.71813 | spectral_norm = 6.60638 | nuclear_norm = 785.70447
name = 'module._orig_mod.transformer.h.3.attn.c_q.weight' | fro_norm = 43.60281 | spectral_norm = 7.65680 | nuclear_norm = 862.50201
name = 'module._orig_mod.transformer.h.3.attn.c_k.weight' | fro_norm = 40.73146 | spectral_norm = 7.15780 | nuclear_norm = 822.95123
name = 'module._orig_mod.transformer.h.4.attn.c_q.weight' | fro_norm = 43.32267 | spectral_norm = 8.06040 | nuclear_norm = 856.53223
name = 'module._orig_mod.transformer.h.4.attn.c_k.weight' | fro_norm = 40.48112 | spectral_norm = 7.78553 | nuclear_norm = 820.25220
name = 'module._orig_mod.transformer.h.5.attn.c_q.weight' | fro_norm = 44.60828 | spectral_norm = 8.59233 | nuclear_norm = 865.84802
name = 'module._orig_mod.transformer.h.5.attn.c_k.weight' | fro_norm = 41.96369 | spectral_norm = 7.71990 | nuclear_norm = 829.60754
name = 'module._orig_mod.transformer.h.6.attn.c_q.weight' | fro_norm = 44.24799 | spectral_norm = 8.29913 | nuclear_norm = 864.69495
name = 'module._orig_mod.transformer.h.6.attn.c_k.weight' | fro_norm = 42.28262 | spectral_norm = 7.64984 | nuclear_norm = 849.91028
name = 'module._orig_mod.transformer.h.7.attn.c_q.weight' | fro_norm = 44.51659 | spectral_norm = 6.88001 | nuclear_norm = 911.33215
name = 'module._orig_mod.transformer.h.7.attn.c_k.weight' | fro_norm = 41.77724 | spectral_norm = 7.04932 | nuclear_norm = 866.33868
name = 'module._orig_mod.transformer.h.8.attn.c_q.weight' | fro_norm = 43.71236 | spectral_norm = 8.31223 | nuclear_norm = 867.98621
name = 'module._orig_mod.transformer.h.8.attn.c_k.weight' | fro_norm = 42.38150 | spectral_norm = 7.68212 | nuclear_norm = 853.01276
name = 'module._orig_mod.transformer.h.9.attn.c_q.weight' | fro_norm = 42.79126 | spectral_norm = 8.66512 | nuclear_norm = 823.50989
name = 'module._orig_mod.transformer.h.9.attn.c_k.weight' | fro_norm = 39.09901 | spectral_norm = 8.41108 | nuclear_norm = 763.31964
name = 'module._orig_mod.transformer.h.10.attn.c_q.weight' | fro_norm = 43.74961 | spectral_norm = 8.23837 | nuclear_norm = 863.79736
name = 'module._orig_mod.transformer.h.10.attn.c_k.weight' | fro_norm = 40.59893 | spectral_norm = 7.24287 | nuclear_norm = 813.85327
name = 'module._orig_mod.transformer.h.11.attn.c_q.weight' | fro_norm = 43.08027 | spectral_norm = 8.38333 | nuclear_norm = 852.75842
name = 'module._orig_mod.transformer.h.11.attn.c_k.weight' | fro_norm = 39.85490 | spectral_norm = 7.42653 | nuclear_norm = 804.62085
===========================================
step:1501/1875 train_loss:3.6464 train_time:1085571ms step_avg:728.08ms
step:1502/1875 train_loss:3.6279 train_time:1086297ms step_avg:728.08ms
step:1503/1875 train_loss:3.6005 train_time:1087036ms step_avg:728.09ms
step:1504/1875 train_loss:3.3910 train_time:1087764ms step_avg:728.09ms
step:1505/1875 train_loss:3.6660 train_time:1088507ms step_avg:728.10ms
step:1506/1875 train_loss:3.5523 train_time:1089255ms step_avg:728.11ms
step:1507/1875 train_loss:3.5583 train_time:1089979ms step_avg:728.11ms
step:1508/1875 train_loss:3.5112 train_time:1090718ms step_avg:728.12ms
step:1509/1875 train_loss:3.5908 train_time:1091439ms step_avg:728.11ms
step:1510/1875 train_loss:3.4866 train_time:1092163ms step_avg:728.11ms
step:1511/1875 train_loss:3.8020 train_time:1092891ms step_avg:728.11ms
step:1512/1875 train_loss:3.5798 train_time:1093610ms step_avg:728.10ms
step:1513/1875 train_loss:3.5927 train_time:1094334ms step_avg:728.10ms
step:1514/1875 train_loss:3.7036 train_time:1095056ms step_avg:728.10ms
step:1515/1875 train_loss:3.7290 train_time:1095787ms step_avg:728.10ms
step:1516/1875 train_loss:3.5682 train_time:1096507ms step_avg:728.09ms
step:1517/1875 train_loss:3.3933 train_time:1097248ms step_avg:728.10ms
step:1518/1875 train_loss:3.5455 train_time:1097974ms step_avg:728.10ms
step:1519/1875 train_loss:3.5541 train_time:1098703ms step_avg:728.10ms
step:1520/1875 train_loss:3.6158 train_time:1099653ms step_avg:728.25ms
step:1521/1875 train_loss:3.5212 train_time:1100375ms step_avg:728.24ms
step:1522/1875 train_loss:3.8060 train_time:1101091ms step_avg:728.24ms
step:1523/1875 train_loss:3.4574 train_time:1101818ms step_avg:728.23ms
step:1524/1875 train_loss:3.5530 train_time:1102768ms step_avg:728.38ms
step:1525/1875 train_loss:3.6050 train_time:1103501ms step_avg:728.38ms
step:1526/1875 train_loss:3.5887 train_time:1104233ms step_avg:728.39ms
step:1527/1875 train_loss:3.6428 train_time:1104965ms step_avg:728.39ms
step:1528/1875 train_loss:3.5468 train_time:1105691ms step_avg:728.39ms
step:1529/1875 train_loss:3.5213 train_time:1106412ms step_avg:728.38ms
step:1530/1875 train_loss:3.5605 train_time:1107136ms step_avg:728.38ms
step:1531/1875 train_loss:3.5915 train_time:1107853ms step_avg:728.37ms
step:1532/1875 train_loss:3.5792 train_time:1108588ms step_avg:728.38ms
step:1533/1875 train_loss:3.5453 train_time:1109328ms step_avg:728.38ms
step:1534/1875 train_loss:3.7215 train_time:1110072ms step_avg:728.39ms
step:1535/1875 train_loss:3.5091 train_time:1110805ms step_avg:728.40ms
step:1536/1875 train_loss:3.6349 train_time:1111519ms step_avg:728.39ms
step:1537/1875 train_loss:3.5408 train_time:1112248ms step_avg:728.39ms
step:1538/1875 train_loss:3.4326 train_time:1112984ms step_avg:728.39ms
step:1539/1875 train_loss:3.3767 train_time:1113711ms step_avg:728.39ms
step:1540/1875 train_loss:3.4960 train_time:1114443ms step_avg:728.39ms
step:1541/1875 train_loss:3.5094 train_time:1115158ms step_avg:728.39ms
step:1542/1875 train_loss:3.4098 train_time:1115897ms step_avg:728.39ms
step:1543/1875 train_loss:3.7092 train_time:1116618ms step_avg:728.39ms
step:1544/1875 train_loss:3.5142 train_time:1117341ms step_avg:728.38ms
step:1545/1875 train_loss:3.3800 train_time:1118082ms step_avg:728.39ms
step:1546/1875 train_loss:3.5772 train_time:1118815ms step_avg:728.40ms
step:1547/1875 train_loss:3.5996 train_time:1119543ms step_avg:728.39ms
step:1548/1875 train_loss:3.3721 train_time:1120264ms step_avg:728.39ms
step:1549/1875 train_loss:3.7503 train_time:1120999ms step_avg:728.39ms
step:1550/1875 train_loss:3.6959 train_time:1121722ms step_avg:728.39ms
step:1551/1875 train_loss:3.5746 train_time:1122457ms step_avg:728.40ms
step:1552/1875 train_loss:3.7168 train_time:1123198ms step_avg:728.40ms
step:1553/1875 train_loss:3.6239 train_time:1123921ms step_avg:728.40ms
step:1554/1875 train_loss:3.5334 train_time:1124645ms step_avg:728.40ms
step:1555/1875 train_loss:3.7146 train_time:1125368ms step_avg:728.39ms
step:1556/1875 train_loss:3.6532 train_time:1126084ms step_avg:728.39ms
step:1557/1875 train_loss:3.5458 train_time:1126813ms step_avg:728.39ms
step:1558/1875 train_loss:3.4945 train_time:1127530ms step_avg:728.38ms
step:1559/1875 train_loss:3.5306 train_time:1128258ms step_avg:728.38ms
step:1560/1875 train_loss:3.5403 train_time:1128980ms step_avg:728.37ms
step:1561/1875 train_loss:3.5729 train_time:1129702ms step_avg:728.37ms
step:1562/1875 train_loss:3.5598 train_time:1130426ms step_avg:728.37ms
step:1563/1875 train_loss:3.6408 train_time:1131166ms step_avg:728.37ms
step:1564/1875 train_loss:3.5240 train_time:1131888ms step_avg:728.37ms
step:1565/1875 train_loss:3.6348 train_time:1132617ms step_avg:728.37ms
step:1566/1875 train_loss:3.5119 train_time:1133340ms step_avg:728.37ms
step:1567/1875 train_loss:3.6564 train_time:1134063ms step_avg:728.36ms
step:1568/1875 train_loss:3.4558 train_time:1134792ms step_avg:728.36ms
step:1569/1875 train_loss:3.5007 train_time:1135523ms step_avg:728.37ms
step:1570/1875 train_loss:3.4384 train_time:1136242ms step_avg:728.36ms
step:1571/1875 train_loss:3.4380 train_time:1136962ms step_avg:728.35ms
step:1572/1875 train_loss:3.4871 train_time:1137699ms step_avg:728.36ms
step:1573/1875 train_loss:3.5575 train_time:1138424ms step_avg:728.36ms
step:1574/1875 train_loss:3.3459 train_time:1139144ms step_avg:728.35ms
step:1575/1875 train_loss:3.5402 train_time:1139870ms step_avg:728.35ms
step:1576/1875 train_loss:3.5612 train_time:1140589ms step_avg:728.35ms
step:1577/1875 train_loss:3.5358 train_time:1141335ms step_avg:728.36ms
step:1578/1875 train_loss:3.5708 train_time:1142074ms step_avg:728.36ms
step:1579/1875 train_loss:3.5484 train_time:1142810ms step_avg:728.37ms
step:1580/1875 train_loss:3.5175 train_time:1143528ms step_avg:728.36ms
step:1581/1875 train_loss:3.7340 train_time:1144254ms step_avg:728.36ms
step:1582/1875 train_loss:3.5965 train_time:1144973ms step_avg:728.35ms
step:1583/1875 train_loss:3.6498 train_time:1145700ms step_avg:728.35ms
step:1584/1875 train_loss:3.3874 train_time:1146434ms step_avg:728.36ms
step:1585/1875 train_loss:3.5307 train_time:1147172ms step_avg:728.36ms
step:1586/1875 train_loss:3.4704 train_time:1147890ms step_avg:728.36ms
step:1587/1875 train_loss:3.6417 train_time:1148617ms step_avg:728.36ms
step:1588/1875 train_loss:3.5176 train_time:1149343ms step_avg:728.35ms
step:1589/1875 train_loss:3.4895 train_time:1150057ms step_avg:728.35ms
step:1590/1875 train_loss:3.5228 train_time:1150782ms step_avg:728.34ms
step:1591/1875 train_loss:3.5336 train_time:1151520ms step_avg:728.35ms
step:1592/1875 train_loss:3.3945 train_time:1152245ms step_avg:728.35ms
step:1593/1875 train_loss:3.4811 train_time:1152968ms step_avg:728.34ms
step:1594/1875 train_loss:3.8400 train_time:1153692ms step_avg:728.34ms
step:1595/1875 train_loss:3.4388 train_time:1154417ms step_avg:728.34ms
step:1596/1875 train_loss:3.4384 train_time:1155153ms step_avg:728.34ms
step:1597/1875 train_loss:3.5941 train_time:1155879ms step_avg:728.34ms
step:1598/1875 train_loss:3.5117 train_time:1156619ms step_avg:728.35ms
step:1599/1875 train_loss:3.3757 train_time:1157354ms step_avg:728.35ms
step:1600/1875 train_loss:3.5396 train_time:1158091ms step_avg:728.36ms
step:1601/1875 train_loss:3.5132 train_time:1158813ms step_avg:728.35ms
step:1602/1875 train_loss:3.5882 train_time:1159530ms step_avg:728.35ms
step:1603/1875 train_loss:3.4902 train_time:1160254ms step_avg:728.35ms
step:1604/1875 train_loss:3.4151 train_time:1160992ms step_avg:728.35ms
step:1605/1875 train_loss:3.5581 train_time:1161716ms step_avg:728.35ms
step:1606/1875 train_loss:3.3775 train_time:1162464ms step_avg:728.36ms
step:1607/1875 train_loss:3.5638 train_time:1163187ms step_avg:728.36ms
step:1608/1875 train_loss:3.4341 train_time:1163916ms step_avg:728.36ms
step:1609/1875 train_loss:3.5159 train_time:1164636ms step_avg:728.35ms
step:1610/1875 train_loss:3.5535 train_time:1165378ms step_avg:728.36ms
step:1611/1875 train_loss:3.3963 train_time:1166109ms step_avg:728.36ms
step:1612/1875 train_loss:3.5444 train_time:1166852ms step_avg:728.37ms
step:1613/1875 train_loss:3.5311 train_time:1167570ms step_avg:728.37ms
step:1614/1875 train_loss:3.3844 train_time:1168324ms step_avg:728.38ms
step:1615/1875 train_loss:3.6172 train_time:1169085ms step_avg:728.40ms
step:1616/1875 train_loss:3.5760 train_time:1169811ms step_avg:728.40ms
step:1617/1875 train_loss:3.5458 train_time:1170536ms step_avg:728.40ms
step:1618/1875 train_loss:3.4827 train_time:1171268ms step_avg:728.40ms
step:1619/1875 train_loss:3.6449 train_time:1171998ms step_avg:728.40ms
step:1620/1875 train_loss:3.6198 train_time:1172723ms step_avg:728.40ms
step:1621/1875 train_loss:3.5262 train_time:1173450ms step_avg:728.40ms
step:1622/1875 train_loss:3.8005 train_time:1174178ms step_avg:728.40ms
step:1623/1875 train_loss:3.4739 train_time:1174906ms step_avg:728.40ms
step:1624/1875 train_loss:3.7895 train_time:1175617ms step_avg:728.39ms
step:1625/1875 train_loss:3.5148 train_time:1176372ms step_avg:728.40ms
step:1625/1875 val_loss:3.5470 train_time:1176582ms step_avg:728.53ms
============== Weight norms: ==============
name = 'module._orig_mod.transformer.h.0.attn.c_q.weight' | fro_norm = 44.73406 | spectral_norm = 17.52579 | nuclear_norm = 874.06335
name = 'module._orig_mod.transformer.h.0.attn.c_k.weight' | fro_norm = 42.88102 | spectral_norm = 17.12533 | nuclear_norm = 822.49536
name = 'module._orig_mod.transformer.h.1.attn.c_q.weight' | fro_norm = 44.35397 | spectral_norm = 11.56030 | nuclear_norm = 852.06012
name = 'module._orig_mod.transformer.h.1.attn.c_k.weight' | fro_norm = 41.60792 | spectral_norm = 11.20172 | nuclear_norm = 816.09497
name = 'module._orig_mod.transformer.h.2.attn.c_q.weight' | fro_norm = 43.38663 | spectral_norm = 6.96647 | nuclear_norm = 808.75757
name = 'module._orig_mod.transformer.h.2.attn.c_k.weight' | fro_norm = 41.29626 | spectral_norm = 6.66135 | nuclear_norm = 796.08411
name = 'module._orig_mod.transformer.h.3.attn.c_q.weight' | fro_norm = 44.30039 | spectral_norm = 7.79325 | nuclear_norm = 877.43268
name = 'module._orig_mod.transformer.h.3.attn.c_k.weight' | fro_norm = 41.44482 | spectral_norm = 7.21898 | nuclear_norm = 838.42358
name = 'module._orig_mod.transformer.h.4.attn.c_q.weight' | fro_norm = 43.99237 | spectral_norm = 8.22003 | nuclear_norm = 869.69336
name = 'module._orig_mod.transformer.h.4.attn.c_k.weight' | fro_norm = 41.14368 | spectral_norm = 7.87974 | nuclear_norm = 834.28186
name = 'module._orig_mod.transformer.h.5.attn.c_q.weight' | fro_norm = 45.29351 | spectral_norm = 8.71368 | nuclear_norm = 880.78632
name = 'module._orig_mod.transformer.h.5.attn.c_k.weight' | fro_norm = 42.61712 | spectral_norm = 7.79186 | nuclear_norm = 844.13904
name = 'module._orig_mod.transformer.h.6.attn.c_q.weight' | fro_norm = 45.01220 | spectral_norm = 8.37060 | nuclear_norm = 880.92645
name = 'module._orig_mod.transformer.h.6.attn.c_k.weight' | fro_norm = 43.00779 | spectral_norm = 7.77377 | nuclear_norm = 866.16864
name = 'module._orig_mod.transformer.h.7.attn.c_q.weight' | fro_norm = 45.26441 | spectral_norm = 6.92504 | nuclear_norm = 928.47266
name = 'module._orig_mod.transformer.h.7.attn.c_k.weight' | fro_norm = 42.50004 | spectral_norm = 7.17763 | nuclear_norm = 883.05707
name = 'module._orig_mod.transformer.h.8.attn.c_q.weight' | fro_norm = 44.48697 | spectral_norm = 8.38623 | nuclear_norm = 885.62415
name = 'module._orig_mod.transformer.h.8.attn.c_k.weight' | fro_norm = 43.15203 | spectral_norm = 7.76461 | nuclear_norm = 870.64343
name = 'module._orig_mod.transformer.h.9.attn.c_q.weight' | fro_norm = 43.53750 | spectral_norm = 8.79737 | nuclear_norm = 838.25684
name = 'module._orig_mod.transformer.h.9.attn.c_k.weight' | fro_norm = 39.80352 | spectral_norm = 8.52607 | nuclear_norm = 777.73853
name = 'module._orig_mod.transformer.h.10.attn.c_q.weight' | fro_norm = 44.51448 | spectral_norm = 8.36019 | nuclear_norm = 879.85010
name = 'module._orig_mod.transformer.h.10.attn.c_k.weight' | fro_norm = 41.35965 | spectral_norm = 7.34232 | nuclear_norm = 829.85950
name = 'module._orig_mod.transformer.h.11.attn.c_q.weight' | fro_norm = 43.87791 | spectral_norm = 8.40043 | nuclear_norm = 870.94006
name = 'module._orig_mod.transformer.h.11.attn.c_k.weight' | fro_norm = 40.60013 | spectral_norm = 7.43941 | nuclear_norm = 821.64111
===========================================
step:1626/1875 train_loss:3.5962 train_time:1177083ms step_avg:728.39ms
step:1627/1875 train_loss:3.6157 train_time:1177804ms step_avg:728.39ms
step:1628/1875 train_loss:3.6431 train_time:1178529ms step_avg:728.39ms
step:1629/1875 train_loss:3.4923 train_time:1179248ms step_avg:728.38ms
step:1630/1875 train_loss:3.5485 train_time:1179978ms step_avg:728.38ms
step:1631/1875 train_loss:3.5218 train_time:1180702ms step_avg:728.38ms
step:1632/1875 train_loss:3.4160 train_time:1181426ms step_avg:728.38ms
step:1633/1875 train_loss:3.5193 train_time:1182148ms step_avg:728.37ms
step:1634/1875 train_loss:3.5242 train_time:1182872ms step_avg:728.37ms
step:1635/1875 train_loss:3.5225 train_time:1183604ms step_avg:728.37ms
step:1636/1875 train_loss:3.5968 train_time:1184322ms step_avg:728.37ms
step:1637/1875 train_loss:3.8755 train_time:1185062ms step_avg:728.37ms
step:1638/1875 train_loss:3.4927 train_time:1185792ms step_avg:728.37ms
step:1639/1875 train_loss:3.4740 train_time:1186525ms step_avg:728.38ms
step:1640/1875 train_loss:3.4840 train_time:1187269ms step_avg:728.39ms
step:1641/1875 train_loss:3.6011 train_time:1187989ms step_avg:728.38ms
step:1642/1875 train_loss:3.5472 train_time:1188712ms step_avg:728.38ms
step:1643/1875 train_loss:3.5452 train_time:1189446ms step_avg:728.38ms
step:1644/1875 train_loss:3.4429 train_time:1190165ms step_avg:728.38ms
step:1645/1875 train_loss:3.4618 train_time:1190891ms step_avg:728.37ms
step:1646/1875 train_loss:3.5353 train_time:1191620ms step_avg:728.37ms
step:1647/1875 train_loss:3.4252 train_time:1192358ms step_avg:728.38ms
step:1648/1875 train_loss:3.5537 train_time:1193086ms step_avg:728.38ms
step:1649/1875 train_loss:3.6025 train_time:1193807ms step_avg:728.37ms
step:1650/1875 train_loss:3.5066 train_time:1194532ms step_avg:728.37ms
step:1651/1875 train_loss:3.5825 train_time:1195262ms step_avg:728.37ms
step:1652/1875 train_loss:3.5366 train_time:1195994ms step_avg:728.38ms
step:1653/1875 train_loss:3.5055 train_time:1196710ms step_avg:728.37ms
step:1654/1875 train_loss:3.6050 train_time:1197437ms step_avg:728.37ms
step:1655/1875 train_loss:3.4362 train_time:1198170ms step_avg:728.37ms
step:1656/1875 train_loss:3.2379 train_time:1198900ms step_avg:728.37ms
step:1657/1875 train_loss:3.5521 train_time:1199637ms step_avg:728.38ms
step:1658/1875 train_loss:3.5822 train_time:1200349ms step_avg:728.37ms
step:1659/1875 train_loss:3.5099 train_time:1201076ms step_avg:728.37ms
step:1660/1875 train_loss:3.7570 train_time:1201814ms step_avg:728.37ms
step:1661/1875 train_loss:3.5998 train_time:1202537ms step_avg:728.37ms
step:1662/1875 train_loss:3.5820 train_time:1203268ms step_avg:728.37ms
step:1663/1875 train_loss:3.5564 train_time:1204005ms step_avg:728.38ms
step:1664/1875 train_loss:3.5865 train_time:1204730ms step_avg:728.37ms
step:1665/1875 train_loss:3.4103 train_time:1205453ms step_avg:728.37ms
step:1666/1875 train_loss:3.5553 train_time:1206179ms step_avg:728.37ms
step:1667/1875 train_loss:3.3641 train_time:1206912ms step_avg:728.37ms
step:1668/1875 train_loss:3.5019 train_time:1207635ms step_avg:728.37ms
step:1669/1875 train_loss:3.5403 train_time:1208362ms step_avg:728.37ms
step:1670/1875 train_loss:3.3609 train_time:1209089ms step_avg:728.37ms
step:1671/1875 train_loss:3.5309 train_time:1209819ms step_avg:728.37ms
step:1672/1875 train_loss:3.4022 train_time:1210572ms step_avg:728.38ms
step:1673/1875 train_loss:3.6901 train_time:1211299ms step_avg:728.38ms
step:1674/1875 train_loss:3.5502 train_time:1212033ms step_avg:728.39ms
step:1675/1875 train_loss:3.5289 train_time:1212758ms step_avg:728.38ms
step:1676/1875 train_loss:3.4032 train_time:1213489ms step_avg:728.38ms
step:1677/1875 train_loss:3.4757 train_time:1214223ms step_avg:728.39ms
step:1678/1875 train_loss:3.8036 train_time:1214945ms step_avg:728.38ms
step:1679/1875 train_loss:3.5380 train_time:1215671ms step_avg:728.38ms
step:1680/1875 train_loss:3.5195 train_time:1216408ms step_avg:728.39ms
step:1681/1875 train_loss:3.6435 train_time:1217126ms step_avg:728.38ms
step:1682/1875 train_loss:3.5786 train_time:1217849ms step_avg:728.38ms
step:1683/1875 train_loss:3.4786 train_time:1218589ms step_avg:728.39ms
step:1684/1875 train_loss:3.5886 train_time:1219322ms step_avg:728.39ms
step:1685/1875 train_loss:3.4108 train_time:1220053ms step_avg:728.39ms
step:1686/1875 train_loss:3.5722 train_time:1220779ms step_avg:728.39ms
step:1687/1875 train_loss:3.4579 train_time:1221507ms step_avg:728.39ms
step:1688/1875 train_loss:3.2894 train_time:1222243ms step_avg:728.39ms
step:1689/1875 train_loss:3.6413 train_time:1222976ms step_avg:728.40ms
step:1690/1875 train_loss:3.5615 train_time:1223712ms step_avg:728.40ms
step:1691/1875 train_loss:3.5579 train_time:1224436ms step_avg:728.40ms
step:1692/1875 train_loss:3.4624 train_time:1225174ms step_avg:728.40ms
step:1693/1875 train_loss:3.4422 train_time:1225906ms step_avg:728.41ms
step:1694/1875 train_loss:3.5487 train_time:1226637ms step_avg:728.41ms
step:1695/1875 train_loss:3.4774 train_time:1227358ms step_avg:728.40ms
step:1696/1875 train_loss:3.5590 train_time:1228078ms step_avg:728.40ms
step:1697/1875 train_loss:3.5171 train_time:1228806ms step_avg:728.40ms
step:1698/1875 train_loss:3.6083 train_time:1229539ms step_avg:728.40ms
step:1699/1875 train_loss:3.4652 train_time:1230265ms step_avg:728.40ms
step:1700/1875 train_loss:3.4913 train_time:1230990ms step_avg:728.40ms
step:1701/1875 train_loss:3.4165 train_time:1231712ms step_avg:728.39ms
step:1702/1875 train_loss:3.4428 train_time:1232441ms step_avg:728.39ms
step:1703/1875 train_loss:3.5154 train_time:1233161ms step_avg:728.39ms
step:1704/1875 train_loss:3.5392 train_time:1233884ms step_avg:728.38ms
step:1705/1875 train_loss:3.5109 train_time:1234606ms step_avg:728.38ms
step:1706/1875 train_loss:3.5611 train_time:1235328ms step_avg:728.38ms
step:1707/1875 train_loss:3.4979 train_time:1236052ms step_avg:728.37ms
step:1708/1875 train_loss:3.6572 train_time:1236784ms step_avg:728.38ms
step:1709/1875 train_loss:3.3696 train_time:1237510ms step_avg:728.38ms
step:1710/1875 train_loss:3.4848 train_time:1238459ms step_avg:728.51ms
step:1711/1875 train_loss:3.4642 train_time:1239181ms step_avg:728.50ms
step:1712/1875 train_loss:3.4582 train_time:1239914ms step_avg:728.50ms
step:1713/1875 train_loss:3.9482 train_time:1240637ms step_avg:728.50ms
step:1714/1875 train_loss:3.5132 train_time:1241388ms step_avg:728.51ms
step:1715/1875 train_loss:3.5117 train_time:1242188ms step_avg:728.56ms
step:1716/1875 train_loss:3.5612 train_time:1242912ms step_avg:728.55ms
step:1717/1875 train_loss:3.5783 train_time:1243635ms step_avg:728.55ms
step:1718/1875 train_loss:3.4875 train_time:1244367ms step_avg:728.55ms
step:1719/1875 train_loss:3.5051 train_time:1245097ms step_avg:728.55ms
step:1720/1875 train_loss:3.3403 train_time:1245828ms step_avg:728.55ms
step:1721/1875 train_loss:3.4739 train_time:1246536ms step_avg:728.54ms
step:1722/1875 train_loss:3.4927 train_time:1247264ms step_avg:728.54ms
step:1723/1875 train_loss:3.4520 train_time:1247986ms step_avg:728.54ms
step:1724/1875 train_loss:3.5964 train_time:1248706ms step_avg:728.53ms
step:1725/1875 train_loss:3.4014 train_time:1249450ms step_avg:728.54ms
step:1726/1875 train_loss:3.5463 train_time:1250168ms step_avg:728.54ms
step:1727/1875 train_loss:3.6379 train_time:1250906ms step_avg:728.54ms
step:1728/1875 train_loss:3.4833 train_time:1251637ms step_avg:728.54ms
step:1729/1875 train_loss:3.7167 train_time:1252366ms step_avg:728.54ms
step:1730/1875 train_loss:3.4922 train_time:1253099ms step_avg:728.55ms
step:1731/1875 train_loss:3.5545 train_time:1253823ms step_avg:728.54ms
step:1732/1875 train_loss:3.5367 train_time:1254540ms step_avg:728.54ms
step:1733/1875 train_loss:3.5217 train_time:1255268ms step_avg:728.54ms
step:1734/1875 train_loss:3.9028 train_time:1255996ms step_avg:728.54ms
step:1735/1875 train_loss:3.5299 train_time:1256734ms step_avg:728.54ms
step:1736/1875 train_loss:3.6588 train_time:1257456ms step_avg:728.54ms
step:1737/1875 train_loss:3.4319 train_time:1258189ms step_avg:728.54ms
step:1738/1875 train_loss:3.4712 train_time:1258914ms step_avg:728.54ms
step:1739/1875 train_loss:3.4963 train_time:1259634ms step_avg:728.53ms
step:1740/1875 train_loss:3.4836 train_time:1260360ms step_avg:728.53ms
step:1741/1875 train_loss:3.6203 train_time:1261079ms step_avg:728.53ms
step:1742/1875 train_loss:3.4662 train_time:1261804ms step_avg:728.52ms
step:1743/1875 train_loss:3.5287 train_time:1262530ms step_avg:728.52ms
step:1744/1875 train_loss:3.5956 train_time:1263248ms step_avg:728.52ms
step:1745/1875 train_loss:3.3936 train_time:1263992ms step_avg:728.53ms
step:1746/1875 train_loss:3.2856 train_time:1264708ms step_avg:728.52ms
step:1747/1875 train_loss:3.1950 train_time:1265447ms step_avg:728.52ms
step:1748/1875 train_loss:3.5089 train_time:1266178ms step_avg:728.53ms
step:1749/1875 train_loss:3.5390 train_time:1266896ms step_avg:728.52ms
step:1750/1875 train_loss:3.4992 train_time:1267619ms step_avg:728.52ms
step:1750/1875 val_loss:3.5049 train_time:1267835ms step_avg:728.64ms
============== Weight norms: ==============
name = 'module._orig_mod.transformer.h.0.attn.c_q.weight' | fro_norm = 44.98111 | spectral_norm = 17.67467 | nuclear_norm = 879.34021
name = 'module._orig_mod.transformer.h.0.attn.c_k.weight' | fro_norm = 43.15128 | spectral_norm = 17.19774 | nuclear_norm = 829.02692
name = 'module._orig_mod.transformer.h.1.attn.c_q.weight' | fro_norm = 44.59619 | spectral_norm = 11.65168 | nuclear_norm = 857.14734
name = 'module._orig_mod.transformer.h.1.attn.c_k.weight' | fro_norm = 41.88017 | spectral_norm = 11.28066 | nuclear_norm = 822.20618
name = 'module._orig_mod.transformer.h.2.attn.c_q.weight' | fro_norm = 43.59378 | spectral_norm = 7.00093 | nuclear_norm = 811.69464
name = 'module._orig_mod.transformer.h.2.attn.c_k.weight' | fro_norm = 41.52134 | spectral_norm = 6.70955 | nuclear_norm = 799.75043
name = 'module._orig_mod.transformer.h.3.attn.c_q.weight' | fro_norm = 44.57555 | spectral_norm = 7.81644 | nuclear_norm = 883.81360
name = 'module._orig_mod.transformer.h.3.attn.c_k.weight' | fro_norm = 41.73813 | spectral_norm = 7.24055 | nuclear_norm = 845.65186
name = 'module._orig_mod.transformer.h.4.attn.c_q.weight' | fro_norm = 44.24189 | spectral_norm = 8.30133 | nuclear_norm = 874.77771
name = 'module._orig_mod.transformer.h.4.attn.c_k.weight' | fro_norm = 41.41055 | spectral_norm = 7.89333 | nuclear_norm = 840.28613
name = 'module._orig_mod.transformer.h.5.attn.c_q.weight' | fro_norm = 45.56738 | spectral_norm = 8.72890 | nuclear_norm = 887.50916
name = 'module._orig_mod.transformer.h.5.attn.c_k.weight' | fro_norm = 42.89420 | spectral_norm = 7.80627 | nuclear_norm = 851.08087
name = 'module._orig_mod.transformer.h.6.attn.c_q.weight' | fro_norm = 45.32777 | spectral_norm = 8.40175 | nuclear_norm = 888.72430
name = 'module._orig_mod.transformer.h.6.attn.c_k.weight' | fro_norm = 43.31897 | spectral_norm = 7.81440 | nuclear_norm = 873.80884
name = 'module._orig_mod.transformer.h.7.attn.c_q.weight' | fro_norm = 45.55460 | spectral_norm = 6.94675 | nuclear_norm = 935.88855
name = 'module._orig_mod.transformer.h.7.attn.c_k.weight' | fro_norm = 42.78635 | spectral_norm = 7.21701 | nuclear_norm = 890.41815
name = 'module._orig_mod.transformer.h.8.attn.c_q.weight' | fro_norm = 44.78986 | spectral_norm = 8.39079 | nuclear_norm = 893.54822
name = 'module._orig_mod.transformer.h.8.attn.c_k.weight' | fro_norm = 43.46348 | spectral_norm = 7.74775 | nuclear_norm = 878.67822
name = 'module._orig_mod.transformer.h.9.attn.c_q.weight' | fro_norm = 43.81845 | spectral_norm = 8.81499 | nuclear_norm = 844.13684
name = 'module._orig_mod.transformer.h.9.attn.c_k.weight' | fro_norm = 40.09053 | spectral_norm = 8.51405 | nuclear_norm = 784.22424
name = 'module._orig_mod.transformer.h.10.attn.c_q.weight' | fro_norm = 44.80373 | spectral_norm = 8.39455 | nuclear_norm = 886.67041
name = 'module._orig_mod.transformer.h.10.attn.c_k.weight' | fro_norm = 41.66022 | spectral_norm = 7.36889 | nuclear_norm = 836.79602
name = 'module._orig_mod.transformer.h.11.attn.c_q.weight' | fro_norm = 44.19722 | spectral_norm = 8.40812 | nuclear_norm = 878.80609
name = 'module._orig_mod.transformer.h.11.attn.c_k.weight' | fro_norm = 40.92355 | spectral_norm = 7.43088 | nuclear_norm = 829.52588
===========================================
step:1751/1875 train_loss:3.5115 train_time:1268336ms step_avg:728.51ms
step:1752/1875 train_loss:3.7374 train_time:1269082ms step_avg:728.52ms
step:1753/1875 train_loss:3.4494 train_time:1269804ms step_avg:728.52ms
step:1754/1875 train_loss:3.5162 train_time:1270528ms step_avg:728.51ms
step:1755/1875 train_loss:3.5282 train_time:1271244ms step_avg:728.51ms
step:1756/1875 train_loss:3.1189 train_time:1271988ms step_avg:728.52ms
step:1757/1875 train_loss:3.2534 train_time:1272714ms step_avg:728.51ms
step:1758/1875 train_loss:3.3257 train_time:1273446ms step_avg:728.52ms
step:1759/1875 train_loss:3.3013 train_time:1274167ms step_avg:728.51ms
step:1760/1875 train_loss:3.4900 train_time:1274889ms step_avg:728.51ms
step:1761/1875 train_loss:3.3775 train_time:1275622ms step_avg:728.51ms
step:1762/1875 train_loss:3.3457 train_time:1276345ms step_avg:728.51ms
step:1763/1875 train_loss:4.4063 train_time:1277070ms step_avg:728.51ms
step:1764/1875 train_loss:3.4826 train_time:1277797ms step_avg:728.50ms
step:1765/1875 train_loss:3.5280 train_time:1278514ms step_avg:728.50ms
step:1766/1875 train_loss:3.5282 train_time:1279235ms step_avg:728.49ms
step:1767/1875 train_loss:3.5384 train_time:1279954ms step_avg:728.49ms
step:1768/1875 train_loss:3.4515 train_time:1280685ms step_avg:728.49ms
step:1769/1875 train_loss:3.5058 train_time:1281412ms step_avg:728.49ms
step:1770/1875 train_loss:3.5163 train_time:1282160ms step_avg:728.50ms
step:1771/1875 train_loss:3.7280 train_time:1282882ms step_avg:728.50ms
step:1772/1875 train_loss:3.5057 train_time:1283601ms step_avg:728.49ms
step:1773/1875 train_loss:3.5723 train_time:1284327ms step_avg:728.49ms
step:1774/1875 train_loss:3.7944 train_time:1285058ms step_avg:728.49ms
step:1775/1875 train_loss:3.4780 train_time:1285789ms step_avg:728.49ms
step:1776/1875 train_loss:3.3922 train_time:1286522ms step_avg:728.50ms
step:1777/1875 train_loss:3.6340 train_time:1287254ms step_avg:728.50ms
step:1778/1875 train_loss:3.3585 train_time:1287979ms step_avg:728.49ms
step:1779/1875 train_loss:3.5520 train_time:1288723ms step_avg:728.50ms
step:1780/1875 train_loss:3.5866 train_time:1289448ms step_avg:728.50ms
step:1781/1875 train_loss:3.6948 train_time:1290172ms step_avg:728.50ms
step:1782/1875 train_loss:3.5096 train_time:1290889ms step_avg:728.49ms
step:1783/1875 train_loss:3.7849 train_time:1291607ms step_avg:728.49ms
step:1784/1875 train_loss:3.5751 train_time:1292333ms step_avg:728.49ms
step:1785/1875 train_loss:3.5674 train_time:1293061ms step_avg:728.49ms
step:1786/1875 train_loss:3.3636 train_time:1293787ms step_avg:728.48ms
step:1787/1875 train_loss:3.4569 train_time:1294509ms step_avg:728.48ms
step:1788/1875 train_loss:3.5926 train_time:1295234ms step_avg:728.48ms
step:1789/1875 train_loss:3.4895 train_time:1295959ms step_avg:728.48ms
step:1790/1875 train_loss:3.6635 train_time:1296680ms step_avg:728.47ms
step:1791/1875 train_loss:3.4802 train_time:1297404ms step_avg:728.47ms
step:1792/1875 train_loss:3.4355 train_time:1298133ms step_avg:728.47ms
step:1793/1875 train_loss:3.5935 train_time:1298851ms step_avg:728.46ms
step:1794/1875 train_loss:3.4974 train_time:1299574ms step_avg:728.46ms
step:1795/1875 train_loss:3.4443 train_time:1300294ms step_avg:728.46ms
step:1796/1875 train_loss:3.5553 train_time:1301013ms step_avg:728.45ms
step:1797/1875 train_loss:3.4483 train_time:1301744ms step_avg:728.45ms
step:1798/1875 train_loss:3.4494 train_time:1302469ms step_avg:728.45ms
step:1799/1875 train_loss:3.4882 train_time:1303196ms step_avg:728.45ms
step:1800/1875 train_loss:3.4293 train_time:1303918ms step_avg:728.45ms
step:1801/1875 train_loss:3.5930 train_time:1304654ms step_avg:728.45ms
step:1802/1875 train_loss:3.4900 train_time:1305380ms step_avg:728.45ms
step:1803/1875 train_loss:3.5582 train_time:1306111ms step_avg:728.45ms
step:1804/1875 train_loss:3.4692 train_time:1306830ms step_avg:728.44ms
step:1805/1875 train_loss:3.5377 train_time:1307564ms step_avg:728.45ms
step:1806/1875 train_loss:3.4060 train_time:1308289ms step_avg:728.45ms
step:1807/1875 train_loss:3.3510 train_time:1309006ms step_avg:728.44ms
step:1808/1875 train_loss:3.6140 train_time:1309749ms step_avg:728.45ms
step:1809/1875 train_loss:3.5311 train_time:1310471ms step_avg:728.44ms
step:1810/1875 train_loss:3.5174 train_time:1311212ms step_avg:728.45ms
step:1811/1875 train_loss:3.6623 train_time:1311945ms step_avg:728.45ms
step:1812/1875 train_loss:3.4428 train_time:1312672ms step_avg:728.45ms
step:1813/1875 train_loss:3.5565 train_time:1313393ms step_avg:728.45ms
step:1814/1875 train_loss:3.6992 train_time:1314119ms step_avg:728.45ms
step:1815/1875 train_loss:3.5460 train_time:1314841ms step_avg:728.44ms
step:1816/1875 train_loss:3.5830 train_time:1315568ms step_avg:728.44ms
step:1817/1875 train_loss:3.5895 train_time:1316309ms step_avg:728.45ms
step:1818/1875 train_loss:3.5449 train_time:1317034ms step_avg:728.45ms
step:1819/1875 train_loss:3.5745 train_time:1317769ms step_avg:728.45ms
step:1820/1875 train_loss:3.5406 train_time:1318506ms step_avg:728.46ms
step:1821/1875 train_loss:3.5883 train_time:1319249ms step_avg:728.46ms
step:1822/1875 train_loss:3.5165 train_time:1319965ms step_avg:728.46ms
step:1823/1875 train_loss:3.5204 train_time:1320701ms step_avg:728.46ms
step:1824/1875 train_loss:3.4678 train_time:1321437ms step_avg:728.47ms
step:1825/1875 train_loss:3.4202 train_time:1322178ms step_avg:728.47ms
step:1826/1875 train_loss:3.3560 train_time:1322908ms step_avg:728.47ms
step:1827/1875 train_loss:3.5288 train_time:1323622ms step_avg:728.47ms
step:1828/1875 train_loss:3.6157 train_time:1324351ms step_avg:728.47ms
step:1829/1875 train_loss:3.5918 train_time:1325086ms step_avg:728.47ms
step:1830/1875 train_loss:3.5756 train_time:1325823ms step_avg:728.47ms
step:1831/1875 train_loss:3.4442 train_time:1326549ms step_avg:728.47ms
step:1832/1875 train_loss:3.4251 train_time:1327271ms step_avg:728.47ms
step:1833/1875 train_loss:3.6069 train_time:1328029ms step_avg:728.49ms
step:1834/1875 train_loss:3.3732 train_time:1328756ms step_avg:728.48ms
step:1835/1875 train_loss:3.5206 train_time:1329480ms step_avg:728.48ms
step:1836/1875 train_loss:3.3896 train_time:1330204ms step_avg:728.48ms
step:1837/1875 train_loss:3.7224 train_time:1330925ms step_avg:728.48ms
step:1838/1875 train_loss:3.5697 train_time:1331645ms step_avg:728.47ms
step:1839/1875 train_loss:3.5512 train_time:1332387ms step_avg:728.48ms
step:1840/1875 train_loss:3.6536 train_time:1333118ms step_avg:728.48ms
step:1841/1875 train_loss:3.5384 train_time:1333840ms step_avg:728.48ms
step:1842/1875 train_loss:3.4139 train_time:1334567ms step_avg:728.48ms
step:1843/1875 train_loss:3.5286 train_time:1335305ms step_avg:728.48ms
step:1844/1875 train_loss:3.4021 train_time:1336048ms step_avg:728.49ms
step:1845/1875 train_loss:3.5250 train_time:1336756ms step_avg:728.48ms
step:1846/1875 train_loss:3.5749 train_time:1337505ms step_avg:728.49ms
step:1847/1875 train_loss:3.3151 train_time:1338237ms step_avg:728.49ms
step:1848/1875 train_loss:3.4607 train_time:1338946ms step_avg:728.48ms
step:1849/1875 train_loss:3.5118 train_time:1339681ms step_avg:728.48ms
step:1850/1875 train_loss:3.4623 train_time:1340429ms step_avg:728.49ms
step:1851/1875 train_loss:3.3500 train_time:1341158ms step_avg:728.49ms
step:1852/1875 train_loss:3.6005 train_time:1341891ms step_avg:728.50ms
step:1853/1875 train_loss:3.3929 train_time:1342614ms step_avg:728.49ms
step:1854/1875 train_loss:3.4762 train_time:1343338ms step_avg:728.49ms
step:1855/1875 train_loss:3.4290 train_time:1344058ms step_avg:728.49ms
step:1856/1875 train_loss:3.6251 train_time:1344787ms step_avg:728.49ms
step:1857/1875 train_loss:3.6064 train_time:1345505ms step_avg:728.48ms
step:1858/1875 train_loss:3.4768 train_time:1346238ms step_avg:728.48ms
step:1859/1875 train_loss:3.4369 train_time:1346962ms step_avg:728.48ms
step:1860/1875 train_loss:3.4660 train_time:1347680ms step_avg:728.48ms
step:1861/1875 train_loss:3.6926 train_time:1348426ms step_avg:728.49ms
step:1862/1875 train_loss:3.5096 train_time:1349166ms step_avg:728.49ms
step:1863/1875 train_loss:3.4795 train_time:1349892ms step_avg:728.49ms
step:1864/1875 train_loss:3.5372 train_time:1350611ms step_avg:728.49ms
step:1865/1875 train_loss:3.3928 train_time:1351334ms step_avg:728.48ms
step:1866/1875 train_loss:3.4018 train_time:1352063ms step_avg:728.48ms
step:1867/1875 train_loss:3.4917 train_time:1352786ms step_avg:728.48ms
step:1868/1875 train_loss:3.5308 train_time:1353519ms step_avg:728.48ms
step:1869/1875 train_loss:3.2845 train_time:1354252ms step_avg:728.48ms
step:1870/1875 train_loss:3.4211 train_time:1354977ms step_avg:728.48ms
step:1871/1875 train_loss:3.3835 train_time:1355692ms step_avg:728.48ms
step:1872/1875 train_loss:3.3674 train_time:1356430ms step_avg:728.48ms
step:1873/1875 train_loss:3.5405 train_time:1357152ms step_avg:728.48ms
step:1874/1875 train_loss:3.5241 train_time:1357882ms step_avg:728.48ms
step:1875/1875 train_loss:3.4656 train_time:1358604ms step_avg:728.47ms
step:1875/1875 val_loss:3.4806 train_time:1358819ms step_avg:728.59ms
============== Weight norms: ==============
name = 'module._orig_mod.transformer.h.0.attn.c_q.weight' | fro_norm = 45.02490 | spectral_norm = 17.70860 | nuclear_norm = 880.35608
name = 'module._orig_mod.transformer.h.0.attn.c_k.weight' | fro_norm = 43.20098 | spectral_norm = 17.20310 | nuclear_norm = 830.48956
name = 'module._orig_mod.transformer.h.1.attn.c_q.weight' | fro_norm = 44.63246 | spectral_norm = 11.67268 | nuclear_norm = 858.08752
name = 'module._orig_mod.transformer.h.1.attn.c_k.weight' | fro_norm = 41.92730 | spectral_norm = 11.29692 | nuclear_norm = 823.51984
name = 'module._orig_mod.transformer.h.2.attn.c_q.weight' | fro_norm = 43.61825 | spectral_norm = 7.00442 | nuclear_norm = 811.58905
name = 'module._orig_mod.transformer.h.2.attn.c_k.weight' | fro_norm = 41.55386 | spectral_norm = 6.70111 | nuclear_norm = 800.12427
name = 'module._orig_mod.transformer.h.3.attn.c_q.weight' | fro_norm = 44.61604 | spectral_norm = 7.81117 | nuclear_norm = 885.09778
name = 'module._orig_mod.transformer.h.3.attn.c_k.weight' | fro_norm = 41.78834 | spectral_norm = 7.23383 | nuclear_norm = 847.20801
name = 'module._orig_mod.transformer.h.4.attn.c_q.weight' | fro_norm = 44.28063 | spectral_norm = 8.31873 | nuclear_norm = 875.55487
name = 'module._orig_mod.transformer.h.4.attn.c_k.weight' | fro_norm = 41.45305 | spectral_norm = 7.88376 | nuclear_norm = 841.50476
name = 'module._orig_mod.transformer.h.5.attn.c_q.weight' | fro_norm = 45.61123 | spectral_norm = 8.73729 | nuclear_norm = 888.83813
name = 'module._orig_mod.transformer.h.5.attn.c_k.weight' | fro_norm = 42.94604 | spectral_norm = 7.79640 | nuclear_norm = 852.64819
name = 'module._orig_mod.transformer.h.6.attn.c_q.weight' | fro_norm = 45.38561 | spectral_norm = 8.39638 | nuclear_norm = 890.46765
name = 'module._orig_mod.transformer.h.6.attn.c_k.weight' | fro_norm = 43.37679 | spectral_norm = 7.79884 | nuclear_norm = 875.68768
name = 'module._orig_mod.transformer.h.7.attn.c_q.weight' | fro_norm = 45.60007 | spectral_norm = 6.93921 | nuclear_norm = 937.50067
name = 'module._orig_mod.transformer.h.7.attn.c_k.weight' | fro_norm = 42.83435 | spectral_norm = 7.22005 | nuclear_norm = 892.06775
name = 'module._orig_mod.transformer.h.8.attn.c_q.weight' | fro_norm = 44.84423 | spectral_norm = 8.37510 | nuclear_norm = 895.39813
name = 'module._orig_mod.transformer.h.8.attn.c_k.weight' | fro_norm = 43.51781 | spectral_norm = 7.73404 | nuclear_norm = 880.50977
name = 'module._orig_mod.transformer.h.9.attn.c_q.weight' | fro_norm = 43.86575 | spectral_norm = 8.80756 | nuclear_norm = 845.35327
name = 'module._orig_mod.transformer.h.9.attn.c_k.weight' | fro_norm = 40.14050 | spectral_norm = 8.50156 | nuclear_norm = 785.62952
name = 'module._orig_mod.transformer.h.10.attn.c_q.weight' | fro_norm = 44.84601 | spectral_norm = 8.41199 | nuclear_norm = 887.88715
name = 'module._orig_mod.transformer.h.10.attn.c_k.weight' | fro_norm = 41.71387 | spectral_norm = 7.37338 | nuclear_norm = 838.31677
name = 'module._orig_mod.transformer.h.11.attn.c_q.weight' | fro_norm = 44.25063 | spectral_norm = 8.39067 | nuclear_norm = 880.58984
name = 'module._orig_mod.transformer.h.11.attn.c_k.weight' | fro_norm = 40.98010 | spectral_norm = 7.41866 | nuclear_norm = 831.32239
===========================================
