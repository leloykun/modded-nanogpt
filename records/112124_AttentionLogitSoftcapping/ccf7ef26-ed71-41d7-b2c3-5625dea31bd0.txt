====================================================================================================
import os
import sys
with open(sys.argv[0]) as f:
    code = f.read() # read the code of this file ASAP, for logging
import uuid
import glob
import time
from dataclasses import dataclass

import numpy as np
import torch
from torch import nn
import torch.nn.functional as F
import torch.distributed as dist
import torch._inductor.config as config
from torch.nn.parallel import DistributedDataParallel as DDP
# Use of FlexAttention contributed by @KoszarskyB
from torch.nn.attention.flex_attention import flex_attention, create_block_mask, BlockMask, _score_mod_signature
from torch._inductor.lowering import make_pointwise, register_lowering
# Some internal torch.compile details
from torch._inductor.virtualized import ops
from functools import partial
flex_attention = torch.compile(flex_attention, dynamic=False)
create_block_mask = torch.compile(create_block_mask, dynamic=False)

# -----------------------------------------------------------------------------
# Muon optimizer

def zeropower_via_svd(G, steps=None):
    U, S, V = G.svd()
    return U @ V.T

@torch.compile
def zeropower_via_newtonschulz5(G, steps=10, eps=1e-7):
    """
    Newton-Schulz iteration to compute the zeroth power / orthogonalization of G. We opt to use a
    quintic iteration whose coefficients are selected to maximize the slope at zero. For the purpose
    of minimizing steps, it turns out to be empirically effective to keep increasing the slope at
    zero even beyond the point where the iteration no longer converges all the way to one everywhere
    on the interval. This iteration therefore does not produce UV^T but rather something like US'V^T
    where S' is diagonal with S_{ii}' ~ Uniform(0.5, 1.5), which turns out not to hurt model
    performance at all relative to UV^T, where USV^T = G is the SVD.
    """
    assert len(G.shape) == 2
    a, b, c = (3.4445, -4.7750,  2.0315)
    X = G.bfloat16()
    X /= (X.norm() + eps) # ensure top singular value <= 1
    if G.size(0) > G.size(1):
        X = X.T
    for _ in range(steps):
        A = X @ X.T
        B = b * A + c * A @ A # adapted from suggestion by @jxbz, @leloykun, and @YouJiacheng
        X = a * X + B @ X
    if G.size(0) > G.size(1):
        X = X.T
    return X

zeropower_backends = dict(svd=zeropower_via_svd, newtonschulz5=zeropower_via_newtonschulz5)

class Muon(torch.optim.Optimizer):
    """
    Muon - MomentUm Orthogonalized by Newton-schulz

    Muon internally runs standard SGD-momentum, and then performs an orthogonalization post-
    processing step, in which each 2D parameter's update is replaced with the nearest orthogonal
    matrix. To efficiently orthogonalize each update, we use a Newton-Schulz iteration, which has
    the advantage that it can be stably run in bfloat16 on the GPU.

    Some warnings:
    - This optimizer assumes that all parameters passed in are 2D.
    - It should not be used for the embedding layer, the final fully connected layer, or any {0,1}-D
    parameters; those should all be optimized by a standard method (e.g., AdamW).
    - To use it with 4D convolutional filters, it works well to just flatten their last 3 dimensions.
    - We believe it is unlikely to work well for training with small batch size.
    - We believe it may not work well for finetuning pretrained models, but we haven't tested this.
    - We have not yet tried this optimizer for training scenarios larger than NanoGPT (124M).

    Arguments:
        lr: The learning rate used by the internal SGD.
        momentum: The momentum used by the internal SGD.
        nesterov: Whether to use Nesterov-style momentum in the internal SGD. (recommended)
        backend: The chosen backend for the orthogonalization step. (recommended: 'newtonschulz5')
        backend_steps: The number of iteration steps to use in the backend, if it is iterative.
    """
    def __init__(self, params, lr=0.02, momentum=0.95, nesterov=True,
                 backend='newtonschulz5', backend_steps=5):
        defaults = dict(lr=lr, momentum=momentum, nesterov=nesterov, backend=backend, backend_steps=backend_steps)
        super().__init__(params, defaults)

    def step(self):

        for group in self.param_groups:

            lr = group['lr']
            momentum = group['momentum']
            zeropower_backend = zeropower_backends[group['backend']]

            # generate weight updates in distributed fashion
            total_params = sum(p.numel() for p in group['params'])
            updates_flat = torch.zeros(total_params, device='cuda', dtype=torch.bfloat16)
            curr_idx = 0
            for i, p in enumerate(group['params']):
                # luckily this will perfectly distribute a transformer with multiple of 4 layers to 8 GPUs
                if i % int(os.environ['WORLD_SIZE']) == int(os.environ['RANK']):
                    g = p.grad
                    assert g is not None
                    state = self.state[p]
                    if 'momentum_buffer' not in state:
                        state['momentum_buffer'] = torch.zeros_like(g)
                    buf = state['momentum_buffer']
                    buf.mul_(momentum).add_(g)
                    if group['nesterov']:
                        g = g.add(buf, alpha=momentum)
                    g = zeropower_backend(g, steps=group['backend_steps'])
                    g *= max(1, g.size(0)/g.size(1))**0.5
                    updates_flat[curr_idx:curr_idx+p.numel()] = g.flatten()
                curr_idx += p.numel()

            # sync updates across devices. we are not memory-constrained so can do this simple deserialization
            dist.all_reduce(updates_flat, op=dist.ReduceOp.SUM)

            # deserialize and apply updates
            curr_idx = 0
            for p in group['params']:
                g = updates_flat[curr_idx:curr_idx+p.numel()].view_as(p.data).type_as(p.data)
                p.data.add_(g, alpha=-lr)
                curr_idx += p.numel()

# -----------------------------------------------------------------------------
# Attention Tanh softcapping

@torch.library.custom_op("approx::tanh", mutates_args=())
def _tanh_approx(inp: torch.Tensor) -> torch.Tensor:
    return torch.tanh(inp)

@_tanh_approx.register_fake
def _(inp: torch.Tensor) -> torch.Tensor:
    return torch.tanh(inp)

def _tanh_approx_lowering(inp):
    fn = partial(ops.inline_asm_elementwise, asm="tanh.approx.f32 $0, $1;")
    return make_pointwise(fn)(inp)

register_lowering(torch.ops.approx.tanh)(_tanh_approx_lowering)

class _TanhApprox(torch.autograd.Function):
    @staticmethod
    def forward(x):
        return torch.ops.approx.tanh(x)

    @staticmethod
    def setup_context(ctx, inputs, output):
        (x,) = inputs
        result = output
        ctx.save_for_backward(result)

    @staticmethod
    def backward(ctx, grad_output):
        (result,) = ctx.saved_tensors
        return grad_output * (1 - result * result)

    @staticmethod
    def vmap(info, in_dims, x):
        return torch.tanh(x), 0

_tanh_approx = _TanhApprox.apply

def generate_tanh_softcap(soft_cap: int, approx: bool=True) -> _score_mod_signature:
    tanh = _tanh_approx if approx else torch.tanh

    def tanh_softcap(score, b, h, q_idx, kv_idx):
        return soft_cap * tanh(score / soft_cap)

    prefix = "tanh_softcap_approx" if approx else "tanh_softcap"
    tanh_softcap.__name__ = f"{prefix}_{soft_cap}"

    return tanh_softcap

# -----------------------------------------------------------------------------
# PyTorch nn.Module definitions for the GPT-2 model

class Rotary(torch.nn.Module):

    def __init__(self, dim, base=10000):
        super().__init__()
        self.dim = dim
        self.base = base
        self.inv_freq = None
        self.seq_len_cached = None
        self.cos_cached = None
        self.sin_cached = None

    def forward(self, x):
        seq_len = x.shape[1]
        if seq_len != self.seq_len_cached:
            self.inv_freq = 1.0 / (self.base ** (torch.arange(0, self.dim, 2, device=x.device).float() / self.dim))
            self.seq_len_cached = seq_len
            t = torch.arange(seq_len, device=x.device).type_as(self.inv_freq)
            freqs = torch.outer(t, self.inv_freq)
            self.cos_cached = freqs.cos().bfloat16()
            self.sin_cached = freqs.sin().bfloat16()
        return self.cos_cached[None, :, None, :], self.sin_cached[None, :, None, :]

def apply_rotary_emb(x, cos, sin):
    assert x.ndim == 4 # multihead attention
    d = x.shape[3]//2
    x1 = x[..., :d]
    x2 = x[..., d:]
    y1 = x1 * cos + x2 * sin
    y2 = x1 * (-sin) + x2 * cos
    return torch.cat([y1, y2], 3).type_as(x)

class CastedLinear(nn.Linear):
    def forward(self, x):
        return F.linear(x, self.weight.to(x.dtype))

class CausalSelfAttention(nn.Module):

    def __init__(self, config):
        super().__init__()
        self.n_head = config.n_head
        self.n_embd = config.n_embd
        self.head_dim = self.n_embd // self.n_head
        assert self.n_embd % self.n_head == 0
        self.c_q = CastedLinear(self.n_embd, self.n_embd, bias=False)
        self.c_k = CastedLinear(self.n_embd, self.n_embd, bias=False)
        self.c_v = CastedLinear(self.n_embd, self.n_embd, bias=False)
        # output projection
        self.c_proj = CastedLinear(self.n_embd, self.n_embd, bias=False)
        self.c_proj.weight.data.zero_() # zero init suggested by @Grad62304977
        self.rotary = Rotary(self.head_dim)
        self.lamb = nn.Parameter(torch.tensor(0.5)) # @Grad62304977

    def forward(self, x, v1, block_mask: BlockMask, score_mod: _score_mod_signature):
        B, T, C = x.size() # batch size, sequence length, embedding dimensionality (n_embd)
        q = self.c_q(x).view(B, T, self.n_head, self.head_dim)
        k = self.c_k(x).view(B, T, self.n_head, self.head_dim)
        v = self.c_v(x).view(B, T, self.n_head, self.head_dim)
        if v1 is None:
            v1 = v # This happens if we are in the first block. v needs to be accessed by subsequent blocks
        v = (1 - self.lamb) * v + self.lamb * v1.view_as(v) # @Grad62304977
        cos, sin = self.rotary(q)
        q, k = F.rms_norm(q, (q.size(-1),)), F.rms_norm(k, (k.size(-1),)) # QK norm suggested by @Grad62304977
        q, k = apply_rotary_emb(q, cos, sin), apply_rotary_emb(k, cos, sin)
        y = flex_attention(q.transpose(1, 2), k.transpose(1, 2), v.transpose(1, 2), score_mod=score_mod, block_mask=block_mask)
        y = y.transpose(1, 2).contiguous().view_as(x) # re-assemble all head outputs side by side
        y = self.c_proj(y)
        return y, v1

class MLP(nn.Module):

    def __init__(self, config):
        super().__init__()
        self.c_fc    = CastedLinear(config.n_embd, 4 * config.n_embd, bias=False)
        self.c_proj  = CastedLinear(4 * config.n_embd, config.n_embd, bias=False)
        self.c_proj.weight.data.zero_() # zero init suggested by @Grad62304977

    def forward(self, x):
        x = self.c_fc(x)
        x = F.relu(x).square() # https://arxiv.org/abs/2109.08668v2; ~1-2% better than GELU; suggested by @SKYLINEZ007 and @Grad62304977
        x = self.c_proj(x)
        return x

class Block(nn.Module):

    def __init__(self, config):
        super().__init__()
        self.attn = CausalSelfAttention(config)
        self.mlp = MLP(config)
        self.lambdas = nn.Parameter(torch.tensor([1., 0.]))

    def forward(self, x, v1, x0, block_mask: BlockMask, score_mod: _score_mod_signature):
        x = self.lambdas[0] * x + self.lambdas[1] * x0
        x1, v1 = self.attn(F.rms_norm(x, (x.size(-1),)), v1, block_mask, score_mod)
        x = x + x1
        x = x + self.mlp(F.rms_norm(x, (x.size(-1),)))
        return x, v1

# -----------------------------------------------------------------------------
# The main GPT-2 model

@dataclass
class GPTConfig:
    vocab_size : int = 50304
    n_layer : int = 12
    n_head : int = 6 # head dim 128 suggested by @Grad62304977
    n_embd : int = 768
    attention_soft_cap : int = 50
    lm_head_soft_cap : int = 30

class GPT(nn.Module):

    def __init__(self, config: GPTConfig):
        super().__init__()
        self.attention_soft_cap = config.attention_soft_cap
        self.lm_head_soft_cap = config.lm_head_soft_cap

        # U-net design by @brendanh0gan
        self.num_encoder_layers = config.n_layer // 2 # Half of the layers for encoder
        self.num_decoder_layers = config.n_layer - self.num_encoder_layers # Remaining for decoder
        # Add learnable skip connection weights for decoder layers
        self.skip_weights = nn.Parameter(torch.ones(self.num_decoder_layers))

        self.transformer = nn.ModuleDict(dict(
            wte = nn.Embedding(config.vocab_size, config.n_embd),
            h = nn.ModuleList([Block(config) for _ in range(config.n_layer)]),
        ))
        self.lm_head = CastedLinear(config.n_embd, config.vocab_size, bias=False)
        self.lm_head.weight.data.zero_() # @Grad62304977

    def forward(self, idx, target):

        docs = (idx == 50256).cumsum(0)
        def document_causal_mask(b, h, q_idx, kv_idx):
            causal_mask = q_idx >= kv_idx
            document_mask = docs[q_idx] == docs[kv_idx]
            window_mask = q_idx - kv_idx < 1024
            return causal_mask & document_mask & window_mask

        softcap_mod = generate_tanh_softcap(self.attention_soft_cap, approx=True)  # @leloykun

        S = len(idx)
        block_mask = create_block_mask(document_causal_mask, None, None, S, S, device="cuda", _compile=True)

        # forward the GPT model itself
        x = self.transformer.wte(idx[None]) # token embeddings of shape (b, t, n_embd)
        x = F.rms_norm(x, (x.size(-1),)) # @Grad62304977
        x0 = x
        v1 = None

        # Store outputs for U-Net skip connections
        skip_connections = []
        # Encoder pass - process only the first half of the blocks
        for i in range(self.num_encoder_layers):
            x, v1 = self.transformer.h[i](x, v1, x0, block_mask, softcap_mod)
            skip_connections.append(x)
        # Decoder pass - process the remaining blocks with weighted skip connections
        for i in range(self.num_decoder_layers):
            x = x + self.skip_weights[i] * skip_connections.pop()
            x, v1 = self.transformer.h[self.num_encoder_layers + i](x, v1, x0, block_mask, softcap_mod)

        x = F.rms_norm(x, (x.size(-1),))
        logits = self.lm_head(x)
        logits = self.lm_head_soft_cap * torch.tanh(logits / self.lm_head_soft_cap) # @Grad62304977
        logits = logits.float()
        loss = F.cross_entropy(logits.view(-1, logits.size(-1)), target.view(-1))
        return loss

# -----------------------------------------------------------------------------
# Our own simple Distributed Data Loader

def _peek_data_shard(filename):
    # only reads the header, returns header data
    with open(filename, "rb") as f:
        # first read the header, which is 256 int32 integers (4 bytes each)
        header = np.frombuffer(f.read(256*4), dtype=np.int32)
    if header[0] != 20240520:
        print("ERROR: magic number mismatch in the data .bin file!")
        print("---> HINT: Are you passing in a correct file with --input_bin?")
        print("---> HINT: Dataset encoding changed recently, re-run data prepro or refer again to README")
        print("---> HINT: For example re-run: `python dev/data/tinyshakespeare.py`, then re-try")
        exit(1)
    assert header[1] == 1, "unsupported version"
    ntok = header[2] # number of tokens (claimed)
    return ntok # for now just return the number of tokens

def _load_data_shard(filename):
    with open(filename, "rb") as f:
        # first read the header, which is 256 int32 integers (4 bytes each)
        header = np.frombuffer(f.read(256*4), dtype=np.int32)
        assert header[0] == 20240520, "magic number mismatch in the data .bin file"
        assert header[1] == 1, "unsupported version"
        ntok = header[2] # number of tokens (claimed)
        # the rest of it are tokens, stored as uint16
        tokens = np.frombuffer(f.read(), dtype=np.uint16)
    assert len(tokens) == ntok, "number of tokens read does not match header?"
    return tokens

class DistributedDataLoader:
    def __init__(self, filename_pattern, B, T, process_rank, num_processes):
        self.process_rank = process_rank
        self.num_processes = num_processes
        self.B = B
        self.T = T

        # glob files that match the pattern
        self.files = sorted(glob.glob(filename_pattern))
        assert len(self.files) > 0, f"did not find any files that match the pattern {filename_pattern}"

        # load and validate all data shards, count number of tokens in total
        ntok_total = 0
        for fname in self.files:
            shard_ntok = _peek_data_shard(fname)
            assert shard_ntok >= num_processes * B * T + 1
            ntok_total += int(shard_ntok)
        self.ntok_total = ntok_total

        self.reset()

    def reset(self):
        self.current_shard = -1
        self.advance()

    def advance(self): # advance to next data shard
        self.current_shard = (self.current_shard + 1) % len(self.files)
        self.current_position = self.process_rank * self.B * self.T
        self.tokens = _load_data_shard(self.files[self.current_shard])

    def next_batch(self):
        batch_size = self.B * self.T * self.num_processes
        buf = self.tokens[self.current_position:self.current_position+self.B*self.T+1]
        buf = torch.tensor(buf.astype(np.int32), dtype=torch.long)
        x = buf[:-1] # inputs
        y = buf[1:] # targets
        # advance current position and load next shard if necessary
        self.current_position += batch_size
        if self.current_position + batch_size >= len(self.tokens):
            self.advance()
        return x.cuda(), y.cuda()

# -----------------------------------------------------------------------------
# int main

@dataclass
class Hyperparameters:
    # data hyperparams
    input_bin : str = 'data/fineweb10B/fineweb_train_*.bin' # input .bin to train on
    input_val_bin : str = 'data/fineweb10B/fineweb_val_*.bin' # input .bin to eval validation loss on
    # optimization hyperparams
    batch_size : int = 8 # batch size, in sequences, across all devices
    device_batch_size : int = 1 # batch size, in sequences, per device
    sequence_length : int = 64*1024 # sequence length, in tokens
    num_iterations : int = 1875 # number of iterations to run
    warmup_iters : int = 0
    warmdown_iters : int = 562 # number of iterations of linear warmup/warmdown for triangular or trapezoidal schedule
    weight_decay : float = 0
    # evaluation and logging hyperparams
    val_loss_every : int = 125 # every how many steps to evaluate val loss? 0 for only at the end
    val_tokens : int = 10485760 # how many tokens of validation data? it's important to keep this fixed for consistent comparisons
    save_every : int = 0 # every how many steps to save the checkpoint? 0 for only at the end
args = Hyperparameters()

# set up DDP (distributed data parallel). torchrun sets this env variable
assert torch.cuda.is_available()
dist.init_process_group(backend='nccl')
ddp_rank = int(os.environ['RANK'])
ddp_local_rank = int(os.environ['LOCAL_RANK'])
ddp_world_size = int(os.environ['WORLD_SIZE'])
device = f'cuda:{ddp_local_rank}'
torch.cuda.set_device(device)
print(f"using device: {device}")
master_process = (ddp_rank == 0) # this process will do logging, checkpointing etc.

# begin logging
logfile = None
if master_process:
    run_id = str(uuid.uuid4())
    logdir = 'logs/%s/' % run_id
    os.makedirs(logdir, exist_ok=True)
    logfile = 'logs/%s.txt' % run_id
    # create the log file
    with open(logfile, "w") as f:
        # begin the log by printing this file (the Python code)
        f.write('='*100 + '\n')
        f.write(code)
        f.write('='*100 + '\n')
def print0(s, logonly=False):
    if master_process:
        with open(logfile, "a") as f:
            if not logonly:
                print(s)
            f.write(s+'\n')
# log information about the hardware/software environment this is running on
# and print the full `nvidia-smi` to file
print0(f"Running pytorch {torch.version.__version__} compiled for CUDA {torch.version.cuda}\nnvidia-smi:")
import subprocess
result = subprocess.run(['nvidia-smi'], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True)
print0(f'{result.stdout}', logonly=True)
print0('='*100, logonly=True)

# convenience variables
B, T = args.device_batch_size, args.sequence_length
# calculate the number of steps to take in the val loop.
assert args.val_tokens % (B * T * ddp_world_size) == 0
val_steps = args.val_tokens // (B * T * ddp_world_size)
# calculate the steps of gradient accumulation required to attain the desired global batch size.
assert args.batch_size % (B * ddp_world_size) == 0
train_accumulation_steps = args.batch_size // (B * ddp_world_size)

# load tokens
train_loader = DistributedDataLoader(args.input_bin, B, T, ddp_rank, ddp_world_size)
val_loader = DistributedDataLoader(args.input_val_bin, B, T, ddp_rank, ddp_world_size)
print0(f"Training DataLoader: total number of tokens: {train_loader.ntok_total} across {len(train_loader.files)} files")
print0(f"Validation DataLoader: total number of tokens: {val_loader.ntok_total} across {len(val_loader.files)} files")
print0('='*100, logonly=True)
x, y = train_loader.next_batch()

# there are only 50257 unique GPT-2 tokens; we extend to nearest multiple of 128 for efficiency. suggested to me by @Grad62304977.
# this originates from Karpathy's experiments.
num_vocab = 50304
model = GPT(GPTConfig(vocab_size=num_vocab, n_layer=12, n_head=6, n_embd=768))
model = model.cuda().bfloat16()
for m in model.modules():
    if isinstance(m, CastedLinear):
        m.float()
if hasattr(config, "coordinate_descent_tuning"):
    config.coordinate_descent_tuning = True # suggested by @Chillee
model = torch.compile(model)
# here we wrap model into DDP container
model = DDP(model, device_ids=[ddp_local_rank])
raw_model = model.module # always contains the "raw" unwrapped model

# CUDNN attention is ~4ms faster than Flash, but doesn't get selected by default in PyTorch 2.5.1
from torch.backends.cuda import enable_cudnn_sdp, enable_flash_sdp, enable_math_sdp, enable_mem_efficient_sdp
enable_cudnn_sdp(True)
enable_flash_sdp(False)
enable_mem_efficient_sdp(False)
enable_math_sdp(False)

# init the optimizer(s)
optimizer1 = torch.optim.Adam([raw_model.transformer.wte.weight], lr=0.6,   betas=(0.9, 0.95), fused=True)
optimizer2 = torch.optim.Adam([raw_model.lm_head.weight],         lr=0.008, betas=(0.9, 0.95), fused=True)
params = list(raw_model.transformer.h.parameters())
matrix_params = [p for p in params if p.ndim == 2]
scalar_params = [p for p in params if p.ndim < 2] + [raw_model.skip_weights]
# optimizer3 = Muon(matrix_params, lr=0.04, momentum=0.95)
optimizer3 = torch.optim.Adam(matrix_params, lr=0.0018, betas=(0.9, 0.95), fused=True)
optimizer4 = torch.optim.Adam(scalar_params, lr=0.04, betas=(0.9, 0.95), fused=True) # note that this learning rate is neither sensitive nor tuned
optimizers = [optimizer1, optimizer2, optimizer3, optimizer4]
# learning rate decay scheduler (linear warmup and warmdown)
def get_lr(it):
    assert it <= args.num_iterations
    # 1) linear warmup for warmup_iters steps
    if it < args.warmup_iters:
        return (it+1) / args.warmup_iters
    # 2) constant lr for a while
    elif it < args.num_iterations - args.warmdown_iters:
        return 1.0
    # 3) linear warmdown
    else:
        decay_ratio = (args.num_iterations - it) / args.warmdown_iters
        return decay_ratio
schedulers = [torch.optim.lr_scheduler.LambdaLR(opt, get_lr) for opt in optimizers]

# Start training loop
training_time_ms = 0
# start the clock
torch.cuda.synchronize()
t0 = time.time()
# begin training
for step in range(args.num_iterations + 1):
    last_step = (step == args.num_iterations)
    # This effectively ignores timing first 10 steps, which are slower for weird reasons.
    # Alternately, and slightly more correctly in terms of benchmarking, we could do 10
    # steps with dummy data first, and then re-initialize the model and reset the loader.
    if step == 10:
        training_time_ms = 0
        t0 = time.time()
    timed_steps = float('nan') if step <= 11 else (step - 10) + 1 # <= 11 to avoid bug in val

    # once in a while evaluate the validation dataset
    if (last_step or (args.val_loss_every > 0 and step % args.val_loss_every == 0)):
        # stop the clock
        torch.cuda.synchronize()
        training_time_ms += 1000 * (time.time() - t0)
        # run validation batches
        model.eval()
        val_loader.reset()
        val_loss = 0.0
        for _ in range(val_steps):
            with torch.no_grad():
                x_val, y_val = val_loader.next_batch()
                val_loss += model(x_val, y_val)
        dist.all_reduce(val_loss, op=dist.ReduceOp.AVG)
        val_loss /= val_steps
        # log val loss to console and to logfile
        print0(f'step:{step}/{args.num_iterations} val_loss:{val_loss:.4f} train_time:{training_time_ms:.0f}ms step_avg:{training_time_ms/(timed_steps-1):.2f}ms')
        if master_process:
            with open(logfile, "a") as f:
                print("============== Weight norms: ==============")
                f.write("============== Weight norms: ==============\n")
                for name, p in model.named_parameters():
                    if p.ndim != 2:
                        continue
                    if "c_q" not in name and "c_k" not in name:
                        continue
                    fro_norm = torch.linalg.norm(p.data.float(), ord="fro").item()
                    spectral_norm = torch.linalg.matrix_norm(p.data.float(), ord=2).item()
                    nuclear_norm = torch.linalg.matrix_norm(p.data.float(), ord="nuc").item()
                    print(f"{name = } | {fro_norm = :.5f} | {spectral_norm = :.5f} | {nuclear_norm = :.5f}")
                    f.write(f"{name = } | {fro_norm = :.5f} | {spectral_norm = :.5f} | {nuclear_norm = :.5f}\n")
                f.write("===========================================\n")
                print("===========================================")
        # start the clock again
        torch.cuda.synchronize()
        t0 = time.time()

    if master_process and (last_step or (args.save_every > 0 and step % args.save_every == 0)):
        # stop the clock
        torch.cuda.synchronize()
        training_time_ms += 1000 * (time.time() - t0)
        # save the state of the training process
        log = dict(step=step, code=code, model=raw_model.state_dict(), optimizers=[opt.state_dict() for opt in optimizers])
        torch.save(log, 'logs/%s/state_step%06d.pt' % (run_id, step))
        # start the clock again
        torch.cuda.synchronize()
        t0 = time.time()

    # bit confusing: we want to make sure to eval on 0th iteration
    # but also after the very last iteration. so we loop for step <= num_iterations
    # instead of just < num_iterations (one extra due to <=), only to do
    # the validation/sampling one last time, and then we break right here as we're done.
    if last_step:
        break

    # --------------- TRAINING SECTION BEGIN -----------------
    model.train()
    for i in range(1, train_accumulation_steps+1):
        # forward pass
        loss = model(x, y)
        train_loss = loss.detach()
        # advance the dataset for the next batch
        x, y = train_loader.next_batch()
        # backward pass
        if i < train_accumulation_steps:
            with model.no_sync(): # there's no need to sync gradients every accumulation step
                loss.backward()
        else:
            loss.backward() # just sync on the last step
    for p in model.parameters():
        p.grad /= train_accumulation_steps
    # momentum warmup for Muon
    frac = min(step/500, 1)
    optimizer3.param_groups[0]['momentum'] = (1 - frac) * 0.85 + frac * 0.95
    # step the optimizers and schedulers
    for opt, sched in zip(optimizers, schedulers):
        opt.step()
        sched.step()
    # null the gradients
    model.zero_grad(set_to_none=True)
    # --------------- TRAINING SECTION END -------------------
    # everything that follows now is just diagnostics, prints, logging, etc.

    #dist.all_reduce(train_loss, op=dist.ReduceOp.AVG) # all-reducing the training loss would be more correct in terms of logging, but slower
    approx_time = training_time_ms + 1000 * (time.time() - t0)
    print0(f"step:{step+1}/{args.num_iterations} train_loss:{train_loss.item():.4f} train_time:{approx_time:.0f}ms step_avg:{approx_time/timed_steps:.2f}ms")

if master_process:
    print(f"peak memory consumption: {torch.cuda.max_memory_allocated() // 1024 // 1024} MiB")

# -------------------------------------------------------------------------
# clean up nice
dist.destroy_process_group()
====================================================================================================
Running pytorch 2.6.0.dev20241122+cu124 compiled for CUDA 12.4
nvidia-smi:
Sat Nov 23 07:02:30 2024       
+---------------------------------------------------------------------------------------+
| NVIDIA-SMI 535.104.12             Driver Version: 535.104.12   CUDA Version: 12.4     |
|-----------------------------------------+----------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |
|                                         |                      |               MIG M. |
|=========================================+======================+======================|
|   0  NVIDIA A100-SXM4-80GB          On  | 00000000:07:00.0 Off |                    0 |
| N/A   30C    P0              65W / 400W |      7MiB / 81920MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   1  NVIDIA A100-SXM4-80GB          On  | 00000000:0A:00.0 Off |                    0 |
| N/A   28C    P0              68W / 400W |    427MiB / 81920MiB |      2%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   2  NVIDIA A100-SXM4-80GB          On  | 00000000:45:00.0 Off |                    0 |
| N/A   28C    P0              70W / 400W |    427MiB / 81920MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   3  NVIDIA A100-SXM4-80GB          On  | 00000000:4B:00.0 Off |                    0 |
| N/A   31C    P0              71W / 400W |    427MiB / 81920MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   4  NVIDIA A100-SXM4-80GB          On  | 00000000:84:00.0 Off |                    0 |
| N/A   31C    P0              71W / 400W |    427MiB / 81920MiB |      3%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   5  NVIDIA A100-SXM4-80GB          On  | 00000000:8A:00.0 Off |                    0 |
| N/A   28C    P0              68W / 400W |    427MiB / 81920MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   6  NVIDIA A100-SXM4-80GB          On  | 00000000:C0:00.0 Off |                    0 |
| N/A   27C    P0              69W / 400W |    427MiB / 81920MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
|   7  NVIDIA A100-SXM4-80GB          On  | 00000000:C3:00.0 Off |                    0 |
| N/A   31C    P0              71W / 400W |    427MiB / 81920MiB |      0%      Default |
|                                         |                      |             Disabled |
+-----------------------------------------+----------------------+----------------------+
                                                                                         
+---------------------------------------------------------------------------------------+
| Processes:                                                                            |
|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |
|        ID   ID                                                             Usage      |
|=======================================================================================|
+---------------------------------------------------------------------------------------+

====================================================================================================
Training DataLoader: total number of tokens: 1100000000 across 11 files
Validation DataLoader: total number of tokens: 100000000 across 1 files
====================================================================================================
step:0/1875 val_loss:10.8258 train_time:0ms step_avg:nanms
============== Weight norms: ==============
name = 'module._orig_mod.transformer.h.0.attn.c_q.weight' | fro_norm = 15.99087 | spectral_norm = 1.14462 | nuclear_norm = 376.16672
name = 'module._orig_mod.transformer.h.0.attn.c_k.weight' | fro_norm = 16.00071 | spectral_norm = 1.15240 | nuclear_norm = 376.30652
name = 'module._orig_mod.transformer.h.1.attn.c_q.weight' | fro_norm = 15.98868 | spectral_norm = 1.14914 | nuclear_norm = 376.14081
name = 'module._orig_mod.transformer.h.1.attn.c_k.weight' | fro_norm = 16.00489 | spectral_norm = 1.14103 | nuclear_norm = 376.55902
name = 'module._orig_mod.transformer.h.2.attn.c_q.weight' | fro_norm = 15.99042 | spectral_norm = 1.15542 | nuclear_norm = 376.24036
name = 'module._orig_mod.transformer.h.2.attn.c_k.weight' | fro_norm = 15.98322 | spectral_norm = 1.14535 | nuclear_norm = 375.85089
name = 'module._orig_mod.transformer.h.3.attn.c_q.weight' | fro_norm = 15.99909 | spectral_norm = 1.14925 | nuclear_norm = 376.51257
name = 'module._orig_mod.transformer.h.3.attn.c_k.weight' | fro_norm = 15.99100 | spectral_norm = 1.14401 | nuclear_norm = 376.26736
name = 'module._orig_mod.transformer.h.4.attn.c_q.weight' | fro_norm = 15.99607 | spectral_norm = 1.14274 | nuclear_norm = 376.26865
name = 'module._orig_mod.transformer.h.4.attn.c_k.weight' | fro_norm = 16.00034 | spectral_norm = 1.14726 | nuclear_norm = 376.42471
name = 'module._orig_mod.transformer.h.5.attn.c_q.weight' | fro_norm = 15.99357 | spectral_norm = 1.15081 | nuclear_norm = 376.23312
name = 'module._orig_mod.transformer.h.5.attn.c_k.weight' | fro_norm = 15.99802 | spectral_norm = 1.15708 | nuclear_norm = 376.25104
name = 'module._orig_mod.transformer.h.6.attn.c_q.weight' | fro_norm = 16.00428 | spectral_norm = 1.15326 | nuclear_norm = 376.55414
name = 'module._orig_mod.transformer.h.6.attn.c_k.weight' | fro_norm = 15.98551 | spectral_norm = 1.14714 | nuclear_norm = 375.82855
name = 'module._orig_mod.transformer.h.7.attn.c_q.weight' | fro_norm = 15.99199 | spectral_norm = 1.14518 | nuclear_norm = 376.40503
name = 'module._orig_mod.transformer.h.7.attn.c_k.weight' | fro_norm = 16.00509 | spectral_norm = 1.14677 | nuclear_norm = 376.50333
name = 'module._orig_mod.transformer.h.8.attn.c_q.weight' | fro_norm = 15.99102 | spectral_norm = 1.14553 | nuclear_norm = 376.03149
name = 'module._orig_mod.transformer.h.8.attn.c_k.weight' | fro_norm = 16.00835 | spectral_norm = 1.15171 | nuclear_norm = 376.50931
name = 'module._orig_mod.transformer.h.9.attn.c_q.weight' | fro_norm = 16.00956 | spectral_norm = 1.13773 | nuclear_norm = 376.63599
name = 'module._orig_mod.transformer.h.9.attn.c_k.weight' | fro_norm = 15.99900 | spectral_norm = 1.15266 | nuclear_norm = 376.02441
name = 'module._orig_mod.transformer.h.10.attn.c_q.weight' | fro_norm = 15.99489 | spectral_norm = 1.14307 | nuclear_norm = 376.19177
name = 'module._orig_mod.transformer.h.10.attn.c_k.weight' | fro_norm = 16.00120 | spectral_norm = 1.14564 | nuclear_norm = 376.46857
name = 'module._orig_mod.transformer.h.11.attn.c_q.weight' | fro_norm = 16.02241 | spectral_norm = 1.14127 | nuclear_norm = 377.10446
name = 'module._orig_mod.transformer.h.11.attn.c_k.weight' | fro_norm = 15.99875 | spectral_norm = 1.14075 | nuclear_norm = 376.36676
===========================================
step:1/1875 train_loss:10.8258 train_time:147592ms step_avg:nanms
step:2/1875 train_loss:10.0670 train_time:147775ms step_avg:nanms
step:3/1875 train_loss:9.4131 train_time:148130ms step_avg:nanms
step:4/1875 train_loss:7.8494 train_time:148493ms step_avg:nanms
step:5/1875 train_loss:7.2318 train_time:148858ms step_avg:nanms
step:6/1875 train_loss:6.9371 train_time:149217ms step_avg:nanms
step:7/1875 train_loss:8.0049 train_time:149578ms step_avg:nanms
step:8/1875 train_loss:7.2358 train_time:149950ms step_avg:nanms
step:9/1875 train_loss:7.0566 train_time:150330ms step_avg:nanms
step:10/1875 train_loss:6.8716 train_time:150689ms step_avg:nanms
step:11/1875 train_loss:6.8555 train_time:149ms step_avg:nanms
step:12/1875 train_loss:7.1672 train_time:513ms step_avg:nanms
step:13/1875 train_loss:6.8091 train_time:881ms step_avg:293.61ms
step:14/1875 train_loss:6.7375 train_time:1250ms step_avg:312.38ms
step:15/1875 train_loss:6.6190 train_time:1617ms step_avg:323.35ms
step:16/1875 train_loss:6.6071 train_time:1985ms step_avg:330.77ms
step:17/1875 train_loss:6.6313 train_time:2350ms step_avg:335.65ms
step:18/1875 train_loss:6.4448 train_time:2717ms step_avg:339.59ms
step:19/1875 train_loss:6.4691 train_time:3089ms step_avg:343.21ms
step:20/1875 train_loss:6.1580 train_time:3458ms step_avg:345.76ms
step:21/1875 train_loss:6.4404 train_time:3824ms step_avg:347.68ms
step:22/1875 train_loss:6.7156 train_time:4191ms step_avg:349.22ms
step:23/1875 train_loss:6.3366 train_time:4561ms step_avg:350.82ms
step:24/1875 train_loss:6.5070 train_time:4930ms step_avg:352.12ms
step:25/1875 train_loss:6.2051 train_time:5291ms step_avg:352.72ms
step:26/1875 train_loss:6.1021 train_time:5662ms step_avg:353.85ms
step:27/1875 train_loss:6.3241 train_time:6033ms step_avg:354.87ms
step:28/1875 train_loss:5.9771 train_time:6402ms step_avg:355.65ms
step:29/1875 train_loss:6.2466 train_time:6764ms step_avg:356.02ms
step:30/1875 train_loss:6.0884 train_time:7127ms step_avg:356.33ms
step:31/1875 train_loss:6.0430 train_time:7496ms step_avg:356.94ms
step:32/1875 train_loss:5.8923 train_time:7870ms step_avg:357.71ms
step:33/1875 train_loss:6.2450 train_time:8234ms step_avg:357.98ms
step:34/1875 train_loss:6.1328 train_time:8607ms step_avg:358.61ms
step:35/1875 train_loss:6.3012 train_time:8973ms step_avg:358.94ms
step:36/1875 train_loss:6.2113 train_time:9342ms step_avg:359.33ms
step:37/1875 train_loss:6.1029 train_time:9712ms step_avg:359.69ms
step:38/1875 train_loss:5.9788 train_time:10082ms step_avg:360.07ms
step:39/1875 train_loss:6.0484 train_time:10457ms step_avg:360.57ms
step:40/1875 train_loss:5.9543 train_time:10825ms step_avg:360.82ms
step:41/1875 train_loss:5.9710 train_time:11196ms step_avg:361.17ms
step:42/1875 train_loss:5.8728 train_time:11562ms step_avg:361.30ms
step:43/1875 train_loss:5.9648 train_time:11923ms step_avg:361.32ms
step:44/1875 train_loss:5.9560 train_time:12286ms step_avg:361.34ms
step:45/1875 train_loss:6.1416 train_time:12659ms step_avg:361.67ms
step:46/1875 train_loss:5.9383 train_time:13028ms step_avg:361.90ms
step:47/1875 train_loss:5.8238 train_time:13397ms step_avg:362.08ms
step:48/1875 train_loss:6.0177 train_time:13761ms step_avg:362.12ms
step:49/1875 train_loss:5.9222 train_time:14131ms step_avg:362.34ms
step:50/1875 train_loss:6.0651 train_time:14510ms step_avg:362.76ms
step:51/1875 train_loss:5.9306 train_time:14871ms step_avg:362.70ms
step:52/1875 train_loss:5.7920 train_time:15253ms step_avg:363.18ms
step:53/1875 train_loss:5.9197 train_time:15625ms step_avg:363.37ms
step:54/1875 train_loss:5.8322 train_time:15991ms step_avg:363.44ms
step:55/1875 train_loss:6.1334 train_time:16353ms step_avg:363.39ms
step:56/1875 train_loss:5.8229 train_time:16732ms step_avg:363.75ms
step:57/1875 train_loss:5.6947 train_time:17097ms step_avg:363.77ms
step:58/1875 train_loss:5.8277 train_time:17464ms step_avg:363.83ms
step:59/1875 train_loss:5.8204 train_time:17831ms step_avg:363.90ms
step:60/1875 train_loss:5.9518 train_time:18206ms step_avg:364.13ms
step:61/1875 train_loss:5.7033 train_time:18578ms step_avg:364.27ms
step:62/1875 train_loss:5.7896 train_time:18951ms step_avg:364.43ms
step:63/1875 train_loss:5.7539 train_time:19315ms step_avg:364.43ms
step:64/1875 train_loss:5.5518 train_time:19688ms step_avg:364.59ms
step:65/1875 train_loss:5.6108 train_time:20058ms step_avg:364.68ms
step:66/1875 train_loss:5.7838 train_time:20422ms step_avg:364.67ms
step:67/1875 train_loss:5.6148 train_time:20794ms step_avg:364.81ms
step:68/1875 train_loss:5.9264 train_time:21161ms step_avg:364.85ms
step:69/1875 train_loss:5.5371 train_time:21538ms step_avg:365.04ms
step:70/1875 train_loss:5.6893 train_time:21905ms step_avg:365.09ms
step:71/1875 train_loss:5.8062 train_time:22277ms step_avg:365.19ms
step:72/1875 train_loss:5.7242 train_time:22645ms step_avg:365.25ms
step:73/1875 train_loss:5.6171 train_time:23028ms step_avg:365.53ms
step:74/1875 train_loss:5.7274 train_time:23402ms step_avg:365.66ms
step:75/1875 train_loss:5.7116 train_time:23772ms step_avg:365.73ms
step:76/1875 train_loss:5.6662 train_time:24142ms step_avg:365.78ms
step:77/1875 train_loss:5.7169 train_time:24519ms step_avg:365.95ms
step:78/1875 train_loss:5.8805 train_time:24891ms step_avg:366.05ms
step:79/1875 train_loss:5.6221 train_time:25264ms step_avg:366.14ms
step:80/1875 train_loss:5.7132 train_time:25644ms step_avg:366.34ms
step:81/1875 train_loss:5.4737 train_time:26008ms step_avg:366.31ms
step:82/1875 train_loss:5.6726 train_time:26378ms step_avg:366.36ms
step:83/1875 train_loss:5.5991 train_time:26751ms step_avg:366.45ms
step:84/1875 train_loss:5.6084 train_time:27117ms step_avg:366.44ms
step:85/1875 train_loss:5.4489 train_time:27483ms step_avg:366.44ms
step:86/1875 train_loss:5.6551 train_time:27853ms step_avg:366.48ms
step:87/1875 train_loss:5.5616 train_time:28222ms step_avg:366.51ms
step:88/1875 train_loss:5.6498 train_time:28591ms step_avg:366.55ms
step:89/1875 train_loss:5.6032 train_time:28961ms step_avg:366.60ms
step:90/1875 train_loss:5.4990 train_time:29333ms step_avg:366.66ms
step:91/1875 train_loss:5.5138 train_time:29713ms step_avg:366.83ms
step:92/1875 train_loss:5.6240 train_time:30082ms step_avg:366.86ms
step:93/1875 train_loss:5.4647 train_time:30453ms step_avg:366.90ms
step:94/1875 train_loss:5.4722 train_time:30819ms step_avg:366.89ms
step:95/1875 train_loss:5.4863 train_time:31194ms step_avg:366.99ms
step:96/1875 train_loss:5.3976 train_time:31561ms step_avg:366.99ms
step:97/1875 train_loss:5.4984 train_time:31929ms step_avg:367.00ms
step:98/1875 train_loss:5.4117 train_time:32301ms step_avg:367.05ms
step:99/1875 train_loss:5.5278 train_time:32670ms step_avg:367.07ms
step:100/1875 train_loss:5.4759 train_time:33045ms step_avg:367.17ms
step:101/1875 train_loss:5.4051 train_time:33436ms step_avg:367.43ms
step:102/1875 train_loss:5.4979 train_time:33814ms step_avg:367.54ms
step:103/1875 train_loss:5.4739 train_time:34181ms step_avg:367.53ms
step:104/1875 train_loss:5.3400 train_time:34559ms step_avg:367.64ms
step:105/1875 train_loss:5.4468 train_time:34929ms step_avg:367.67ms
step:106/1875 train_loss:5.6304 train_time:35297ms step_avg:367.67ms
step:107/1875 train_loss:5.3979 train_time:35666ms step_avg:367.70ms
step:108/1875 train_loss:5.1766 train_time:36036ms step_avg:367.72ms
step:109/1875 train_loss:5.3589 train_time:36400ms step_avg:367.68ms
step:110/1875 train_loss:5.3500 train_time:36765ms step_avg:367.65ms
step:111/1875 train_loss:5.3289 train_time:37140ms step_avg:367.73ms
step:112/1875 train_loss:5.4395 train_time:37507ms step_avg:367.71ms
step:113/1875 train_loss:5.3432 train_time:37881ms step_avg:367.78ms
step:114/1875 train_loss:5.2012 train_time:38248ms step_avg:367.77ms
step:115/1875 train_loss:5.3491 train_time:38616ms step_avg:367.77ms
step:116/1875 train_loss:5.2380 train_time:38987ms step_avg:367.80ms
step:117/1875 train_loss:5.2118 train_time:39354ms step_avg:367.79ms
step:118/1875 train_loss:5.3415 train_time:39723ms step_avg:367.81ms
step:119/1875 train_loss:5.3588 train_time:40096ms step_avg:367.85ms
step:120/1875 train_loss:5.2552 train_time:40460ms step_avg:367.81ms
step:121/1875 train_loss:5.1554 train_time:40829ms step_avg:367.83ms
step:122/1875 train_loss:5.2749 train_time:41192ms step_avg:367.79ms
step:123/1875 train_loss:5.1225 train_time:41565ms step_avg:367.83ms
step:124/1875 train_loss:5.4217 train_time:41929ms step_avg:367.80ms
step:125/1875 train_loss:5.2781 train_time:42291ms step_avg:367.75ms
step:125/1875 val_loss:5.2542 train_time:42503ms step_avg:369.59ms
============== Weight norms: ==============
name = 'module._orig_mod.transformer.h.0.attn.c_q.weight' | fro_norm = 21.16821 | spectral_norm = 6.34144 | nuclear_norm = 436.94110
name = 'module._orig_mod.transformer.h.0.attn.c_k.weight' | fro_norm = 21.12536 | spectral_norm = 7.08577 | nuclear_norm = 434.27136
name = 'module._orig_mod.transformer.h.1.attn.c_q.weight' | fro_norm = 21.50253 | spectral_norm = 6.85559 | nuclear_norm = 439.22308
name = 'module._orig_mod.transformer.h.1.attn.c_k.weight' | fro_norm = 20.08358 | spectral_norm = 4.71144 | nuclear_norm = 429.04333
name = 'module._orig_mod.transformer.h.2.attn.c_q.weight' | fro_norm = 21.00240 | spectral_norm = 6.31363 | nuclear_norm = 432.28668
name = 'module._orig_mod.transformer.h.2.attn.c_k.weight' | fro_norm = 20.54805 | spectral_norm = 5.61213 | nuclear_norm = 431.30685
name = 'module._orig_mod.transformer.h.3.attn.c_q.weight' | fro_norm = 20.93169 | spectral_norm = 5.76704 | nuclear_norm = 431.26675
name = 'module._orig_mod.transformer.h.3.attn.c_k.weight' | fro_norm = 20.53523 | spectral_norm = 5.29620 | nuclear_norm = 430.47702
name = 'module._orig_mod.transformer.h.4.attn.c_q.weight' | fro_norm = 20.46052 | spectral_norm = 5.01489 | nuclear_norm = 428.62643
name = 'module._orig_mod.transformer.h.4.attn.c_k.weight' | fro_norm = 20.29837 | spectral_norm = 4.55929 | nuclear_norm = 430.36279
name = 'module._orig_mod.transformer.h.5.attn.c_q.weight' | fro_norm = 20.36674 | spectral_norm = 5.34095 | nuclear_norm = 429.45804
name = 'module._orig_mod.transformer.h.5.attn.c_k.weight' | fro_norm = 19.89111 | spectral_norm = 4.70041 | nuclear_norm = 425.98337
name = 'module._orig_mod.transformer.h.6.attn.c_q.weight' | fro_norm = 19.64244 | spectral_norm = 6.05472 | nuclear_norm = 417.27521
name = 'module._orig_mod.transformer.h.6.attn.c_k.weight' | fro_norm = 19.24848 | spectral_norm = 5.17013 | nuclear_norm = 415.14639
name = 'module._orig_mod.transformer.h.7.attn.c_q.weight' | fro_norm = 21.01770 | spectral_norm = 5.05994 | nuclear_norm = 433.90808
name = 'module._orig_mod.transformer.h.7.attn.c_k.weight' | fro_norm = 20.07364 | spectral_norm = 4.92386 | nuclear_norm = 427.36496
name = 'module._orig_mod.transformer.h.8.attn.c_q.weight' | fro_norm = 20.85717 | spectral_norm = 5.77182 | nuclear_norm = 430.70917
name = 'module._orig_mod.transformer.h.8.attn.c_k.weight' | fro_norm = 20.08722 | spectral_norm = 5.34462 | nuclear_norm = 426.41806
name = 'module._orig_mod.transformer.h.9.attn.c_q.weight' | fro_norm = 19.97349 | spectral_norm = 6.08311 | nuclear_norm = 419.92773
name = 'module._orig_mod.transformer.h.9.attn.c_k.weight' | fro_norm = 19.49386 | spectral_norm = 5.09767 | nuclear_norm = 418.59680
name = 'module._orig_mod.transformer.h.10.attn.c_q.weight' | fro_norm = 19.41632 | spectral_norm = 5.45857 | nuclear_norm = 414.37170
name = 'module._orig_mod.transformer.h.10.attn.c_k.weight' | fro_norm = 18.95294 | spectral_norm = 4.37469 | nuclear_norm = 415.40643
name = 'module._orig_mod.transformer.h.11.attn.c_q.weight' | fro_norm = 18.96837 | spectral_norm = 5.06797 | nuclear_norm = 411.03369
name = 'module._orig_mod.transformer.h.11.attn.c_k.weight' | fro_norm = 18.59690 | spectral_norm = 4.26808 | nuclear_norm = 409.03192
===========================================
step:126/1875 train_loss:5.2380 train_time:42657ms step_avg:367.73ms
step:127/1875 train_loss:5.3117 train_time:43015ms step_avg:367.65ms
step:128/1875 train_loss:5.1839 train_time:43382ms step_avg:367.65ms
step:129/1875 train_loss:5.4673 train_time:43753ms step_avg:367.67ms
step:130/1875 train_loss:5.2392 train_time:44119ms step_avg:367.66ms
step:131/1875 train_loss:5.2571 train_time:44495ms step_avg:367.73ms
step:132/1875 train_loss:5.2028 train_time:44867ms step_avg:367.76ms
step:133/1875 train_loss:5.2163 train_time:45232ms step_avg:367.74ms
step:134/1875 train_loss:5.1552 train_time:45597ms step_avg:367.72ms
step:135/1875 train_loss:5.2381 train_time:45963ms step_avg:367.70ms
step:136/1875 train_loss:5.0458 train_time:46332ms step_avg:367.71ms
step:137/1875 train_loss:5.1876 train_time:46701ms step_avg:367.72ms
step:138/1875 train_loss:5.1584 train_time:47071ms step_avg:367.74ms
step:139/1875 train_loss:5.1819 train_time:47441ms step_avg:367.76ms
step:140/1875 train_loss:5.2302 train_time:47803ms step_avg:367.72ms
step:141/1875 train_loss:5.1294 train_time:48170ms step_avg:367.71ms
step:142/1875 train_loss:5.1984 train_time:48549ms step_avg:367.79ms
step:143/1875 train_loss:5.0318 train_time:48917ms step_avg:367.80ms
step:144/1875 train_loss:5.1559 train_time:49285ms step_avg:367.80ms
step:145/1875 train_loss:5.0964 train_time:49653ms step_avg:367.80ms
step:146/1875 train_loss:5.0253 train_time:50024ms step_avg:367.83ms
step:147/1875 train_loss:5.1478 train_time:50393ms step_avg:367.83ms
step:148/1875 train_loss:5.1206 train_time:50759ms step_avg:367.82ms
step:149/1875 train_loss:5.1729 train_time:51139ms step_avg:367.91ms
step:150/1875 train_loss:5.1686 train_time:51509ms step_avg:367.92ms
step:151/1875 train_loss:5.0935 train_time:51877ms step_avg:367.92ms
step:152/1875 train_loss:5.0924 train_time:52246ms step_avg:367.93ms
step:153/1875 train_loss:5.1613 train_time:52624ms step_avg:368.00ms
step:154/1875 train_loss:5.0936 train_time:52996ms step_avg:368.03ms
step:155/1875 train_loss:5.0685 train_time:53359ms step_avg:367.99ms
step:156/1875 train_loss:5.0878 train_time:53731ms step_avg:368.02ms
step:157/1875 train_loss:5.2209 train_time:54104ms step_avg:368.05ms
step:158/1875 train_loss:5.0240 train_time:54475ms step_avg:368.07ms
step:159/1875 train_loss:5.0949 train_time:54838ms step_avg:368.04ms
step:160/1875 train_loss:4.9467 train_time:55207ms step_avg:368.05ms
step:161/1875 train_loss:5.0882 train_time:55581ms step_avg:368.08ms
step:162/1875 train_loss:5.1228 train_time:55951ms step_avg:368.10ms
step:163/1875 train_loss:5.1108 train_time:56320ms step_avg:368.11ms
step:164/1875 train_loss:4.9100 train_time:56685ms step_avg:368.09ms
step:165/1875 train_loss:5.0468 train_time:57059ms step_avg:368.12ms
step:166/1875 train_loss:5.1984 train_time:57424ms step_avg:368.10ms
step:167/1875 train_loss:4.9805 train_time:57793ms step_avg:368.11ms
step:168/1875 train_loss:5.0700 train_time:58166ms step_avg:368.14ms
step:169/1875 train_loss:4.9355 train_time:58540ms step_avg:368.18ms
step:170/1875 train_loss:4.8406 train_time:58908ms step_avg:368.18ms
step:171/1875 train_loss:4.9904 train_time:59290ms step_avg:368.26ms
step:172/1875 train_loss:4.9526 train_time:59667ms step_avg:368.32ms
step:173/1875 train_loss:5.0039 train_time:60034ms step_avg:368.31ms
step:174/1875 train_loss:5.1540 train_time:60410ms step_avg:368.36ms
step:175/1875 train_loss:5.0521 train_time:60777ms step_avg:368.35ms
step:176/1875 train_loss:4.8768 train_time:61145ms step_avg:368.34ms
step:177/1875 train_loss:4.8746 train_time:61514ms step_avg:368.35ms
step:178/1875 train_loss:4.9059 train_time:61884ms step_avg:368.36ms
step:179/1875 train_loss:4.9359 train_time:62251ms step_avg:368.35ms
step:180/1875 train_loss:4.9271 train_time:62626ms step_avg:368.39ms
step:181/1875 train_loss:5.0361 train_time:62991ms step_avg:368.37ms
step:182/1875 train_loss:4.9462 train_time:63356ms step_avg:368.35ms
step:183/1875 train_loss:4.8650 train_time:63722ms step_avg:368.34ms
step:184/1875 train_loss:4.8746 train_time:64088ms step_avg:368.32ms
step:185/1875 train_loss:5.0118 train_time:64460ms step_avg:368.34ms
step:186/1875 train_loss:4.8935 train_time:64828ms step_avg:368.34ms
step:187/1875 train_loss:5.1551 train_time:65201ms step_avg:368.37ms
step:188/1875 train_loss:4.9286 train_time:65578ms step_avg:368.41ms
step:189/1875 train_loss:4.8598 train_time:66183ms step_avg:369.74ms
step:190/1875 train_loss:5.0002 train_time:66543ms step_avg:369.68ms
step:191/1875 train_loss:4.8596 train_time:66917ms step_avg:369.71ms
step:192/1875 train_loss:4.7906 train_time:67286ms step_avg:369.70ms
step:193/1875 train_loss:4.9906 train_time:67653ms step_avg:369.69ms
step:194/1875 train_loss:4.9224 train_time:68036ms step_avg:369.76ms
step:195/1875 train_loss:5.1067 train_time:68399ms step_avg:369.72ms
step:196/1875 train_loss:4.9907 train_time:68770ms step_avg:369.73ms
step:197/1875 train_loss:4.8278 train_time:69146ms step_avg:369.77ms
step:198/1875 train_loss:4.8720 train_time:69516ms step_avg:369.76ms
step:199/1875 train_loss:4.7730 train_time:69876ms step_avg:369.72ms
step:200/1875 train_loss:4.8356 train_time:70243ms step_avg:369.70ms
step:201/1875 train_loss:4.7835 train_time:70620ms step_avg:369.74ms
step:202/1875 train_loss:5.0236 train_time:70994ms step_avg:369.76ms
step:203/1875 train_loss:4.9175 train_time:71355ms step_avg:369.71ms
step:204/1875 train_loss:4.8774 train_time:71725ms step_avg:369.72ms
step:205/1875 train_loss:5.0270 train_time:72090ms step_avg:369.69ms
step:206/1875 train_loss:4.7052 train_time:72459ms step_avg:369.69ms
step:207/1875 train_loss:4.8305 train_time:72823ms step_avg:369.66ms
step:208/1875 train_loss:4.8114 train_time:73188ms step_avg:369.64ms
step:209/1875 train_loss:4.9558 train_time:73563ms step_avg:369.66ms
step:210/1875 train_loss:4.9115 train_time:73931ms step_avg:369.65ms
step:211/1875 train_loss:4.7691 train_time:74303ms step_avg:369.67ms
step:212/1875 train_loss:4.9595 train_time:74671ms step_avg:369.66ms
step:213/1875 train_loss:4.7507 train_time:75046ms step_avg:369.68ms
step:214/1875 train_loss:4.8288 train_time:75416ms step_avg:369.69ms
step:215/1875 train_loss:4.6995 train_time:75789ms step_avg:369.70ms
step:216/1875 train_loss:4.8280 train_time:76150ms step_avg:369.66ms
step:217/1875 train_loss:4.7965 train_time:76528ms step_avg:369.70ms
step:218/1875 train_loss:4.7675 train_time:76891ms step_avg:369.67ms
step:219/1875 train_loss:4.7901 train_time:77259ms step_avg:369.66ms
step:220/1875 train_loss:4.8178 train_time:77629ms step_avg:369.66ms
step:221/1875 train_loss:4.8349 train_time:77995ms step_avg:369.64ms
step:222/1875 train_loss:4.7707 train_time:78362ms step_avg:369.63ms
step:223/1875 train_loss:4.8037 train_time:78726ms step_avg:369.60ms
step:224/1875 train_loss:4.9203 train_time:79110ms step_avg:369.67ms
step:225/1875 train_loss:4.6775 train_time:79477ms step_avg:369.66ms
step:226/1875 train_loss:4.6693 train_time:79845ms step_avg:369.65ms
step:227/1875 train_loss:4.6591 train_time:80209ms step_avg:369.63ms
step:228/1875 train_loss:4.8349 train_time:80574ms step_avg:369.61ms
step:229/1875 train_loss:4.6816 train_time:80951ms step_avg:369.64ms
step:230/1875 train_loss:4.7898 train_time:81314ms step_avg:369.61ms
step:231/1875 train_loss:4.6632 train_time:81686ms step_avg:369.62ms
step:232/1875 train_loss:4.6264 train_time:82057ms step_avg:369.63ms
step:233/1875 train_loss:4.8438 train_time:82423ms step_avg:369.61ms
step:234/1875 train_loss:4.6674 train_time:82793ms step_avg:369.61ms
step:235/1875 train_loss:4.6025 train_time:83169ms step_avg:369.64ms
step:236/1875 train_loss:4.8803 train_time:83546ms step_avg:369.67ms
step:237/1875 train_loss:4.7463 train_time:83913ms step_avg:369.66ms
step:238/1875 train_loss:4.6614 train_time:84287ms step_avg:369.68ms
step:239/1875 train_loss:4.8079 train_time:84658ms step_avg:369.69ms
step:240/1875 train_loss:4.7899 train_time:85032ms step_avg:369.70ms
step:241/1875 train_loss:4.6909 train_time:85417ms step_avg:369.77ms
step:242/1875 train_loss:4.8489 train_time:85788ms step_avg:369.78ms
step:243/1875 train_loss:4.6864 train_time:86156ms step_avg:369.77ms
step:244/1875 train_loss:4.7015 train_time:86527ms step_avg:369.77ms
step:245/1875 train_loss:4.7700 train_time:86894ms step_avg:369.76ms
step:246/1875 train_loss:4.7146 train_time:87267ms step_avg:369.77ms
step:247/1875 train_loss:4.6614 train_time:87635ms step_avg:369.77ms
step:248/1875 train_loss:4.8237 train_time:88003ms step_avg:369.76ms
step:249/1875 train_loss:4.5611 train_time:88368ms step_avg:369.74ms
step:250/1875 train_loss:4.6035 train_time:88736ms step_avg:369.73ms
step:250/1875 val_loss:4.6643 train_time:88951ms step_avg:370.63ms
============== Weight norms: ==============
name = 'module._orig_mod.transformer.h.0.attn.c_q.weight' | fro_norm = 24.12574 | spectral_norm = 8.18889 | nuclear_norm = 488.43878
name = 'module._orig_mod.transformer.h.0.attn.c_k.weight' | fro_norm = 23.54042 | spectral_norm = 7.54879 | nuclear_norm = 476.41724
name = 'module._orig_mod.transformer.h.1.attn.c_q.weight' | fro_norm = 24.44168 | spectral_norm = 6.37202 | nuclear_norm = 493.03934
name = 'module._orig_mod.transformer.h.1.attn.c_k.weight' | fro_norm = 22.40705 | spectral_norm = 5.05236 | nuclear_norm = 469.75018
name = 'module._orig_mod.transformer.h.2.attn.c_q.weight' | fro_norm = 24.19668 | spectral_norm = 5.78084 | nuclear_norm = 485.99863
name = 'module._orig_mod.transformer.h.2.attn.c_k.weight' | fro_norm = 23.25428 | spectral_norm = 5.45483 | nuclear_norm = 479.70935
name = 'module._orig_mod.transformer.h.3.attn.c_q.weight' | fro_norm = 24.36153 | spectral_norm = 5.20117 | nuclear_norm = 485.76456
name = 'module._orig_mod.transformer.h.3.attn.c_k.weight' | fro_norm = 23.52458 | spectral_norm = 4.99078 | nuclear_norm = 480.67960
name = 'module._orig_mod.transformer.h.4.attn.c_q.weight' | fro_norm = 23.33429 | spectral_norm = 4.83369 | nuclear_norm = 476.94330
name = 'module._orig_mod.transformer.h.4.attn.c_k.weight' | fro_norm = 22.96785 | spectral_norm = 4.47239 | nuclear_norm = 476.77328
name = 'module._orig_mod.transformer.h.5.attn.c_q.weight' | fro_norm = 23.36416 | spectral_norm = 5.64049 | nuclear_norm = 477.64752
name = 'module._orig_mod.transformer.h.5.attn.c_k.weight' | fro_norm = 22.63717 | spectral_norm = 5.02270 | nuclear_norm = 472.58893
name = 'module._orig_mod.transformer.h.6.attn.c_q.weight' | fro_norm = 22.50372 | spectral_norm = 5.74257 | nuclear_norm = 462.16586
name = 'module._orig_mod.transformer.h.6.attn.c_k.weight' | fro_norm = 21.50655 | spectral_norm = 5.72267 | nuclear_norm = 452.11835
name = 'module._orig_mod.transformer.h.7.attn.c_q.weight' | fro_norm = 23.75950 | spectral_norm = 5.25267 | nuclear_norm = 478.91830
name = 'module._orig_mod.transformer.h.7.attn.c_k.weight' | fro_norm = 22.51601 | spectral_norm = 5.17628 | nuclear_norm = 469.51099
name = 'module._orig_mod.transformer.h.8.attn.c_q.weight' | fro_norm = 23.71085 | spectral_norm = 5.47823 | nuclear_norm = 476.14459
name = 'module._orig_mod.transformer.h.8.attn.c_k.weight' | fro_norm = 22.66918 | spectral_norm = 5.65802 | nuclear_norm = 468.32327
name = 'module._orig_mod.transformer.h.9.attn.c_q.weight' | fro_norm = 23.11533 | spectral_norm = 5.53595 | nuclear_norm = 468.31516
name = 'module._orig_mod.transformer.h.9.attn.c_k.weight' | fro_norm = 22.17904 | spectral_norm = 5.29482 | nuclear_norm = 461.77167
name = 'module._orig_mod.transformer.h.10.attn.c_q.weight' | fro_norm = 22.42573 | spectral_norm = 5.33489 | nuclear_norm = 460.64850
name = 'module._orig_mod.transformer.h.10.attn.c_k.weight' | fro_norm = 21.48092 | spectral_norm = 4.55377 | nuclear_norm = 455.20990
name = 'module._orig_mod.transformer.h.11.attn.c_q.weight' | fro_norm = 21.84118 | spectral_norm = 5.70791 | nuclear_norm = 451.59821
name = 'module._orig_mod.transformer.h.11.attn.c_k.weight' | fro_norm = 20.86492 | spectral_norm = 4.80968 | nuclear_norm = 443.68933
===========================================
step:251/1875 train_loss:4.7275 train_time:89105ms step_avg:369.73ms
step:252/1875 train_loss:4.7437 train_time:89462ms step_avg:369.68ms
step:253/1875 train_loss:4.6090 train_time:89832ms step_avg:369.68ms
step:254/1875 train_loss:4.5924 train_time:90201ms step_avg:369.68ms
step:255/1875 train_loss:4.7313 train_time:90569ms step_avg:369.67ms
step:256/1875 train_loss:4.6901 train_time:90929ms step_avg:369.63ms
step:257/1875 train_loss:4.6400 train_time:91295ms step_avg:369.61ms
step:258/1875 train_loss:4.5887 train_time:91667ms step_avg:369.62ms
step:259/1875 train_loss:4.6079 train_time:92035ms step_avg:369.62ms
step:260/1875 train_loss:4.6755 train_time:92406ms step_avg:369.62ms
step:261/1875 train_loss:4.6781 train_time:92790ms step_avg:369.68ms
step:262/1875 train_loss:4.5975 train_time:93162ms step_avg:369.69ms
step:263/1875 train_loss:4.5331 train_time:93537ms step_avg:369.71ms
step:264/1875 train_loss:4.5865 train_time:93906ms step_avg:369.71ms
step:265/1875 train_loss:4.4434 train_time:94275ms step_avg:369.70ms
step:266/1875 train_loss:4.5122 train_time:94643ms step_avg:369.70ms
step:267/1875 train_loss:4.5249 train_time:95014ms step_avg:369.70ms
step:268/1875 train_loss:4.5029 train_time:95395ms step_avg:369.75ms
step:269/1875 train_loss:4.4431 train_time:95766ms step_avg:369.75ms
step:270/1875 train_loss:4.6575 train_time:96137ms step_avg:369.76ms
step:271/1875 train_loss:4.5909 train_time:96505ms step_avg:369.75ms
step:272/1875 train_loss:4.4646 train_time:96877ms step_avg:369.76ms
step:273/1875 train_loss:4.5060 train_time:97242ms step_avg:369.74ms
step:274/1875 train_loss:4.6148 train_time:97616ms step_avg:369.76ms
step:275/1875 train_loss:4.6182 train_time:97982ms step_avg:369.74ms
step:276/1875 train_loss:4.7998 train_time:98357ms step_avg:369.76ms
step:277/1875 train_loss:4.5672 train_time:98722ms step_avg:369.74ms
step:278/1875 train_loss:4.6828 train_time:99092ms step_avg:369.75ms
step:279/1875 train_loss:4.5415 train_time:99456ms step_avg:369.72ms
step:280/1875 train_loss:4.5935 train_time:99830ms step_avg:369.74ms
step:281/1875 train_loss:4.5132 train_time:100216ms step_avg:369.80ms
step:282/1875 train_loss:4.5457 train_time:100589ms step_avg:369.81ms
step:283/1875 train_loss:4.4528 train_time:100964ms step_avg:369.83ms
step:284/1875 train_loss:4.6038 train_time:101333ms step_avg:369.83ms
step:285/1875 train_loss:4.5723 train_time:101702ms step_avg:369.82ms
step:286/1875 train_loss:4.6076 train_time:102072ms step_avg:369.82ms
step:287/1875 train_loss:4.4518 train_time:102442ms step_avg:369.83ms
step:288/1875 train_loss:4.5449 train_time:102818ms step_avg:369.85ms
step:289/1875 train_loss:4.3934 train_time:103183ms step_avg:369.83ms
step:290/1875 train_loss:4.3878 train_time:103554ms step_avg:369.84ms
step:291/1875 train_loss:4.4695 train_time:103924ms step_avg:369.84ms
step:292/1875 train_loss:4.3860 train_time:104294ms step_avg:369.84ms
step:293/1875 train_loss:4.4160 train_time:104657ms step_avg:369.81ms
step:294/1875 train_loss:4.4568 train_time:105021ms step_avg:369.79ms
step:295/1875 train_loss:4.3459 train_time:105386ms step_avg:369.78ms
step:296/1875 train_loss:4.3384 train_time:105763ms step_avg:369.80ms
step:297/1875 train_loss:4.3510 train_time:106131ms step_avg:369.80ms
step:298/1875 train_loss:4.4412 train_time:106500ms step_avg:369.79ms
step:299/1875 train_loss:4.3329 train_time:106870ms step_avg:369.79ms
step:300/1875 train_loss:4.4640 train_time:107243ms step_avg:369.81ms
step:301/1875 train_loss:4.4694 train_time:107610ms step_avg:369.79ms
step:302/1875 train_loss:4.3971 train_time:107972ms step_avg:369.77ms
step:303/1875 train_loss:4.4669 train_time:108337ms step_avg:369.75ms
step:304/1875 train_loss:4.4319 train_time:108702ms step_avg:369.74ms
step:305/1875 train_loss:4.8854 train_time:109067ms step_avg:369.72ms
step:306/1875 train_loss:4.4116 train_time:109434ms step_avg:369.71ms
step:307/1875 train_loss:4.2968 train_time:109804ms step_avg:369.71ms
step:308/1875 train_loss:4.4697 train_time:110178ms step_avg:369.73ms
step:309/1875 train_loss:4.2955 train_time:110542ms step_avg:369.71ms
step:310/1875 train_loss:4.5300 train_time:110908ms step_avg:369.69ms
step:311/1875 train_loss:4.3860 train_time:111282ms step_avg:369.71ms
step:312/1875 train_loss:4.3324 train_time:111651ms step_avg:369.70ms
step:313/1875 train_loss:4.4121 train_time:112024ms step_avg:369.72ms
step:314/1875 train_loss:4.5411 train_time:112399ms step_avg:369.73ms
step:315/1875 train_loss:4.4008 train_time:112763ms step_avg:369.72ms
step:316/1875 train_loss:4.2535 train_time:113134ms step_avg:369.72ms
step:317/1875 train_loss:4.3278 train_time:113509ms step_avg:369.74ms
step:318/1875 train_loss:4.3656 train_time:113879ms step_avg:369.74ms
step:319/1875 train_loss:4.3217 train_time:114248ms step_avg:369.73ms
step:320/1875 train_loss:4.4151 train_time:114615ms step_avg:369.72ms
step:321/1875 train_loss:4.3952 train_time:114985ms step_avg:369.73ms
step:322/1875 train_loss:4.3454 train_time:115356ms step_avg:369.73ms
step:323/1875 train_loss:4.4159 train_time:115723ms step_avg:369.72ms
step:324/1875 train_loss:4.3906 train_time:116091ms step_avg:369.72ms
step:325/1875 train_loss:4.4723 train_time:116463ms step_avg:369.72ms
step:326/1875 train_loss:4.3267 train_time:116834ms step_avg:369.73ms
step:327/1875 train_loss:4.7942 train_time:117203ms step_avg:369.72ms
step:328/1875 train_loss:4.4909 train_time:117591ms step_avg:369.78ms
step:329/1875 train_loss:4.2482 train_time:117975ms step_avg:369.83ms
step:330/1875 train_loss:4.1797 train_time:118346ms step_avg:369.83ms
step:331/1875 train_loss:4.3888 train_time:118714ms step_avg:369.82ms
step:332/1875 train_loss:4.3084 train_time:119083ms step_avg:369.82ms
step:333/1875 train_loss:4.3030 train_time:119449ms step_avg:369.81ms
step:334/1875 train_loss:4.2651 train_time:119817ms step_avg:369.81ms
step:335/1875 train_loss:4.4258 train_time:120185ms step_avg:369.80ms
step:336/1875 train_loss:4.3697 train_time:120550ms step_avg:369.79ms
step:337/1875 train_loss:4.7994 train_time:120921ms step_avg:369.79ms
step:338/1875 train_loss:4.3651 train_time:121294ms step_avg:369.80ms
step:339/1875 train_loss:4.2932 train_time:121663ms step_avg:369.80ms
step:340/1875 train_loss:4.3433 train_time:122038ms step_avg:369.81ms
step:341/1875 train_loss:4.2675 train_time:122408ms step_avg:369.81ms
step:342/1875 train_loss:4.2232 train_time:122777ms step_avg:369.81ms
step:343/1875 train_loss:4.2752 train_time:123142ms step_avg:369.80ms
step:344/1875 train_loss:4.4173 train_time:123510ms step_avg:369.79ms
step:345/1875 train_loss:4.2583 train_time:123884ms step_avg:369.80ms
step:346/1875 train_loss:4.1822 train_time:124259ms step_avg:369.82ms
step:347/1875 train_loss:4.2135 train_time:124629ms step_avg:369.82ms
step:348/1875 train_loss:4.2666 train_time:125000ms step_avg:369.82ms
step:349/1875 train_loss:4.2327 train_time:125369ms step_avg:369.82ms
step:350/1875 train_loss:3.9413 train_time:125740ms step_avg:369.82ms
step:351/1875 train_loss:4.2134 train_time:126111ms step_avg:369.83ms
step:352/1875 train_loss:4.5838 train_time:126482ms step_avg:369.83ms
step:353/1875 train_loss:4.0552 train_time:126851ms step_avg:369.83ms
step:354/1875 train_loss:4.3280 train_time:127215ms step_avg:369.81ms
step:355/1875 train_loss:4.1867 train_time:127588ms step_avg:369.82ms
step:356/1875 train_loss:4.2868 train_time:127955ms step_avg:369.81ms
step:357/1875 train_loss:4.2274 train_time:128328ms step_avg:369.82ms
step:358/1875 train_loss:4.2373 train_time:128700ms step_avg:369.83ms
step:359/1875 train_loss:4.1873 train_time:129080ms step_avg:369.86ms
step:360/1875 train_loss:3.8639 train_time:129460ms step_avg:369.89ms
step:361/1875 train_loss:4.4042 train_time:129839ms step_avg:369.91ms
step:362/1875 train_loss:4.2969 train_time:130213ms step_avg:369.92ms
step:363/1875 train_loss:4.2254 train_time:130577ms step_avg:369.91ms
step:364/1875 train_loss:4.1454 train_time:130941ms step_avg:369.89ms
step:365/1875 train_loss:4.2920 train_time:131318ms step_avg:369.91ms
step:366/1875 train_loss:4.2571 train_time:131693ms step_avg:369.92ms
step:367/1875 train_loss:4.2287 train_time:132063ms step_avg:369.92ms
step:368/1875 train_loss:4.2315 train_time:132432ms step_avg:369.92ms
step:369/1875 train_loss:4.1164 train_time:132799ms step_avg:369.91ms
step:370/1875 train_loss:4.2964 train_time:133163ms step_avg:369.90ms
step:371/1875 train_loss:4.1487 train_time:133531ms step_avg:369.89ms
step:372/1875 train_loss:4.0707 train_time:133901ms step_avg:369.89ms
step:373/1875 train_loss:4.2949 train_time:134266ms step_avg:369.88ms
step:374/1875 train_loss:4.2183 train_time:134632ms step_avg:369.87ms
step:375/1875 train_loss:4.1824 train_time:135002ms step_avg:369.87ms
step:375/1875 val_loss:4.2043 train_time:135222ms step_avg:370.47ms
============== Weight norms: ==============
name = 'module._orig_mod.transformer.h.0.attn.c_q.weight' | fro_norm = 26.90992 | spectral_norm = 10.05929 | nuclear_norm = 534.82458
name = 'module._orig_mod.transformer.h.0.attn.c_k.weight' | fro_norm = 25.89169 | spectral_norm = 8.78481 | nuclear_norm = 514.57019
name = 'module._orig_mod.transformer.h.1.attn.c_q.weight' | fro_norm = 26.70246 | spectral_norm = 6.76706 | nuclear_norm = 534.19751
name = 'module._orig_mod.transformer.h.1.attn.c_k.weight' | fro_norm = 24.41316 | spectral_norm = 5.58983 | nuclear_norm = 505.30170
name = 'module._orig_mod.transformer.h.2.attn.c_q.weight' | fro_norm = 26.50684 | spectral_norm = 6.46596 | nuclear_norm = 527.92914
name = 'module._orig_mod.transformer.h.2.attn.c_k.weight' | fro_norm = 25.47404 | spectral_norm = 5.97761 | nuclear_norm = 519.78546
name = 'module._orig_mod.transformer.h.3.attn.c_q.weight' | fro_norm = 26.67309 | spectral_norm = 5.27288 | nuclear_norm = 517.39990
name = 'module._orig_mod.transformer.h.3.attn.c_k.weight' | fro_norm = 25.90788 | spectral_norm = 4.95158 | nuclear_norm = 521.91016
name = 'module._orig_mod.transformer.h.4.attn.c_q.weight' | fro_norm = 25.73448 | spectral_norm = 4.97155 | nuclear_norm = 519.30670
name = 'module._orig_mod.transformer.h.4.attn.c_k.weight' | fro_norm = 25.29816 | spectral_norm = 4.72909 | nuclear_norm = 521.30573
name = 'module._orig_mod.transformer.h.5.attn.c_q.weight' | fro_norm = 25.78528 | spectral_norm = 5.54636 | nuclear_norm = 519.82349
name = 'module._orig_mod.transformer.h.5.attn.c_k.weight' | fro_norm = 24.91242 | spectral_norm = 5.21326 | nuclear_norm = 513.97186
name = 'module._orig_mod.transformer.h.6.attn.c_q.weight' | fro_norm = 24.88894 | spectral_norm = 5.62456 | nuclear_norm = 501.85724
name = 'module._orig_mod.transformer.h.6.attn.c_k.weight' | fro_norm = 23.51440 | spectral_norm = 5.98130 | nuclear_norm = 486.83786
name = 'module._orig_mod.transformer.h.7.attn.c_q.weight' | fro_norm = 26.01109 | spectral_norm = 5.37256 | nuclear_norm = 519.86768
name = 'module._orig_mod.transformer.h.7.attn.c_k.weight' | fro_norm = 24.67102 | spectral_norm = 5.16502 | nuclear_norm = 510.29401
name = 'module._orig_mod.transformer.h.8.attn.c_q.weight' | fro_norm = 25.98997 | spectral_norm = 5.60635 | nuclear_norm = 516.69330
name = 'module._orig_mod.transformer.h.8.attn.c_k.weight' | fro_norm = 24.78894 | spectral_norm = 5.89064 | nuclear_norm = 505.59055
name = 'module._orig_mod.transformer.h.9.attn.c_q.weight' | fro_norm = 25.43093 | spectral_norm = 5.81807 | nuclear_norm = 507.32407
name = 'module._orig_mod.transformer.h.9.attn.c_k.weight' | fro_norm = 24.38365 | spectral_norm = 5.31746 | nuclear_norm = 501.15695
name = 'module._orig_mod.transformer.h.10.attn.c_q.weight' | fro_norm = 25.05112 | spectral_norm = 5.60507 | nuclear_norm = 505.62247
name = 'module._orig_mod.transformer.h.10.attn.c_k.weight' | fro_norm = 23.92414 | spectral_norm = 4.72556 | nuclear_norm = 497.89154
name = 'module._orig_mod.transformer.h.11.attn.c_q.weight' | fro_norm = 24.21282 | spectral_norm = 6.21484 | nuclear_norm = 489.31168
name = 'module._orig_mod.transformer.h.11.attn.c_k.weight' | fro_norm = 22.89915 | spectral_norm = 5.28891 | nuclear_norm = 477.45422
===========================================
step:376/1875 train_loss:4.2474 train_time:135375ms step_avg:369.88ms
step:377/1875 train_loss:4.1489 train_time:135732ms step_avg:369.84ms
step:378/1875 train_loss:4.2173 train_time:136201ms step_avg:370.11ms
step:379/1875 train_loss:4.2774 train_time:136693ms step_avg:370.44ms
step:380/1875 train_loss:4.3004 train_time:137055ms step_avg:370.42ms
step:381/1875 train_loss:4.2231 train_time:137418ms step_avg:370.40ms
step:382/1875 train_loss:4.1808 train_time:137797ms step_avg:370.42ms
step:383/1875 train_loss:4.1475 train_time:138171ms step_avg:370.43ms
step:384/1875 train_loss:4.2472 train_time:138537ms step_avg:370.42ms
step:385/1875 train_loss:4.1432 train_time:138914ms step_avg:370.44ms
step:386/1875 train_loss:4.2682 train_time:139274ms step_avg:370.41ms
step:387/1875 train_loss:4.4348 train_time:139643ms step_avg:370.41ms
step:388/1875 train_loss:4.1767 train_time:140017ms step_avg:370.42ms
step:389/1875 train_loss:4.1519 train_time:140391ms step_avg:370.42ms
step:390/1875 train_loss:4.2453 train_time:140762ms step_avg:370.43ms
step:391/1875 train_loss:4.1829 train_time:141135ms step_avg:370.43ms
step:392/1875 train_loss:4.2756 train_time:141500ms step_avg:370.42ms
step:393/1875 train_loss:4.1095 train_time:141865ms step_avg:370.41ms
step:394/1875 train_loss:4.2443 train_time:142233ms step_avg:370.40ms
step:395/1875 train_loss:3.9672 train_time:142605ms step_avg:370.40ms
step:396/1875 train_loss:4.1885 train_time:142977ms step_avg:370.41ms
step:397/1875 train_loss:4.2525 train_time:143355ms step_avg:370.43ms
step:398/1875 train_loss:4.2303 train_time:143720ms step_avg:370.41ms
step:399/1875 train_loss:4.1462 train_time:144084ms step_avg:370.40ms
step:400/1875 train_loss:4.1714 train_time:144453ms step_avg:370.39ms
step:401/1875 train_loss:4.2484 train_time:144824ms step_avg:370.40ms
step:402/1875 train_loss:4.2142 train_time:145204ms step_avg:370.42ms
step:403/1875 train_loss:4.3087 train_time:145570ms step_avg:370.41ms
step:404/1875 train_loss:4.0530 train_time:145941ms step_avg:370.41ms
step:405/1875 train_loss:4.1369 train_time:146310ms step_avg:370.41ms
step:406/1875 train_loss:4.4209 train_time:146677ms step_avg:370.40ms
step:407/1875 train_loss:4.1545 train_time:147046ms step_avg:370.39ms
step:408/1875 train_loss:4.1918 train_time:147413ms step_avg:370.38ms
step:409/1875 train_loss:4.2316 train_time:147783ms step_avg:370.38ms
step:410/1875 train_loss:4.1069 train_time:148148ms step_avg:370.37ms
step:411/1875 train_loss:4.1269 train_time:148516ms step_avg:370.36ms
step:412/1875 train_loss:4.5254 train_time:148883ms step_avg:370.36ms
step:413/1875 train_loss:3.9950 train_time:149250ms step_avg:370.35ms
step:414/1875 train_loss:4.3547 train_time:149619ms step_avg:370.34ms
step:415/1875 train_loss:4.1107 train_time:149981ms step_avg:370.32ms
step:416/1875 train_loss:4.1121 train_time:150348ms step_avg:370.32ms
step:417/1875 train_loss:4.3135 train_time:150725ms step_avg:370.33ms
step:418/1875 train_loss:4.0348 train_time:151090ms step_avg:370.32ms
step:419/1875 train_loss:4.1396 train_time:151454ms step_avg:370.30ms
step:420/1875 train_loss:4.0701 train_time:151829ms step_avg:370.31ms
step:421/1875 train_loss:3.9877 train_time:152201ms step_avg:370.32ms
step:422/1875 train_loss:4.1218 train_time:152563ms step_avg:370.30ms
step:423/1875 train_loss:4.2221 train_time:152935ms step_avg:370.30ms
step:424/1875 train_loss:3.9633 train_time:153303ms step_avg:370.30ms
step:425/1875 train_loss:4.1475 train_time:153676ms step_avg:370.30ms
step:426/1875 train_loss:4.0246 train_time:154045ms step_avg:370.30ms
step:427/1875 train_loss:4.2240 train_time:154410ms step_avg:370.29ms
step:428/1875 train_loss:4.1668 train_time:154784ms step_avg:370.30ms
step:429/1875 train_loss:4.0936 train_time:155153ms step_avg:370.29ms
step:430/1875 train_loss:4.0552 train_time:155518ms step_avg:370.28ms
step:431/1875 train_loss:3.9791 train_time:155886ms step_avg:370.28ms
step:432/1875 train_loss:4.1134 train_time:156257ms step_avg:370.28ms
step:433/1875 train_loss:4.1740 train_time:156625ms step_avg:370.27ms
step:434/1875 train_loss:4.1071 train_time:156994ms step_avg:370.27ms
step:435/1875 train_loss:4.1529 train_time:157365ms step_avg:370.27ms
step:436/1875 train_loss:4.1603 train_time:157734ms step_avg:370.27ms
step:437/1875 train_loss:4.0369 train_time:158103ms step_avg:370.26ms
step:438/1875 train_loss:4.0515 train_time:158469ms step_avg:370.25ms
step:439/1875 train_loss:4.0338 train_time:158839ms step_avg:370.25ms
step:440/1875 train_loss:4.2116 train_time:159208ms step_avg:370.25ms
step:441/1875 train_loss:4.0956 train_time:159584ms step_avg:370.26ms
step:442/1875 train_loss:4.0768 train_time:159947ms step_avg:370.25ms
step:443/1875 train_loss:3.9654 train_time:160313ms step_avg:370.24ms
step:444/1875 train_loss:4.2386 train_time:160678ms step_avg:370.23ms
step:445/1875 train_loss:4.1761 train_time:161052ms step_avg:370.23ms
step:446/1875 train_loss:4.1704 train_time:161419ms step_avg:370.23ms
step:447/1875 train_loss:4.0770 train_time:161788ms step_avg:370.22ms
step:448/1875 train_loss:4.1753 train_time:162161ms step_avg:370.23ms
step:449/1875 train_loss:4.0029 train_time:162537ms step_avg:370.24ms
step:450/1875 train_loss:4.0492 train_time:162906ms step_avg:370.24ms
step:451/1875 train_loss:3.9028 train_time:163280ms step_avg:370.25ms
step:452/1875 train_loss:4.0496 train_time:163646ms step_avg:370.24ms
step:453/1875 train_loss:4.0154 train_time:164014ms step_avg:370.23ms
step:454/1875 train_loss:3.9786 train_time:164383ms step_avg:370.23ms
step:455/1875 train_loss:4.1975 train_time:164757ms step_avg:370.24ms
step:456/1875 train_loss:4.0552 train_time:165125ms step_avg:370.24ms
step:457/1875 train_loss:4.1116 train_time:165490ms step_avg:370.22ms
step:458/1875 train_loss:4.1662 train_time:165856ms step_avg:370.21ms
step:459/1875 train_loss:3.9575 train_time:166235ms step_avg:370.23ms
step:460/1875 train_loss:4.1408 train_time:166603ms step_avg:370.23ms
step:461/1875 train_loss:4.0177 train_time:166977ms step_avg:370.24ms
step:462/1875 train_loss:4.0509 train_time:167351ms step_avg:370.25ms
step:463/1875 train_loss:4.1125 train_time:167719ms step_avg:370.24ms
step:464/1875 train_loss:4.0484 train_time:168088ms step_avg:370.24ms
step:465/1875 train_loss:4.0541 train_time:168457ms step_avg:370.23ms
step:466/1875 train_loss:4.1363 train_time:168831ms step_avg:370.24ms
step:467/1875 train_loss:4.1401 train_time:169202ms step_avg:370.24ms
step:468/1875 train_loss:4.1139 train_time:169574ms step_avg:370.25ms
step:469/1875 train_loss:4.0149 train_time:169939ms step_avg:370.24ms
step:470/1875 train_loss:4.0764 train_time:170305ms step_avg:370.23ms
step:471/1875 train_loss:4.1359 train_time:170673ms step_avg:370.22ms
step:472/1875 train_loss:4.0988 train_time:171054ms step_avg:370.25ms
step:473/1875 train_loss:4.0461 train_time:171417ms step_avg:370.23ms
step:474/1875 train_loss:3.9278 train_time:171784ms step_avg:370.22ms
step:475/1875 train_loss:4.3308 train_time:172149ms step_avg:370.21ms
step:476/1875 train_loss:4.0931 train_time:172521ms step_avg:370.22ms
step:477/1875 train_loss:3.9053 train_time:172896ms step_avg:370.23ms
step:478/1875 train_loss:4.1302 train_time:173264ms step_avg:370.22ms
step:479/1875 train_loss:4.0997 train_time:173642ms step_avg:370.24ms
step:480/1875 train_loss:4.2378 train_time:174012ms step_avg:370.24ms
step:481/1875 train_loss:4.0497 train_time:174381ms step_avg:370.24ms
step:482/1875 train_loss:3.8567 train_time:174750ms step_avg:370.23ms
step:483/1875 train_loss:4.1246 train_time:175113ms step_avg:370.22ms
step:484/1875 train_loss:3.9750 train_time:175489ms step_avg:370.23ms
step:485/1875 train_loss:3.9810 train_time:175860ms step_avg:370.23ms
step:486/1875 train_loss:3.8982 train_time:176228ms step_avg:370.23ms
step:487/1875 train_loss:3.9862 train_time:176600ms step_avg:370.23ms
step:488/1875 train_loss:4.1823 train_time:176968ms step_avg:370.23ms
step:489/1875 train_loss:4.0325 train_time:177341ms step_avg:370.23ms
step:490/1875 train_loss:3.9172 train_time:177708ms step_avg:370.23ms
step:491/1875 train_loss:3.9410 train_time:178072ms step_avg:370.21ms
step:492/1875 train_loss:4.0420 train_time:178438ms step_avg:370.20ms
step:493/1875 train_loss:3.8964 train_time:178819ms step_avg:370.22ms
step:494/1875 train_loss:4.0340 train_time:179189ms step_avg:370.22ms
step:495/1875 train_loss:3.9589 train_time:179561ms step_avg:370.23ms
step:496/1875 train_loss:3.8249 train_time:179934ms step_avg:370.24ms
step:497/1875 train_loss:4.0434 train_time:180304ms step_avg:370.23ms
step:498/1875 train_loss:4.1065 train_time:180671ms step_avg:370.23ms
step:499/1875 train_loss:4.1366 train_time:181040ms step_avg:370.23ms
step:500/1875 train_loss:4.0482 train_time:181414ms step_avg:370.23ms
step:500/1875 val_loss:4.0230 train_time:181638ms step_avg:370.69ms
============== Weight norms: ==============
name = 'module._orig_mod.transformer.h.0.attn.c_q.weight' | fro_norm = 29.56516 | spectral_norm = 11.28984 | nuclear_norm = 581.42346
name = 'module._orig_mod.transformer.h.0.attn.c_k.weight' | fro_norm = 28.21659 | spectral_norm = 10.01729 | nuclear_norm = 552.48853
name = 'module._orig_mod.transformer.h.1.attn.c_q.weight' | fro_norm = 28.85194 | spectral_norm = 7.25305 | nuclear_norm = 573.26575
name = 'module._orig_mod.transformer.h.1.attn.c_k.weight' | fro_norm = 26.39355 | spectral_norm = 6.10927 | nuclear_norm = 540.63342
name = 'module._orig_mod.transformer.h.2.attn.c_q.weight' | fro_norm = 28.75108 | spectral_norm = 7.01515 | nuclear_norm = 568.85321
name = 'module._orig_mod.transformer.h.2.attn.c_k.weight' | fro_norm = 27.61928 | spectral_norm = 6.61194 | nuclear_norm = 558.42407
name = 'module._orig_mod.transformer.h.3.attn.c_q.weight' | fro_norm = 28.83400 | spectral_norm = 5.52679 | nuclear_norm = 554.58350
name = 'module._orig_mod.transformer.h.3.attn.c_k.weight' | fro_norm = 27.97512 | spectral_norm = 5.13746 | nuclear_norm = 560.72571
name = 'module._orig_mod.transformer.h.4.attn.c_q.weight' | fro_norm = 28.17685 | spectral_norm = 5.22554 | nuclear_norm = 562.32440
name = 'module._orig_mod.transformer.h.4.attn.c_k.weight' | fro_norm = 27.56578 | spectral_norm = 4.97972 | nuclear_norm = 563.96326
name = 'module._orig_mod.transformer.h.5.attn.c_q.weight' | fro_norm = 28.25928 | spectral_norm = 5.61716 | nuclear_norm = 564.90240
name = 'module._orig_mod.transformer.h.5.attn.c_k.weight' | fro_norm = 27.26344 | spectral_norm = 5.43501 | nuclear_norm = 557.64893
name = 'module._orig_mod.transformer.h.6.attn.c_q.weight' | fro_norm = 27.29547 | spectral_norm = 5.76991 | nuclear_norm = 542.70081
name = 'module._orig_mod.transformer.h.6.attn.c_k.weight' | fro_norm = 25.60505 | spectral_norm = 6.26975 | nuclear_norm = 523.41583
name = 'module._orig_mod.transformer.h.7.attn.c_q.weight' | fro_norm = 28.31331 | spectral_norm = 5.47367 | nuclear_norm = 563.36041
name = 'module._orig_mod.transformer.h.7.attn.c_k.weight' | fro_norm = 26.90843 | spectral_norm = 5.27689 | nuclear_norm = 553.68298
name = 'module._orig_mod.transformer.h.8.attn.c_q.weight' | fro_norm = 28.29950 | spectral_norm = 5.77740 | nuclear_norm = 560.32703
name = 'module._orig_mod.transformer.h.8.attn.c_k.weight' | fro_norm = 26.97450 | spectral_norm = 5.96490 | nuclear_norm = 546.82971
name = 'module._orig_mod.transformer.h.9.attn.c_q.weight' | fro_norm = 27.61326 | spectral_norm = 6.33659 | nuclear_norm = 545.49231
name = 'module._orig_mod.transformer.h.9.attn.c_k.weight' | fro_norm = 26.51405 | spectral_norm = 5.46430 | nuclear_norm = 540.74243
name = 'module._orig_mod.transformer.h.10.attn.c_q.weight' | fro_norm = 27.34120 | spectral_norm = 6.02757 | nuclear_norm = 547.55457
name = 'module._orig_mod.transformer.h.10.attn.c_k.weight' | fro_norm = 26.08629 | spectral_norm = 4.92320 | nuclear_norm = 538.89307
name = 'module._orig_mod.transformer.h.11.attn.c_q.weight' | fro_norm = 26.26343 | spectral_norm = 6.66869 | nuclear_norm = 524.78809
name = 'module._orig_mod.transformer.h.11.attn.c_k.weight' | fro_norm = 24.75063 | spectral_norm = 5.52758 | nuclear_norm = 509.75473
===========================================
step:501/1875 train_loss:4.1147 train_time:181788ms step_avg:370.24ms
step:502/1875 train_loss:4.0609 train_time:182142ms step_avg:370.21ms
step:503/1875 train_loss:4.0903 train_time:182516ms step_avg:370.21ms
step:504/1875 train_loss:4.0591 train_time:182877ms step_avg:370.20ms
step:505/1875 train_loss:4.1166 train_time:183247ms step_avg:370.20ms
step:506/1875 train_loss:3.9397 train_time:183615ms step_avg:370.19ms
step:507/1875 train_loss:4.0715 train_time:183980ms step_avg:370.18ms
step:508/1875 train_loss:4.1405 train_time:184355ms step_avg:370.19ms
step:509/1875 train_loss:4.1038 train_time:184727ms step_avg:370.19ms
step:510/1875 train_loss:3.8904 train_time:185091ms step_avg:370.18ms
step:511/1875 train_loss:4.0968 train_time:185456ms step_avg:370.17ms
step:512/1875 train_loss:4.0416 train_time:185847ms step_avg:370.21ms
step:513/1875 train_loss:3.9793 train_time:186218ms step_avg:370.21ms
step:514/1875 train_loss:4.0810 train_time:186592ms step_avg:370.22ms
step:515/1875 train_loss:4.0477 train_time:186962ms step_avg:370.22ms
step:516/1875 train_loss:4.3492 train_time:187333ms step_avg:370.22ms
step:517/1875 train_loss:3.9775 train_time:187708ms step_avg:370.23ms
step:518/1875 train_loss:4.0860 train_time:188073ms step_avg:370.22ms
step:519/1875 train_loss:3.9823 train_time:188440ms step_avg:370.22ms
step:520/1875 train_loss:3.9836 train_time:188814ms step_avg:370.22ms
step:521/1875 train_loss:3.9533 train_time:189184ms step_avg:370.22ms
step:522/1875 train_loss:3.9556 train_time:189560ms step_avg:370.23ms
step:523/1875 train_loss:4.5340 train_time:189927ms step_avg:370.23ms
step:524/1875 train_loss:4.0574 train_time:190298ms step_avg:370.23ms
step:525/1875 train_loss:4.0004 train_time:190661ms step_avg:370.21ms
step:526/1875 train_loss:4.0074 train_time:191034ms step_avg:370.22ms
step:527/1875 train_loss:3.9640 train_time:191402ms step_avg:370.22ms
step:528/1875 train_loss:3.9381 train_time:191771ms step_avg:370.21ms
step:529/1875 train_loss:4.1436 train_time:192141ms step_avg:370.21ms
step:530/1875 train_loss:3.9344 train_time:192512ms step_avg:370.22ms
step:531/1875 train_loss:4.2199 train_time:192892ms step_avg:370.23ms
step:532/1875 train_loss:4.0427 train_time:193259ms step_avg:370.23ms
step:533/1875 train_loss:3.9618 train_time:193624ms step_avg:370.22ms
step:534/1875 train_loss:3.9755 train_time:193989ms step_avg:370.21ms
step:535/1875 train_loss:3.9022 train_time:194355ms step_avg:370.20ms
step:536/1875 train_loss:4.0418 train_time:194738ms step_avg:370.22ms
step:537/1875 train_loss:4.0252 train_time:195106ms step_avg:370.22ms
step:538/1875 train_loss:3.9414 train_time:195489ms step_avg:370.24ms
step:539/1875 train_loss:4.3749 train_time:195867ms step_avg:370.26ms
step:540/1875 train_loss:3.9706 train_time:196243ms step_avg:370.27ms
step:541/1875 train_loss:4.0870 train_time:196608ms step_avg:370.26ms
step:542/1875 train_loss:3.9170 train_time:196977ms step_avg:370.26ms
step:543/1875 train_loss:3.9028 train_time:197352ms step_avg:370.27ms
step:544/1875 train_loss:3.9441 train_time:197718ms step_avg:370.26ms
step:545/1875 train_loss:3.9005 train_time:198086ms step_avg:370.25ms
step:546/1875 train_loss:3.9312 train_time:198460ms step_avg:370.26ms
step:547/1875 train_loss:3.9647 train_time:198829ms step_avg:370.26ms
step:548/1875 train_loss:3.9113 train_time:199198ms step_avg:370.26ms
step:549/1875 train_loss:4.0344 train_time:199571ms step_avg:370.26ms
step:550/1875 train_loss:3.8992 train_time:199950ms step_avg:370.28ms
step:551/1875 train_loss:3.9217 train_time:200315ms step_avg:370.27ms
step:552/1875 train_loss:4.2320 train_time:200681ms step_avg:370.26ms
step:553/1875 train_loss:4.0377 train_time:201053ms step_avg:370.26ms
step:554/1875 train_loss:4.0138 train_time:201420ms step_avg:370.26ms
step:555/1875 train_loss:3.9530 train_time:201788ms step_avg:370.25ms
step:556/1875 train_loss:3.9924 train_time:202152ms step_avg:370.24ms
step:557/1875 train_loss:3.6161 train_time:202521ms step_avg:370.24ms
step:558/1875 train_loss:3.9016 train_time:202892ms step_avg:370.24ms
step:559/1875 train_loss:3.9403 train_time:203256ms step_avg:370.23ms
step:560/1875 train_loss:3.9768 train_time:203622ms step_avg:370.22ms
step:561/1875 train_loss:3.9062 train_time:203988ms step_avg:370.21ms
step:562/1875 train_loss:3.8513 train_time:204356ms step_avg:370.21ms
step:563/1875 train_loss:4.0596 train_time:204722ms step_avg:370.20ms
step:564/1875 train_loss:3.8780 train_time:205106ms step_avg:370.23ms
step:565/1875 train_loss:3.9903 train_time:205472ms step_avg:370.22ms
step:566/1875 train_loss:3.9198 train_time:205840ms step_avg:370.22ms
step:567/1875 train_loss:3.8846 train_time:206319ms step_avg:370.41ms
step:568/1875 train_loss:4.0013 train_time:206688ms step_avg:370.41ms
step:569/1875 train_loss:3.9687 train_time:207175ms step_avg:370.62ms
step:570/1875 train_loss:3.9766 train_time:207534ms step_avg:370.60ms
step:571/1875 train_loss:4.0665 train_time:207898ms step_avg:370.58ms
step:572/1875 train_loss:3.9979 train_time:208265ms step_avg:370.58ms
step:573/1875 train_loss:4.0134 train_time:208634ms step_avg:370.58ms
step:574/1875 train_loss:4.0775 train_time:209024ms step_avg:370.61ms
step:575/1875 train_loss:4.0245 train_time:209391ms step_avg:370.60ms
step:576/1875 train_loss:4.0400 train_time:209757ms step_avg:370.60ms
step:577/1875 train_loss:3.9775 train_time:210122ms step_avg:370.59ms
step:578/1875 train_loss:3.9501 train_time:210495ms step_avg:370.59ms
step:579/1875 train_loss:3.9538 train_time:210859ms step_avg:370.58ms
step:580/1875 train_loss:3.8934 train_time:211231ms step_avg:370.58ms
step:581/1875 train_loss:3.9344 train_time:211601ms step_avg:370.58ms
step:582/1875 train_loss:4.1516 train_time:211970ms step_avg:370.58ms
step:583/1875 train_loss:3.9321 train_time:212341ms step_avg:370.58ms
step:584/1875 train_loss:3.8816 train_time:212717ms step_avg:370.59ms
step:585/1875 train_loss:4.0701 train_time:213084ms step_avg:370.58ms
step:586/1875 train_loss:3.8133 train_time:213452ms step_avg:370.58ms
step:587/1875 train_loss:3.9568 train_time:213824ms step_avg:370.58ms
step:588/1875 train_loss:3.9553 train_time:214194ms step_avg:370.58ms
step:589/1875 train_loss:4.2866 train_time:214567ms step_avg:370.58ms
step:590/1875 train_loss:4.0573 train_time:214934ms step_avg:370.58ms
step:591/1875 train_loss:3.8085 train_time:215298ms step_avg:370.57ms
step:592/1875 train_loss:3.8306 train_time:215675ms step_avg:370.58ms
step:593/1875 train_loss:3.7989 train_time:216052ms step_avg:370.59ms
step:594/1875 train_loss:3.8404 train_time:216421ms step_avg:370.58ms
step:595/1875 train_loss:4.2032 train_time:216794ms step_avg:370.59ms
step:596/1875 train_loss:3.9246 train_time:217172ms step_avg:370.60ms
step:597/1875 train_loss:3.8882 train_time:217541ms step_avg:370.60ms
step:598/1875 train_loss:3.9482 train_time:217908ms step_avg:370.59ms
step:599/1875 train_loss:3.7690 train_time:218277ms step_avg:370.59ms
step:600/1875 train_loss:3.8963 train_time:218645ms step_avg:370.59ms
step:601/1875 train_loss:3.9262 train_time:219026ms step_avg:370.60ms
step:602/1875 train_loss:3.9495 train_time:219404ms step_avg:370.62ms
step:603/1875 train_loss:4.0635 train_time:219773ms step_avg:370.61ms
step:604/1875 train_loss:3.9162 train_time:220140ms step_avg:370.61ms
step:605/1875 train_loss:3.9103 train_time:220513ms step_avg:370.61ms
step:606/1875 train_loss:3.8347 train_time:220883ms step_avg:370.61ms
step:607/1875 train_loss:4.1105 train_time:221261ms step_avg:370.62ms
step:608/1875 train_loss:3.9405 train_time:221627ms step_avg:370.61ms
step:609/1875 train_loss:3.8903 train_time:221998ms step_avg:370.61ms
step:610/1875 train_loss:4.0007 train_time:222362ms step_avg:370.60ms
step:611/1875 train_loss:3.8952 train_time:222729ms step_avg:370.60ms
step:612/1875 train_loss:3.8402 train_time:223100ms step_avg:370.60ms
step:613/1875 train_loss:4.0415 train_time:223471ms step_avg:370.60ms
step:614/1875 train_loss:3.9852 train_time:223844ms step_avg:370.60ms
step:615/1875 train_loss:3.9735 train_time:224210ms step_avg:370.60ms
step:616/1875 train_loss:3.9170 train_time:224582ms step_avg:370.60ms
step:617/1875 train_loss:3.8393 train_time:224950ms step_avg:370.59ms
step:618/1875 train_loss:3.9615 train_time:225314ms step_avg:370.58ms
step:619/1875 train_loss:3.8452 train_time:225688ms step_avg:370.59ms
step:620/1875 train_loss:3.8650 train_time:226054ms step_avg:370.58ms
step:621/1875 train_loss:4.1822 train_time:226433ms step_avg:370.59ms
step:622/1875 train_loss:3.8616 train_time:226809ms step_avg:370.60ms
step:623/1875 train_loss:3.9024 train_time:227184ms step_avg:370.61ms
step:624/1875 train_loss:3.9677 train_time:227554ms step_avg:370.61ms
step:625/1875 train_loss:3.9829 train_time:227918ms step_avg:370.60ms
step:625/1875 val_loss:3.9077 train_time:228145ms step_avg:370.97ms
============== Weight norms: ==============
name = 'module._orig_mod.transformer.h.0.attn.c_q.weight' | fro_norm = 32.12989 | spectral_norm = 12.26283 | nuclear_norm = 627.42773
name = 'module._orig_mod.transformer.h.0.attn.c_k.weight' | fro_norm = 30.49721 | spectral_norm = 11.20173 | nuclear_norm = 591.01990
name = 'module._orig_mod.transformer.h.1.attn.c_q.weight' | fro_norm = 30.96811 | spectral_norm = 7.69534 | nuclear_norm = 611.48322
name = 'module._orig_mod.transformer.h.1.attn.c_k.weight' | fro_norm = 28.36562 | spectral_norm = 6.61083 | nuclear_norm = 576.00153
name = 'module._orig_mod.transformer.h.2.attn.c_q.weight' | fro_norm = 30.91706 | spectral_norm = 7.57955 | nuclear_norm = 607.94971
name = 'module._orig_mod.transformer.h.2.attn.c_k.weight' | fro_norm = 29.65104 | spectral_norm = 7.25637 | nuclear_norm = 595.26898
name = 'module._orig_mod.transformer.h.3.attn.c_q.weight' | fro_norm = 30.96114 | spectral_norm = 5.72629 | nuclear_norm = 592.10809
name = 'module._orig_mod.transformer.h.3.attn.c_k.weight' | fro_norm = 29.99859 | spectral_norm = 5.33113 | nuclear_norm = 598.51990
name = 'module._orig_mod.transformer.h.4.attn.c_q.weight' | fro_norm = 30.59161 | spectral_norm = 5.61815 | nuclear_norm = 605.51685
name = 'module._orig_mod.transformer.h.4.attn.c_k.weight' | fro_norm = 29.75671 | spectral_norm = 5.26301 | nuclear_norm = 605.92194
name = 'module._orig_mod.transformer.h.5.attn.c_q.weight' | fro_norm = 30.68649 | spectral_norm = 5.90773 | nuclear_norm = 609.75812
name = 'module._orig_mod.transformer.h.5.attn.c_k.weight' | fro_norm = 29.54019 | spectral_norm = 5.72376 | nuclear_norm = 600.21509
name = 'module._orig_mod.transformer.h.6.attn.c_q.weight' | fro_norm = 29.67550 | spectral_norm = 6.15397 | nuclear_norm = 583.00208
name = 'module._orig_mod.transformer.h.6.attn.c_k.weight' | fro_norm = 27.72588 | spectral_norm = 6.64056 | nuclear_norm = 560.79651
name = 'module._orig_mod.transformer.h.7.attn.c_q.weight' | fro_norm = 30.70508 | spectral_norm = 5.76500 | nuclear_norm = 608.95325
name = 'module._orig_mod.transformer.h.7.attn.c_k.weight' | fro_norm = 29.20711 | spectral_norm = 5.46357 | nuclear_norm = 598.09344
name = 'module._orig_mod.transformer.h.8.attn.c_q.weight' | fro_norm = 30.75430 | spectral_norm = 6.03263 | nuclear_norm = 607.48547
name = 'module._orig_mod.transformer.h.8.attn.c_k.weight' | fro_norm = 29.32829 | spectral_norm = 6.01503 | nuclear_norm = 592.10278
name = 'module._orig_mod.transformer.h.9.attn.c_q.weight' | fro_norm = 29.90679 | spectral_norm = 6.74008 | nuclear_norm = 586.74756
name = 'module._orig_mod.transformer.h.9.attn.c_k.weight' | fro_norm = 28.71738 | spectral_norm = 5.66117 | nuclear_norm = 582.06262
name = 'module._orig_mod.transformer.h.10.attn.c_q.weight' | fro_norm = 29.58336 | spectral_norm = 6.48759 | nuclear_norm = 589.95312
name = 'module._orig_mod.transformer.h.10.attn.c_k.weight' | fro_norm = 28.21136 | spectral_norm = 5.17117 | nuclear_norm = 579.54205
name = 'module._orig_mod.transformer.h.11.attn.c_q.weight' | fro_norm = 28.39309 | spectral_norm = 7.07618 | nuclear_norm = 562.90137
name = 'module._orig_mod.transformer.h.11.attn.c_k.weight' | fro_norm = 26.62636 | spectral_norm = 5.81387 | nuclear_norm = 543.91803
===========================================
step:626/1875 train_loss:4.0245 train_time:228294ms step_avg:370.61ms
step:627/1875 train_loss:3.9946 train_time:228654ms step_avg:370.59ms
step:628/1875 train_loss:4.0523 train_time:229025ms step_avg:370.59ms
step:629/1875 train_loss:3.8735 train_time:229391ms step_avg:370.58ms
step:630/1875 train_loss:3.9890 train_time:229759ms step_avg:370.58ms
step:631/1875 train_loss:4.0262 train_time:230124ms step_avg:370.57ms
step:632/1875 train_loss:3.9398 train_time:230498ms step_avg:370.58ms
step:633/1875 train_loss:3.8692 train_time:230872ms step_avg:370.58ms
step:634/1875 train_loss:3.9805 train_time:231240ms step_avg:370.58ms
step:635/1875 train_loss:4.2294 train_time:231604ms step_avg:370.57ms
step:636/1875 train_loss:3.8214 train_time:231973ms step_avg:370.56ms
step:637/1875 train_loss:3.6197 train_time:232348ms step_avg:370.57ms
step:638/1875 train_loss:3.8655 train_time:232715ms step_avg:370.57ms
step:639/1875 train_loss:3.9063 train_time:233081ms step_avg:370.56ms
step:640/1875 train_loss:3.8564 train_time:233448ms step_avg:370.55ms
step:641/1875 train_loss:3.8561 train_time:233814ms step_avg:370.55ms
step:642/1875 train_loss:3.9082 train_time:234184ms step_avg:370.54ms
step:643/1875 train_loss:3.9057 train_time:234554ms step_avg:370.54ms
step:644/1875 train_loss:3.8357 train_time:234923ms step_avg:370.54ms
step:645/1875 train_loss:4.0503 train_time:235294ms step_avg:370.54ms
step:646/1875 train_loss:3.9636 train_time:235668ms step_avg:370.55ms
step:647/1875 train_loss:3.9294 train_time:236032ms step_avg:370.54ms
step:648/1875 train_loss:3.9767 train_time:236417ms step_avg:370.56ms
step:649/1875 train_loss:4.0347 train_time:236787ms step_avg:370.56ms
step:650/1875 train_loss:3.8948 train_time:237162ms step_avg:370.57ms
step:651/1875 train_loss:4.0484 train_time:237533ms step_avg:370.57ms
step:652/1875 train_loss:3.8712 train_time:237907ms step_avg:370.57ms
step:653/1875 train_loss:3.9555 train_time:238278ms step_avg:370.57ms
step:654/1875 train_loss:3.7202 train_time:238649ms step_avg:370.57ms
step:655/1875 train_loss:3.8640 train_time:239014ms step_avg:370.56ms
step:656/1875 train_loss:3.8633 train_time:239380ms step_avg:370.56ms
step:657/1875 train_loss:3.7799 train_time:239748ms step_avg:370.55ms
step:658/1875 train_loss:3.9651 train_time:240119ms step_avg:370.55ms
step:659/1875 train_loss:3.8782 train_time:240488ms step_avg:370.55ms
step:660/1875 train_loss:3.9419 train_time:240855ms step_avg:370.55ms
step:661/1875 train_loss:4.0286 train_time:241227ms step_avg:370.55ms
step:662/1875 train_loss:3.9400 train_time:241596ms step_avg:370.55ms
step:663/1875 train_loss:3.8318 train_time:241961ms step_avg:370.54ms
step:664/1875 train_loss:3.8847 train_time:242335ms step_avg:370.54ms
step:665/1875 train_loss:3.7638 train_time:242706ms step_avg:370.54ms
step:666/1875 train_loss:4.0584 train_time:243074ms step_avg:370.54ms
step:667/1875 train_loss:3.9093 train_time:243444ms step_avg:370.54ms
step:668/1875 train_loss:3.9087 train_time:243818ms step_avg:370.54ms
step:669/1875 train_loss:3.7692 train_time:244197ms step_avg:370.56ms
step:670/1875 train_loss:3.8674 train_time:244565ms step_avg:370.55ms
step:671/1875 train_loss:3.8272 train_time:244938ms step_avg:370.56ms
step:672/1875 train_loss:3.8453 train_time:245313ms step_avg:370.56ms
step:673/1875 train_loss:4.1111 train_time:245682ms step_avg:370.56ms
step:674/1875 train_loss:3.9114 train_time:246054ms step_avg:370.56ms
step:675/1875 train_loss:3.9955 train_time:246423ms step_avg:370.56ms
step:676/1875 train_loss:3.7554 train_time:246794ms step_avg:370.56ms
step:677/1875 train_loss:3.8791 train_time:247165ms step_avg:370.56ms
step:678/1875 train_loss:3.8204 train_time:247537ms step_avg:370.56ms
step:679/1875 train_loss:3.9360 train_time:247911ms step_avg:370.57ms
step:680/1875 train_loss:3.8740 train_time:248284ms step_avg:370.57ms
step:681/1875 train_loss:3.8915 train_time:248655ms step_avg:370.57ms
step:682/1875 train_loss:3.9248 train_time:249034ms step_avg:370.59ms
step:683/1875 train_loss:4.0260 train_time:249402ms step_avg:370.58ms
step:684/1875 train_loss:3.9127 train_time:249772ms step_avg:370.58ms
step:685/1875 train_loss:3.9798 train_time:250140ms step_avg:370.58ms
step:686/1875 train_loss:3.9057 train_time:250513ms step_avg:370.58ms
step:687/1875 train_loss:3.9443 train_time:250877ms step_avg:370.57ms
step:688/1875 train_loss:3.5118 train_time:251256ms step_avg:370.58ms
step:689/1875 train_loss:3.6816 train_time:251629ms step_avg:370.59ms
step:690/1875 train_loss:3.8152 train_time:252011ms step_avg:370.60ms
step:691/1875 train_loss:3.6903 train_time:252379ms step_avg:370.60ms
step:692/1875 train_loss:3.9098 train_time:252749ms step_avg:370.60ms
step:693/1875 train_loss:3.9241 train_time:253117ms step_avg:370.60ms
step:694/1875 train_loss:3.8309 train_time:253488ms step_avg:370.60ms
step:695/1875 train_loss:3.8027 train_time:253853ms step_avg:370.59ms
step:696/1875 train_loss:4.1133 train_time:254221ms step_avg:370.58ms
step:697/1875 train_loss:3.8603 train_time:254591ms step_avg:370.58ms
step:698/1875 train_loss:3.9008 train_time:254961ms step_avg:370.58ms
step:699/1875 train_loss:4.0442 train_time:255329ms step_avg:370.58ms
step:700/1875 train_loss:3.8345 train_time:255700ms step_avg:370.58ms
step:701/1875 train_loss:3.8044 train_time:256070ms step_avg:370.58ms
step:702/1875 train_loss:3.7879 train_time:256445ms step_avg:370.59ms
step:703/1875 train_loss:3.7598 train_time:256815ms step_avg:370.58ms
step:704/1875 train_loss:3.8543 train_time:257179ms step_avg:370.57ms
step:705/1875 train_loss:3.8245 train_time:257553ms step_avg:370.58ms
step:706/1875 train_loss:3.8583 train_time:257941ms step_avg:370.60ms
step:707/1875 train_loss:3.9243 train_time:258314ms step_avg:370.61ms
step:708/1875 train_loss:3.8661 train_time:258684ms step_avg:370.61ms
step:709/1875 train_loss:3.8486 train_time:259051ms step_avg:370.60ms
step:710/1875 train_loss:3.8214 train_time:259421ms step_avg:370.60ms
step:711/1875 train_loss:3.8576 train_time:259793ms step_avg:370.60ms
step:712/1875 train_loss:3.9277 train_time:260174ms step_avg:370.62ms
step:713/1875 train_loss:3.9169 train_time:260547ms step_avg:370.62ms
step:714/1875 train_loss:3.8365 train_time:260921ms step_avg:370.63ms
step:715/1875 train_loss:3.8488 train_time:261285ms step_avg:370.62ms
step:716/1875 train_loss:3.8597 train_time:261656ms step_avg:370.62ms
step:717/1875 train_loss:3.9690 train_time:262032ms step_avg:370.62ms
step:718/1875 train_loss:3.8740 train_time:262399ms step_avg:370.62ms
step:719/1875 train_loss:3.9469 train_time:262764ms step_avg:370.61ms
step:720/1875 train_loss:4.0683 train_time:263137ms step_avg:370.62ms
step:721/1875 train_loss:3.7364 train_time:263510ms step_avg:370.62ms
step:722/1875 train_loss:3.9903 train_time:263878ms step_avg:370.62ms
step:723/1875 train_loss:4.0361 train_time:264244ms step_avg:370.61ms
step:724/1875 train_loss:3.8265 train_time:264616ms step_avg:370.61ms
step:725/1875 train_loss:3.9250 train_time:264988ms step_avg:370.61ms
step:726/1875 train_loss:3.8231 train_time:265359ms step_avg:370.61ms
step:727/1875 train_loss:3.8348 train_time:265739ms step_avg:370.63ms
step:728/1875 train_loss:4.0057 train_time:266112ms step_avg:370.63ms
step:729/1875 train_loss:3.9313 train_time:266481ms step_avg:370.63ms
step:730/1875 train_loss:3.9392 train_time:266855ms step_avg:370.63ms
step:731/1875 train_loss:3.8403 train_time:267224ms step_avg:370.63ms
step:732/1875 train_loss:3.8666 train_time:267587ms step_avg:370.62ms
step:733/1875 train_loss:4.0869 train_time:267961ms step_avg:370.62ms
step:734/1875 train_loss:3.8258 train_time:268338ms step_avg:370.63ms
step:735/1875 train_loss:3.8733 train_time:268711ms step_avg:370.64ms
step:736/1875 train_loss:3.9979 train_time:269080ms step_avg:370.63ms
step:737/1875 train_loss:3.9316 train_time:269447ms step_avg:370.63ms
step:738/1875 train_loss:3.8554 train_time:269814ms step_avg:370.62ms
step:739/1875 train_loss:3.7655 train_time:270185ms step_avg:370.62ms
step:740/1875 train_loss:4.3823 train_time:270565ms step_avg:370.64ms
step:741/1875 train_loss:3.7671 train_time:270944ms step_avg:370.65ms
step:742/1875 train_loss:3.8317 train_time:271315ms step_avg:370.65ms
step:743/1875 train_loss:3.8445 train_time:271682ms step_avg:370.64ms
step:744/1875 train_loss:3.9062 train_time:272051ms step_avg:370.64ms
step:745/1875 train_loss:3.8655 train_time:272432ms step_avg:370.66ms
step:746/1875 train_loss:3.8587 train_time:272800ms step_avg:370.65ms
step:747/1875 train_loss:3.9090 train_time:273169ms step_avg:370.65ms
step:748/1875 train_loss:3.8335 train_time:273558ms step_avg:370.67ms
step:749/1875 train_loss:3.8313 train_time:273932ms step_avg:370.68ms
step:750/1875 train_loss:3.8776 train_time:274298ms step_avg:370.67ms
step:750/1875 val_loss:3.8317 train_time:274517ms step_avg:370.97ms
============== Weight norms: ==============
name = 'module._orig_mod.transformer.h.0.attn.c_q.weight' | fro_norm = 34.56706 | spectral_norm = 13.07683 | nuclear_norm = 672.76953
name = 'module._orig_mod.transformer.h.0.attn.c_k.weight' | fro_norm = 32.70527 | spectral_norm = 12.12412 | nuclear_norm = 630.99200
name = 'module._orig_mod.transformer.h.1.attn.c_q.weight' | fro_norm = 33.03310 | spectral_norm = 8.19442 | nuclear_norm = 648.98730
name = 'module._orig_mod.transformer.h.1.attn.c_k.weight' | fro_norm = 30.29230 | spectral_norm = 7.20750 | nuclear_norm = 610.72876
name = 'module._orig_mod.transformer.h.2.attn.c_q.weight' | fro_norm = 33.01549 | spectral_norm = 8.09895 | nuclear_norm = 646.17041
name = 'module._orig_mod.transformer.h.2.attn.c_k.weight' | fro_norm = 31.68660 | spectral_norm = 7.81171 | nuclear_norm = 632.62030
name = 'module._orig_mod.transformer.h.3.attn.c_q.weight' | fro_norm = 33.03772 | spectral_norm = 5.97307 | nuclear_norm = 629.70404
name = 'module._orig_mod.transformer.h.3.attn.c_k.weight' | fro_norm = 32.01168 | spectral_norm = 5.52647 | nuclear_norm = 636.34717
name = 'module._orig_mod.transformer.h.4.attn.c_q.weight' | fro_norm = 32.95447 | spectral_norm = 6.01671 | nuclear_norm = 649.02234
name = 'module._orig_mod.transformer.h.4.attn.c_k.weight' | fro_norm = 31.93153 | spectral_norm = 5.50380 | nuclear_norm = 648.36816
name = 'module._orig_mod.transformer.h.5.attn.c_q.weight' | fro_norm = 33.04855 | spectral_norm = 6.22825 | nuclear_norm = 653.70264
name = 'module._orig_mod.transformer.h.5.attn.c_k.weight' | fro_norm = 31.74586 | spectral_norm = 5.98046 | nuclear_norm = 642.20630
name = 'module._orig_mod.transformer.h.6.attn.c_q.weight' | fro_norm = 32.03378 | spectral_norm = 6.61296 | nuclear_norm = 623.81555
name = 'module._orig_mod.transformer.h.6.attn.c_k.weight' | fro_norm = 29.89094 | spectral_norm = 7.04881 | nuclear_norm = 599.19818
name = 'module._orig_mod.transformer.h.7.attn.c_q.weight' | fro_norm = 33.10461 | spectral_norm = 6.03631 | nuclear_norm = 655.35095
name = 'module._orig_mod.transformer.h.7.attn.c_k.weight' | fro_norm = 31.48407 | spectral_norm = 5.65911 | nuclear_norm = 642.91901
name = 'module._orig_mod.transformer.h.8.attn.c_q.weight' | fro_norm = 33.20054 | spectral_norm = 6.31441 | nuclear_norm = 654.94720
name = 'module._orig_mod.transformer.h.8.attn.c_k.weight' | fro_norm = 31.67600 | spectral_norm = 6.12968 | nuclear_norm = 637.93445
name = 'module._orig_mod.transformer.h.9.attn.c_q.weight' | fro_norm = 32.23665 | spectral_norm = 7.16586 | nuclear_norm = 629.92010
name = 'module._orig_mod.transformer.h.9.attn.c_k.weight' | fro_norm = 30.92980 | spectral_norm = 5.93467 | nuclear_norm = 623.89545
name = 'module._orig_mod.transformer.h.10.attn.c_q.weight' | fro_norm = 31.85509 | spectral_norm = 6.94757 | nuclear_norm = 633.13434
name = 'module._orig_mod.transformer.h.10.attn.c_k.weight' | fro_norm = 30.30495 | spectral_norm = 5.36854 | nuclear_norm = 620.08972
name = 'module._orig_mod.transformer.h.11.attn.c_q.weight' | fro_norm = 30.54381 | spectral_norm = 7.50840 | nuclear_norm = 602.63965
name = 'module._orig_mod.transformer.h.11.attn.c_k.weight' | fro_norm = 28.47006 | spectral_norm = 5.98546 | nuclear_norm = 578.85767
===========================================
step:751/1875 train_loss:3.8368 train_time:274666ms step_avg:370.67ms
step:752/1875 train_loss:3.8749 train_time:275028ms step_avg:370.66ms
step:753/1875 train_loss:3.8892 train_time:275389ms step_avg:370.64ms
step:754/1875 train_loss:3.8543 train_time:275763ms step_avg:370.65ms
step:755/1875 train_loss:3.9406 train_time:276134ms step_avg:370.65ms
step:756/1875 train_loss:3.7380 train_time:276612ms step_avg:370.79ms
step:757/1875 train_loss:3.9872 train_time:276992ms step_avg:370.81ms
step:758/1875 train_loss:3.9185 train_time:277360ms step_avg:370.80ms
step:759/1875 train_loss:3.8499 train_time:277859ms step_avg:370.97ms
step:760/1875 train_loss:3.9541 train_time:278224ms step_avg:370.97ms
step:761/1875 train_loss:3.6570 train_time:278594ms step_avg:370.96ms
step:762/1875 train_loss:3.8145 train_time:278962ms step_avg:370.96ms
step:763/1875 train_loss:3.9344 train_time:279330ms step_avg:370.96ms
step:764/1875 train_loss:3.5780 train_time:279702ms step_avg:370.96ms
step:765/1875 train_loss:3.9921 train_time:280072ms step_avg:370.96ms
step:766/1875 train_loss:3.8503 train_time:280454ms step_avg:370.97ms
step:767/1875 train_loss:3.8372 train_time:280824ms step_avg:370.97ms
step:768/1875 train_loss:3.8301 train_time:281193ms step_avg:370.97ms
step:769/1875 train_loss:3.8512 train_time:281572ms step_avg:370.98ms
step:770/1875 train_loss:3.8937 train_time:281942ms step_avg:370.98ms
step:771/1875 train_loss:4.1455 train_time:282311ms step_avg:370.97ms
step:772/1875 train_loss:3.7158 train_time:282675ms step_avg:370.97ms
step:773/1875 train_loss:3.9144 train_time:283047ms step_avg:370.97ms
step:774/1875 train_loss:3.9072 train_time:283415ms step_avg:370.96ms
step:775/1875 train_loss:3.8658 train_time:283784ms step_avg:370.96ms
step:776/1875 train_loss:3.6499 train_time:284155ms step_avg:370.96ms
step:777/1875 train_loss:3.6318 train_time:284528ms step_avg:370.96ms
step:778/1875 train_loss:3.7481 train_time:284899ms step_avg:370.96ms
step:779/1875 train_loss:3.8358 train_time:285266ms step_avg:370.96ms
step:780/1875 train_loss:3.8545 train_time:285642ms step_avg:370.96ms
step:781/1875 train_loss:3.9210 train_time:286010ms step_avg:370.96ms
step:782/1875 train_loss:3.8357 train_time:286381ms step_avg:370.96ms
step:783/1875 train_loss:3.8386 train_time:286747ms step_avg:370.95ms
step:784/1875 train_loss:3.8387 train_time:287120ms step_avg:370.96ms
step:785/1875 train_loss:3.8265 train_time:287487ms step_avg:370.95ms
step:786/1875 train_loss:3.7141 train_time:287853ms step_avg:370.94ms
step:787/1875 train_loss:3.9568 train_time:288222ms step_avg:370.94ms
step:788/1875 train_loss:3.7662 train_time:288608ms step_avg:370.96ms
step:789/1875 train_loss:3.8216 train_time:288970ms step_avg:370.95ms
step:790/1875 train_loss:3.8876 train_time:289340ms step_avg:370.95ms
step:791/1875 train_loss:4.0280 train_time:289721ms step_avg:370.96ms
step:792/1875 train_loss:4.0233 train_time:290090ms step_avg:370.96ms
step:793/1875 train_loss:3.7439 train_time:290457ms step_avg:370.95ms
step:794/1875 train_loss:3.8438 train_time:290825ms step_avg:370.95ms
step:795/1875 train_loss:3.9139 train_time:291200ms step_avg:370.96ms
step:796/1875 train_loss:3.9694 train_time:291574ms step_avg:370.96ms
step:797/1875 train_loss:3.7783 train_time:291946ms step_avg:370.96ms
step:798/1875 train_loss:3.8974 train_time:292316ms step_avg:370.96ms
step:799/1875 train_loss:3.8056 train_time:292701ms step_avg:370.98ms
step:800/1875 train_loss:3.7941 train_time:293069ms step_avg:370.97ms
step:801/1875 train_loss:3.9051 train_time:293438ms step_avg:370.97ms
step:802/1875 train_loss:3.7575 train_time:293813ms step_avg:370.98ms
step:803/1875 train_loss:3.7722 train_time:294182ms step_avg:370.97ms
step:804/1875 train_loss:3.8933 train_time:294545ms step_avg:370.96ms
step:805/1875 train_loss:3.7978 train_time:294924ms step_avg:370.97ms
step:806/1875 train_loss:3.8136 train_time:295292ms step_avg:370.97ms
step:807/1875 train_loss:3.9027 train_time:295657ms step_avg:370.96ms
step:808/1875 train_loss:3.8131 train_time:296029ms step_avg:370.96ms
step:809/1875 train_loss:3.7438 train_time:296396ms step_avg:370.96ms
step:810/1875 train_loss:3.8221 train_time:296764ms step_avg:370.95ms
step:811/1875 train_loss:3.8574 train_time:297132ms step_avg:370.95ms
step:812/1875 train_loss:3.8420 train_time:297496ms step_avg:370.94ms
step:813/1875 train_loss:3.8935 train_time:297858ms step_avg:370.93ms
step:814/1875 train_loss:3.8379 train_time:298229ms step_avg:370.93ms
step:815/1875 train_loss:3.8224 train_time:298595ms step_avg:370.93ms
step:816/1875 train_loss:3.9230 train_time:298976ms step_avg:370.94ms
step:817/1875 train_loss:4.0101 train_time:299345ms step_avg:370.94ms
step:818/1875 train_loss:3.7861 train_time:299709ms step_avg:370.93ms
step:819/1875 train_loss:3.9819 train_time:300082ms step_avg:370.93ms
step:820/1875 train_loss:3.7680 train_time:300456ms step_avg:370.93ms
step:821/1875 train_loss:3.8072 train_time:300824ms step_avg:370.93ms
step:822/1875 train_loss:3.9287 train_time:301195ms step_avg:370.93ms
step:823/1875 train_loss:3.8388 train_time:301568ms step_avg:370.93ms
step:824/1875 train_loss:3.7639 train_time:301937ms step_avg:370.93ms
step:825/1875 train_loss:3.8686 train_time:302311ms step_avg:370.93ms
step:826/1875 train_loss:3.7363 train_time:302684ms step_avg:370.94ms
step:827/1875 train_loss:3.9623 train_time:303055ms step_avg:370.94ms
step:828/1875 train_loss:3.8712 train_time:303428ms step_avg:370.94ms
step:829/1875 train_loss:3.8940 train_time:303797ms step_avg:370.94ms
step:830/1875 train_loss:3.7745 train_time:304169ms step_avg:370.94ms
step:831/1875 train_loss:3.8520 train_time:304535ms step_avg:370.93ms
step:832/1875 train_loss:3.7651 train_time:304907ms step_avg:370.93ms
step:833/1875 train_loss:3.8940 train_time:305275ms step_avg:370.93ms
step:834/1875 train_loss:3.7538 train_time:305646ms step_avg:370.93ms
step:835/1875 train_loss:3.7126 train_time:306018ms step_avg:370.93ms
step:836/1875 train_loss:3.9768 train_time:306396ms step_avg:370.94ms
step:837/1875 train_loss:3.6817 train_time:306770ms step_avg:370.94ms
step:838/1875 train_loss:3.8377 train_time:307137ms step_avg:370.94ms
step:839/1875 train_loss:3.6854 train_time:307504ms step_avg:370.93ms
step:840/1875 train_loss:3.7305 train_time:307874ms step_avg:370.93ms
step:841/1875 train_loss:3.8236 train_time:308242ms step_avg:370.93ms
step:842/1875 train_loss:3.8350 train_time:308617ms step_avg:370.93ms
step:843/1875 train_loss:3.8201 train_time:308983ms step_avg:370.93ms
step:844/1875 train_loss:3.6787 train_time:309351ms step_avg:370.92ms
step:845/1875 train_loss:3.9068 train_time:309723ms step_avg:370.93ms
step:846/1875 train_loss:3.7792 train_time:310097ms step_avg:370.93ms
step:847/1875 train_loss:3.7452 train_time:310468ms step_avg:370.93ms
step:848/1875 train_loss:3.8810 train_time:310841ms step_avg:370.93ms
step:849/1875 train_loss:3.7527 train_time:311211ms step_avg:370.93ms
step:850/1875 train_loss:3.6897 train_time:311586ms step_avg:370.94ms
step:851/1875 train_loss:3.9953 train_time:311959ms step_avg:370.94ms
step:852/1875 train_loss:3.7092 train_time:312326ms step_avg:370.93ms
step:853/1875 train_loss:3.8157 train_time:312689ms step_avg:370.92ms
step:854/1875 train_loss:3.9108 train_time:313067ms step_avg:370.93ms
step:855/1875 train_loss:3.7869 train_time:313434ms step_avg:370.93ms
step:856/1875 train_loss:3.7910 train_time:313798ms step_avg:370.92ms
step:857/1875 train_loss:3.8532 train_time:314172ms step_avg:370.92ms
step:858/1875 train_loss:3.7285 train_time:314550ms step_avg:370.93ms
step:859/1875 train_loss:3.8041 train_time:314919ms step_avg:370.93ms
step:860/1875 train_loss:3.8455 train_time:315288ms step_avg:370.93ms
step:861/1875 train_loss:3.8968 train_time:315651ms step_avg:370.92ms
step:862/1875 train_loss:3.8355 train_time:316046ms step_avg:370.95ms
step:863/1875 train_loss:3.8194 train_time:316420ms step_avg:370.95ms
step:864/1875 train_loss:3.6387 train_time:316794ms step_avg:370.95ms
step:865/1875 train_loss:3.8439 train_time:317160ms step_avg:370.95ms
step:866/1875 train_loss:4.1150 train_time:317531ms step_avg:370.95ms
step:867/1875 train_loss:3.7025 train_time:317905ms step_avg:370.95ms
step:868/1875 train_loss:3.8909 train_time:318269ms step_avg:370.94ms
step:869/1875 train_loss:3.8648 train_time:318641ms step_avg:370.94ms
step:870/1875 train_loss:3.6994 train_time:319017ms step_avg:370.95ms
step:871/1875 train_loss:3.6814 train_time:319383ms step_avg:370.94ms
step:872/1875 train_loss:3.9121 train_time:319756ms step_avg:370.95ms
step:873/1875 train_loss:3.7067 train_time:320120ms step_avg:370.94ms
step:874/1875 train_loss:3.4184 train_time:320496ms step_avg:370.94ms
step:875/1875 train_loss:3.8808 train_time:320873ms step_avg:370.95ms
step:875/1875 val_loss:3.7716 train_time:321091ms step_avg:371.20ms
============== Weight norms: ==============
name = 'module._orig_mod.transformer.h.0.attn.c_q.weight' | fro_norm = 36.88432 | spectral_norm = 13.91519 | nuclear_norm = 716.81909
name = 'module._orig_mod.transformer.h.0.attn.c_k.weight' | fro_norm = 34.87755 | spectral_norm = 13.04631 | nuclear_norm = 671.15131
name = 'module._orig_mod.transformer.h.1.attn.c_q.weight' | fro_norm = 35.05230 | spectral_norm = 8.62414 | nuclear_norm = 686.12958
name = 'module._orig_mod.transformer.h.1.attn.c_k.weight' | fro_norm = 32.18810 | spectral_norm = 7.71621 | nuclear_norm = 644.85217
name = 'module._orig_mod.transformer.h.2.attn.c_q.weight' | fro_norm = 35.13019 | spectral_norm = 8.59189 | nuclear_norm = 684.65796
name = 'module._orig_mod.transformer.h.2.attn.c_k.weight' | fro_norm = 33.68668 | spectral_norm = 8.38783 | nuclear_norm = 669.67676
name = 'module._orig_mod.transformer.h.3.attn.c_q.weight' | fro_norm = 35.11073 | spectral_norm = 6.19846 | nuclear_norm = 667.65466
name = 'module._orig_mod.transformer.h.3.attn.c_k.weight' | fro_norm = 34.00153 | spectral_norm = 5.71117 | nuclear_norm = 673.67029
name = 'module._orig_mod.transformer.h.4.attn.c_q.weight' | fro_norm = 35.22467 | spectral_norm = 6.30913 | nuclear_norm = 691.85791
name = 'module._orig_mod.transformer.h.4.attn.c_k.weight' | fro_norm = 34.03604 | spectral_norm = 5.78148 | nuclear_norm = 689.66644
name = 'module._orig_mod.transformer.h.5.attn.c_q.weight' | fro_norm = 35.33424 | spectral_norm = 6.60715 | nuclear_norm = 696.83569
name = 'module._orig_mod.transformer.h.5.attn.c_k.weight' | fro_norm = 33.89589 | spectral_norm = 6.31098 | nuclear_norm = 683.46594
name = 'module._orig_mod.transformer.h.6.attn.c_q.weight' | fro_norm = 34.36087 | spectral_norm = 6.99334 | nuclear_norm = 664.39209
name = 'module._orig_mod.transformer.h.6.attn.c_k.weight' | fro_norm = 32.04706 | spectral_norm = 7.44173 | nuclear_norm = 637.99377
name = 'module._orig_mod.transformer.h.7.attn.c_q.weight' | fro_norm = 35.47072 | spectral_norm = 6.30541 | nuclear_norm = 701.18860
name = 'module._orig_mod.transformer.h.7.attn.c_k.weight' | fro_norm = 33.72752 | spectral_norm = 5.90960 | nuclear_norm = 687.21936
name = 'module._orig_mod.transformer.h.8.attn.c_q.weight' | fro_norm = 35.59069 | spectral_norm = 6.59715 | nuclear_norm = 701.44275
name = 'module._orig_mod.transformer.h.8.attn.c_k.weight' | fro_norm = 33.94835 | spectral_norm = 6.34720 | nuclear_norm = 682.88336
name = 'module._orig_mod.transformer.h.9.attn.c_q.weight' | fro_norm = 34.62640 | spectral_norm = 7.54877 | nuclear_norm = 673.63000
name = 'module._orig_mod.transformer.h.9.attn.c_k.weight' | fro_norm = 33.18340 | spectral_norm = 6.25198 | nuclear_norm = 666.19177
name = 'module._orig_mod.transformer.h.10.attn.c_q.weight' | fro_norm = 34.13044 | spectral_norm = 7.33345 | nuclear_norm = 677.48535
name = 'module._orig_mod.transformer.h.10.attn.c_k.weight' | fro_norm = 32.37429 | spectral_norm = 5.61085 | nuclear_norm = 660.96735
name = 'module._orig_mod.transformer.h.11.attn.c_q.weight' | fro_norm = 32.78719 | spectral_norm = 7.76377 | nuclear_norm = 645.47827
name = 'module._orig_mod.transformer.h.11.attn.c_k.weight' | fro_norm = 30.36526 | spectral_norm = 6.13512 | nuclear_norm = 615.34753
===========================================
step:876/1875 train_loss:3.7051 train_time:321240ms step_avg:370.95ms
step:877/1875 train_loss:3.8728 train_time:321593ms step_avg:370.93ms
step:878/1875 train_loss:3.7261 train_time:321960ms step_avg:370.92ms
step:879/1875 train_loss:3.8923 train_time:322332ms step_avg:370.92ms
step:880/1875 train_loss:3.5481 train_time:322700ms step_avg:370.92ms
step:881/1875 train_loss:3.7522 train_time:323061ms step_avg:370.91ms
step:882/1875 train_loss:3.9411 train_time:323436ms step_avg:370.91ms
step:883/1875 train_loss:4.0985 train_time:323802ms step_avg:370.91ms
step:884/1875 train_loss:3.8331 train_time:324174ms step_avg:370.91ms
step:885/1875 train_loss:3.7353 train_time:324542ms step_avg:370.90ms
step:886/1875 train_loss:3.8311 train_time:324918ms step_avg:370.91ms
step:887/1875 train_loss:4.3135 train_time:325285ms step_avg:370.91ms
step:888/1875 train_loss:4.0743 train_time:325661ms step_avg:370.91ms
step:889/1875 train_loss:3.7840 train_time:326046ms step_avg:370.93ms
step:890/1875 train_loss:3.7882 train_time:326405ms step_avg:370.91ms
step:891/1875 train_loss:3.6031 train_time:326771ms step_avg:370.91ms
step:892/1875 train_loss:3.9497 train_time:327142ms step_avg:370.91ms
step:893/1875 train_loss:3.6799 train_time:327508ms step_avg:370.90ms
step:894/1875 train_loss:3.8991 train_time:327880ms step_avg:370.91ms
step:895/1875 train_loss:3.9353 train_time:328258ms step_avg:370.91ms
step:896/1875 train_loss:3.7637 train_time:328622ms step_avg:370.90ms
step:897/1875 train_loss:3.7831 train_time:328997ms step_avg:370.91ms
step:898/1875 train_loss:3.8345 train_time:329369ms step_avg:370.91ms
step:899/1875 train_loss:3.7401 train_time:329738ms step_avg:370.91ms
step:900/1875 train_loss:3.6707 train_time:330103ms step_avg:370.90ms
step:901/1875 train_loss:3.8772 train_time:330477ms step_avg:370.91ms
step:902/1875 train_loss:3.8970 train_time:330842ms step_avg:370.90ms
step:903/1875 train_loss:3.7802 train_time:331218ms step_avg:370.91ms
step:904/1875 train_loss:3.7411 train_time:331592ms step_avg:370.91ms
step:905/1875 train_loss:3.7622 train_time:331958ms step_avg:370.90ms
step:906/1875 train_loss:3.9324 train_time:332326ms step_avg:370.90ms
step:907/1875 train_loss:3.7674 train_time:332708ms step_avg:370.91ms
step:908/1875 train_loss:3.8119 train_time:333075ms step_avg:370.91ms
step:909/1875 train_loss:3.7007 train_time:333445ms step_avg:370.91ms
step:910/1875 train_loss:3.7909 train_time:333831ms step_avg:370.92ms
step:911/1875 train_loss:3.8865 train_time:334197ms step_avg:370.92ms
step:912/1875 train_loss:3.8239 train_time:334569ms step_avg:370.92ms
step:913/1875 train_loss:3.7131 train_time:334941ms step_avg:370.92ms
step:914/1875 train_loss:3.9939 train_time:335311ms step_avg:370.92ms
step:915/1875 train_loss:3.7774 train_time:335693ms step_avg:370.93ms
step:916/1875 train_loss:3.8778 train_time:336061ms step_avg:370.93ms
step:917/1875 train_loss:3.8531 train_time:336428ms step_avg:370.92ms
step:918/1875 train_loss:5.0716 train_time:336808ms step_avg:370.93ms
step:919/1875 train_loss:3.7706 train_time:337180ms step_avg:370.94ms
step:920/1875 train_loss:3.8712 train_time:337552ms step_avg:370.94ms
step:921/1875 train_loss:3.8123 train_time:337919ms step_avg:370.93ms
step:922/1875 train_loss:3.8499 train_time:338298ms step_avg:370.94ms
step:923/1875 train_loss:3.8695 train_time:338666ms step_avg:370.94ms
step:924/1875 train_loss:3.9494 train_time:339033ms step_avg:370.93ms
step:925/1875 train_loss:3.9107 train_time:339408ms step_avg:370.94ms
step:926/1875 train_loss:3.8104 train_time:339779ms step_avg:370.94ms
step:927/1875 train_loss:3.8073 train_time:340140ms step_avg:370.93ms
step:928/1875 train_loss:4.0113 train_time:340507ms step_avg:370.92ms
step:929/1875 train_loss:3.8644 train_time:340880ms step_avg:370.92ms
step:930/1875 train_loss:3.6352 train_time:341249ms step_avg:370.92ms
step:931/1875 train_loss:3.7517 train_time:341615ms step_avg:370.92ms
step:932/1875 train_loss:3.9102 train_time:341983ms step_avg:370.91ms
step:933/1875 train_loss:3.6777 train_time:342353ms step_avg:370.91ms
step:934/1875 train_loss:3.8236 train_time:342720ms step_avg:370.91ms
step:935/1875 train_loss:3.6963 train_time:343095ms step_avg:370.91ms
step:936/1875 train_loss:3.7567 train_time:343463ms step_avg:370.91ms
step:937/1875 train_loss:3.8649 train_time:343842ms step_avg:370.92ms
step:938/1875 train_loss:3.7838 train_time:344209ms step_avg:370.91ms
step:939/1875 train_loss:3.9189 train_time:344582ms step_avg:370.92ms
step:940/1875 train_loss:3.7329 train_time:344959ms step_avg:370.92ms
step:941/1875 train_loss:3.7910 train_time:345325ms step_avg:370.92ms
step:942/1875 train_loss:3.6055 train_time:345693ms step_avg:370.91ms
step:943/1875 train_loss:3.9493 train_time:346066ms step_avg:370.92ms
step:944/1875 train_loss:3.6481 train_time:346443ms step_avg:370.92ms
step:945/1875 train_loss:3.6682 train_time:346908ms step_avg:371.03ms
step:946/1875 train_loss:5.2545 train_time:347284ms step_avg:371.03ms
step:947/1875 train_loss:3.8261 train_time:347663ms step_avg:371.04ms
step:948/1875 train_loss:3.7357 train_time:348030ms step_avg:371.03ms
step:949/1875 train_loss:3.6338 train_time:348522ms step_avg:371.16ms
step:950/1875 train_loss:3.6910 train_time:348885ms step_avg:371.15ms
step:951/1875 train_loss:3.6570 train_time:349260ms step_avg:371.16ms
step:952/1875 train_loss:3.7166 train_time:349622ms step_avg:371.15ms
step:953/1875 train_loss:3.8146 train_time:349995ms step_avg:371.15ms
step:954/1875 train_loss:3.6794 train_time:350378ms step_avg:371.16ms
step:955/1875 train_loss:3.7275 train_time:350740ms step_avg:371.15ms
step:956/1875 train_loss:3.6913 train_time:351106ms step_avg:371.15ms
step:957/1875 train_loss:3.7502 train_time:351482ms step_avg:371.15ms
step:958/1875 train_loss:3.7549 train_time:351870ms step_avg:371.17ms
step:959/1875 train_loss:3.7590 train_time:352237ms step_avg:371.17ms
step:960/1875 train_loss:3.6440 train_time:352606ms step_avg:371.16ms
step:961/1875 train_loss:3.8853 train_time:352978ms step_avg:371.17ms
step:962/1875 train_loss:3.8481 train_time:353346ms step_avg:371.16ms
step:963/1875 train_loss:3.7187 train_time:353717ms step_avg:371.16ms
step:964/1875 train_loss:3.6713 train_time:354091ms step_avg:371.16ms
step:965/1875 train_loss:3.7439 train_time:354463ms step_avg:371.17ms
step:966/1875 train_loss:3.9617 train_time:354829ms step_avg:371.16ms
step:967/1875 train_loss:3.7766 train_time:355197ms step_avg:371.16ms
step:968/1875 train_loss:3.7704 train_time:355565ms step_avg:371.15ms
step:969/1875 train_loss:3.8172 train_time:355936ms step_avg:371.15ms
step:970/1875 train_loss:3.6190 train_time:356305ms step_avg:371.15ms
step:971/1875 train_loss:3.7898 train_time:356678ms step_avg:371.15ms
step:972/1875 train_loss:3.7321 train_time:357043ms step_avg:371.15ms
step:973/1875 train_loss:3.7944 train_time:357409ms step_avg:371.14ms
step:974/1875 train_loss:3.8509 train_time:357779ms step_avg:371.14ms
step:975/1875 train_loss:3.7207 train_time:358147ms step_avg:371.14ms
step:976/1875 train_loss:3.9163 train_time:358517ms step_avg:371.14ms
step:977/1875 train_loss:3.8169 train_time:358883ms step_avg:371.13ms
step:978/1875 train_loss:3.6206 train_time:359247ms step_avg:371.12ms
step:979/1875 train_loss:3.8875 train_time:359617ms step_avg:371.12ms
step:980/1875 train_loss:3.6697 train_time:359994ms step_avg:371.13ms
step:981/1875 train_loss:3.8257 train_time:360373ms step_avg:371.14ms
step:982/1875 train_loss:3.8063 train_time:360739ms step_avg:371.13ms
step:983/1875 train_loss:3.7745 train_time:361113ms step_avg:371.13ms
step:984/1875 train_loss:3.7477 train_time:361480ms step_avg:371.13ms
step:985/1875 train_loss:3.8322 train_time:361857ms step_avg:371.14ms
step:986/1875 train_loss:3.6482 train_time:362230ms step_avg:371.14ms
step:987/1875 train_loss:3.7395 train_time:362598ms step_avg:371.13ms
step:988/1875 train_loss:3.7356 train_time:362962ms step_avg:371.13ms
step:989/1875 train_loss:3.6773 train_time:363332ms step_avg:371.13ms
step:990/1875 train_loss:3.8810 train_time:363701ms step_avg:371.12ms
step:991/1875 train_loss:3.7268 train_time:364066ms step_avg:371.12ms
step:992/1875 train_loss:3.6836 train_time:364445ms step_avg:371.13ms
step:993/1875 train_loss:3.7608 train_time:364839ms step_avg:371.15ms
step:994/1875 train_loss:3.8488 train_time:365205ms step_avg:371.14ms
step:995/1875 train_loss:3.7895 train_time:365571ms step_avg:371.14ms
step:996/1875 train_loss:3.7037 train_time:365936ms step_avg:371.13ms
step:997/1875 train_loss:4.0260 train_time:366303ms step_avg:371.13ms
step:998/1875 train_loss:3.7015 train_time:366667ms step_avg:371.12ms
step:999/1875 train_loss:3.8273 train_time:367036ms step_avg:371.12ms
step:1000/1875 train_loss:3.6899 train_time:367409ms step_avg:371.12ms
step:1000/1875 val_loss:3.7236 train_time:367626ms step_avg:371.34ms
============== Weight norms: ==============
name = 'module._orig_mod.transformer.h.0.attn.c_q.weight' | fro_norm = 39.11153 | spectral_norm = 14.68468 | nuclear_norm = 759.37305
name = 'module._orig_mod.transformer.h.0.attn.c_k.weight' | fro_norm = 36.89563 | spectral_norm = 13.93329 | nuclear_norm = 708.66840
name = 'module._orig_mod.transformer.h.1.attn.c_q.weight' | fro_norm = 37.03581 | spectral_norm = 9.09858 | nuclear_norm = 722.51605
name = 'module._orig_mod.transformer.h.1.attn.c_k.weight' | fro_norm = 34.04316 | spectral_norm = 8.20922 | nuclear_norm = 678.13849
name = 'module._orig_mod.transformer.h.2.attn.c_q.weight' | fro_norm = 37.14354 | spectral_norm = 9.05920 | nuclear_norm = 721.71899
name = 'module._orig_mod.transformer.h.2.attn.c_k.weight' | fro_norm = 35.61270 | spectral_norm = 8.88844 | nuclear_norm = 705.48682
name = 'module._orig_mod.transformer.h.3.attn.c_q.weight' | fro_norm = 37.10001 | spectral_norm = 6.42531 | nuclear_norm = 704.50342
name = 'module._orig_mod.transformer.h.3.attn.c_k.weight' | fro_norm = 35.93393 | spectral_norm = 5.93398 | nuclear_norm = 710.20496
name = 'module._orig_mod.transformer.h.4.attn.c_q.weight' | fro_norm = 37.42492 | spectral_norm = 6.60550 | nuclear_norm = 733.52124
name = 'module._orig_mod.transformer.h.4.attn.c_k.weight' | fro_norm = 36.07519 | spectral_norm = 6.06673 | nuclear_norm = 730.62122
name = 'module._orig_mod.transformer.h.5.attn.c_q.weight' | fro_norm = 37.54170 | spectral_norm = 6.99475 | nuclear_norm = 739.32013
name = 'module._orig_mod.transformer.h.5.attn.c_k.weight' | fro_norm = 35.99149 | spectral_norm = 6.61690 | nuclear_norm = 724.18433
name = 'module._orig_mod.transformer.h.6.attn.c_q.weight' | fro_norm = 36.62308 | spectral_norm = 7.39129 | nuclear_norm = 705.11511
name = 'module._orig_mod.transformer.h.6.attn.c_k.weight' | fro_norm = 34.14902 | spectral_norm = 7.83561 | nuclear_norm = 676.17041
name = 'module._orig_mod.transformer.h.7.attn.c_q.weight' | fro_norm = 37.75370 | spectral_norm = 6.56147 | nuclear_norm = 746.43152
name = 'module._orig_mod.transformer.h.7.attn.c_k.weight' | fro_norm = 35.89283 | spectral_norm = 6.16595 | nuclear_norm = 730.64423
name = 'module._orig_mod.transformer.h.8.attn.c_q.weight' | fro_norm = 37.90490 | spectral_norm = 6.92871 | nuclear_norm = 747.34888
name = 'module._orig_mod.transformer.h.8.attn.c_k.weight' | fro_norm = 36.17630 | spectral_norm = 6.65403 | nuclear_norm = 727.37750
name = 'module._orig_mod.transformer.h.9.attn.c_q.weight' | fro_norm = 36.96809 | spectral_norm = 7.88424 | nuclear_norm = 718.09570
name = 'module._orig_mod.transformer.h.9.attn.c_k.weight' | fro_norm = 35.41373 | spectral_norm = 6.54765 | nuclear_norm = 708.91699
name = 'module._orig_mod.transformer.h.10.attn.c_q.weight' | fro_norm = 36.37550 | spectral_norm = 7.56264 | nuclear_norm = 722.00043
name = 'module._orig_mod.transformer.h.10.attn.c_k.weight' | fro_norm = 34.44675 | spectral_norm = 5.85317 | nuclear_norm = 702.42169
name = 'module._orig_mod.transformer.h.11.attn.c_q.weight' | fro_norm = 34.99846 | spectral_norm = 8.04756 | nuclear_norm = 688.02271
name = 'module._orig_mod.transformer.h.11.attn.c_k.weight' | fro_norm = 32.27401 | spectral_norm = 6.24731 | nuclear_norm = 652.05853
===========================================
step:1001/1875 train_loss:3.7501 train_time:367778ms step_avg:371.12ms
step:1002/1875 train_loss:3.6418 train_time:368130ms step_avg:371.10ms
step:1003/1875 train_loss:3.8040 train_time:368501ms step_avg:371.10ms
step:1004/1875 train_loss:3.8635 train_time:368874ms step_avg:371.10ms
step:1005/1875 train_loss:3.6509 train_time:369240ms step_avg:371.10ms
step:1006/1875 train_loss:3.7112 train_time:369612ms step_avg:371.10ms
step:1007/1875 train_loss:3.6992 train_time:369982ms step_avg:371.10ms
step:1008/1875 train_loss:3.8264 train_time:370346ms step_avg:371.09ms
step:1009/1875 train_loss:3.9270 train_time:370729ms step_avg:371.10ms
step:1010/1875 train_loss:3.8200 train_time:371095ms step_avg:371.09ms
step:1011/1875 train_loss:3.7763 train_time:371464ms step_avg:371.09ms
step:1012/1875 train_loss:3.6446 train_time:371828ms step_avg:371.09ms
step:1013/1875 train_loss:3.7913 train_time:372201ms step_avg:371.09ms
step:1014/1875 train_loss:3.8891 train_time:372571ms step_avg:371.09ms
step:1015/1875 train_loss:3.5839 train_time:372952ms step_avg:371.10ms
step:1016/1875 train_loss:3.6817 train_time:373320ms step_avg:371.09ms
step:1017/1875 train_loss:3.6822 train_time:373691ms step_avg:371.09ms
step:1018/1875 train_loss:3.6412 train_time:374067ms step_avg:371.10ms
step:1019/1875 train_loss:3.7794 train_time:374443ms step_avg:371.10ms
step:1020/1875 train_loss:3.6592 train_time:374808ms step_avg:371.10ms
step:1021/1875 train_loss:3.6148 train_time:375174ms step_avg:371.09ms
step:1022/1875 train_loss:3.7317 train_time:375540ms step_avg:371.09ms
step:1023/1875 train_loss:3.7743 train_time:375914ms step_avg:371.09ms
step:1024/1875 train_loss:3.7265 train_time:376285ms step_avg:371.09ms
step:1025/1875 train_loss:3.7456 train_time:376655ms step_avg:371.09ms
step:1026/1875 train_loss:3.8829 train_time:377023ms step_avg:371.09ms
step:1027/1875 train_loss:3.5790 train_time:377390ms step_avg:371.08ms
step:1028/1875 train_loss:3.6433 train_time:377762ms step_avg:371.08ms
step:1029/1875 train_loss:3.5843 train_time:378137ms step_avg:371.09ms
step:1030/1875 train_loss:3.7834 train_time:378511ms step_avg:371.09ms
step:1031/1875 train_loss:3.7668 train_time:378877ms step_avg:371.08ms
step:1032/1875 train_loss:3.9509 train_time:379260ms step_avg:371.10ms
step:1033/1875 train_loss:3.7520 train_time:379626ms step_avg:371.09ms
step:1034/1875 train_loss:3.7043 train_time:379991ms step_avg:371.08ms
step:1035/1875 train_loss:3.7044 train_time:380363ms step_avg:371.09ms
step:1036/1875 train_loss:3.7514 train_time:380731ms step_avg:371.08ms
step:1037/1875 train_loss:4.0537 train_time:381097ms step_avg:371.08ms
step:1038/1875 train_loss:3.8805 train_time:381466ms step_avg:371.08ms
step:1039/1875 train_loss:3.7717 train_time:381840ms step_avg:371.08ms
step:1040/1875 train_loss:3.6695 train_time:382212ms step_avg:371.08ms
step:1041/1875 train_loss:3.7384 train_time:382582ms step_avg:371.08ms
step:1042/1875 train_loss:3.7818 train_time:382946ms step_avg:371.07ms
step:1043/1875 train_loss:3.6903 train_time:383310ms step_avg:371.06ms
step:1044/1875 train_loss:3.7114 train_time:383681ms step_avg:371.06ms
step:1045/1875 train_loss:3.7772 train_time:384052ms step_avg:371.06ms
step:1046/1875 train_loss:3.6873 train_time:384419ms step_avg:371.06ms
step:1047/1875 train_loss:3.8916 train_time:384789ms step_avg:371.06ms
step:1048/1875 train_loss:3.7661 train_time:385158ms step_avg:371.06ms
step:1049/1875 train_loss:3.6677 train_time:385529ms step_avg:371.06ms
step:1050/1875 train_loss:3.6497 train_time:385903ms step_avg:371.06ms
step:1051/1875 train_loss:3.7699 train_time:386277ms step_avg:371.06ms
step:1052/1875 train_loss:3.6176 train_time:386649ms step_avg:371.06ms
step:1053/1875 train_loss:3.9478 train_time:387025ms step_avg:371.07ms
step:1054/1875 train_loss:3.7946 train_time:387394ms step_avg:371.07ms
step:1055/1875 train_loss:3.6388 train_time:387762ms step_avg:371.06ms
step:1056/1875 train_loss:3.7533 train_time:388130ms step_avg:371.06ms
step:1057/1875 train_loss:3.8384 train_time:388500ms step_avg:371.06ms
step:1058/1875 train_loss:3.5644 train_time:388876ms step_avg:371.06ms
step:1059/1875 train_loss:3.6377 train_time:389244ms step_avg:371.06ms
step:1060/1875 train_loss:3.7013 train_time:389619ms step_avg:371.07ms
step:1061/1875 train_loss:3.6815 train_time:389985ms step_avg:371.06ms
step:1062/1875 train_loss:3.6439 train_time:390354ms step_avg:371.06ms
step:1063/1875 train_loss:3.7340 train_time:390723ms step_avg:371.06ms
step:1064/1875 train_loss:3.6590 train_time:391087ms step_avg:371.05ms
step:1065/1875 train_loss:3.6122 train_time:391457ms step_avg:371.05ms
step:1066/1875 train_loss:3.6610 train_time:391835ms step_avg:371.06ms
step:1067/1875 train_loss:3.5520 train_time:392205ms step_avg:371.05ms
step:1068/1875 train_loss:3.6856 train_time:392573ms step_avg:371.05ms
step:1069/1875 train_loss:3.5762 train_time:392953ms step_avg:371.06ms
step:1070/1875 train_loss:3.8156 train_time:393320ms step_avg:371.06ms
step:1071/1875 train_loss:3.7619 train_time:393694ms step_avg:371.06ms
step:1072/1875 train_loss:3.7050 train_time:394057ms step_avg:371.05ms
step:1073/1875 train_loss:3.7866 train_time:394424ms step_avg:371.05ms
step:1074/1875 train_loss:3.7276 train_time:394791ms step_avg:371.04ms
step:1075/1875 train_loss:3.6634 train_time:395160ms step_avg:371.04ms
step:1076/1875 train_loss:4.0338 train_time:395527ms step_avg:371.04ms
step:1077/1875 train_loss:3.7246 train_time:395894ms step_avg:371.03ms
step:1078/1875 train_loss:3.3455 train_time:396270ms step_avg:371.04ms
step:1079/1875 train_loss:3.7870 train_time:396652ms step_avg:371.05ms
step:1080/1875 train_loss:3.6893 train_time:397021ms step_avg:371.05ms
step:1081/1875 train_loss:3.7783 train_time:397391ms step_avg:371.05ms
step:1082/1875 train_loss:3.8535 train_time:397758ms step_avg:371.04ms
step:1083/1875 train_loss:3.7653 train_time:398127ms step_avg:371.04ms
step:1084/1875 train_loss:3.7487 train_time:398496ms step_avg:371.04ms
step:1085/1875 train_loss:3.6843 train_time:398867ms step_avg:371.04ms
step:1086/1875 train_loss:3.8998 train_time:399238ms step_avg:371.04ms
step:1087/1875 train_loss:3.7845 train_time:399609ms step_avg:371.04ms
step:1088/1875 train_loss:3.6302 train_time:399976ms step_avg:371.03ms
step:1089/1875 train_loss:3.6474 train_time:400354ms step_avg:371.04ms
step:1090/1875 train_loss:3.7565 train_time:400735ms step_avg:371.05ms
step:1091/1875 train_loss:3.5473 train_time:401108ms step_avg:371.05ms
step:1092/1875 train_loss:3.7603 train_time:401483ms step_avg:371.06ms
step:1093/1875 train_loss:3.8779 train_time:401855ms step_avg:371.06ms
step:1094/1875 train_loss:3.7203 train_time:402223ms step_avg:371.05ms
step:1095/1875 train_loss:3.6826 train_time:402592ms step_avg:371.05ms
step:1096/1875 train_loss:3.6982 train_time:402967ms step_avg:371.06ms
step:1097/1875 train_loss:3.7508 train_time:403345ms step_avg:371.06ms
step:1098/1875 train_loss:3.8212 train_time:403714ms step_avg:371.06ms
step:1099/1875 train_loss:3.7879 train_time:404082ms step_avg:371.06ms
step:1100/1875 train_loss:3.7151 train_time:404453ms step_avg:371.06ms
step:1101/1875 train_loss:3.5530 train_time:404831ms step_avg:371.06ms
step:1102/1875 train_loss:3.6082 train_time:405202ms step_avg:371.06ms
step:1103/1875 train_loss:3.7218 train_time:405579ms step_avg:371.07ms
step:1104/1875 train_loss:3.5919 train_time:405949ms step_avg:371.07ms
step:1105/1875 train_loss:4.3060 train_time:406318ms step_avg:371.07ms
step:1106/1875 train_loss:3.5058 train_time:406691ms step_avg:371.07ms
step:1107/1875 train_loss:3.8371 train_time:407055ms step_avg:371.06ms
step:1108/1875 train_loss:3.6189 train_time:407423ms step_avg:371.06ms
step:1109/1875 train_loss:3.7597 train_time:407790ms step_avg:371.06ms
step:1110/1875 train_loss:3.7060 train_time:408158ms step_avg:371.05ms
step:1111/1875 train_loss:3.7463 train_time:408529ms step_avg:371.05ms
step:1112/1875 train_loss:3.8309 train_time:408900ms step_avg:371.05ms
step:1113/1875 train_loss:3.7189 train_time:409288ms step_avg:371.07ms
step:1114/1875 train_loss:3.6309 train_time:409658ms step_avg:371.07ms
step:1115/1875 train_loss:3.5180 train_time:410028ms step_avg:371.07ms
step:1116/1875 train_loss:3.7010 train_time:410394ms step_avg:371.06ms
step:1117/1875 train_loss:3.8691 train_time:410766ms step_avg:371.06ms
step:1118/1875 train_loss:3.8945 train_time:411142ms step_avg:371.07ms
step:1119/1875 train_loss:3.7470 train_time:411512ms step_avg:371.07ms
step:1120/1875 train_loss:3.7777 train_time:411882ms step_avg:371.06ms
step:1121/1875 train_loss:3.6653 train_time:412254ms step_avg:371.07ms
step:1122/1875 train_loss:3.7286 train_time:412622ms step_avg:371.06ms
step:1123/1875 train_loss:3.8627 train_time:412986ms step_avg:371.06ms
step:1124/1875 train_loss:3.6276 train_time:413361ms step_avg:371.06ms
step:1125/1875 train_loss:3.4829 train_time:413730ms step_avg:371.06ms
step:1125/1875 val_loss:3.6869 train_time:413949ms step_avg:371.25ms
============== Weight norms: ==============
name = 'module._orig_mod.transformer.h.0.attn.c_q.weight' | fro_norm = 41.24289 | spectral_norm = 15.38850 | nuclear_norm = 800.66553
name = 'module._orig_mod.transformer.h.0.attn.c_k.weight' | fro_norm = 38.89405 | spectral_norm = 14.78925 | nuclear_norm = 745.86005
name = 'module._orig_mod.transformer.h.1.attn.c_q.weight' | fro_norm = 38.98839 | spectral_norm = 9.50276 | nuclear_norm = 759.46863
name = 'module._orig_mod.transformer.h.1.attn.c_k.weight' | fro_norm = 35.90326 | spectral_norm = 8.64280 | nuclear_norm = 712.60498
name = 'module._orig_mod.transformer.h.2.attn.c_q.weight' | fro_norm = 39.16174 | spectral_norm = 9.46526 | nuclear_norm = 759.45740
name = 'module._orig_mod.transformer.h.2.attn.c_k.weight' | fro_norm = 37.53398 | spectral_norm = 9.28464 | nuclear_norm = 741.82574
name = 'module._orig_mod.transformer.h.3.attn.c_q.weight' | fro_norm = 39.08414 | spectral_norm = 6.66129 | nuclear_norm = 742.00348
name = 'module._orig_mod.transformer.h.3.attn.c_k.weight' | fro_norm = 37.85802 | spectral_norm = 6.14190 | nuclear_norm = 747.41168
name = 'module._orig_mod.transformer.h.4.attn.c_q.weight' | fro_norm = 39.57751 | spectral_norm = 6.82073 | nuclear_norm = 775.30670
name = 'module._orig_mod.transformer.h.4.attn.c_k.weight' | fro_norm = 38.09472 | spectral_norm = 6.30187 | nuclear_norm = 771.62848
name = 'module._orig_mod.transformer.h.5.attn.c_q.weight' | fro_norm = 39.71146 | spectral_norm = 7.38349 | nuclear_norm = 781.48010
name = 'module._orig_mod.transformer.h.5.attn.c_k.weight' | fro_norm = 38.08355 | spectral_norm = 6.96243 | nuclear_norm = 765.32764
name = 'module._orig_mod.transformer.h.6.attn.c_q.weight' | fro_norm = 38.81079 | spectral_norm = 7.72311 | nuclear_norm = 745.34424
name = 'module._orig_mod.transformer.h.6.attn.c_k.weight' | fro_norm = 36.21349 | spectral_norm = 8.20561 | nuclear_norm = 714.64417
name = 'module._orig_mod.transformer.h.7.attn.c_q.weight' | fro_norm = 39.98183 | spectral_norm = 6.84514 | nuclear_norm = 791.40533
name = 'module._orig_mod.transformer.h.7.attn.c_k.weight' | fro_norm = 38.00541 | spectral_norm = 6.42864 | nuclear_norm = 773.88440
name = 'module._orig_mod.transformer.h.8.attn.c_q.weight' | fro_norm = 40.14493 | spectral_norm = 7.29967 | nuclear_norm = 792.54065
name = 'module._orig_mod.transformer.h.8.attn.c_k.weight' | fro_norm = 38.29895 | spectral_norm = 7.00948 | nuclear_norm = 770.57526
name = 'module._orig_mod.transformer.h.9.attn.c_q.weight' | fro_norm = 39.27951 | spectral_norm = 8.13226 | nuclear_norm = 764.23169
name = 'module._orig_mod.transformer.h.9.attn.c_k.weight' | fro_norm = 37.61387 | spectral_norm = 6.79639 | nuclear_norm = 752.30139
name = 'module._orig_mod.transformer.h.10.attn.c_q.weight' | fro_norm = 38.60752 | spectral_norm = 7.75600 | nuclear_norm = 767.34595
name = 'module._orig_mod.transformer.h.10.attn.c_k.weight' | fro_norm = 36.47825 | spectral_norm = 6.07130 | nuclear_norm = 743.98236
name = 'module._orig_mod.transformer.h.11.attn.c_q.weight' | fro_norm = 37.27576 | spectral_norm = 8.22548 | nuclear_norm = 732.66162
name = 'module._orig_mod.transformer.h.11.attn.c_k.weight' | fro_norm = 34.21291 | spectral_norm = 6.36281 | nuclear_norm = 689.58911
===========================================
step:1126/1875 train_loss:3.7566 train_time:414098ms step_avg:371.06ms
step:1127/1875 train_loss:3.9665 train_time:414453ms step_avg:371.04ms
step:1128/1875 train_loss:3.5107 train_time:414819ms step_avg:371.04ms
step:1129/1875 train_loss:3.8286 train_time:415189ms step_avg:371.04ms
step:1130/1875 train_loss:3.6657 train_time:415555ms step_avg:371.03ms
step:1131/1875 train_loss:3.6695 train_time:415936ms step_avg:371.04ms
step:1132/1875 train_loss:3.6372 train_time:416304ms step_avg:371.04ms
step:1133/1875 train_loss:3.7894 train_time:416671ms step_avg:371.03ms
step:1134/1875 train_loss:3.7251 train_time:417146ms step_avg:371.13ms
step:1135/1875 train_loss:3.7929 train_time:417515ms step_avg:371.12ms
step:1136/1875 train_loss:3.8262 train_time:417883ms step_avg:371.12ms
step:1137/1875 train_loss:3.7390 train_time:418251ms step_avg:371.12ms
step:1138/1875 train_loss:3.6295 train_time:418620ms step_avg:371.12ms
step:1139/1875 train_loss:3.9450 train_time:419116ms step_avg:371.23ms
step:1140/1875 train_loss:3.7470 train_time:419481ms step_avg:371.22ms
step:1141/1875 train_loss:3.8545 train_time:419855ms step_avg:371.22ms
step:1142/1875 train_loss:3.7380 train_time:420226ms step_avg:371.22ms
step:1143/1875 train_loss:3.6417 train_time:420604ms step_avg:371.23ms
step:1144/1875 train_loss:3.7366 train_time:420974ms step_avg:371.23ms
step:1145/1875 train_loss:3.8780 train_time:421339ms step_avg:371.22ms
step:1146/1875 train_loss:3.8156 train_time:421714ms step_avg:371.23ms
step:1147/1875 train_loss:3.7528 train_time:422086ms step_avg:371.23ms
step:1148/1875 train_loss:3.7742 train_time:422455ms step_avg:371.23ms
step:1149/1875 train_loss:3.6136 train_time:422821ms step_avg:371.22ms
step:1150/1875 train_loss:3.6459 train_time:423186ms step_avg:371.22ms
step:1151/1875 train_loss:3.5983 train_time:423558ms step_avg:371.22ms
step:1152/1875 train_loss:3.7009 train_time:423926ms step_avg:371.21ms
step:1153/1875 train_loss:3.7133 train_time:424302ms step_avg:371.22ms
step:1154/1875 train_loss:3.7915 train_time:424669ms step_avg:371.21ms
step:1155/1875 train_loss:3.6067 train_time:425034ms step_avg:371.21ms
step:1156/1875 train_loss:3.8079 train_time:425413ms step_avg:371.22ms
step:1157/1875 train_loss:3.7706 train_time:425788ms step_avg:371.22ms
step:1158/1875 train_loss:3.5603 train_time:426156ms step_avg:371.22ms
step:1159/1875 train_loss:3.6114 train_time:426527ms step_avg:371.22ms
step:1160/1875 train_loss:3.6026 train_time:426892ms step_avg:371.21ms
step:1161/1875 train_loss:3.3681 train_time:427260ms step_avg:371.21ms
step:1162/1875 train_loss:3.7065 train_time:427632ms step_avg:371.21ms
step:1163/1875 train_loss:3.6771 train_time:427999ms step_avg:371.20ms
step:1164/1875 train_loss:3.5697 train_time:428370ms step_avg:371.20ms
step:1165/1875 train_loss:3.5496 train_time:428736ms step_avg:371.20ms
step:1166/1875 train_loss:3.6643 train_time:429106ms step_avg:371.20ms
step:1167/1875 train_loss:3.6746 train_time:429472ms step_avg:371.19ms
step:1168/1875 train_loss:3.9913 train_time:429838ms step_avg:371.19ms
step:1169/1875 train_loss:3.6675 train_time:430212ms step_avg:371.19ms
step:1170/1875 train_loss:3.6695 train_time:430581ms step_avg:371.19ms
step:1171/1875 train_loss:3.5991 train_time:430951ms step_avg:371.19ms
step:1172/1875 train_loss:3.6833 train_time:431319ms step_avg:371.19ms
step:1173/1875 train_loss:3.8249 train_time:431688ms step_avg:371.18ms
step:1174/1875 train_loss:3.6630 train_time:432073ms step_avg:371.20ms
step:1175/1875 train_loss:3.6636 train_time:432445ms step_avg:371.20ms
step:1176/1875 train_loss:3.7008 train_time:432822ms step_avg:371.20ms
step:1177/1875 train_loss:3.7264 train_time:433205ms step_avg:371.21ms
step:1178/1875 train_loss:3.7780 train_time:433571ms step_avg:371.21ms
step:1179/1875 train_loss:3.7001 train_time:433939ms step_avg:371.20ms
step:1180/1875 train_loss:3.6458 train_time:434323ms step_avg:371.22ms
step:1181/1875 train_loss:3.6241 train_time:434695ms step_avg:371.22ms
step:1182/1875 train_loss:3.6835 train_time:435064ms step_avg:371.22ms
step:1183/1875 train_loss:3.6092 train_time:435432ms step_avg:371.21ms
step:1184/1875 train_loss:3.7836 train_time:435801ms step_avg:371.21ms
step:1185/1875 train_loss:3.8240 train_time:436177ms step_avg:371.21ms
step:1186/1875 train_loss:3.6305 train_time:436543ms step_avg:371.21ms
step:1187/1875 train_loss:3.6921 train_time:436930ms step_avg:371.22ms
step:1188/1875 train_loss:3.7274 train_time:437295ms step_avg:371.22ms
step:1189/1875 train_loss:3.5467 train_time:437666ms step_avg:371.22ms
step:1190/1875 train_loss:3.7214 train_time:438039ms step_avg:371.22ms
step:1191/1875 train_loss:3.8592 train_time:438420ms step_avg:371.23ms
step:1192/1875 train_loss:3.6799 train_time:438790ms step_avg:371.23ms
step:1193/1875 train_loss:3.5501 train_time:439156ms step_avg:371.22ms
step:1194/1875 train_loss:3.8395 train_time:439527ms step_avg:371.22ms
step:1195/1875 train_loss:3.6555 train_time:439894ms step_avg:371.22ms
step:1196/1875 train_loss:3.6625 train_time:440286ms step_avg:371.24ms
step:1197/1875 train_loss:3.5663 train_time:440658ms step_avg:371.24ms
step:1198/1875 train_loss:3.5718 train_time:441037ms step_avg:371.24ms
step:1199/1875 train_loss:3.6201 train_time:441410ms step_avg:371.24ms
step:1200/1875 train_loss:3.7156 train_time:441780ms step_avg:371.24ms
step:1201/1875 train_loss:3.7696 train_time:442148ms step_avg:371.24ms
step:1202/1875 train_loss:3.8396 train_time:442532ms step_avg:371.25ms
step:1203/1875 train_loss:3.6858 train_time:442915ms step_avg:371.26ms
step:1204/1875 train_loss:3.6106 train_time:443285ms step_avg:371.26ms
step:1205/1875 train_loss:3.6994 train_time:443655ms step_avg:371.26ms
step:1206/1875 train_loss:3.7565 train_time:444030ms step_avg:371.26ms
step:1207/1875 train_loss:3.7964 train_time:444392ms step_avg:371.26ms
step:1208/1875 train_loss:3.6879 train_time:444755ms step_avg:371.25ms
step:1209/1875 train_loss:3.5193 train_time:445124ms step_avg:371.25ms
step:1210/1875 train_loss:3.5865 train_time:445503ms step_avg:371.25ms
step:1211/1875 train_loss:3.6901 train_time:445872ms step_avg:371.25ms
step:1212/1875 train_loss:3.6791 train_time:446236ms step_avg:371.24ms
step:1213/1875 train_loss:3.7037 train_time:446607ms step_avg:371.24ms
step:1214/1875 train_loss:3.5826 train_time:446981ms step_avg:371.25ms
step:1215/1875 train_loss:3.6761 train_time:447352ms step_avg:371.25ms
step:1216/1875 train_loss:3.6222 train_time:447718ms step_avg:371.24ms
step:1217/1875 train_loss:3.6400 train_time:448087ms step_avg:371.24ms
step:1218/1875 train_loss:3.7091 train_time:448458ms step_avg:371.24ms
step:1219/1875 train_loss:3.5402 train_time:448837ms step_avg:371.25ms
step:1220/1875 train_loss:3.7623 train_time:449212ms step_avg:371.25ms
step:1221/1875 train_loss:3.7994 train_time:449576ms step_avg:371.24ms
step:1222/1875 train_loss:3.7316 train_time:449945ms step_avg:371.24ms
step:1223/1875 train_loss:3.5743 train_time:450315ms step_avg:371.24ms
step:1224/1875 train_loss:3.5566 train_time:450689ms step_avg:371.24ms
step:1225/1875 train_loss:3.6626 train_time:451061ms step_avg:371.24ms
step:1226/1875 train_loss:3.6142 train_time:451436ms step_avg:371.25ms
step:1227/1875 train_loss:3.5453 train_time:451808ms step_avg:371.25ms
step:1228/1875 train_loss:3.7295 train_time:452178ms step_avg:371.25ms
step:1229/1875 train_loss:3.6545 train_time:452546ms step_avg:371.24ms
step:1230/1875 train_loss:3.6917 train_time:452923ms step_avg:371.25ms
step:1231/1875 train_loss:3.8746 train_time:453297ms step_avg:371.25ms
step:1232/1875 train_loss:3.7811 train_time:453673ms step_avg:371.25ms
step:1233/1875 train_loss:3.7156 train_time:454039ms step_avg:371.25ms
step:1234/1875 train_loss:3.8827 train_time:454405ms step_avg:371.25ms
step:1235/1875 train_loss:3.6270 train_time:454783ms step_avg:371.25ms
step:1236/1875 train_loss:3.5836 train_time:455148ms step_avg:371.25ms
step:1237/1875 train_loss:3.5598 train_time:455514ms step_avg:371.24ms
step:1238/1875 train_loss:3.6030 train_time:455896ms step_avg:371.25ms
step:1239/1875 train_loss:3.6080 train_time:456263ms step_avg:371.25ms
step:1240/1875 train_loss:3.6752 train_time:456637ms step_avg:371.25ms
step:1241/1875 train_loss:3.7237 train_time:457015ms step_avg:371.26ms
step:1242/1875 train_loss:3.5859 train_time:457383ms step_avg:371.25ms
step:1243/1875 train_loss:3.6999 train_time:457753ms step_avg:371.25ms
step:1244/1875 train_loss:3.7039 train_time:458120ms step_avg:371.25ms
step:1245/1875 train_loss:3.7091 train_time:458490ms step_avg:371.25ms
step:1246/1875 train_loss:3.5295 train_time:458858ms step_avg:371.24ms
step:1247/1875 train_loss:3.6715 train_time:459230ms step_avg:371.25ms
step:1248/1875 train_loss:3.7337 train_time:459597ms step_avg:371.24ms
step:1249/1875 train_loss:3.7046 train_time:459966ms step_avg:371.24ms
step:1250/1875 train_loss:3.5851 train_time:460331ms step_avg:371.24ms
step:1250/1875 val_loss:3.6496 train_time:460553ms step_avg:371.41ms
============== Weight norms: ==============
name = 'module._orig_mod.transformer.h.0.attn.c_q.weight' | fro_norm = 43.29088 | spectral_norm = 16.15514 | nuclear_norm = 840.18512
name = 'module._orig_mod.transformer.h.0.attn.c_k.weight' | fro_norm = 40.83867 | spectral_norm = 15.61297 | nuclear_norm = 782.46295
name = 'module._orig_mod.transformer.h.1.attn.c_q.weight' | fro_norm = 40.90805 | spectral_norm = 9.84711 | nuclear_norm = 795.85852
name = 'module._orig_mod.transformer.h.1.attn.c_k.weight' | fro_norm = 37.70956 | spectral_norm = 9.07045 | nuclear_norm = 746.37695
name = 'module._orig_mod.transformer.h.2.attn.c_q.weight' | fro_norm = 41.11664 | spectral_norm = 9.84334 | nuclear_norm = 796.56635
name = 'module._orig_mod.transformer.h.2.attn.c_k.weight' | fro_norm = 39.40482 | spectral_norm = 9.71313 | nuclear_norm = 777.53345
name = 'module._orig_mod.transformer.h.3.attn.c_q.weight' | fro_norm = 41.00755 | spectral_norm = 6.89478 | nuclear_norm = 777.92957
name = 'module._orig_mod.transformer.h.3.attn.c_k.weight' | fro_norm = 39.73331 | spectral_norm = 6.45087 | nuclear_norm = 783.30035
name = 'module._orig_mod.transformer.h.4.attn.c_q.weight' | fro_norm = 41.63921 | spectral_norm = 7.15801 | nuclear_norm = 815.59119
name = 'module._orig_mod.transformer.h.4.attn.c_k.weight' | fro_norm = 40.03435 | spectral_norm = 6.56691 | nuclear_norm = 810.91333
name = 'module._orig_mod.transformer.h.5.attn.c_q.weight' | fro_norm = 41.82696 | spectral_norm = 7.69738 | nuclear_norm = 822.86206
name = 'module._orig_mod.transformer.h.5.attn.c_k.weight' | fro_norm = 40.09214 | spectral_norm = 7.25244 | nuclear_norm = 805.34424
name = 'module._orig_mod.transformer.h.6.attn.c_q.weight' | fro_norm = 40.92863 | spectral_norm = 8.12647 | nuclear_norm = 784.01190
name = 'module._orig_mod.transformer.h.6.attn.c_k.weight' | fro_norm = 38.22322 | spectral_norm = 8.55299 | nuclear_norm = 752.09534
name = 'module._orig_mod.transformer.h.7.attn.c_q.weight' | fro_norm = 42.12891 | spectral_norm = 7.14035 | nuclear_norm = 835.22803
name = 'module._orig_mod.transformer.h.7.attn.c_k.weight' | fro_norm = 40.02668 | spectral_norm = 6.60569 | nuclear_norm = 815.50092
name = 'module._orig_mod.transformer.h.8.attn.c_q.weight' | fro_norm = 42.28952 | spectral_norm = 7.60816 | nuclear_norm = 836.46155
name = 'module._orig_mod.transformer.h.8.attn.c_k.weight' | fro_norm = 40.36670 | spectral_norm = 7.33337 | nuclear_norm = 813.25269
name = 'module._orig_mod.transformer.h.9.attn.c_q.weight' | fro_norm = 41.56033 | spectral_norm = 8.39206 | nuclear_norm = 810.07324
name = 'module._orig_mod.transformer.h.9.attn.c_k.weight' | fro_norm = 39.80006 | spectral_norm = 7.02680 | nuclear_norm = 796.08826
name = 'module._orig_mod.transformer.h.10.attn.c_q.weight' | fro_norm = 40.85254 | spectral_norm = 7.92234 | nuclear_norm = 812.77045
name = 'module._orig_mod.transformer.h.10.attn.c_k.weight' | fro_norm = 38.49315 | spectral_norm = 6.31335 | nuclear_norm = 785.37305
name = 'module._orig_mod.transformer.h.11.attn.c_q.weight' | fro_norm = 39.52208 | spectral_norm = 8.53038 | nuclear_norm = 776.22205
name = 'module._orig_mod.transformer.h.11.attn.c_k.weight' | fro_norm = 36.18790 | spectral_norm = 6.64386 | nuclear_norm = 727.17688
===========================================
step:1251/1875 train_loss:3.7935 train_time:460705ms step_avg:371.24ms
step:1252/1875 train_loss:3.6782 train_time:461072ms step_avg:371.23ms
step:1253/1875 train_loss:3.5896 train_time:461436ms step_avg:371.23ms
step:1254/1875 train_loss:3.7115 train_time:461799ms step_avg:371.22ms
step:1255/1875 train_loss:3.8022 train_time:462181ms step_avg:371.23ms
step:1256/1875 train_loss:3.6063 train_time:462557ms step_avg:371.23ms
step:1257/1875 train_loss:3.6381 train_time:462925ms step_avg:371.23ms
step:1258/1875 train_loss:3.6358 train_time:463299ms step_avg:371.23ms
step:1259/1875 train_loss:3.6400 train_time:463671ms step_avg:371.23ms
step:1260/1875 train_loss:3.5065 train_time:464034ms step_avg:371.23ms
step:1261/1875 train_loss:3.5847 train_time:464402ms step_avg:371.22ms
step:1262/1875 train_loss:3.6219 train_time:464777ms step_avg:371.23ms
step:1263/1875 train_loss:3.5165 train_time:465157ms step_avg:371.23ms
step:1264/1875 train_loss:3.7395 train_time:465521ms step_avg:371.23ms
step:1265/1875 train_loss:3.7298 train_time:465886ms step_avg:371.22ms
step:1266/1875 train_loss:3.7385 train_time:466259ms step_avg:371.23ms
step:1267/1875 train_loss:3.6581 train_time:466625ms step_avg:371.22ms
step:1268/1875 train_loss:3.7028 train_time:466990ms step_avg:371.22ms
step:1269/1875 train_loss:3.5564 train_time:467363ms step_avg:371.22ms
step:1270/1875 train_loss:3.3910 train_time:467733ms step_avg:371.22ms
step:1271/1875 train_loss:3.6936 train_time:468103ms step_avg:371.22ms
step:1272/1875 train_loss:3.6534 train_time:468471ms step_avg:371.21ms
step:1273/1875 train_loss:3.6902 train_time:468842ms step_avg:371.21ms
step:1274/1875 train_loss:3.6470 train_time:469219ms step_avg:371.22ms
step:1275/1875 train_loss:3.7318 train_time:469587ms step_avg:371.21ms
step:1276/1875 train_loss:3.7703 train_time:469951ms step_avg:371.21ms
step:1277/1875 train_loss:3.7147 train_time:470319ms step_avg:371.21ms
step:1278/1875 train_loss:3.6884 train_time:470688ms step_avg:371.20ms
step:1279/1875 train_loss:3.5394 train_time:471056ms step_avg:371.20ms
step:1280/1875 train_loss:3.6645 train_time:471431ms step_avg:371.21ms
step:1281/1875 train_loss:3.7155 train_time:471801ms step_avg:371.20ms
step:1282/1875 train_loss:3.7549 train_time:472164ms step_avg:371.20ms
step:1283/1875 train_loss:3.6378 train_time:472535ms step_avg:371.20ms
step:1284/1875 train_loss:3.6750 train_time:472909ms step_avg:371.20ms
step:1285/1875 train_loss:3.6626 train_time:473277ms step_avg:371.20ms
step:1286/1875 train_loss:3.6279 train_time:473646ms step_avg:371.20ms
step:1287/1875 train_loss:3.7719 train_time:474013ms step_avg:371.19ms
step:1288/1875 train_loss:3.6051 train_time:474382ms step_avg:371.19ms
step:1289/1875 train_loss:3.6725 train_time:474749ms step_avg:371.19ms
step:1290/1875 train_loss:3.7562 train_time:475132ms step_avg:371.20ms
step:1291/1875 train_loss:3.6709 train_time:475507ms step_avg:371.20ms
step:1292/1875 train_loss:3.7730 train_time:475875ms step_avg:371.20ms
step:1293/1875 train_loss:3.8069 train_time:476247ms step_avg:371.20ms
step:1294/1875 train_loss:3.7547 train_time:476615ms step_avg:371.20ms
step:1295/1875 train_loss:3.5860 train_time:476986ms step_avg:371.19ms
step:1296/1875 train_loss:3.6690 train_time:477353ms step_avg:371.19ms
step:1297/1875 train_loss:3.5712 train_time:477726ms step_avg:371.19ms
step:1298/1875 train_loss:3.5977 train_time:478094ms step_avg:371.19ms
step:1299/1875 train_loss:3.6866 train_time:478461ms step_avg:371.19ms
step:1300/1875 train_loss:3.7070 train_time:478830ms step_avg:371.19ms
step:1301/1875 train_loss:3.7139 train_time:479197ms step_avg:371.18ms
step:1302/1875 train_loss:3.8627 train_time:479571ms step_avg:371.18ms
step:1303/1875 train_loss:3.6099 train_time:479941ms step_avg:371.18ms
step:1304/1875 train_loss:3.8313 train_time:480315ms step_avg:371.19ms
step:1305/1875 train_loss:3.5741 train_time:480684ms step_avg:371.18ms
step:1306/1875 train_loss:3.7301 train_time:481057ms step_avg:371.19ms
step:1307/1875 train_loss:3.7502 train_time:481428ms step_avg:371.19ms
step:1308/1875 train_loss:3.6069 train_time:481789ms step_avg:371.18ms
step:1309/1875 train_loss:3.5753 train_time:482163ms step_avg:371.18ms
step:1310/1875 train_loss:3.6316 train_time:482532ms step_avg:371.18ms
step:1311/1875 train_loss:3.5859 train_time:482899ms step_avg:371.18ms
step:1312/1875 train_loss:3.6925 train_time:483275ms step_avg:371.18ms
step:1313/1875 train_loss:3.6408 train_time:483640ms step_avg:371.17ms
step:1314/1875 train_loss:3.3442 train_time:484013ms step_avg:371.18ms
step:1315/1875 train_loss:3.5924 train_time:484384ms step_avg:371.18ms
step:1316/1875 train_loss:3.6832 train_time:484749ms step_avg:371.17ms
step:1317/1875 train_loss:3.7109 train_time:485112ms step_avg:371.16ms
step:1318/1875 train_loss:3.5704 train_time:485483ms step_avg:371.16ms
step:1319/1875 train_loss:3.7295 train_time:485858ms step_avg:371.17ms
step:1320/1875 train_loss:3.7518 train_time:486236ms step_avg:371.17ms
step:1321/1875 train_loss:3.6579 train_time:486608ms step_avg:371.17ms
step:1322/1875 train_loss:3.6164 train_time:486981ms step_avg:371.17ms
step:1323/1875 train_loss:3.6402 train_time:487456ms step_avg:371.25ms
step:1324/1875 train_loss:3.7290 train_time:487826ms step_avg:371.25ms
step:1325/1875 train_loss:3.7932 train_time:488203ms step_avg:371.26ms
step:1326/1875 train_loss:3.5420 train_time:488574ms step_avg:371.26ms
step:1327/1875 train_loss:3.4656 train_time:488942ms step_avg:371.25ms
step:1328/1875 train_loss:3.7844 train_time:489308ms step_avg:371.25ms
step:1329/1875 train_loss:3.6160 train_time:489814ms step_avg:371.35ms
step:1330/1875 train_loss:3.7387 train_time:490185ms step_avg:371.35ms
step:1331/1875 train_loss:3.6505 train_time:490558ms step_avg:371.35ms
step:1332/1875 train_loss:4.0426 train_time:490922ms step_avg:371.35ms
step:1333/1875 train_loss:3.7531 train_time:491295ms step_avg:371.35ms
step:1334/1875 train_loss:3.6626 train_time:491667ms step_avg:371.35ms
step:1335/1875 train_loss:3.6176 train_time:492035ms step_avg:371.35ms
step:1336/1875 train_loss:3.5992 train_time:492409ms step_avg:371.35ms
step:1337/1875 train_loss:3.8521 train_time:492778ms step_avg:371.35ms
step:1338/1875 train_loss:3.8110 train_time:493149ms step_avg:371.35ms
step:1339/1875 train_loss:3.6446 train_time:493519ms step_avg:371.35ms
step:1340/1875 train_loss:3.5950 train_time:493892ms step_avg:371.35ms
step:1341/1875 train_loss:3.8915 train_time:494263ms step_avg:371.35ms
step:1342/1875 train_loss:3.6669 train_time:494635ms step_avg:371.35ms
step:1343/1875 train_loss:3.6607 train_time:494998ms step_avg:371.34ms
step:1344/1875 train_loss:3.7096 train_time:495367ms step_avg:371.34ms
step:1345/1875 train_loss:3.6913 train_time:495748ms step_avg:371.35ms
step:1346/1875 train_loss:3.5991 train_time:496116ms step_avg:371.34ms
step:1347/1875 train_loss:3.5410 train_time:496486ms step_avg:371.34ms
step:1348/1875 train_loss:3.6328 train_time:496858ms step_avg:371.34ms
step:1349/1875 train_loss:3.5699 train_time:497230ms step_avg:371.34ms
step:1350/1875 train_loss:3.7013 train_time:497603ms step_avg:371.35ms
step:1351/1875 train_loss:3.5360 train_time:497974ms step_avg:371.34ms
step:1352/1875 train_loss:3.6008 train_time:498336ms step_avg:371.34ms
step:1353/1875 train_loss:3.7105 train_time:498712ms step_avg:371.34ms
step:1354/1875 train_loss:3.5463 train_time:499083ms step_avg:371.34ms
step:1355/1875 train_loss:3.4782 train_time:499454ms step_avg:371.34ms
step:1356/1875 train_loss:3.8180 train_time:499827ms step_avg:371.34ms
step:1357/1875 train_loss:3.7266 train_time:500197ms step_avg:371.34ms
step:1358/1875 train_loss:3.4715 train_time:500570ms step_avg:371.34ms
step:1359/1875 train_loss:3.7512 train_time:500942ms step_avg:371.34ms
step:1360/1875 train_loss:3.6542 train_time:501315ms step_avg:371.34ms
step:1361/1875 train_loss:3.4787 train_time:501681ms step_avg:371.34ms
step:1362/1875 train_loss:3.6899 train_time:502054ms step_avg:371.34ms
step:1363/1875 train_loss:3.5725 train_time:502427ms step_avg:371.34ms
step:1364/1875 train_loss:3.6121 train_time:502796ms step_avg:371.34ms
step:1365/1875 train_loss:3.6105 train_time:503162ms step_avg:371.34ms
step:1366/1875 train_loss:3.7400 train_time:503535ms step_avg:371.34ms
step:1367/1875 train_loss:3.6925 train_time:503904ms step_avg:371.34ms
step:1368/1875 train_loss:3.6619 train_time:504275ms step_avg:371.34ms
step:1369/1875 train_loss:3.5487 train_time:504652ms step_avg:371.34ms
step:1370/1875 train_loss:3.8966 train_time:505025ms step_avg:371.34ms
step:1371/1875 train_loss:3.6252 train_time:505395ms step_avg:371.34ms
step:1372/1875 train_loss:3.6625 train_time:505773ms step_avg:371.35ms
step:1373/1875 train_loss:3.6616 train_time:506137ms step_avg:371.34ms
step:1374/1875 train_loss:3.4620 train_time:506507ms step_avg:371.34ms
step:1375/1875 train_loss:3.8620 train_time:506875ms step_avg:371.34ms
step:1375/1875 val_loss:3.6176 train_time:507090ms step_avg:371.49ms
============== Weight norms: ==============
name = 'module._orig_mod.transformer.h.0.attn.c_q.weight' | fro_norm = 45.20796 | spectral_norm = 16.81030 | nuclear_norm = 877.53412
name = 'module._orig_mod.transformer.h.0.attn.c_k.weight' | fro_norm = 42.67133 | spectral_norm = 16.42266 | nuclear_norm = 816.86700
name = 'module._orig_mod.transformer.h.1.attn.c_q.weight' | fro_norm = 42.70058 | spectral_norm = 10.22506 | nuclear_norm = 830.25415
name = 'module._orig_mod.transformer.h.1.attn.c_k.weight' | fro_norm = 39.41192 | spectral_norm = 9.46519 | nuclear_norm = 778.55988
name = 'module._orig_mod.transformer.h.2.attn.c_q.weight' | fro_norm = 42.94456 | spectral_norm = 10.18766 | nuclear_norm = 831.54846
name = 'module._orig_mod.transformer.h.2.attn.c_k.weight' | fro_norm = 41.17519 | spectral_norm = 10.04734 | nuclear_norm = 811.86365
name = 'module._orig_mod.transformer.h.3.attn.c_q.weight' | fro_norm = 42.81435 | spectral_norm = 7.09225 | nuclear_norm = 812.24121
name = 'module._orig_mod.transformer.h.3.attn.c_k.weight' | fro_norm = 41.50661 | spectral_norm = 6.59275 | nuclear_norm = 817.76471
name = 'module._orig_mod.transformer.h.4.attn.c_q.weight' | fro_norm = 43.57777 | spectral_norm = 7.39303 | nuclear_norm = 853.74426
name = 'module._orig_mod.transformer.h.4.attn.c_k.weight' | fro_norm = 41.87726 | spectral_norm = 6.77450 | nuclear_norm = 848.93091
name = 'module._orig_mod.transformer.h.5.attn.c_q.weight' | fro_norm = 43.78416 | spectral_norm = 8.04024 | nuclear_norm = 861.79126
name = 'module._orig_mod.transformer.h.5.attn.c_k.weight' | fro_norm = 41.99713 | spectral_norm = 7.55462 | nuclear_norm = 844.12311
name = 'module._orig_mod.transformer.h.6.attn.c_q.weight' | fro_norm = 42.89636 | spectral_norm = 8.45627 | nuclear_norm = 821.23303
name = 'module._orig_mod.transformer.h.6.attn.c_k.weight' | fro_norm = 40.10667 | spectral_norm = 8.90376 | nuclear_norm = 788.26819
name = 'module._orig_mod.transformer.h.7.attn.c_q.weight' | fro_norm = 44.13666 | spectral_norm = 7.34415 | nuclear_norm = 876.98071
name = 'module._orig_mod.transformer.h.7.attn.c_k.weight' | fro_norm = 41.94667 | spectral_norm = 6.83144 | nuclear_norm = 855.43939
name = 'module._orig_mod.transformer.h.8.attn.c_q.weight' | fro_norm = 44.26454 | spectral_norm = 7.92728 | nuclear_norm = 876.91479
name = 'module._orig_mod.transformer.h.8.attn.c_k.weight' | fro_norm = 42.29297 | spectral_norm = 7.68619 | nuclear_norm = 853.04120
name = 'module._orig_mod.transformer.h.9.attn.c_q.weight' | fro_norm = 43.64568 | spectral_norm = 8.60993 | nuclear_norm = 852.80762
name = 'module._orig_mod.transformer.h.9.attn.c_k.weight' | fro_norm = 41.82669 | spectral_norm = 7.28378 | nuclear_norm = 837.18188
name = 'module._orig_mod.transformer.h.10.attn.c_q.weight' | fro_norm = 42.85647 | spectral_norm = 8.08709 | nuclear_norm = 854.56720
name = 'module._orig_mod.transformer.h.10.attn.c_k.weight' | fro_norm = 40.36100 | spectral_norm = 6.56182 | nuclear_norm = 824.22009
name = 'module._orig_mod.transformer.h.11.attn.c_q.weight' | fro_norm = 41.57402 | spectral_norm = 8.77351 | nuclear_norm = 816.72626
name = 'module._orig_mod.transformer.h.11.attn.c_k.weight' | fro_norm = 38.06843 | spectral_norm = 7.23840 | nuclear_norm = 762.83905
===========================================
step:1376/1875 train_loss:3.6364 train_time:507239ms step_avg:371.33ms
step:1377/1875 train_loss:3.7730 train_time:507601ms step_avg:371.32ms
step:1378/1875 train_loss:3.7959 train_time:507967ms step_avg:371.32ms
step:1379/1875 train_loss:3.4282 train_time:508337ms step_avg:371.32ms
step:1380/1875 train_loss:3.6116 train_time:508708ms step_avg:371.32ms
step:1381/1875 train_loss:4.0212 train_time:509079ms step_avg:371.32ms
step:1382/1875 train_loss:3.5333 train_time:509449ms step_avg:371.32ms
step:1383/1875 train_loss:3.6969 train_time:509818ms step_avg:371.32ms
step:1384/1875 train_loss:3.7739 train_time:510191ms step_avg:371.32ms
step:1385/1875 train_loss:3.6972 train_time:510555ms step_avg:371.31ms
step:1386/1875 train_loss:3.6726 train_time:510924ms step_avg:371.31ms
step:1387/1875 train_loss:3.4930 train_time:511298ms step_avg:371.31ms
step:1388/1875 train_loss:3.6475 train_time:511664ms step_avg:371.31ms
step:1389/1875 train_loss:3.6151 train_time:512038ms step_avg:371.31ms
step:1390/1875 train_loss:3.8788 train_time:512406ms step_avg:371.31ms
step:1391/1875 train_loss:3.5894 train_time:512774ms step_avg:371.31ms
step:1392/1875 train_loss:3.5924 train_time:513151ms step_avg:371.31ms
step:1393/1875 train_loss:3.5555 train_time:513514ms step_avg:371.30ms
step:1394/1875 train_loss:3.8200 train_time:513880ms step_avg:371.30ms
step:1395/1875 train_loss:3.7011 train_time:514248ms step_avg:371.30ms
step:1396/1875 train_loss:3.7031 train_time:514618ms step_avg:371.30ms
step:1397/1875 train_loss:3.5954 train_time:514983ms step_avg:371.29ms
step:1398/1875 train_loss:3.5563 train_time:515351ms step_avg:371.29ms
step:1399/1875 train_loss:3.6415 train_time:515718ms step_avg:371.29ms
step:1400/1875 train_loss:3.6016 train_time:516098ms step_avg:371.29ms
step:1401/1875 train_loss:3.6295 train_time:516463ms step_avg:371.29ms
step:1402/1875 train_loss:3.5942 train_time:516827ms step_avg:371.28ms
step:1403/1875 train_loss:3.7919 train_time:517199ms step_avg:371.28ms
step:1404/1875 train_loss:3.5671 train_time:517568ms step_avg:371.28ms
step:1405/1875 train_loss:3.6061 train_time:517934ms step_avg:371.28ms
step:1406/1875 train_loss:3.6148 train_time:518303ms step_avg:371.28ms
step:1407/1875 train_loss:3.4662 train_time:518673ms step_avg:371.28ms
step:1408/1875 train_loss:3.5916 train_time:519034ms step_avg:371.27ms
step:1409/1875 train_loss:3.5822 train_time:519419ms step_avg:371.28ms
step:1410/1875 train_loss:3.5709 train_time:519791ms step_avg:371.28ms
step:1411/1875 train_loss:3.6622 train_time:520159ms step_avg:371.28ms
step:1412/1875 train_loss:3.6030 train_time:520529ms step_avg:371.28ms
step:1413/1875 train_loss:3.6535 train_time:520897ms step_avg:371.27ms
step:1414/1875 train_loss:3.6309 train_time:521270ms step_avg:371.27ms
step:1415/1875 train_loss:3.7085 train_time:521638ms step_avg:371.27ms
step:1416/1875 train_loss:3.5109 train_time:522029ms step_avg:371.29ms
step:1417/1875 train_loss:3.5764 train_time:522405ms step_avg:371.29ms
step:1418/1875 train_loss:3.6772 train_time:522776ms step_avg:371.29ms
step:1419/1875 train_loss:3.6545 train_time:523150ms step_avg:371.29ms
step:1420/1875 train_loss:3.6540 train_time:523522ms step_avg:371.29ms
step:1421/1875 train_loss:3.6557 train_time:523898ms step_avg:371.30ms
step:1422/1875 train_loss:3.6390 train_time:524266ms step_avg:371.29ms
step:1423/1875 train_loss:3.6212 train_time:524629ms step_avg:371.29ms
step:1424/1875 train_loss:3.6176 train_time:525002ms step_avg:371.29ms
step:1425/1875 train_loss:3.4792 train_time:525381ms step_avg:371.29ms
step:1426/1875 train_loss:3.6211 train_time:525752ms step_avg:371.29ms
step:1427/1875 train_loss:3.5592 train_time:526125ms step_avg:371.30ms
step:1428/1875 train_loss:3.6607 train_time:526492ms step_avg:371.29ms
step:1429/1875 train_loss:3.6521 train_time:526857ms step_avg:371.29ms
step:1430/1875 train_loss:3.5494 train_time:527228ms step_avg:371.29ms
step:1431/1875 train_loss:3.6079 train_time:527602ms step_avg:371.29ms
step:1432/1875 train_loss:3.6453 train_time:527975ms step_avg:371.29ms
step:1433/1875 train_loss:3.4391 train_time:528354ms step_avg:371.30ms
step:1434/1875 train_loss:3.5862 train_time:528732ms step_avg:371.30ms
step:1435/1875 train_loss:3.4174 train_time:529104ms step_avg:371.30ms
step:1436/1875 train_loss:3.5059 train_time:529464ms step_avg:371.29ms
step:1437/1875 train_loss:3.7013 train_time:529839ms step_avg:371.30ms
step:1438/1875 train_loss:3.6574 train_time:530209ms step_avg:371.29ms
step:1439/1875 train_loss:3.6042 train_time:530581ms step_avg:371.30ms
step:1440/1875 train_loss:3.4657 train_time:530948ms step_avg:371.29ms
step:1441/1875 train_loss:3.6447 train_time:531317ms step_avg:371.29ms
step:1442/1875 train_loss:3.6804 train_time:531689ms step_avg:371.29ms
step:1443/1875 train_loss:3.7508 train_time:532066ms step_avg:371.30ms
step:1444/1875 train_loss:3.7407 train_time:532436ms step_avg:371.29ms
step:1445/1875 train_loss:3.6256 train_time:532803ms step_avg:371.29ms
step:1446/1875 train_loss:3.5005 train_time:533175ms step_avg:371.29ms
step:1447/1875 train_loss:3.5720 train_time:533545ms step_avg:371.29ms
step:1448/1875 train_loss:3.5894 train_time:533918ms step_avg:371.29ms
step:1449/1875 train_loss:3.6936 train_time:534284ms step_avg:371.29ms
step:1450/1875 train_loss:3.6822 train_time:534654ms step_avg:371.29ms
step:1451/1875 train_loss:3.5055 train_time:535022ms step_avg:371.29ms
step:1452/1875 train_loss:3.6229 train_time:535391ms step_avg:371.28ms
step:1453/1875 train_loss:3.5495 train_time:535759ms step_avg:371.28ms
step:1454/1875 train_loss:3.5704 train_time:536124ms step_avg:371.28ms
step:1455/1875 train_loss:3.6129 train_time:536494ms step_avg:371.28ms
step:1456/1875 train_loss:3.5520 train_time:536864ms step_avg:371.27ms
step:1457/1875 train_loss:3.4518 train_time:537228ms step_avg:371.27ms
step:1458/1875 train_loss:3.6994 train_time:537598ms step_avg:371.27ms
step:1459/1875 train_loss:3.5588 train_time:537969ms step_avg:371.27ms
step:1460/1875 train_loss:3.6053 train_time:538338ms step_avg:371.27ms
step:1461/1875 train_loss:3.7323 train_time:538705ms step_avg:371.26ms
step:1462/1875 train_loss:3.5527 train_time:539070ms step_avg:371.26ms
step:1463/1875 train_loss:3.7427 train_time:539437ms step_avg:371.26ms
step:1464/1875 train_loss:3.6407 train_time:539812ms step_avg:371.26ms
step:1465/1875 train_loss:3.6383 train_time:540180ms step_avg:371.26ms
step:1466/1875 train_loss:3.5675 train_time:540545ms step_avg:371.25ms
step:1467/1875 train_loss:3.6916 train_time:540917ms step_avg:371.25ms
step:1468/1875 train_loss:3.5721 train_time:541287ms step_avg:371.25ms
step:1469/1875 train_loss:3.5343 train_time:541657ms step_avg:371.25ms
step:1470/1875 train_loss:3.6154 train_time:542031ms step_avg:371.25ms
step:1471/1875 train_loss:3.5322 train_time:542406ms step_avg:371.26ms
step:1472/1875 train_loss:3.5515 train_time:542782ms step_avg:371.26ms
step:1473/1875 train_loss:3.7118 train_time:543150ms step_avg:371.26ms
step:1474/1875 train_loss:3.6036 train_time:543520ms step_avg:371.26ms
step:1475/1875 train_loss:3.4196 train_time:543898ms step_avg:371.26ms
step:1476/1875 train_loss:3.5380 train_time:544265ms step_avg:371.26ms
step:1477/1875 train_loss:3.5230 train_time:544635ms step_avg:371.26ms
step:1478/1875 train_loss:3.6035 train_time:545012ms step_avg:371.26ms
step:1479/1875 train_loss:3.6809 train_time:545386ms step_avg:371.26ms
step:1480/1875 train_loss:3.5626 train_time:545750ms step_avg:371.26ms
step:1481/1875 train_loss:3.7360 train_time:546117ms step_avg:371.26ms
step:1482/1875 train_loss:3.6525 train_time:546492ms step_avg:371.26ms
step:1483/1875 train_loss:3.5633 train_time:546871ms step_avg:371.26ms
step:1484/1875 train_loss:3.5370 train_time:547247ms step_avg:371.27ms
step:1485/1875 train_loss:3.5505 train_time:547615ms step_avg:371.26ms
step:1486/1875 train_loss:3.4965 train_time:547985ms step_avg:371.26ms
step:1487/1875 train_loss:3.6099 train_time:548360ms step_avg:371.27ms
step:1488/1875 train_loss:3.5015 train_time:548734ms step_avg:371.27ms
step:1489/1875 train_loss:3.6088 train_time:549105ms step_avg:371.27ms
step:1490/1875 train_loss:3.5231 train_time:549478ms step_avg:371.27ms
step:1491/1875 train_loss:3.4540 train_time:549850ms step_avg:371.27ms
step:1492/1875 train_loss:3.5374 train_time:550218ms step_avg:371.27ms
step:1493/1875 train_loss:3.7175 train_time:550586ms step_avg:371.27ms
step:1494/1875 train_loss:3.5769 train_time:550950ms step_avg:371.26ms
step:1495/1875 train_loss:3.3090 train_time:551321ms step_avg:371.26ms
step:1496/1875 train_loss:3.6313 train_time:551691ms step_avg:371.26ms
step:1497/1875 train_loss:3.5861 train_time:552065ms step_avg:371.26ms
step:1498/1875 train_loss:3.6152 train_time:552436ms step_avg:371.26ms
step:1499/1875 train_loss:3.5938 train_time:552815ms step_avg:371.27ms
step:1500/1875 train_loss:3.5667 train_time:553195ms step_avg:371.27ms
step:1500/1875 val_loss:3.5593 train_time:553421ms step_avg:371.42ms
============== Weight norms: ==============
name = 'module._orig_mod.transformer.h.0.attn.c_q.weight' | fro_norm = 46.45033 | spectral_norm = 17.29453 | nuclear_norm = 901.58508
name = 'module._orig_mod.transformer.h.0.attn.c_k.weight' | fro_norm = 43.88271 | spectral_norm = 16.96811 | nuclear_norm = 839.95471
name = 'module._orig_mod.transformer.h.1.attn.c_q.weight' | fro_norm = 43.91692 | spectral_norm = 10.43507 | nuclear_norm = 854.17072
name = 'module._orig_mod.transformer.h.1.attn.c_k.weight' | fro_norm = 40.58463 | spectral_norm = 9.70840 | nuclear_norm = 801.04785
name = 'module._orig_mod.transformer.h.2.attn.c_q.weight' | fro_norm = 44.17442 | spectral_norm = 10.41108 | nuclear_norm = 855.63086
name = 'module._orig_mod.transformer.h.2.attn.c_k.weight' | fro_norm = 42.38918 | spectral_norm = 10.28179 | nuclear_norm = 836.49811
name = 'module._orig_mod.transformer.h.3.attn.c_q.weight' | fro_norm = 43.99909 | spectral_norm = 7.25948 | nuclear_norm = 834.86523
name = 'module._orig_mod.transformer.h.3.attn.c_k.weight' | fro_norm = 42.70264 | spectral_norm = 6.71577 | nuclear_norm = 841.31677
name = 'module._orig_mod.transformer.h.4.attn.c_q.weight' | fro_norm = 44.83904 | spectral_norm = 7.53174 | nuclear_norm = 879.26068
name = 'module._orig_mod.transformer.h.4.attn.c_k.weight' | fro_norm = 43.10160 | spectral_norm = 6.91839 | nuclear_norm = 874.72992
name = 'module._orig_mod.transformer.h.5.attn.c_q.weight' | fro_norm = 45.10415 | spectral_norm = 8.19256 | nuclear_norm = 889.02203
name = 'module._orig_mod.transformer.h.5.attn.c_k.weight' | fro_norm = 43.27599 | spectral_norm = 7.75034 | nuclear_norm = 870.97382
name = 'module._orig_mod.transformer.h.6.attn.c_q.weight' | fro_norm = 44.19640 | spectral_norm = 8.64342 | nuclear_norm = 846.48102
name = 'module._orig_mod.transformer.h.6.attn.c_k.weight' | fro_norm = 41.38047 | spectral_norm = 9.15011 | nuclear_norm = 813.43298
name = 'module._orig_mod.transformer.h.7.attn.c_q.weight' | fro_norm = 45.47007 | spectral_norm = 7.51020 | nuclear_norm = 905.96887
name = 'module._orig_mod.transformer.h.7.attn.c_k.weight' | fro_norm = 43.22936 | spectral_norm = 6.97136 | nuclear_norm = 883.49463
name = 'module._orig_mod.transformer.h.8.attn.c_q.weight' | fro_norm = 45.54987 | spectral_norm = 8.11674 | nuclear_norm = 904.26819
name = 'module._orig_mod.transformer.h.8.attn.c_k.weight' | fro_norm = 43.54331 | spectral_norm = 7.86146 | nuclear_norm = 879.43555
name = 'module._orig_mod.transformer.h.9.attn.c_q.weight' | fro_norm = 45.03733 | spectral_norm = 8.80496 | nuclear_norm = 881.92249
name = 'module._orig_mod.transformer.h.9.attn.c_k.weight' | fro_norm = 43.17153 | spectral_norm = 7.40537 | nuclear_norm = 865.70374
name = 'module._orig_mod.transformer.h.10.attn.c_q.weight' | fro_norm = 44.19896 | spectral_norm = 8.08724 | nuclear_norm = 883.33691
name = 'module._orig_mod.transformer.h.10.attn.c_k.weight' | fro_norm = 41.59857 | spectral_norm = 6.71992 | nuclear_norm = 851.48627
name = 'module._orig_mod.transformer.h.11.attn.c_q.weight' | fro_norm = 42.91018 | spectral_norm = 9.02534 | nuclear_norm = 843.04553
name = 'module._orig_mod.transformer.h.11.attn.c_k.weight' | fro_norm = 39.33511 | spectral_norm = 7.71485 | nuclear_norm = 787.04254
===========================================
step:1501/1875 train_loss:3.3718 train_time:553571ms step_avg:371.27ms
step:1502/1875 train_loss:3.6340 train_time:553931ms step_avg:371.27ms
step:1503/1875 train_loss:3.5184 train_time:554293ms step_avg:371.26ms
step:1504/1875 train_loss:3.5283 train_time:554662ms step_avg:371.26ms
step:1505/1875 train_loss:3.4836 train_time:555027ms step_avg:371.26ms
step:1506/1875 train_loss:3.5600 train_time:555392ms step_avg:371.25ms
step:1507/1875 train_loss:3.4480 train_time:555772ms step_avg:371.26ms
step:1508/1875 train_loss:3.7676 train_time:556144ms step_avg:371.26ms
step:1509/1875 train_loss:3.5520 train_time:556510ms step_avg:371.25ms
step:1510/1875 train_loss:3.5564 train_time:556879ms step_avg:371.25ms
step:1511/1875 train_loss:3.6715 train_time:557243ms step_avg:371.25ms
step:1512/1875 train_loss:3.6978 train_time:557706ms step_avg:371.31ms
step:1513/1875 train_loss:3.5452 train_time:558080ms step_avg:371.31ms
step:1514/1875 train_loss:3.3622 train_time:558450ms step_avg:371.31ms
step:1515/1875 train_loss:3.5147 train_time:558821ms step_avg:371.31ms
step:1516/1875 train_loss:3.5265 train_time:559196ms step_avg:371.31ms
step:1517/1875 train_loss:3.5828 train_time:559564ms step_avg:371.31ms
step:1518/1875 train_loss:3.4844 train_time:559939ms step_avg:371.31ms
step:1519/1875 train_loss:3.7704 train_time:560428ms step_avg:371.39ms
step:1520/1875 train_loss:3.4193 train_time:560795ms step_avg:371.39ms
step:1521/1875 train_loss:3.4973 train_time:561165ms step_avg:371.39ms
step:1522/1875 train_loss:3.6312 train_time:561537ms step_avg:371.39ms
step:1523/1875 train_loss:3.5055 train_time:561903ms step_avg:371.38ms
step:1524/1875 train_loss:3.6083 train_time:562274ms step_avg:371.38ms
step:1525/1875 train_loss:3.6033 train_time:562645ms step_avg:371.38ms
step:1526/1875 train_loss:3.5558 train_time:563031ms step_avg:371.39ms
step:1527/1875 train_loss:3.5507 train_time:563403ms step_avg:371.39ms
step:1528/1875 train_loss:3.6953 train_time:563775ms step_avg:371.39ms
step:1529/1875 train_loss:3.6817 train_time:564143ms step_avg:371.39ms
step:1530/1875 train_loss:3.4982 train_time:564507ms step_avg:371.39ms
step:1531/1875 train_loss:3.4722 train_time:564880ms step_avg:371.39ms
step:1532/1875 train_loss:3.6222 train_time:565248ms step_avg:371.38ms
step:1533/1875 train_loss:3.5507 train_time:565620ms step_avg:371.39ms
step:1534/1875 train_loss:3.5520 train_time:566002ms step_avg:371.39ms
step:1535/1875 train_loss:3.5499 train_time:566371ms step_avg:371.39ms
step:1536/1875 train_loss:3.4933 train_time:566750ms step_avg:371.40ms
step:1537/1875 train_loss:3.5492 train_time:567114ms step_avg:371.39ms
step:1538/1875 train_loss:3.7086 train_time:567492ms step_avg:371.40ms
step:1539/1875 train_loss:3.6590 train_time:567867ms step_avg:371.40ms
step:1540/1875 train_loss:3.5478 train_time:568236ms step_avg:371.40ms
step:1541/1875 train_loss:3.5116 train_time:568610ms step_avg:371.40ms
step:1542/1875 train_loss:3.5205 train_time:568989ms step_avg:371.40ms
step:1543/1875 train_loss:3.4340 train_time:569357ms step_avg:371.40ms
step:1544/1875 train_loss:3.5669 train_time:569723ms step_avg:371.40ms
step:1545/1875 train_loss:3.5430 train_time:570089ms step_avg:371.39ms
step:1546/1875 train_loss:3.5202 train_time:570472ms step_avg:371.40ms
step:1547/1875 train_loss:3.4816 train_time:570843ms step_avg:371.40ms
step:1548/1875 train_loss:3.5193 train_time:571227ms step_avg:371.41ms
step:1549/1875 train_loss:3.6121 train_time:571594ms step_avg:371.41ms
step:1550/1875 train_loss:3.5512 train_time:571964ms step_avg:371.41ms
step:1551/1875 train_loss:3.4705 train_time:572333ms step_avg:371.40ms
step:1552/1875 train_loss:3.4848 train_time:572706ms step_avg:371.40ms
step:1553/1875 train_loss:3.4813 train_time:573073ms step_avg:371.40ms
step:1554/1875 train_loss:3.6187 train_time:573442ms step_avg:371.40ms
step:1555/1875 train_loss:3.6014 train_time:573818ms step_avg:371.40ms
step:1556/1875 train_loss:3.5421 train_time:574185ms step_avg:371.40ms
step:1557/1875 train_loss:3.6001 train_time:574553ms step_avg:371.40ms
step:1558/1875 train_loss:3.5308 train_time:574918ms step_avg:371.39ms
step:1559/1875 train_loss:3.4174 train_time:575291ms step_avg:371.40ms
step:1560/1875 train_loss:3.6889 train_time:575661ms step_avg:371.39ms
step:1561/1875 train_loss:3.5087 train_time:576032ms step_avg:371.39ms
step:1562/1875 train_loss:3.4742 train_time:576397ms step_avg:371.39ms
step:1563/1875 train_loss:3.5922 train_time:576763ms step_avg:371.39ms
step:1564/1875 train_loss:3.4182 train_time:577138ms step_avg:371.39ms
step:1565/1875 train_loss:3.4671 train_time:577517ms step_avg:371.39ms
step:1566/1875 train_loss:3.6312 train_time:577887ms step_avg:371.39ms
step:1567/1875 train_loss:3.5046 train_time:578254ms step_avg:371.39ms
step:1568/1875 train_loss:3.5046 train_time:578621ms step_avg:371.39ms
step:1569/1875 train_loss:3.5975 train_time:579007ms step_avg:371.40ms
step:1570/1875 train_loss:3.5651 train_time:579383ms step_avg:371.40ms
step:1571/1875 train_loss:3.4303 train_time:579762ms step_avg:371.40ms
step:1572/1875 train_loss:3.4583 train_time:580128ms step_avg:371.40ms
step:1573/1875 train_loss:3.5783 train_time:580500ms step_avg:371.40ms
step:1574/1875 train_loss:3.4269 train_time:580867ms step_avg:371.40ms
step:1575/1875 train_loss:3.5927 train_time:581235ms step_avg:371.40ms
step:1576/1875 train_loss:3.4988 train_time:581603ms step_avg:371.39ms
step:1577/1875 train_loss:3.5446 train_time:581978ms step_avg:371.40ms
step:1578/1875 train_loss:3.5224 train_time:582349ms step_avg:371.40ms
step:1579/1875 train_loss:3.4999 train_time:582727ms step_avg:371.40ms
step:1580/1875 train_loss:3.4615 train_time:583104ms step_avg:371.40ms
step:1581/1875 train_loss:3.6657 train_time:583462ms step_avg:371.40ms
step:1582/1875 train_loss:3.4779 train_time:583842ms step_avg:371.40ms
step:1583/1875 train_loss:3.6348 train_time:584221ms step_avg:371.41ms
step:1584/1875 train_loss:3.4549 train_time:584583ms step_avg:371.40ms
step:1585/1875 train_loss:3.6295 train_time:584959ms step_avg:371.40ms
step:1586/1875 train_loss:3.4081 train_time:585330ms step_avg:371.40ms
step:1587/1875 train_loss:3.6152 train_time:585700ms step_avg:371.40ms
step:1588/1875 train_loss:3.4971 train_time:586063ms step_avg:371.40ms
step:1589/1875 train_loss:3.6617 train_time:586436ms step_avg:371.40ms
step:1590/1875 train_loss:3.4944 train_time:586805ms step_avg:371.40ms
step:1591/1875 train_loss:3.5097 train_time:587173ms step_avg:371.39ms
step:1592/1875 train_loss:3.5777 train_time:587538ms step_avg:371.39ms
step:1593/1875 train_loss:3.5571 train_time:587915ms step_avg:371.39ms
step:1594/1875 train_loss:3.5278 train_time:588295ms step_avg:371.40ms
step:1595/1875 train_loss:3.6650 train_time:588656ms step_avg:371.39ms
step:1596/1875 train_loss:3.3949 train_time:589032ms step_avg:371.39ms
step:1597/1875 train_loss:3.5470 train_time:589402ms step_avg:371.39ms
step:1598/1875 train_loss:3.5993 train_time:589777ms step_avg:371.40ms
step:1599/1875 train_loss:3.6563 train_time:590153ms step_avg:371.40ms
step:1600/1875 train_loss:3.4859 train_time:590526ms step_avg:371.40ms
step:1601/1875 train_loss:3.7873 train_time:590900ms step_avg:371.40ms
step:1602/1875 train_loss:3.6734 train_time:591268ms step_avg:371.40ms
step:1603/1875 train_loss:3.4573 train_time:591645ms step_avg:371.40ms
step:1604/1875 train_loss:3.4929 train_time:592010ms step_avg:371.40ms
step:1605/1875 train_loss:3.3810 train_time:592395ms step_avg:371.41ms
step:1606/1875 train_loss:3.7058 train_time:592776ms step_avg:371.41ms
step:1607/1875 train_loss:3.5067 train_time:593146ms step_avg:371.41ms
step:1608/1875 train_loss:3.5283 train_time:593516ms step_avg:371.41ms
step:1609/1875 train_loss:3.4543 train_time:593884ms step_avg:371.41ms
step:1610/1875 train_loss:3.9941 train_time:594254ms step_avg:371.41ms
step:1611/1875 train_loss:3.7123 train_time:594633ms step_avg:371.41ms
step:1612/1875 train_loss:3.6328 train_time:595005ms step_avg:371.41ms
step:1613/1875 train_loss:3.4919 train_time:595392ms step_avg:371.42ms
step:1614/1875 train_loss:3.5237 train_time:595768ms step_avg:371.43ms
step:1615/1875 train_loss:3.5264 train_time:596137ms step_avg:371.42ms
step:1616/1875 train_loss:3.4845 train_time:596527ms step_avg:371.44ms
step:1617/1875 train_loss:3.5663 train_time:596909ms step_avg:371.44ms
step:1618/1875 train_loss:3.5057 train_time:597274ms step_avg:371.44ms
step:1619/1875 train_loss:3.4082 train_time:597642ms step_avg:371.44ms
step:1620/1875 train_loss:3.6835 train_time:598015ms step_avg:371.44ms
step:1621/1875 train_loss:3.5857 train_time:598391ms step_avg:371.44ms
step:1622/1875 train_loss:3.3763 train_time:598763ms step_avg:371.44ms
step:1623/1875 train_loss:3.4678 train_time:599135ms step_avg:371.44ms
step:1624/1875 train_loss:3.4399 train_time:599509ms step_avg:371.44ms
step:1625/1875 train_loss:3.5297 train_time:599867ms step_avg:371.43ms
step:1625/1875 val_loss:3.5141 train_time:600086ms step_avg:371.57ms
============== Weight norms: ==============
name = 'module._orig_mod.transformer.h.0.attn.c_q.weight' | fro_norm = 47.10322 | spectral_norm = 17.59691 | nuclear_norm = 914.37805
name = 'module._orig_mod.transformer.h.0.attn.c_k.weight' | fro_norm = 44.52415 | spectral_norm = 17.36535 | nuclear_norm = 852.17523
name = 'module._orig_mod.transformer.h.1.attn.c_q.weight' | fro_norm = 44.56588 | spectral_norm = 10.55168 | nuclear_norm = 867.71667
name = 'module._orig_mod.transformer.h.1.attn.c_k.weight' | fro_norm = 41.22903 | spectral_norm = 9.84009 | nuclear_norm = 814.11377
name = 'module._orig_mod.transformer.h.2.attn.c_q.weight' | fro_norm = 44.84221 | spectral_norm = 10.50685 | nuclear_norm = 869.34204
name = 'module._orig_mod.transformer.h.2.attn.c_k.weight' | fro_norm = 43.06739 | spectral_norm = 10.41132 | nuclear_norm = 850.74713
name = 'module._orig_mod.transformer.h.3.attn.c_q.weight' | fro_norm = 44.63149 | spectral_norm = 7.34919 | nuclear_norm = 846.76965
name = 'module._orig_mod.transformer.h.3.attn.c_k.weight' | fro_norm = 43.34304 | spectral_norm = 6.77605 | nuclear_norm = 854.05298
name = 'module._orig_mod.transformer.h.4.attn.c_q.weight' | fro_norm = 45.53154 | spectral_norm = 7.59856 | nuclear_norm = 893.47089
name = 'module._orig_mod.transformer.h.4.attn.c_k.weight' | fro_norm = 43.76957 | spectral_norm = 6.92702 | nuclear_norm = 889.56140
name = 'module._orig_mod.transformer.h.5.attn.c_q.weight' | fro_norm = 45.81080 | spectral_norm = 8.33666 | nuclear_norm = 904.08765
name = 'module._orig_mod.transformer.h.5.attn.c_k.weight' | fro_norm = 43.97740 | spectral_norm = 7.84687 | nuclear_norm = 886.36670
name = 'module._orig_mod.transformer.h.6.attn.c_q.weight' | fro_norm = 44.90189 | spectral_norm = 8.74270 | nuclear_norm = 860.92023
name = 'module._orig_mod.transformer.h.6.attn.c_k.weight' | fro_norm = 42.08488 | spectral_norm = 9.19304 | nuclear_norm = 828.59314
name = 'module._orig_mod.transformer.h.7.attn.c_q.weight' | fro_norm = 46.20106 | spectral_norm = 7.52045 | nuclear_norm = 922.96783
name = 'module._orig_mod.transformer.h.7.attn.c_k.weight' | fro_norm = 43.93174 | spectral_norm = 7.00143 | nuclear_norm = 900.08154
name = 'module._orig_mod.transformer.h.8.attn.c_q.weight' | fro_norm = 46.23610 | spectral_norm = 8.21521 | nuclear_norm = 919.52246
name = 'module._orig_mod.transformer.h.8.attn.c_k.weight' | fro_norm = 44.21823 | spectral_norm = 7.93020 | nuclear_norm = 894.59692
name = 'module._orig_mod.transformer.h.9.attn.c_q.weight' | fro_norm = 45.78534 | spectral_norm = 8.87637 | nuclear_norm = 898.48730
name = 'module._orig_mod.transformer.h.9.attn.c_k.weight' | fro_norm = 43.89861 | spectral_norm = 7.45181 | nuclear_norm = 882.17981
name = 'module._orig_mod.transformer.h.10.attn.c_q.weight' | fro_norm = 44.92130 | spectral_norm = 8.08105 | nuclear_norm = 899.92004
name = 'module._orig_mod.transformer.h.10.attn.c_k.weight' | fro_norm = 42.30439 | spectral_norm = 6.80766 | nuclear_norm = 867.71924
name = 'module._orig_mod.transformer.h.11.attn.c_q.weight' | fro_norm = 43.58560 | spectral_norm = 9.17495 | nuclear_norm = 856.34613
name = 'module._orig_mod.transformer.h.11.attn.c_k.weight' | fro_norm = 40.01164 | spectral_norm = 8.03570 | nuclear_norm = 799.73932
===========================================
step:1626/1875 train_loss:3.4695 train_time:600245ms step_avg:371.44ms
step:1627/1875 train_loss:3.4440 train_time:600601ms step_avg:371.43ms
step:1628/1875 train_loss:3.5712 train_time:600967ms step_avg:371.43ms
step:1629/1875 train_loss:3.4590 train_time:601339ms step_avg:371.43ms
step:1630/1875 train_loss:3.5281 train_time:601707ms step_avg:371.42ms
step:1631/1875 train_loss:3.3780 train_time:602093ms step_avg:371.43ms
step:1632/1875 train_loss:3.3525 train_time:602464ms step_avg:371.43ms
step:1633/1875 train_loss:3.5190 train_time:602830ms step_avg:371.43ms
step:1634/1875 train_loss:3.5119 train_time:603201ms step_avg:371.43ms
step:1635/1875 train_loss:3.4556 train_time:603567ms step_avg:371.43ms
step:1636/1875 train_loss:3.5434 train_time:603943ms step_avg:371.43ms
step:1637/1875 train_loss:3.5972 train_time:604308ms step_avg:371.42ms
step:1638/1875 train_loss:3.6190 train_time:604683ms step_avg:371.43ms
step:1639/1875 train_loss:3.7836 train_time:605050ms step_avg:371.42ms
step:1640/1875 train_loss:3.5734 train_time:605425ms step_avg:371.43ms
step:1641/1875 train_loss:3.5078 train_time:605797ms step_avg:371.43ms
step:1642/1875 train_loss:3.6167 train_time:606166ms step_avg:371.43ms
step:1643/1875 train_loss:3.4814 train_time:606540ms step_avg:371.43ms
step:1644/1875 train_loss:3.5208 train_time:606917ms step_avg:371.43ms
step:1645/1875 train_loss:3.5307 train_time:607283ms step_avg:371.43ms
step:1646/1875 train_loss:3.2807 train_time:607655ms step_avg:371.43ms
step:1647/1875 train_loss:3.5440 train_time:608021ms step_avg:371.42ms
step:1648/1875 train_loss:3.4220 train_time:608391ms step_avg:371.42ms
step:1649/1875 train_loss:3.4899 train_time:608761ms step_avg:371.42ms
step:1650/1875 train_loss:3.4803 train_time:609134ms step_avg:371.42ms
step:1651/1875 train_loss:3.5442 train_time:609498ms step_avg:371.42ms
step:1652/1875 train_loss:3.4753 train_time:609864ms step_avg:371.42ms
step:1653/1875 train_loss:3.6096 train_time:610242ms step_avg:371.42ms
step:1654/1875 train_loss:3.5975 train_time:610611ms step_avg:371.42ms
step:1655/1875 train_loss:3.3952 train_time:610989ms step_avg:371.42ms
step:1656/1875 train_loss:3.5313 train_time:611362ms step_avg:371.42ms
step:1657/1875 train_loss:3.4615 train_time:611742ms step_avg:371.43ms
step:1658/1875 train_loss:3.4343 train_time:612110ms step_avg:371.43ms
step:1659/1875 train_loss:3.5088 train_time:612480ms step_avg:371.43ms
step:1660/1875 train_loss:3.5549 train_time:612848ms step_avg:371.42ms
step:1661/1875 train_loss:3.4586 train_time:613217ms step_avg:371.42ms
step:1662/1875 train_loss:3.5603 train_time:613585ms step_avg:371.42ms
step:1663/1875 train_loss:3.5527 train_time:613953ms step_avg:371.42ms
step:1664/1875 train_loss:3.6034 train_time:614346ms step_avg:371.43ms
step:1665/1875 train_loss:3.5385 train_time:614723ms step_avg:371.43ms
step:1666/1875 train_loss:3.7117 train_time:615097ms step_avg:371.44ms
step:1667/1875 train_loss:3.4196 train_time:615469ms step_avg:371.44ms
step:1668/1875 train_loss:3.4956 train_time:615843ms step_avg:371.44ms
step:1669/1875 train_loss:3.4215 train_time:616212ms step_avg:371.44ms
step:1670/1875 train_loss:3.4229 train_time:616587ms step_avg:371.44ms
step:1671/1875 train_loss:3.5856 train_time:616952ms step_avg:371.43ms
step:1672/1875 train_loss:3.7783 train_time:617326ms step_avg:371.44ms
step:1673/1875 train_loss:3.4918 train_time:617697ms step_avg:371.44ms
step:1674/1875 train_loss:3.4668 train_time:618061ms step_avg:371.43ms
step:1675/1875 train_loss:3.3390 train_time:618444ms step_avg:371.44ms
step:1676/1875 train_loss:3.5458 train_time:618817ms step_avg:371.44ms
step:1677/1875 train_loss:3.4808 train_time:619183ms step_avg:371.44ms
step:1678/1875 train_loss:3.5021 train_time:619560ms step_avg:371.44ms
step:1679/1875 train_loss:3.5066 train_time:619921ms step_avg:371.43ms
step:1680/1875 train_loss:3.2925 train_time:620308ms step_avg:371.44ms
step:1681/1875 train_loss:3.4963 train_time:620681ms step_avg:371.44ms
step:1682/1875 train_loss:3.4941 train_time:621058ms step_avg:371.45ms
step:1683/1875 train_loss:3.5262 train_time:621426ms step_avg:371.44ms
step:1684/1875 train_loss:3.5513 train_time:621798ms step_avg:371.44ms
step:1685/1875 train_loss:3.4501 train_time:622165ms step_avg:371.44ms
step:1686/1875 train_loss:3.5774 train_time:622538ms step_avg:371.44ms
step:1687/1875 train_loss:3.4457 train_time:622908ms step_avg:371.44ms
step:1688/1875 train_loss:3.5277 train_time:623280ms step_avg:371.44ms
step:1689/1875 train_loss:3.4315 train_time:623656ms step_avg:371.45ms
step:1690/1875 train_loss:3.2947 train_time:624030ms step_avg:371.45ms
step:1691/1875 train_loss:3.5064 train_time:624397ms step_avg:371.44ms
step:1692/1875 train_loss:3.4861 train_time:624764ms step_avg:371.44ms
step:1693/1875 train_loss:3.4158 train_time:625137ms step_avg:371.44ms
step:1694/1875 train_loss:3.8280 train_time:625505ms step_avg:371.44ms
step:1695/1875 train_loss:3.5464 train_time:625878ms step_avg:371.44ms
step:1696/1875 train_loss:3.5381 train_time:626249ms step_avg:371.44ms
step:1697/1875 train_loss:3.4524 train_time:626615ms step_avg:371.44ms
step:1698/1875 train_loss:3.3392 train_time:626983ms step_avg:371.44ms
step:1699/1875 train_loss:3.4421 train_time:627346ms step_avg:371.43ms
step:1700/1875 train_loss:3.4450 train_time:627725ms step_avg:371.44ms
step:1701/1875 train_loss:3.5214 train_time:628191ms step_avg:371.49ms
step:1702/1875 train_loss:3.4355 train_time:628557ms step_avg:371.49ms
step:1703/1875 train_loss:3.6234 train_time:628926ms step_avg:371.49ms
step:1704/1875 train_loss:3.4219 train_time:629291ms step_avg:371.48ms
step:1705/1875 train_loss:3.6302 train_time:629658ms step_avg:371.48ms
step:1706/1875 train_loss:3.4761 train_time:630023ms step_avg:371.48ms
step:1707/1875 train_loss:3.2422 train_time:630391ms step_avg:371.47ms
step:1708/1875 train_loss:3.5879 train_time:630757ms step_avg:371.47ms
step:1709/1875 train_loss:3.5026 train_time:631251ms step_avg:371.54ms
step:1710/1875 train_loss:3.4957 train_time:631624ms step_avg:371.54ms
step:1711/1875 train_loss:3.4834 train_time:631996ms step_avg:371.54ms
step:1712/1875 train_loss:3.5299 train_time:632367ms step_avg:371.54ms
step:1713/1875 train_loss:3.5442 train_time:632740ms step_avg:371.54ms
step:1714/1875 train_loss:3.4541 train_time:633108ms step_avg:371.54ms
step:1715/1875 train_loss:3.4776 train_time:633494ms step_avg:371.55ms
step:1716/1875 train_loss:3.2992 train_time:633864ms step_avg:371.55ms
step:1717/1875 train_loss:3.4449 train_time:634228ms step_avg:371.55ms
step:1718/1875 train_loss:3.4623 train_time:634593ms step_avg:371.54ms
step:1719/1875 train_loss:3.4181 train_time:634963ms step_avg:371.54ms
step:1720/1875 train_loss:3.5682 train_time:635333ms step_avg:371.54ms
step:1721/1875 train_loss:3.3729 train_time:635724ms step_avg:371.55ms
step:1722/1875 train_loss:3.5134 train_time:636093ms step_avg:371.55ms
step:1723/1875 train_loss:3.6068 train_time:636467ms step_avg:371.55ms
step:1724/1875 train_loss:3.4532 train_time:636834ms step_avg:371.55ms
step:1725/1875 train_loss:3.6867 train_time:637208ms step_avg:371.55ms
step:1726/1875 train_loss:3.4592 train_time:637584ms step_avg:371.55ms
step:1727/1875 train_loss:3.5256 train_time:637953ms step_avg:371.55ms
step:1728/1875 train_loss:3.5030 train_time:638316ms step_avg:371.55ms
step:1729/1875 train_loss:3.4869 train_time:638697ms step_avg:371.55ms
step:1730/1875 train_loss:3.8700 train_time:639062ms step_avg:371.55ms
step:1731/1875 train_loss:3.4918 train_time:639435ms step_avg:371.55ms
step:1732/1875 train_loss:3.6285 train_time:639804ms step_avg:371.55ms
step:1733/1875 train_loss:3.3980 train_time:640172ms step_avg:371.55ms
step:1734/1875 train_loss:3.4398 train_time:640534ms step_avg:371.54ms
step:1735/1875 train_loss:3.4626 train_time:640903ms step_avg:371.54ms
step:1736/1875 train_loss:3.4498 train_time:641278ms step_avg:371.54ms
step:1737/1875 train_loss:3.5866 train_time:641646ms step_avg:371.54ms
step:1738/1875 train_loss:3.4352 train_time:642027ms step_avg:371.54ms
step:1739/1875 train_loss:3.4999 train_time:642402ms step_avg:371.55ms
step:1740/1875 train_loss:3.5607 train_time:642771ms step_avg:371.54ms
step:1741/1875 train_loss:3.3625 train_time:643144ms step_avg:371.54ms
step:1742/1875 train_loss:3.2582 train_time:643514ms step_avg:371.54ms
step:1743/1875 train_loss:3.1524 train_time:643891ms step_avg:371.55ms
step:1744/1875 train_loss:3.4816 train_time:644262ms step_avg:371.55ms
step:1745/1875 train_loss:3.5104 train_time:644627ms step_avg:371.54ms
step:1746/1875 train_loss:3.4665 train_time:644995ms step_avg:371.54ms
step:1747/1875 train_loss:3.4794 train_time:645362ms step_avg:371.54ms
step:1748/1875 train_loss:3.7073 train_time:645747ms step_avg:371.55ms
step:1749/1875 train_loss:3.4192 train_time:646113ms step_avg:371.54ms
step:1750/1875 train_loss:3.4889 train_time:646492ms step_avg:371.55ms
step:1750/1875 val_loss:3.4734 train_time:646715ms step_avg:371.68ms
============== Weight norms: ==============
name = 'module._orig_mod.transformer.h.0.attn.c_q.weight' | fro_norm = 47.33916 | spectral_norm = 17.77744 | nuclear_norm = 919.04285
name = 'module._orig_mod.transformer.h.0.attn.c_k.weight' | fro_norm = 44.76429 | spectral_norm = 17.54271 | nuclear_norm = 857.08759
name = 'module._orig_mod.transformer.h.1.attn.c_q.weight' | fro_norm = 44.83698 | spectral_norm = 10.61154 | nuclear_norm = 873.66840
name = 'module._orig_mod.transformer.h.1.attn.c_k.weight' | fro_norm = 41.49675 | spectral_norm = 9.89713 | nuclear_norm = 820.03455
name = 'module._orig_mod.transformer.h.2.attn.c_q.weight' | fro_norm = 45.10555 | spectral_norm = 10.53498 | nuclear_norm = 875.43274
name = 'module._orig_mod.transformer.h.2.attn.c_k.weight' | fro_norm = 43.35368 | spectral_norm = 10.42299 | nuclear_norm = 857.55005
name = 'module._orig_mod.transformer.h.3.attn.c_q.weight' | fro_norm = 44.87686 | spectral_norm = 7.39546 | nuclear_norm = 851.38135
name = 'module._orig_mod.transformer.h.3.attn.c_k.weight' | fro_norm = 43.59998 | spectral_norm = 6.81333 | nuclear_norm = 859.29114
name = 'module._orig_mod.transformer.h.4.attn.c_q.weight' | fro_norm = 45.78704 | spectral_norm = 7.62229 | nuclear_norm = 899.09387
name = 'module._orig_mod.transformer.h.4.attn.c_k.weight' | fro_norm = 44.03205 | spectral_norm = 6.94776 | nuclear_norm = 895.82635
name = 'module._orig_mod.transformer.h.5.attn.c_q.weight' | fro_norm = 46.09157 | spectral_norm = 8.36177 | nuclear_norm = 910.41138
name = 'module._orig_mod.transformer.h.5.attn.c_k.weight' | fro_norm = 44.26957 | spectral_norm = 7.84990 | nuclear_norm = 893.42267
name = 'module._orig_mod.transformer.h.6.attn.c_q.weight' | fro_norm = 45.17567 | spectral_norm = 8.73870 | nuclear_norm = 867.45581
name = 'module._orig_mod.transformer.h.6.attn.c_k.weight' | fro_norm = 42.38606 | spectral_norm = 9.16761 | nuclear_norm = 835.85107
name = 'module._orig_mod.transformer.h.7.attn.c_q.weight' | fro_norm = 46.48986 | spectral_norm = 7.50598 | nuclear_norm = 930.66846
name = 'module._orig_mod.transformer.h.7.attn.c_k.weight' | fro_norm = 44.21292 | spectral_norm = 7.00290 | nuclear_norm = 907.67285
name = 'module._orig_mod.transformer.h.8.attn.c_q.weight' | fro_norm = 46.50159 | spectral_norm = 8.21967 | nuclear_norm = 925.95795
name = 'module._orig_mod.transformer.h.8.attn.c_k.weight' | fro_norm = 44.48922 | spectral_norm = 7.94210 | nuclear_norm = 901.17188
name = 'module._orig_mod.transformer.h.9.attn.c_q.weight' | fro_norm = 46.08752 | spectral_norm = 8.87516 | nuclear_norm = 905.92145
name = 'module._orig_mod.transformer.h.9.attn.c_k.weight' | fro_norm = 44.20617 | spectral_norm = 7.48313 | nuclear_norm = 889.80212
name = 'module._orig_mod.transformer.h.10.attn.c_q.weight' | fro_norm = 45.20034 | spectral_norm = 8.08590 | nuclear_norm = 906.95593
name = 'module._orig_mod.transformer.h.10.attn.c_k.weight' | fro_norm = 42.57218 | spectral_norm = 6.82438 | nuclear_norm = 874.71960
name = 'module._orig_mod.transformer.h.11.attn.c_q.weight' | fro_norm = 43.82728 | spectral_norm = 9.25450 | nuclear_norm = 861.19879
name = 'module._orig_mod.transformer.h.11.attn.c_k.weight' | fro_norm = 40.26545 | spectral_norm = 8.17437 | nuclear_norm = 804.43030
===========================================
step:1751/1875 train_loss:3.4908 train_time:646868ms step_avg:371.55ms
step:1752/1875 train_loss:3.0869 train_time:647221ms step_avg:371.54ms
step:1753/1875 train_loss:3.2197 train_time:647593ms step_avg:371.54ms
step:1754/1875 train_loss:3.2955 train_time:647969ms step_avg:371.54ms
step:1755/1875 train_loss:3.2715 train_time:648347ms step_avg:371.55ms
step:1756/1875 train_loss:3.4606 train_time:648713ms step_avg:371.54ms
step:1757/1875 train_loss:3.3465 train_time:649085ms step_avg:371.54ms
step:1758/1875 train_loss:3.3125 train_time:649456ms step_avg:371.54ms
step:1759/1875 train_loss:4.3828 train_time:649821ms step_avg:371.54ms
step:1760/1875 train_loss:3.4470 train_time:650189ms step_avg:371.54ms
step:1761/1875 train_loss:3.4981 train_time:650577ms step_avg:371.55ms
step:1762/1875 train_loss:3.4998 train_time:650942ms step_avg:371.54ms
step:1763/1875 train_loss:3.5058 train_time:651306ms step_avg:371.54ms
step:1764/1875 train_loss:3.4225 train_time:651677ms step_avg:371.54ms
step:1765/1875 train_loss:3.4785 train_time:652048ms step_avg:371.54ms
step:1766/1875 train_loss:3.4884 train_time:652418ms step_avg:371.54ms
step:1767/1875 train_loss:3.7023 train_time:652793ms step_avg:371.54ms
step:1768/1875 train_loss:3.4699 train_time:653160ms step_avg:371.54ms
step:1769/1875 train_loss:3.5408 train_time:653534ms step_avg:371.54ms
step:1770/1875 train_loss:3.7378 train_time:653906ms step_avg:371.54ms
step:1771/1875 train_loss:3.4458 train_time:654283ms step_avg:371.54ms
step:1772/1875 train_loss:3.3599 train_time:654648ms step_avg:371.54ms
step:1773/1875 train_loss:3.6062 train_time:655021ms step_avg:371.54ms
step:1774/1875 train_loss:3.3291 train_time:655393ms step_avg:371.54ms
step:1775/1875 train_loss:3.5183 train_time:655775ms step_avg:371.54ms
step:1776/1875 train_loss:3.5505 train_time:656145ms step_avg:371.54ms
step:1777/1875 train_loss:3.6680 train_time:656512ms step_avg:371.54ms
step:1778/1875 train_loss:3.4729 train_time:656880ms step_avg:371.54ms
step:1779/1875 train_loss:3.7585 train_time:657253ms step_avg:371.54ms
step:1780/1875 train_loss:3.5448 train_time:657627ms step_avg:371.54ms
step:1781/1875 train_loss:3.5386 train_time:657992ms step_avg:371.54ms
step:1782/1875 train_loss:3.3273 train_time:658361ms step_avg:371.54ms
step:1783/1875 train_loss:3.4309 train_time:658736ms step_avg:371.54ms
step:1784/1875 train_loss:3.5594 train_time:659101ms step_avg:371.53ms
step:1785/1875 train_loss:3.4599 train_time:659470ms step_avg:371.53ms
step:1786/1875 train_loss:3.6298 train_time:659845ms step_avg:371.53ms
step:1787/1875 train_loss:3.4440 train_time:660208ms step_avg:371.53ms
step:1788/1875 train_loss:3.4061 train_time:660577ms step_avg:371.53ms
step:1789/1875 train_loss:3.5582 train_time:660951ms step_avg:371.53ms
step:1790/1875 train_loss:3.4649 train_time:661318ms step_avg:371.53ms
step:1791/1875 train_loss:3.4165 train_time:661688ms step_avg:371.53ms
step:1792/1875 train_loss:3.5282 train_time:662055ms step_avg:371.52ms
step:1793/1875 train_loss:3.4164 train_time:662420ms step_avg:371.52ms
step:1794/1875 train_loss:3.4173 train_time:662791ms step_avg:371.52ms
step:1795/1875 train_loss:3.4617 train_time:663165ms step_avg:371.52ms
step:1796/1875 train_loss:3.3963 train_time:663538ms step_avg:371.52ms
step:1797/1875 train_loss:3.5616 train_time:663909ms step_avg:371.52ms
step:1798/1875 train_loss:3.4601 train_time:664280ms step_avg:371.52ms
step:1799/1875 train_loss:3.5318 train_time:664648ms step_avg:371.52ms
step:1800/1875 train_loss:3.4411 train_time:665018ms step_avg:371.52ms
step:1801/1875 train_loss:3.5053 train_time:665388ms step_avg:371.52ms
step:1802/1875 train_loss:3.3789 train_time:665760ms step_avg:371.52ms
step:1803/1875 train_loss:3.3157 train_time:666129ms step_avg:371.52ms
step:1804/1875 train_loss:3.5821 train_time:666502ms step_avg:371.52ms
step:1805/1875 train_loss:3.5032 train_time:666871ms step_avg:371.52ms
step:1806/1875 train_loss:3.4937 train_time:667252ms step_avg:371.52ms
step:1807/1875 train_loss:3.6287 train_time:667631ms step_avg:371.53ms
step:1808/1875 train_loss:3.4134 train_time:667997ms step_avg:371.52ms
step:1809/1875 train_loss:3.5210 train_time:668368ms step_avg:371.52ms
step:1810/1875 train_loss:3.6637 train_time:668741ms step_avg:371.52ms
step:1811/1875 train_loss:3.5146 train_time:669110ms step_avg:371.52ms
step:1812/1875 train_loss:3.5552 train_time:669484ms step_avg:371.52ms
step:1813/1875 train_loss:3.5603 train_time:669854ms step_avg:371.52ms
step:1814/1875 train_loss:3.5169 train_time:670219ms step_avg:371.52ms
step:1815/1875 train_loss:3.5429 train_time:670594ms step_avg:371.52ms
step:1816/1875 train_loss:3.5082 train_time:670971ms step_avg:371.52ms
step:1817/1875 train_loss:3.5584 train_time:671354ms step_avg:371.53ms
step:1818/1875 train_loss:3.4870 train_time:671731ms step_avg:371.53ms
step:1819/1875 train_loss:3.4918 train_time:672098ms step_avg:371.53ms
step:1820/1875 train_loss:3.4388 train_time:672467ms step_avg:371.53ms
step:1821/1875 train_loss:3.3888 train_time:672843ms step_avg:371.53ms
step:1822/1875 train_loss:3.3266 train_time:673211ms step_avg:371.53ms
step:1823/1875 train_loss:3.4943 train_time:673580ms step_avg:371.53ms
step:1824/1875 train_loss:3.5848 train_time:673957ms step_avg:371.53ms
step:1825/1875 train_loss:3.5581 train_time:674330ms step_avg:371.53ms
step:1826/1875 train_loss:3.5466 train_time:674711ms step_avg:371.54ms
step:1827/1875 train_loss:3.4115 train_time:675083ms step_avg:371.54ms
step:1828/1875 train_loss:3.4042 train_time:675456ms step_avg:371.54ms
step:1829/1875 train_loss:3.5786 train_time:675838ms step_avg:371.54ms
step:1830/1875 train_loss:3.3390 train_time:676209ms step_avg:371.54ms
step:1831/1875 train_loss:3.4876 train_time:676579ms step_avg:371.54ms
step:1832/1875 train_loss:3.3607 train_time:676943ms step_avg:371.54ms
step:1833/1875 train_loss:3.6970 train_time:677315ms step_avg:371.54ms
step:1834/1875 train_loss:3.5339 train_time:677708ms step_avg:371.55ms
step:1835/1875 train_loss:3.5148 train_time:678078ms step_avg:371.55ms
step:1836/1875 train_loss:3.6229 train_time:678450ms step_avg:371.55ms
step:1837/1875 train_loss:3.5044 train_time:678824ms step_avg:371.55ms
step:1838/1875 train_loss:3.3804 train_time:679196ms step_avg:371.55ms
step:1839/1875 train_loss:3.4950 train_time:679561ms step_avg:371.55ms
step:1840/1875 train_loss:3.3693 train_time:679936ms step_avg:371.55ms
step:1841/1875 train_loss:3.5009 train_time:680307ms step_avg:371.55ms
step:1842/1875 train_loss:3.5399 train_time:680680ms step_avg:371.55ms
step:1843/1875 train_loss:3.2901 train_time:681043ms step_avg:371.55ms
step:1844/1875 train_loss:3.4228 train_time:681409ms step_avg:371.54ms
step:1845/1875 train_loss:3.4812 train_time:681777ms step_avg:371.54ms
step:1846/1875 train_loss:3.4279 train_time:682146ms step_avg:371.54ms
step:1847/1875 train_loss:3.3223 train_time:682512ms step_avg:371.54ms
step:1848/1875 train_loss:3.5706 train_time:682891ms step_avg:371.54ms
step:1849/1875 train_loss:3.3572 train_time:683273ms step_avg:371.55ms
step:1850/1875 train_loss:3.4479 train_time:683642ms step_avg:371.54ms
step:1851/1875 train_loss:3.3995 train_time:683998ms step_avg:371.54ms
step:1852/1875 train_loss:3.5943 train_time:684382ms step_avg:371.54ms
step:1853/1875 train_loss:3.5759 train_time:684754ms step_avg:371.54ms
step:1854/1875 train_loss:3.4436 train_time:685126ms step_avg:371.54ms
step:1855/1875 train_loss:3.4041 train_time:685494ms step_avg:371.54ms
step:1856/1875 train_loss:3.4321 train_time:685864ms step_avg:371.54ms
step:1857/1875 train_loss:3.6568 train_time:686232ms step_avg:371.54ms
step:1858/1875 train_loss:3.4833 train_time:686602ms step_avg:371.54ms
step:1859/1875 train_loss:3.4507 train_time:686973ms step_avg:371.54ms
step:1860/1875 train_loss:3.5043 train_time:687335ms step_avg:371.53ms
step:1861/1875 train_loss:3.3582 train_time:687705ms step_avg:371.53ms
step:1862/1875 train_loss:3.3690 train_time:688081ms step_avg:371.53ms
step:1863/1875 train_loss:3.4567 train_time:688461ms step_avg:371.54ms
step:1864/1875 train_loss:3.4974 train_time:688831ms step_avg:371.54ms
step:1865/1875 train_loss:3.2555 train_time:689200ms step_avg:371.54ms
step:1866/1875 train_loss:3.3939 train_time:689566ms step_avg:371.53ms
step:1867/1875 train_loss:3.3483 train_time:689937ms step_avg:371.53ms
step:1868/1875 train_loss:3.3312 train_time:690311ms step_avg:371.53ms
step:1869/1875 train_loss:3.5150 train_time:690682ms step_avg:371.53ms
step:1870/1875 train_loss:3.4925 train_time:691057ms step_avg:371.54ms
step:1871/1875 train_loss:3.4341 train_time:691427ms step_avg:371.54ms
step:1872/1875 train_loss:3.4590 train_time:691792ms step_avg:371.53ms
step:1873/1875 train_loss:3.3848 train_time:692164ms step_avg:371.53ms
step:1874/1875 train_loss:3.4850 train_time:692532ms step_avg:371.53ms
step:1875/1875 train_loss:3.4932 train_time:692908ms step_avg:371.53ms
step:1875/1875 val_loss:3.4491 train_time:693131ms step_avg:371.65ms
============== Weight norms: ==============
name = 'module._orig_mod.transformer.h.0.attn.c_q.weight' | fro_norm = 47.37299 | spectral_norm = 17.83973 | nuclear_norm = 919.61841
name = 'module._orig_mod.transformer.h.0.attn.c_k.weight' | fro_norm = 44.80114 | spectral_norm = 17.59789 | nuclear_norm = 857.86145
name = 'module._orig_mod.transformer.h.1.attn.c_q.weight' | fro_norm = 44.87924 | spectral_norm = 10.61504 | nuclear_norm = 874.84473
name = 'module._orig_mod.transformer.h.1.attn.c_k.weight' | fro_norm = 41.54402 | spectral_norm = 9.90952 | nuclear_norm = 821.41284
name = 'module._orig_mod.transformer.h.2.attn.c_q.weight' | fro_norm = 45.15038 | spectral_norm = 10.54665 | nuclear_norm = 876.72375
name = 'module._orig_mod.transformer.h.2.attn.c_k.weight' | fro_norm = 43.40778 | spectral_norm = 10.43273 | nuclear_norm = 859.12451
name = 'module._orig_mod.transformer.h.3.attn.c_q.weight' | fro_norm = 44.91115 | spectral_norm = 7.41885 | nuclear_norm = 851.89148
name = 'module._orig_mod.transformer.h.3.attn.c_k.weight' | fro_norm = 43.64251 | spectral_norm = 6.81030 | nuclear_norm = 860.19385
name = 'module._orig_mod.transformer.h.4.attn.c_q.weight' | fro_norm = 45.82677 | spectral_norm = 7.61349 | nuclear_norm = 900.25806
name = 'module._orig_mod.transformer.h.4.attn.c_k.weight' | fro_norm = 44.07481 | spectral_norm = 6.92442 | nuclear_norm = 897.25476
name = 'module._orig_mod.transformer.h.5.attn.c_q.weight' | fro_norm = 46.13776 | spectral_norm = 8.36883 | nuclear_norm = 911.70813
name = 'module._orig_mod.transformer.h.5.attn.c_k.weight' | fro_norm = 44.31921 | spectral_norm = 7.85351 | nuclear_norm = 894.92200
name = 'module._orig_mod.transformer.h.6.attn.c_q.weight' | fro_norm = 45.22120 | spectral_norm = 8.74329 | nuclear_norm = 868.74548
name = 'module._orig_mod.transformer.h.6.attn.c_k.weight' | fro_norm = 42.43916 | spectral_norm = 9.15161 | nuclear_norm = 837.49261
name = 'module._orig_mod.transformer.h.7.attn.c_q.weight' | fro_norm = 46.53919 | spectral_norm = 7.48776 | nuclear_norm = 932.40576
name = 'module._orig_mod.transformer.h.7.attn.c_k.weight' | fro_norm = 44.26163 | spectral_norm = 6.99346 | nuclear_norm = 909.42273
name = 'module._orig_mod.transformer.h.8.attn.c_q.weight' | fro_norm = 46.54420 | spectral_norm = 8.20725 | nuclear_norm = 927.27734
name = 'module._orig_mod.transformer.h.8.attn.c_k.weight' | fro_norm = 44.53574 | spectral_norm = 7.94487 | nuclear_norm = 902.63263
name = 'module._orig_mod.transformer.h.9.attn.c_q.weight' | fro_norm = 46.13479 | spectral_norm = 8.86584 | nuclear_norm = 907.58167
name = 'module._orig_mod.transformer.h.9.attn.c_k.weight' | fro_norm = 44.25846 | spectral_norm = 7.47398 | nuclear_norm = 891.58923
name = 'module._orig_mod.transformer.h.10.attn.c_q.weight' | fro_norm = 45.23870 | spectral_norm = 8.07886 | nuclear_norm = 908.38306
name = 'module._orig_mod.transformer.h.10.attn.c_k.weight' | fro_norm = 42.61828 | spectral_norm = 6.83191 | nuclear_norm = 876.25793
name = 'module._orig_mod.transformer.h.11.attn.c_q.weight' | fro_norm = 43.85244 | spectral_norm = 9.25756 | nuclear_norm = 861.73273
name = 'module._orig_mod.transformer.h.11.attn.c_k.weight' | fro_norm = 40.30243 | spectral_norm = 8.23242 | nuclear_norm = 805.02844
===========================================
