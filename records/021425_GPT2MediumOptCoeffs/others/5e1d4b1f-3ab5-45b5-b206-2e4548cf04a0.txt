import os
import sys
with open(sys.argv[0]) as f:
    code = f.read() # read the code of this file ASAP, for logging
import uuid
import time
import copy
import glob
from dataclasses import dataclass
from functools import lru_cache
from pathlib import Path

os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True"
import torch
torch.empty(1, device="cuda", requires_grad=True).backward() # prevents a bug on some systems
from torch import Tensor, nn
import torch.nn.functional as F
import torch.distributed as dist
# use of FlexAttention contributed by @KoszarskyB
from torch.nn.attention.flex_attention import BlockMask, flex_attention
#torch._inductor.config.coordinate_descent_tuning = True # we have banned this flag for new records because it causes compilation to take 30min

# -----------------------------------------------------------------------------
# Custom operators: FP8 matmul by @YouJiacheng

@torch.library.custom_op("nanogpt::mm", mutates_args=())
def mm_op(x: Tensor, w: Tensor, x_s: float, w_s: float, grad_s: float) -> tuple[Tensor, Tensor, Tensor]:
    @torch.compile
    def impl(x: Tensor, w: Tensor):
        assert x.is_contiguous() and w.is_contiguous()
        x_f8 = x.div(x_s).to(torch.float8_e4m3fn)
        w_f8 = w.div(w_s).to(torch.float8_e4m3fn)
        out = torch._scaled_mm(
            x_f8,
            w_f8.T,
            out_dtype=torch.bfloat16,
            scale_a=x.new_tensor(x_s, dtype=torch.float32),
            scale_b=x.new_tensor(w_s, dtype=torch.float32),
            use_fast_accum=True,
        )
        return out, x_f8, w_f8

    return impl(x, w)

@mm_op.register_fake
def _(x: Tensor, w: Tensor, *_):
    assert x.ndim == w.ndim == 2
    assert x.shape[1] == w.shape[1]
    assert x.device == w.device
    assert x.is_contiguous() and w.is_contiguous()
    return x @ w.T, x.to(torch.float8_e4m3fn), w.to(torch.float8_e4m3fn)

@torch.library.custom_op("nanogpt::mm_backward", mutates_args=())
def mm_backward_op(g: Tensor, x_f8: Tensor, w_f8: Tensor, x_s: float, w_s: float, grad_s: float) -> tuple[Tensor, Tensor]:
    @torch.compile
    def impl(grad: Tensor, x_f8: Tensor, w_f8: Tensor):
        assert grad.is_contiguous()
        x_inv_s = grad.new_tensor(x_s, dtype=torch.float32)
        w_inv_s = grad.new_tensor(w_s, dtype=torch.float32)
        grad_inv_s = grad.new_tensor(grad_s, dtype=torch.float32)
        grad_f8 = grad.div(grad_s).to(torch.float8_e5m2)
        grad_x = torch._scaled_mm(
            grad_f8,
            w_f8.T.contiguous().T,
            out_dtype=torch.bfloat16,
            scale_a=grad_inv_s,
            scale_b=w_inv_s,
            use_fast_accum=False,
        )
        # faster than grad_f8_t @ x_f8, for (d_out, d_in) == (50304, 768)
        grad_w = torch._scaled_mm(
            x_f8.T.contiguous(),
            grad_f8.T.contiguous().T,
            out_dtype=torch.float32,
            scale_a=x_inv_s,
            scale_b=grad_inv_s,
            use_fast_accum=False,
        ).T
        return grad_x, grad_w

    return impl(g, x_f8, w_f8)

@mm_backward_op.register_fake
def _(g: Tensor, x_f8: Tensor, w_f8: Tensor, *_):
    return x_f8.to(torch.bfloat16), w_f8.to(torch.float32)

def backward(ctx, grad_out: Tensor, *_):
    x_f8, w_f8 = ctx.saved_tensors
    x_s, w_s, grad_s = ctx.scales
    grad_x, grad_w = torch.ops.nanogpt.mm_backward(
        grad_out, x_f8, w_f8, x_s, w_s, grad_s
    )
    return grad_x, grad_w, None, None, None

def setup_context(ctx: torch.autograd.function.FunctionCtx, inputs, output):
    *_, x_s, w_s, grad_s = inputs
    _, x_f8, w_f8 = output
    ctx.save_for_backward(x_f8, w_f8)
    ctx.scales = x_s, w_s, grad_s
    ctx.set_materialize_grads(False)

mm_op.register_autograd(backward, setup_context=setup_context)

# -----------------------------------------------------------------------------
# Muon optimizer

@torch.compile
def zeropower_via_newtonschulz5(G: Tensor, steps: int) -> Tensor:
    """
    Newton-Schulz iteration to compute the zeroth power / orthogonalization of G. We opt to use a
    quintic iteration whose coefficients are selected to maximize the slope at zero. For the purpose
    of minimizing steps, it turns out to be empirically effective to keep increasing the slope at
    zero even beyond the point where the iteration no longer converges all the way to one everywhere
    on the interval. This iteration therefore does not produce UV^T but rather something like US'V^T
    where S' is diagonal with S_{ii}' ~ Uniform(0.5, 1.5), which turns out not to hurt model
    performance at all relative to UV^T, where USV^T = G is the SVD.
    """
    assert G.ndim >= 2 # batched Muon implementation by @scottjmaddox, and put into practice in the record by @YouJiacheng
    X = G.bfloat16()
    if G.size(-2) > G.size(-1):
        X = X.mT

    # Ensure spectral norm is at most 1
    X = X / (X.norm(dim=(-2, -1), keepdim=True) + 1e-7)
    # Perform the NS iterations
    for a, b, c in [
        (3.8839, -3.9828, 1.0989),
        (3.7253, -3.8239, 1.0986),
        (3.5715, -3.6700, 1.0985),
        (3.4220, -3.5202, 1.0983),
        (3.2774, -3.3757, 1.0983),
        (3.1288, -3.2227, 1.0939),
        (2.7203, -2.6642, 0.9439),
    ]:
        A = X @ X.mT
        B = b * A + c * A @ A # quintic computation strategy adapted from suggestion by @jxbz, @leloykun, and @YouJiacheng
        X = a * X + B @ X
    
    if G.size(-2) > G.size(-1):
        X = X.mT
    return X

class Muon(torch.optim.Optimizer):
    """
    Muon - MomentUm Orthogonalized by Newton-schulz

    https://kellerjordan.github.io/posts/muon/

    Muon internally runs standard SGD-momentum, and then performs an orthogonalization post-
    processing step, in which each 2D parameter's update is replaced with the nearest orthogonal
    matrix. To efficiently orthogonalize each update, we use a Newton-Schulz iteration, which has
    the advantage that it can be stably run in bfloat16 on the GPU.

    Some warnings:
    - This optimizer should not be used for the embedding layer, the final fully connected layer,
    or any {0,1}-D parameters; those should all be optimized by a standard method (e.g., AdamW).
    - To use it with 4D convolutional filters, it works well to just flatten their last 3 dimensions.

    Arguments:
        lr: The learning rate used by the internal SGD.
        momentum: The momentum used by the internal SGD.
        nesterov: Whether to use Nesterov-style momentum in the internal SGD. (recommended)
        ns_steps: The number of Newton-Schulz iteration steps to use.
    """
    def __init__(self, params, lr=0.02, momentum=0.95, nesterov=True, ns_steps=5, rank=0, world_size=1):
        self.rank = rank
        self.world_size = world_size
        defaults = dict(lr=lr, momentum=momentum, nesterov=nesterov, ns_steps=ns_steps)
        params: list[Tensor] = [*params]
        param_groups = []
        for size in {p.numel() for p in params}:
            b = torch.empty(world_size, size, dtype=torch.bfloat16, device="cuda")
            group = dict(params=[p for p in params if p.numel() == size],
                         update_buffer=b, update_buffer_views=[b[i] for i in range(world_size)])
            param_groups.append(group)
        super().__init__(param_groups, defaults)

    @torch.no_grad()
    def step(self):
        for group in self.param_groups:
            update_buffer: Tensor = group["update_buffer"]
            update_buffer_views: list[Tensor] = group["update_buffer_views"]
            # generate weight updates in distributed fashion
            params: list[Tensor] = group["params"]
            handle = None
            params_world = None
            def update_prev(): # optimized Muon implementation contributed by @YouJiacheng
                handle.wait()
                for p_world, g_world in zip(params_world, update_buffer_views):
                    p_world.add_(g_world.view_as(p_world),
                                 alpha=-group["lr"] * max(1, p_world.size(-2) / p_world.size(-1))**0.5)
            for base_i in range(len(params))[::self.world_size]:
                if base_i + self.rank < len(params):
                    p = params[base_i + self.rank]
                    g = p.grad
                    assert g is not None
                    state = self.state[p]
                    if "momentum_buffer" not in state:
                        state["momentum_buffer"] = torch.zeros_like(g)
                    buf: Tensor = state["momentum_buffer"]
                    buf.lerp_(g, 1 - group["momentum"])
                    g = g.lerp_(buf, group["momentum"]) if group["nesterov"] else buf
                    g = zeropower_via_newtonschulz5(g, steps=group["ns_steps"]).flatten()
                else:
                    g = update_buffer_views[self.rank]
                if base_i > 0:
                    update_prev() # async all_gather instead of sync all_reduce by @YouJiacheng
                handle = dist.all_gather_into_tensor(update_buffer, g, async_op=True)
                params_world = params[base_i : base_i + self.world_size]
            update_prev()

# -----------------------------------------------------------------------------
# PyTorch nn.Module definitions for the model

def norm(x: Tensor):
    return F.rms_norm(x, (x.size(-1),))

class CastedLinear(nn.Linear):
    def __init__(self, in_features: int, out_features: int, use_fp8=False, x_s=1.0, w_s=1.0, grad_s=1.0):
        super().__init__(in_features, out_features, bias=False)
        self.use_fp8 = use_fp8
        self.x_s = x_s
        self.w_s = w_s
        self.grad_s = grad_s

    def reset_parameters(self) -> None:
        std = 0.5 * (self.in_features ** -0.5) # 0.5 is a bit better than the default 1/sqrt(3)
        bound = (3 ** 0.5) * std
        with torch.no_grad():
            self.weight.uniform_(-bound, bound)

    def forward(self, x: Tensor):
        if self.use_fp8 and self.training:
            _x = x.flatten(0, -2)
            out: Tensor = torch.ops.nanogpt.mm(_x, self.weight, x_s=self.x_s, w_s=self.w_s, grad_s=self.grad_s)[0]
            return out.reshape(*x.shape[:-1], -1)
        else:
            return F.linear(x, self.weight.type_as(x))

class Rotary(nn.Module):
    def __init__(self, dim: int, max_seq_len: int):
        super().__init__()
        # half-truncate RoPE by @YouJiacheng (w/ base freq tuning)
        angular_freq = (1 / 1024) ** torch.linspace(0, 1, steps=dim//4, dtype=torch.float32)
        angular_freq = torch.cat([angular_freq, angular_freq.new_zeros(dim//4)])
        t = torch.arange(max_seq_len, dtype=torch.float32)
        theta = torch.einsum("i,j -> ij", t, angular_freq)
        self.cos = nn.Buffer(theta.cos(), persistent=False)
        self.sin = nn.Buffer(theta.sin(), persistent=False)

    def forward(self, x_BTHD: Tensor):
        assert self.cos.size(0) >= x_BTHD.size(-3)
        cos, sin = self.cos[None, :x_BTHD.size(-3), None, :], self.sin[None, :x_BTHD.size(-3), None, :]
        x1, x2 = x_BTHD.to(dtype=torch.float32).chunk(2, dim=-1)
        y1 = x1 * cos + x2 * sin
        y2 = x1 * (-sin) + x2 * cos
        return torch.cat((y1, y2), 3).type_as(x_BTHD)

class CausalSelfAttention(nn.Module):
    def __init__(self, dim: int, num_heads: int, max_seq_len: int, head_dim=128):
        super().__init__()
        self.num_heads = num_heads
        self.head_dim = head_dim
        hdim = num_heads * head_dim
        std = 0.5 * (dim ** -0.5)
        bound = (3 ** 0.5) * std # improved init scale by @YouJiacheng
        # merged QKV weights: suggested by many, implemented by @fernbear.bsky.social, and further improved by @YouJiacheng
        # https://x.com/hi_tysam/status/1879699187107033311
        self.qkv_w = nn.Parameter(torch.empty(3, hdim, dim).uniform_(-bound, bound))
        self.lambdas = nn.Parameter(torch.tensor([0.5, 0.5]))
        self.rotary = Rotary(head_dim, max_seq_len)
        self.c_proj = CastedLinear(hdim, dim)
        self.c_proj.weight.detach().zero_() # zero init suggested by @Grad62304977

    def forward(self, x: Tensor, ve: Tensor | None, block_mask: BlockMask):
        B, T = x.size(0), x.size(1) # batch size, sequence length
        assert B == 1, "Must use batch size = 1 for FlexAttention"
        q, k, v = F.linear(x, self.qkv_w.flatten(end_dim=1).type_as(x)).view(B, T, 3 * self.num_heads, self.head_dim).chunk(3, dim=-2)
        q, k = norm(q), norm(k) # QK norm @Grad62304977
        q, k = self.rotary(q), self.rotary(k)
        if ve is not None:
            v = self.lambdas[0] * v + self.lambdas[1] * ve.view_as(v) # @KoszarskyB & @Grad62304977
        else: # skip mid-layers token value embeddings by @YouJiacheng
            v = self.lambdas[0] * v
        # scale the attention logits by given constant, instead of the default head_dim**-0.5, by @leloykun
        # inspired by learnable scalars used by @brendanh0gan https://x.com/hi_tysam/status/1879693583898591283
        y = flex_attention(q.transpose(1, 2), k.transpose(1, 2), v.transpose(1, 2), block_mask=block_mask, scale=15/self.head_dim).transpose(1, 2)
        y = y.contiguous().view(B, T, self.num_heads * self.head_dim) # re-assemble all head outputs side by side
        y = self.c_proj(y)
        return y

class MLP(nn.Module):
    def __init__(self, dim: int):
        super().__init__()
        hdim = 4 * dim
        self.c_fc = CastedLinear(dim, hdim)
        self.c_proj = CastedLinear(hdim, dim)
        self.c_proj.weight.detach().zero_() # zero init suggested by @Grad62304977

    def forward(self, x: Tensor):
        x = self.c_fc(x)
        x = F.relu(x).square() # https://arxiv.org/abs/2109.08668v2; ~1-2% better than GELU; suggested by @SKYLINEZ007 and @Grad62304977
        x = self.c_proj(x)
        return x

class Block(nn.Module):
    def __init__(self, dim: int, num_heads: int, max_seq_len: int, layer_idx: int):
        super().__init__()
        # skip attention of blocks.7 (the 8th layer) by @YouJiacheng
        self.attn = CausalSelfAttention(dim, num_heads, max_seq_len) if layer_idx != 7 else None
        self.mlp = MLP(dim)
        self.lambdas = nn.Parameter(torch.tensor([1., 0.]))

    def forward(self, x: Tensor, ve: Tensor | None, x0: Tensor, block_mask: BlockMask):
        x = self.lambdas[0] * x + self.lambdas[1] * x0
        if self.attn is not None:
            x = x + self.attn(norm(x), ve, block_mask)
        x = x + self.mlp(norm(x))
        return x

# -----------------------------------------------------------------------------
# The main model

def next_multiple_of_n(v: float | int, *, n: int):
    return next(x for x in range(n, int(v) + 1 + n, n) if x >= v)

class GPT(nn.Module):
    def __init__(self, vocab_size: int, num_layers: int, num_heads: int, model_dim: int, max_seq_len: int):
        super().__init__()
        self.embed = nn.Embedding(vocab_size, model_dim)
        # token value embeddings by @KoszarskyB - inspired by @Grad62304977's value residual implementation following https://arxiv.org/abs/2410.17897
        # value embedding code simplification inspired by @ragulpr https://github.com/KellerJordan/modded-nanogpt/pull/78
        self.value_embeds = nn.ModuleList([nn.Embedding(vocab_size, model_dim) for _ in range(3)])
        self.blocks = nn.ModuleList([Block(model_dim, num_heads, max_seq_len, i) for i in range(num_layers)])
        # there are only 50257 unique GPT-2 tokens; we extend to nearest multiple of 128 for efficiency.
        # suggested to me by @Grad62304977. this originates from Karpathy's experiments.
        self.lm_head = CastedLinear(model_dim, next_multiple_of_n(vocab_size, n=128), use_fp8=True, x_s=(768**0.5)/448, w_s=2**-9, grad_s=1/448)
        self.lm_head.weight.detach().zero_() # @Grad62304977
        # Add learnable skip connection weights for decoder layers
        assert num_layers % 2 == 0
        self.skip_weights = nn.Parameter(torch.ones(num_layers//2))

    def create_blockmasks(self, input_seq: Tensor, sliding_window_num_blocks: Tensor):
        BLOCK_SIZE = 128
        docs = (input_seq == 50256).cumsum(0)

        def document_causal(b, h, q_idx, kv_idx):
            causal_mask = q_idx >= kv_idx
            document_mask = docs[q_idx] == docs[kv_idx]
            return causal_mask & document_mask

        def dense_to_ordered(dense_blockmask: Tensor):
            num_blocks = dense_blockmask.sum(dim=-1, dtype=torch.int32)
            indices = dense_blockmask.argsort(dim=-1, descending=False, stable=True).flip(-1).to(torch.int32)
            return num_blocks[None, None].contiguous(), indices[None, None].contiguous()

        # manual block mask creation by @YouJiacheng
        assert len(input_seq) % BLOCK_SIZE == 0
        NUM_BLOCKS = len(input_seq) // BLOCK_SIZE
        block_idx = torch.arange(NUM_BLOCKS, dtype=torch.int32, device="cuda")
        causal_blockmask_any = block_idx[:, None] >= block_idx
        causal_blockmask_all = block_idx[:, None] > block_idx
        docs_low = docs.view(-1, BLOCK_SIZE)[:, 0].contiguous()
        docs_high = docs.view(-1, BLOCK_SIZE)[:, -1].contiguous()
        document_blockmask_any = (docs_low[:, None] <= docs_high) & (docs_high[:, None] >= docs_low)
        document_blockmask_all = (docs_low[:, None] == docs_high) & (docs_high[:, None] == docs_low)
        blockmask_any = causal_blockmask_any & document_blockmask_any
        blockmask_all = causal_blockmask_all & document_blockmask_all
        partial_kv_num_blocks, partial_kv_indices = dense_to_ordered(blockmask_any & ~blockmask_all)
        full_kv_num_blocks, full_kv_indices = dense_to_ordered(blockmask_all)
        def build_bm(window_size_blocks: Tensor) -> BlockMask:
            return BlockMask.from_kv_blocks(
                torch.clamp_max(partial_kv_num_blocks, torch.clamp_min(window_size_blocks - full_kv_num_blocks, 1)),
                partial_kv_indices,
                torch.clamp_max(full_kv_num_blocks, window_size_blocks - 1),
                full_kv_indices,
                BLOCK_SIZE=BLOCK_SIZE,
                mask_mod=document_causal,
            )
        # Long-short SWA block masks by @leloykun & @YouJiacheng, adapated from suggestion by @Grad62304977, following Gemma 2 paper
        return build_bm(sliding_window_num_blocks), build_bm(sliding_window_num_blocks // 2)

    def forward(self, input_seq: Tensor, target_seq: Tensor, sliding_window_num_blocks: Tensor):
        assert input_seq.ndim == 1

        ve = [value_embed(input_seq) for value_embed in self.value_embeds]
        # 012 ... 012 structure on token value embeddings by @YouJiacheng, improved on @leloykun's U-net structure
        ve = [ve[0], ve[1], ve[2]] + [None] * (len(self.blocks) - 6) + [ve[0], ve[1], ve[2]]
        assert len(ve) == len(self.blocks)

        long_bm, short_bm = self.create_blockmasks(input_seq, sliding_window_num_blocks)
        block_masks = [long_bm, short_bm, short_bm, short_bm, long_bm, short_bm, short_bm, long_bm, short_bm, short_bm, short_bm, long_bm]
        assert len(block_masks) == len(self.blocks)

        x = x0 = norm(self.embed(input_seq)[None]) # use of norm here by @Grad62304977

        # U-net design by @brendanh0gan
        skip_connections = []
        n = len(self.skip_weights)
        for i in range(len(self.blocks)):
            if i >= n:
                x = x + self.skip_weights[i - n] * skip_connections.pop()
            x = self.blocks[i](x, ve[i], x0, block_masks[i])
            if i < n:
                skip_connections.append(x)

        x = norm(x)
        logits = self.lm_head(x).float()
        # @Grad62304977 added tanh softcapping following Gemma 2 paper, @KoszarskyB reduced it from 30 to 15, @YouJiacheng shifted it by +15 (2*sigmoid(2*x)=tanh(x)+1)
        logits = 30 * torch.sigmoid(logits / 7.5)
        loss = F.cross_entropy(logits.view(-1, logits.size(-1)), target_seq, reduction='sum' if self.training else 'mean')
        return loss

# -----------------------------------------------------------------------------
# Our own simple Distributed Data Loader

def _load_data_shard(file: Path):
    header = torch.from_file(str(file), False, 256, dtype=torch.int32) # header is 256 int32
    assert header[0] == 20240520, "magic number mismatch in the data .bin file"
    assert header[1] == 1, "unsupported version"
    num_tokens = int(header[2]) # number of tokens (claimed)
    with file.open("rb", buffering=0) as f:
        tokens = torch.empty(num_tokens, dtype=torch.uint16, pin_memory=True) # avoid pin_memory copy by @YouJiacheng
        f.seek(256 * 4)
        nbytes = f.readinto(tokens.numpy()) # avoid bytes->array copy by @YouJiacheng
        assert nbytes == 2 * num_tokens, "number of tokens read does not match header"
    return tokens

def distributed_data_generator(filename_pattern: str, batch_size: int, rank : int, world_size : int):
    files = [Path(file) for file in sorted(glob.glob(filename_pattern))]
    assert batch_size % world_size == 0
    local_batch_size = batch_size // world_size
    file_iter = iter(files) # use itertools.cycle(files) instead if you want to do multi-epoch training
    tokens, pos = _load_data_shard(next(file_iter)), 0
    while True:
        if pos + batch_size + 1 >= len(tokens):
            tokens, pos = _load_data_shard(next(file_iter)), 0
        buf = tokens[pos + rank * local_batch_size:][:local_batch_size + 1]
        inputs = buf[:-1].to(device="cuda", dtype=torch.int32, non_blocking=True) # no sync on host side;
        targets = buf[1:].to(device="cuda", dtype=torch.int64, non_blocking=True) # H2D in another stream isn't helpful.
        pos += batch_size
        yield inputs, targets

# -----------------------------------------------------------------------------
# int main

@dataclass
class Hyperparameters:
    # data
    train_files = "data/fineweb10B/fineweb_train_*.bin" # input .bin to train on
    val_files = "data/fineweb10B/fineweb_val_*.bin" # input .bin to eval validation loss on
    val_tokens = 10485760 # how many tokens of validation data? it's important to keep this fixed for consistent comparisons
    train_seq_len = 48*1024 # FlexAttention sequence length
    val_seq_len = 4*64*1024 # FlexAttention sequence length for validation
    # optimization
    num_iterations = 1750 # number of iterations to run
    cooldown_frac = 0.4 # fraction of training spent cooling down the learning rate
    # architecture
    vocab_size = 50257
    # evaluation and logging
    val_loss_every = 125 # every how many steps to evaluate val loss? 0 for only at the end
    save_checkpoint = False
args = Hyperparameters()

# torchrun sets these env variables
rank = int(os.environ["RANK"])
world_size = int(os.environ["WORLD_SIZE"])
assert world_size == 8 # this code is designed for 8xH100
assert torch.cuda.is_available()
device = torch.device("cuda", int(os.environ["LOCAL_RANK"]))
torch.cuda.set_device(device)
dist.init_process_group(backend="nccl", device_id=device)
dist.barrier()
master_process = (rank == 0) # this process will do logging, checkpointing etc.

# begin logging
logfile = None
if master_process:
    run_id = uuid.uuid4()
    os.makedirs("logs", exist_ok=True)
    logfile = f"logs/{run_id}.txt"
    print(logfile)
def print0(s, console=False):
    if master_process:
        with open(logfile, "a") as f:
            if console:
                print(s)
            print(s, file=f)

# begin by printing this file (the Python code)
print0(code)
print0("="*100)
# log information about the hardware/software environment this is running on
print0(f"Running Python {sys.version}")
print0(f"Running PyTorch {torch.version.__version__} compiled for CUDA {torch.version.cuda}")
def nvidia_smi():
    import subprocess  # avoid top level import
    return subprocess.run(["nvidia-smi"], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True).stdout
print0(nvidia_smi())
print0("="*100)

########################################
#    Construct model and optimizer     #
########################################

model: nn.Module = GPT(vocab_size=args.vocab_size, num_layers=12, num_heads=6, model_dim=768,
                       max_seq_len=max(args.train_seq_len, args.val_seq_len)).cuda()
for m in model.modules():
    if isinstance(m, nn.Embedding):
        m.bfloat16()
for param in model.parameters():
    dist.broadcast(param.detach(), 0)

# collect the parameters to optimize
hidden_matrix_params = [p for n, p in model.blocks.named_parameters() if p.ndim >= 2 and "embed" not in n]
embed_params = [p for n, p in model.named_parameters() if "embed" in n]
scalar_params = [p for p in model.parameters() if p.ndim < 2]
head_params = [model.lm_head.weight]

# init the optimizer(s)
adam_params = [dict(params=head_params, lr=0.22/768**0.5), dict(params=embed_params, lr=0.6), dict(params=scalar_params, lr=0.04)]
# small adam epsilon by @YouJiacheng. this is an alternate method of fixing the world_size dependence
# discovered by @fernbear.bsky.social https://x.com/hi_tysam/status/1879692937589875094
optimizer1 = torch.optim.Adam(adam_params, betas=(0.8, 0.95), eps=1e-10, fused=True)
optimizer2 = Muon(hidden_matrix_params, lr=0.05, momentum=0.95, rank=rank, world_size=world_size)
optimizers = [optimizer1, optimizer2]
for opt in optimizers:
    for group in opt.param_groups:
        group["initial_lr"] = group["lr"]

# learning rate schedule: stable then decay
def get_lr(step: int):
    x = step / args.num_iterations # progress in training
    assert 0 <= x < 1
    if x < 1 - args.cooldown_frac:
        return 1.0
    else:
        w = (1 - x) / args.cooldown_frac
        return w * 1.0 + (1 - w) * 0.1

# attention window size schedule: linearly increase
@lru_cache(1)
def get_window_size_blocks_helper(window_size: int):
    return torch.tensor(window_size // 128, dtype=torch.int32, pin_memory=True).cuda(non_blocking=True)
def get_window_size_blocks(step: int):
    x = step / args.num_iterations # progress in training
    assert 0 <= x <= 1
    # Linearly increase the block-wise sliding window size over training 128 -> 1792
    # increase by @fernbear.bsky.social; block-wise by @YouJiacheng
    window_size = next_multiple_of_n(1728 * x, n=128)
    return get_window_size_blocks_helper(window_size)

model: nn.Module = torch.compile(model, dynamic=False)

########################################
#            Warmup kernels            #
########################################

# Warmup the training kernels, then re-initialize the state so we aren't cheating
warmup_steps = 10
initial_state = dict(model=copy.deepcopy(model.state_dict()),
                     optimizers=[copy.deepcopy(opt.state_dict()) for opt in optimizers]) # save the initial state
for _ in range(warmup_steps):
    inputs = targets = torch.randint(0, args.vocab_size, size=(args.train_seq_len,), device="cuda")
    model(inputs.to(torch.int32), targets, get_window_size_blocks(0)).backward()
    for param in model.parameters():
        dist.all_reduce(param.grad, op=dist.ReduceOp.AVG)
    for opt in optimizers:
        opt.step()
    model.zero_grad(set_to_none=True)
model.load_state_dict(initial_state["model"])
for opt, opt_state in zip(optimizers, initial_state["optimizers"]):
    opt.load_state_dict(opt_state)
del initial_state

########################################
#        Training and validation       #
########################################

train_loader = distributed_data_generator(args.train_files, world_size * args.train_seq_len, rank, world_size)
training_time_ms = 0
# start the clock
torch.cuda.synchronize()
t0 = time.perf_counter()
# begin training
train_steps = args.num_iterations
for step in range(train_steps + 1):
    last_step = (step == train_steps)

    # --------------- VALIDATION SECTION -----------------
    if last_step or (args.val_loss_every > 0 and step % args.val_loss_every == 0):
        # stop the clock
        torch.cuda.synchronize()
        training_time_ms += 1000 * (time.perf_counter() - t0)
        model.eval()
        val_batch_size = world_size * args.val_seq_len
        assert args.val_tokens % val_batch_size == 0
        val_steps = args.val_tokens // val_batch_size
        val_loader = distributed_data_generator(args.val_files, val_batch_size, rank, world_size)
        val_loss = 0
        with torch.no_grad():
            for _ in range(val_steps):
                inputs, targets = next(val_loader)
                val_loss += model(inputs, targets, get_window_size_blocks(step))
        val_loss /= val_steps
        del val_loader
        dist.all_reduce(val_loss, op=dist.ReduceOp.AVG)
        print0(f"step:{step}/{train_steps} val_loss:{val_loss:.4f} train_time:{training_time_ms:.0f}ms step_avg:{training_time_ms/max(step, 1):.2f}ms", console=True)
        model.train()
        # start the clock again
        torch.cuda.synchronize()
        t0 = time.perf_counter()

    if last_step:
        if master_process and args.save_checkpoint:
            log = dict(step=step, code=code, model=model.state_dict(), optimizers=[opt.state_dict() for opt in optimizers])
            os.makedirs(f"logs/{run_id}", exist_ok=True)
            torch.save(log, f"logs/{run_id}/state_step{step:06d}.pt")
        # the last step only has the validation loop, so break to avoid training
        break

    # --------------- TRAINING SECTION -----------------
    inputs, targets = next(train_loader)
    model(inputs, targets, get_window_size_blocks(step)).backward()
    for param in model.parameters():
        dist.all_reduce(param.grad, op=dist.ReduceOp.AVG)
    # set optimization hyperparameters
    for opt in optimizers:
        for group in opt.param_groups:
            group["lr"] = group["initial_lr"] * get_lr(step)
    for group in optimizer2.param_groups:
        frac = min(step / 300, 1) # momentum warmup for muon
        group["momentum"] = (1 - frac) * 0.85 + frac * 0.95
    # step the optimizers
    for opt in optimizers:
        opt.step()
    # null the gradients
    model.zero_grad(set_to_none=True)
    # logging
    approx_training_time_ms = training_time_ms + 1000 * (time.perf_counter() - t0)
    print0(f"step:{step+1}/{train_steps} train_time:{approx_training_time_ms:.0f}ms step_avg:{approx_training_time_ms/(step + 1):.2f}ms", console=True)

print0(f"peak memory allocated: {torch.cuda.max_memory_allocated() // 1024 // 1024} MiB "
       f"reserved: {torch.cuda.max_memory_reserved() // 1024 // 1024} MiB", console=True)
dist.destroy_process_group()

====================================================================================================
Running Python 3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]
Running PyTorch 2.7.0.dev20250125+cu126 compiled for CUDA 12.6
Sun Feb 16 18:27:07 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA H100 80GB HBM3          On  |   00000000:19:00.0 Off |                    0 |
| N/A   38C    P0            116W /  700W |    7714MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA H100 80GB HBM3          On  |   00000000:3B:00.0 Off |                    0 |
| N/A   30C    P0            120W /  700W |    3452MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA H100 80GB HBM3          On  |   00000000:4C:00.0 Off |                    0 |
| N/A   29C    P0            115W /  700W |    3452MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA H100 80GB HBM3          On  |   00000000:5D:00.0 Off |                    0 |
| N/A   37C    P0            119W /  700W |    3452MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   4  NVIDIA H100 80GB HBM3          On  |   00000000:9B:00.0 Off |                    0 |
| N/A   37C    P0            119W /  700W |    3452MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   5  NVIDIA H100 80GB HBM3          On  |   00000000:BB:00.0 Off |                    0 |
| N/A   31C    P0            112W /  700W |    3452MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   6  NVIDIA H100 80GB HBM3          On  |   00000000:CB:00.0 Off |                    0 |
| N/A   36C    P0            115W /  700W |    3452MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   7  NVIDIA H100 80GB HBM3          On  |   00000000:DB:00.0 Off |                    0 |
| N/A   29C    P0            113W /  700W |    3212MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
+-----------------------------------------------------------------------------------------+

====================================================================================================
step:0/1750 val_loss:10.8258 train_time:0ms step_avg:0.02ms
step:1/1750 train_time:64ms step_avg:64.43ms
step:2/1750 train_time:142ms step_avg:70.96ms
step:3/1750 train_time:235ms step_avg:78.25ms
step:4/1750 train_time:331ms step_avg:82.73ms
step:5/1750 train_time:428ms step_avg:85.63ms
step:6/1750 train_time:525ms step_avg:87.49ms
step:7/1750 train_time:622ms step_avg:88.92ms
step:8/1750 train_time:719ms step_avg:89.91ms
step:9/1750 train_time:816ms step_avg:90.70ms
step:10/1750 train_time:914ms step_avg:91.35ms
step:11/1750 train_time:1011ms step_avg:91.87ms
step:12/1750 train_time:1108ms step_avg:92.30ms
step:13/1750 train_time:1204ms step_avg:92.63ms
step:14/1750 train_time:1301ms step_avg:92.93ms
step:15/1750 train_time:1398ms step_avg:93.20ms
step:16/1750 train_time:1496ms step_avg:93.51ms
step:17/1750 train_time:1593ms step_avg:93.69ms
step:18/1750 train_time:1690ms step_avg:93.87ms
step:19/1750 train_time:1787ms step_avg:94.04ms
step:20/1750 train_time:1884ms step_avg:94.18ms
step:21/1750 train_time:1981ms step_avg:94.31ms
step:22/1750 train_time:2077ms step_avg:94.42ms
step:23/1750 train_time:2175ms step_avg:94.55ms
step:24/1750 train_time:2272ms step_avg:94.65ms
step:25/1750 train_time:2370ms step_avg:94.78ms
step:26/1750 train_time:2467ms step_avg:94.87ms
step:27/1750 train_time:2563ms step_avg:94.94ms
step:28/1750 train_time:2660ms step_avg:94.99ms
step:29/1750 train_time:2757ms step_avg:95.05ms
step:30/1750 train_time:2855ms step_avg:95.15ms
step:31/1750 train_time:2952ms step_avg:95.22ms
step:32/1750 train_time:3049ms step_avg:95.29ms
step:33/1750 train_time:3146ms step_avg:95.33ms
step:34/1750 train_time:3243ms step_avg:95.37ms
step:35/1750 train_time:3340ms step_avg:95.42ms
step:36/1750 train_time:3437ms step_avg:95.46ms
step:37/1750 train_time:3534ms step_avg:95.52ms
step:38/1750 train_time:3630ms step_avg:95.53ms
step:39/1750 train_time:3727ms step_avg:95.56ms
step:40/1750 train_time:3824ms step_avg:95.59ms
step:41/1750 train_time:3920ms step_avg:95.62ms
step:42/1750 train_time:4017ms step_avg:95.65ms
step:43/1750 train_time:4115ms step_avg:95.69ms
step:44/1750 train_time:4213ms step_avg:95.74ms
step:45/1750 train_time:4310ms step_avg:95.78ms
step:46/1750 train_time:4407ms step_avg:95.81ms
step:47/1750 train_time:4505ms step_avg:95.85ms
step:48/1750 train_time:4603ms step_avg:95.89ms
step:49/1750 train_time:4700ms step_avg:95.91ms
step:50/1750 train_time:4796ms step_avg:95.93ms
step:51/1750 train_time:4894ms step_avg:95.97ms
step:52/1750 train_time:4991ms step_avg:95.98ms
step:53/1750 train_time:5088ms step_avg:96.01ms
step:54/1750 train_time:5185ms step_avg:96.02ms
step:55/1750 train_time:5282ms step_avg:96.04ms
step:56/1750 train_time:5379ms step_avg:96.05ms
step:57/1750 train_time:5476ms step_avg:96.06ms
step:58/1750 train_time:5573ms step_avg:96.08ms
step:59/1750 train_time:5671ms step_avg:96.12ms
step:60/1750 train_time:5769ms step_avg:96.16ms
step:61/1750 train_time:5867ms step_avg:96.19ms
step:62/1750 train_time:5963ms step_avg:96.18ms
step:63/1750 train_time:6059ms step_avg:96.18ms
step:64/1750 train_time:6156ms step_avg:96.19ms
step:65/1750 train_time:6254ms step_avg:96.21ms
step:66/1750 train_time:6351ms step_avg:96.23ms
step:67/1750 train_time:6449ms step_avg:96.26ms
step:68/1750 train_time:6547ms step_avg:96.28ms
step:69/1750 train_time:6644ms step_avg:96.28ms
step:70/1750 train_time:6740ms step_avg:96.29ms
step:71/1750 train_time:6837ms step_avg:96.29ms
step:72/1750 train_time:6934ms step_avg:96.30ms
step:73/1750 train_time:7032ms step_avg:96.33ms
step:74/1750 train_time:7130ms step_avg:96.35ms
step:75/1750 train_time:7227ms step_avg:96.36ms
step:76/1750 train_time:7324ms step_avg:96.37ms
step:77/1750 train_time:7421ms step_avg:96.38ms
step:78/1750 train_time:7518ms step_avg:96.39ms
step:79/1750 train_time:7615ms step_avg:96.39ms
step:80/1750 train_time:7712ms step_avg:96.40ms
step:81/1750 train_time:7809ms step_avg:96.40ms
step:82/1750 train_time:7905ms step_avg:96.41ms
step:83/1750 train_time:8002ms step_avg:96.41ms
step:84/1750 train_time:8099ms step_avg:96.42ms
step:85/1750 train_time:8196ms step_avg:96.43ms
step:86/1750 train_time:8293ms step_avg:96.43ms
step:87/1750 train_time:8390ms step_avg:96.44ms
step:88/1750 train_time:8488ms step_avg:96.45ms
step:89/1750 train_time:8585ms step_avg:96.46ms
step:90/1750 train_time:8681ms step_avg:96.46ms
step:91/1750 train_time:8778ms step_avg:96.46ms
step:92/1750 train_time:8875ms step_avg:96.46ms
step:93/1750 train_time:8972ms step_avg:96.47ms
step:94/1750 train_time:9069ms step_avg:96.48ms
step:95/1750 train_time:9166ms step_avg:96.48ms
step:96/1750 train_time:9263ms step_avg:96.49ms
step:97/1750 train_time:9359ms step_avg:96.48ms
step:98/1750 train_time:9455ms step_avg:96.48ms
step:99/1750 train_time:9553ms step_avg:96.49ms
step:100/1750 train_time:9651ms step_avg:96.51ms
step:101/1750 train_time:9749ms step_avg:96.52ms
step:102/1750 train_time:9846ms step_avg:96.53ms
step:103/1750 train_time:9943ms step_avg:96.54ms
step:104/1750 train_time:10040ms step_avg:96.54ms
step:105/1750 train_time:10138ms step_avg:96.55ms
step:106/1750 train_time:10234ms step_avg:96.54ms
step:107/1750 train_time:10331ms step_avg:96.55ms
step:108/1750 train_time:10428ms step_avg:96.56ms
step:109/1750 train_time:10525ms step_avg:96.56ms
step:110/1750 train_time:10622ms step_avg:96.56ms
step:111/1750 train_time:10719ms step_avg:96.56ms
step:112/1750 train_time:10815ms step_avg:96.57ms
step:113/1750 train_time:10913ms step_avg:96.57ms
step:114/1750 train_time:11009ms step_avg:96.57ms
step:115/1750 train_time:11106ms step_avg:96.58ms
step:116/1750 train_time:11202ms step_avg:96.57ms
step:117/1750 train_time:11299ms step_avg:96.57ms
step:118/1750 train_time:11395ms step_avg:96.57ms
step:119/1750 train_time:11492ms step_avg:96.57ms
step:120/1750 train_time:11590ms step_avg:96.58ms
step:121/1750 train_time:11687ms step_avg:96.58ms
step:122/1750 train_time:12135ms step_avg:99.47ms
step:123/1750 train_time:12194ms step_avg:99.14ms
step:124/1750 train_time:12289ms step_avg:99.11ms
step:125/1750 train_time:12386ms step_avg:99.09ms
step:125/1750 val_loss:4.6328 train_time:12477ms step_avg:99.82ms
step:126/1750 train_time:12498ms step_avg:99.19ms
step:127/1750 train_time:12588ms step_avg:99.11ms
step:128/1750 train_time:12691ms step_avg:99.14ms
step:129/1750 train_time:12790ms step_avg:99.15ms
step:130/1750 train_time:12888ms step_avg:99.14ms
step:131/1750 train_time:12985ms step_avg:99.12ms
step:132/1750 train_time:13082ms step_avg:99.11ms
step:133/1750 train_time:13179ms step_avg:99.09ms
step:134/1750 train_time:13276ms step_avg:99.08ms
step:135/1750 train_time:13374ms step_avg:99.07ms
step:136/1750 train_time:13472ms step_avg:99.06ms
step:137/1750 train_time:13569ms step_avg:99.05ms
step:138/1750 train_time:13667ms step_avg:99.03ms
step:139/1750 train_time:13764ms step_avg:99.02ms
step:140/1750 train_time:13861ms step_avg:99.01ms
step:141/1750 train_time:13959ms step_avg:99.00ms
step:142/1750 train_time:14057ms step_avg:98.99ms
step:143/1750 train_time:14154ms step_avg:98.98ms
step:144/1750 train_time:14252ms step_avg:98.97ms
step:145/1750 train_time:14351ms step_avg:98.97ms
step:146/1750 train_time:14449ms step_avg:98.96ms
step:147/1750 train_time:14547ms step_avg:98.96ms
step:148/1750 train_time:14644ms step_avg:98.95ms
step:149/1750 train_time:14742ms step_avg:98.94ms
step:150/1750 train_time:14839ms step_avg:98.93ms
step:151/1750 train_time:14937ms step_avg:98.92ms
step:152/1750 train_time:15034ms step_avg:98.91ms
step:153/1750 train_time:15132ms step_avg:98.90ms
step:154/1750 train_time:15229ms step_avg:98.89ms
step:155/1750 train_time:15327ms step_avg:98.89ms
step:156/1750 train_time:15425ms step_avg:98.88ms
step:157/1750 train_time:15522ms step_avg:98.86ms
step:158/1750 train_time:15619ms step_avg:98.85ms
step:159/1750 train_time:15716ms step_avg:98.84ms
step:160/1750 train_time:15814ms step_avg:98.84ms
step:161/1750 train_time:15911ms step_avg:98.83ms
step:162/1750 train_time:16009ms step_avg:98.82ms
step:163/1750 train_time:16107ms step_avg:98.82ms
step:164/1750 train_time:16205ms step_avg:98.81ms
step:165/1750 train_time:16303ms step_avg:98.80ms
step:166/1750 train_time:16399ms step_avg:98.79ms
step:167/1750 train_time:16496ms step_avg:98.78ms
step:168/1750 train_time:16593ms step_avg:98.77ms
step:169/1750 train_time:16691ms step_avg:98.76ms
step:170/1750 train_time:16789ms step_avg:98.76ms
step:171/1750 train_time:16888ms step_avg:98.76ms
step:172/1750 train_time:16985ms step_avg:98.75ms
step:173/1750 train_time:17083ms step_avg:98.74ms
step:174/1750 train_time:17179ms step_avg:98.73ms
step:175/1750 train_time:17276ms step_avg:98.72ms
step:176/1750 train_time:17373ms step_avg:98.71ms
step:177/1750 train_time:17471ms step_avg:98.70ms
step:178/1750 train_time:17568ms step_avg:98.70ms
step:179/1750 train_time:17666ms step_avg:98.69ms
step:180/1750 train_time:17763ms step_avg:98.68ms
step:181/1750 train_time:17859ms step_avg:98.67ms
step:182/1750 train_time:17956ms step_avg:98.66ms
step:183/1750 train_time:18054ms step_avg:98.65ms
step:184/1750 train_time:18151ms step_avg:98.65ms
step:185/1750 train_time:18250ms step_avg:98.65ms
step:186/1750 train_time:18348ms step_avg:98.65ms
step:187/1750 train_time:18447ms step_avg:98.65ms
step:188/1750 train_time:18544ms step_avg:98.64ms
step:189/1750 train_time:18641ms step_avg:98.63ms
step:190/1750 train_time:18738ms step_avg:98.62ms
step:191/1750 train_time:18835ms step_avg:98.61ms
step:192/1750 train_time:18933ms step_avg:98.61ms
step:193/1750 train_time:19030ms step_avg:98.60ms
step:194/1750 train_time:19128ms step_avg:98.60ms
step:195/1750 train_time:19226ms step_avg:98.59ms
step:196/1750 train_time:19323ms step_avg:98.59ms
step:197/1750 train_time:19420ms step_avg:98.58ms
step:198/1750 train_time:19518ms step_avg:98.58ms
step:199/1750 train_time:19615ms step_avg:98.57ms
step:200/1750 train_time:19713ms step_avg:98.56ms
step:201/1750 train_time:19811ms step_avg:98.56ms
step:202/1750 train_time:19909ms step_avg:98.56ms
step:203/1750 train_time:20007ms step_avg:98.56ms
step:204/1750 train_time:20104ms step_avg:98.55ms
step:205/1750 train_time:20202ms step_avg:98.54ms
step:206/1750 train_time:20299ms step_avg:98.54ms
step:207/1750 train_time:20396ms step_avg:98.53ms
step:208/1750 train_time:20493ms step_avg:98.52ms
step:209/1750 train_time:20592ms step_avg:98.53ms
step:210/1750 train_time:20689ms step_avg:98.52ms
step:211/1750 train_time:20788ms step_avg:98.52ms
step:212/1750 train_time:20886ms step_avg:98.52ms
step:213/1750 train_time:20983ms step_avg:98.51ms
step:214/1750 train_time:21081ms step_avg:98.51ms
step:215/1750 train_time:21178ms step_avg:98.50ms
step:216/1750 train_time:21275ms step_avg:98.50ms
step:217/1750 train_time:21373ms step_avg:98.49ms
step:218/1750 train_time:21471ms step_avg:98.49ms
step:219/1750 train_time:21569ms step_avg:98.49ms
step:220/1750 train_time:21666ms step_avg:98.48ms
step:221/1750 train_time:21765ms step_avg:98.48ms
step:222/1750 train_time:21860ms step_avg:98.47ms
step:223/1750 train_time:21958ms step_avg:98.46ms
step:224/1750 train_time:22055ms step_avg:98.46ms
step:225/1750 train_time:22152ms step_avg:98.45ms
step:226/1750 train_time:22250ms step_avg:98.45ms
step:227/1750 train_time:22349ms step_avg:98.45ms
step:228/1750 train_time:22446ms step_avg:98.45ms
step:229/1750 train_time:22544ms step_avg:98.44ms
step:230/1750 train_time:22641ms step_avg:98.44ms
step:231/1750 train_time:22739ms step_avg:98.44ms
step:232/1750 train_time:22836ms step_avg:98.43ms
step:233/1750 train_time:22933ms step_avg:98.42ms
step:234/1750 train_time:23031ms step_avg:98.42ms
step:235/1750 train_time:23129ms step_avg:98.42ms
step:236/1750 train_time:23228ms step_avg:98.42ms
step:237/1750 train_time:23326ms step_avg:98.42ms
step:238/1750 train_time:23425ms step_avg:98.42ms
step:239/1750 train_time:23522ms step_avg:98.42ms
step:240/1750 train_time:23620ms step_avg:98.42ms
step:241/1750 train_time:23718ms step_avg:98.41ms
step:242/1750 train_time:23815ms step_avg:98.41ms
step:243/1750 train_time:23912ms step_avg:98.40ms
step:244/1750 train_time:24011ms step_avg:98.40ms
step:245/1750 train_time:24108ms step_avg:98.40ms
step:246/1750 train_time:24206ms step_avg:98.40ms
step:247/1750 train_time:24302ms step_avg:98.39ms
step:248/1750 train_time:24400ms step_avg:98.39ms
step:249/1750 train_time:24497ms step_avg:98.38ms
step:250/1750 train_time:24595ms step_avg:98.38ms
step:250/1750 val_loss:4.1098 train_time:24687ms step_avg:98.75ms
step:251/1750 train_time:24707ms step_avg:98.43ms
step:252/1750 train_time:24796ms step_avg:98.40ms
step:253/1750 train_time:24895ms step_avg:98.40ms
step:254/1750 train_time:24993ms step_avg:98.40ms
step:255/1750 train_time:25091ms step_avg:98.40ms
step:256/1750 train_time:25188ms step_avg:98.39ms
step:257/1750 train_time:25285ms step_avg:98.38ms
step:258/1750 train_time:25381ms step_avg:98.38ms
step:259/1750 train_time:25479ms step_avg:98.37ms
step:260/1750 train_time:25576ms step_avg:98.37ms
step:261/1750 train_time:25674ms step_avg:98.37ms
step:262/1750 train_time:25771ms step_avg:98.36ms
step:263/1750 train_time:25868ms step_avg:98.36ms
step:264/1750 train_time:25966ms step_avg:98.36ms
step:265/1750 train_time:26065ms step_avg:98.36ms
step:266/1750 train_time:26163ms step_avg:98.36ms
step:267/1750 train_time:26261ms step_avg:98.35ms
step:268/1750 train_time:26359ms step_avg:98.35ms
step:269/1750 train_time:26456ms step_avg:98.35ms
step:270/1750 train_time:26554ms step_avg:98.35ms
step:271/1750 train_time:26652ms step_avg:98.35ms
step:272/1750 train_time:26750ms step_avg:98.34ms
step:273/1750 train_time:26848ms step_avg:98.34ms
step:274/1750 train_time:26945ms step_avg:98.34ms
step:275/1750 train_time:27042ms step_avg:98.34ms
step:276/1750 train_time:27140ms step_avg:98.33ms
step:277/1750 train_time:27240ms step_avg:98.34ms
step:278/1750 train_time:27339ms step_avg:98.34ms
step:279/1750 train_time:27437ms step_avg:98.34ms
step:280/1750 train_time:27536ms step_avg:98.34ms
step:281/1750 train_time:27633ms step_avg:98.34ms
step:282/1750 train_time:27731ms step_avg:98.34ms
step:283/1750 train_time:27828ms step_avg:98.33ms
step:284/1750 train_time:27926ms step_avg:98.33ms
step:285/1750 train_time:28023ms step_avg:98.33ms
step:286/1750 train_time:28121ms step_avg:98.33ms
step:287/1750 train_time:28221ms step_avg:98.33ms
step:288/1750 train_time:28318ms step_avg:98.33ms
step:289/1750 train_time:28416ms step_avg:98.33ms
step:290/1750 train_time:28514ms step_avg:98.33ms
step:291/1750 train_time:28612ms step_avg:98.32ms
step:292/1750 train_time:28710ms step_avg:98.32ms
step:293/1750 train_time:28807ms step_avg:98.32ms
step:294/1750 train_time:28905ms step_avg:98.32ms
step:295/1750 train_time:29002ms step_avg:98.31ms
step:296/1750 train_time:29100ms step_avg:98.31ms
step:297/1750 train_time:29198ms step_avg:98.31ms
step:298/1750 train_time:29296ms step_avg:98.31ms
step:299/1750 train_time:29395ms step_avg:98.31ms
step:300/1750 train_time:29492ms step_avg:98.31ms
step:301/1750 train_time:29590ms step_avg:98.31ms
step:302/1750 train_time:29688ms step_avg:98.30ms
step:303/1750 train_time:29786ms step_avg:98.30ms
step:304/1750 train_time:29884ms step_avg:98.30ms
step:305/1750 train_time:29982ms step_avg:98.30ms
step:306/1750 train_time:30080ms step_avg:98.30ms
step:307/1750 train_time:30178ms step_avg:98.30ms
step:308/1750 train_time:30277ms step_avg:98.30ms
step:309/1750 train_time:30375ms step_avg:98.30ms
step:310/1750 train_time:30473ms step_avg:98.30ms
step:311/1750 train_time:30570ms step_avg:98.30ms
step:312/1750 train_time:30668ms step_avg:98.30ms
step:313/1750 train_time:30766ms step_avg:98.29ms
step:314/1750 train_time:30864ms step_avg:98.29ms
step:315/1750 train_time:30962ms step_avg:98.29ms
step:316/1750 train_time:31061ms step_avg:98.29ms
step:317/1750 train_time:31158ms step_avg:98.29ms
step:318/1750 train_time:31257ms step_avg:98.29ms
step:319/1750 train_time:31356ms step_avg:98.29ms
step:320/1750 train_time:31453ms step_avg:98.29ms
step:321/1750 train_time:31551ms step_avg:98.29ms
step:322/1750 train_time:31649ms step_avg:98.29ms
step:323/1750 train_time:31747ms step_avg:98.29ms
step:324/1750 train_time:31845ms step_avg:98.29ms
step:325/1750 train_time:31943ms step_avg:98.28ms
step:326/1750 train_time:32040ms step_avg:98.28ms
step:327/1750 train_time:32139ms step_avg:98.28ms
step:328/1750 train_time:32237ms step_avg:98.28ms
step:329/1750 train_time:32335ms step_avg:98.28ms
step:330/1750 train_time:32433ms step_avg:98.28ms
step:331/1750 train_time:32531ms step_avg:98.28ms
step:332/1750 train_time:32628ms step_avg:98.28ms
step:333/1750 train_time:32726ms step_avg:98.28ms
step:334/1750 train_time:32824ms step_avg:98.28ms
step:335/1750 train_time:32921ms step_avg:98.27ms
step:336/1750 train_time:33019ms step_avg:98.27ms
step:337/1750 train_time:33118ms step_avg:98.27ms
step:338/1750 train_time:33216ms step_avg:98.27ms
step:339/1750 train_time:33314ms step_avg:98.27ms
step:340/1750 train_time:33412ms step_avg:98.27ms
step:341/1750 train_time:33509ms step_avg:98.27ms
step:342/1750 train_time:33607ms step_avg:98.27ms
step:343/1750 train_time:33705ms step_avg:98.27ms
step:344/1750 train_time:33803ms step_avg:98.26ms
step:345/1750 train_time:33902ms step_avg:98.27ms
step:346/1750 train_time:33999ms step_avg:98.26ms
step:347/1750 train_time:34097ms step_avg:98.26ms
step:348/1750 train_time:34196ms step_avg:98.26ms
step:349/1750 train_time:34293ms step_avg:98.26ms
step:350/1750 train_time:34391ms step_avg:98.26ms
step:351/1750 train_time:34489ms step_avg:98.26ms
step:352/1750 train_time:34586ms step_avg:98.26ms
step:353/1750 train_time:34684ms step_avg:98.25ms
step:354/1750 train_time:34782ms step_avg:98.25ms
step:355/1750 train_time:34880ms step_avg:98.25ms
step:356/1750 train_time:34978ms step_avg:98.25ms
step:357/1750 train_time:35076ms step_avg:98.25ms
step:358/1750 train_time:35174ms step_avg:98.25ms
step:359/1750 train_time:35271ms step_avg:98.25ms
step:360/1750 train_time:35369ms step_avg:98.25ms
step:361/1750 train_time:35466ms step_avg:98.24ms
step:362/1750 train_time:35564ms step_avg:98.24ms
step:363/1750 train_time:35661ms step_avg:98.24ms
step:364/1750 train_time:35760ms step_avg:98.24ms
step:365/1750 train_time:35858ms step_avg:98.24ms
step:366/1750 train_time:35956ms step_avg:98.24ms
step:367/1750 train_time:36054ms step_avg:98.24ms
step:368/1750 train_time:36152ms step_avg:98.24ms
step:369/1750 train_time:36250ms step_avg:98.24ms
step:370/1750 train_time:36348ms step_avg:98.24ms
step:371/1750 train_time:36445ms step_avg:98.24ms
step:372/1750 train_time:36543ms step_avg:98.23ms
step:373/1750 train_time:36641ms step_avg:98.23ms
step:374/1750 train_time:36739ms step_avg:98.23ms
step:375/1750 train_time:36838ms step_avg:98.23ms
step:375/1750 val_loss:3.9075 train_time:36931ms step_avg:98.48ms
step:376/1750 train_time:36953ms step_avg:98.28ms
step:377/1750 train_time:37039ms step_avg:98.25ms
step:378/1750 train_time:37140ms step_avg:98.25ms
step:379/1750 train_time:37237ms step_avg:98.25ms
step:380/1750 train_time:37335ms step_avg:98.25ms
step:381/1750 train_time:37432ms step_avg:98.25ms
step:382/1750 train_time:37530ms step_avg:98.25ms
step:383/1750 train_time:37629ms step_avg:98.25ms
step:384/1750 train_time:37727ms step_avg:98.25ms
step:385/1750 train_time:37825ms step_avg:98.25ms
step:386/1750 train_time:37923ms step_avg:98.25ms
step:387/1750 train_time:38021ms step_avg:98.25ms
step:388/1750 train_time:38119ms step_avg:98.24ms
step:389/1750 train_time:38216ms step_avg:98.24ms
step:390/1750 train_time:38314ms step_avg:98.24ms
step:391/1750 train_time:38414ms step_avg:98.25ms
step:392/1750 train_time:38514ms step_avg:98.25ms
step:393/1750 train_time:38614ms step_avg:98.25ms
step:394/1750 train_time:38714ms step_avg:98.26ms
step:395/1750 train_time:38814ms step_avg:98.26ms
step:396/1750 train_time:38914ms step_avg:98.27ms
step:397/1750 train_time:39014ms step_avg:98.27ms
step:398/1750 train_time:39114ms step_avg:98.28ms
step:399/1750 train_time:39213ms step_avg:98.28ms
step:400/1750 train_time:39313ms step_avg:98.28ms
step:401/1750 train_time:39413ms step_avg:98.29ms
step:402/1750 train_time:39514ms step_avg:98.29ms
step:403/1750 train_time:39614ms step_avg:98.30ms
step:404/1750 train_time:39714ms step_avg:98.30ms
step:405/1750 train_time:39814ms step_avg:98.31ms
step:406/1750 train_time:39914ms step_avg:98.31ms
step:407/1750 train_time:40014ms step_avg:98.31ms
step:408/1750 train_time:40114ms step_avg:98.32ms
step:409/1750 train_time:40213ms step_avg:98.32ms
step:410/1750 train_time:40314ms step_avg:98.33ms
step:411/1750 train_time:40414ms step_avg:98.33ms
step:412/1750 train_time:40514ms step_avg:98.33ms
step:413/1750 train_time:40614ms step_avg:98.34ms
step:414/1750 train_time:40714ms step_avg:98.34ms
step:415/1750 train_time:40814ms step_avg:98.35ms
step:416/1750 train_time:40914ms step_avg:98.35ms
step:417/1750 train_time:41014ms step_avg:98.35ms
step:418/1750 train_time:41113ms step_avg:98.36ms
step:419/1750 train_time:41214ms step_avg:98.36ms
step:420/1750 train_time:41314ms step_avg:98.37ms
step:421/1750 train_time:41414ms step_avg:98.37ms
step:422/1750 train_time:41513ms step_avg:98.37ms
step:423/1750 train_time:41613ms step_avg:98.38ms
step:424/1750 train_time:41713ms step_avg:98.38ms
step:425/1750 train_time:41814ms step_avg:98.38ms
step:426/1750 train_time:41914ms step_avg:98.39ms
step:427/1750 train_time:42013ms step_avg:98.39ms
step:428/1750 train_time:42113ms step_avg:98.39ms
step:429/1750 train_time:42213ms step_avg:98.40ms
step:430/1750 train_time:42313ms step_avg:98.40ms
step:431/1750 train_time:42413ms step_avg:98.41ms
step:432/1750 train_time:42513ms step_avg:98.41ms
step:433/1750 train_time:42614ms step_avg:98.41ms
step:434/1750 train_time:42713ms step_avg:98.42ms
step:435/1750 train_time:42812ms step_avg:98.42ms
step:436/1750 train_time:42912ms step_avg:98.42ms
step:437/1750 train_time:43012ms step_avg:98.43ms
step:438/1750 train_time:43112ms step_avg:98.43ms
step:439/1750 train_time:43213ms step_avg:98.43ms
step:440/1750 train_time:43313ms step_avg:98.44ms
step:441/1750 train_time:43413ms step_avg:98.44ms
step:442/1750 train_time:43513ms step_avg:98.44ms
step:443/1750 train_time:43614ms step_avg:98.45ms
step:444/1750 train_time:43714ms step_avg:98.45ms
step:445/1750 train_time:43814ms step_avg:98.46ms
step:446/1750 train_time:43913ms step_avg:98.46ms
step:447/1750 train_time:44013ms step_avg:98.46ms
step:448/1750 train_time:44114ms step_avg:98.47ms
step:449/1750 train_time:44213ms step_avg:98.47ms
step:450/1750 train_time:44314ms step_avg:98.48ms
step:451/1750 train_time:44414ms step_avg:98.48ms
step:452/1750 train_time:44514ms step_avg:98.48ms
step:453/1750 train_time:44614ms step_avg:98.49ms
step:454/1750 train_time:44714ms step_avg:98.49ms
step:455/1750 train_time:44813ms step_avg:98.49ms
step:456/1750 train_time:44913ms step_avg:98.49ms
step:457/1750 train_time:45012ms step_avg:98.50ms
step:458/1750 train_time:45113ms step_avg:98.50ms
step:459/1750 train_time:45213ms step_avg:98.50ms
step:460/1750 train_time:45314ms step_avg:98.51ms
step:461/1750 train_time:45413ms step_avg:98.51ms
step:462/1750 train_time:45513ms step_avg:98.51ms
step:463/1750 train_time:45614ms step_avg:98.52ms
step:464/1750 train_time:45713ms step_avg:98.52ms
step:465/1750 train_time:45812ms step_avg:98.52ms
step:466/1750 train_time:45912ms step_avg:98.52ms
step:467/1750 train_time:46012ms step_avg:98.53ms
step:468/1750 train_time:46111ms step_avg:98.53ms
step:469/1750 train_time:46211ms step_avg:98.53ms
step:470/1750 train_time:46311ms step_avg:98.53ms
step:471/1750 train_time:46411ms step_avg:98.54ms
step:472/1750 train_time:46511ms step_avg:98.54ms
step:473/1750 train_time:46611ms step_avg:98.54ms
step:474/1750 train_time:46711ms step_avg:98.55ms
step:475/1750 train_time:46811ms step_avg:98.55ms
step:476/1750 train_time:46911ms step_avg:98.55ms
step:477/1750 train_time:47012ms step_avg:98.56ms
step:478/1750 train_time:47112ms step_avg:98.56ms
step:479/1750 train_time:47211ms step_avg:98.56ms
step:480/1750 train_time:47312ms step_avg:98.57ms
step:481/1750 train_time:47412ms step_avg:98.57ms
step:482/1750 train_time:47512ms step_avg:98.57ms
step:483/1750 train_time:47613ms step_avg:98.58ms
step:484/1750 train_time:47713ms step_avg:98.58ms
step:485/1750 train_time:47813ms step_avg:98.58ms
step:486/1750 train_time:47913ms step_avg:98.59ms
step:487/1750 train_time:48013ms step_avg:98.59ms
step:488/1750 train_time:48112ms step_avg:98.59ms
step:489/1750 train_time:48212ms step_avg:98.59ms
step:490/1750 train_time:48312ms step_avg:98.60ms
step:491/1750 train_time:48412ms step_avg:98.60ms
step:492/1750 train_time:48512ms step_avg:98.60ms
step:493/1750 train_time:48612ms step_avg:98.60ms
step:494/1750 train_time:48712ms step_avg:98.61ms
step:495/1750 train_time:48811ms step_avg:98.61ms
step:496/1750 train_time:48911ms step_avg:98.61ms
step:497/1750 train_time:49012ms step_avg:98.62ms
step:498/1750 train_time:49112ms step_avg:98.62ms
step:499/1750 train_time:49211ms step_avg:98.62ms
step:500/1750 train_time:49311ms step_avg:98.62ms
step:500/1750 val_loss:3.7567 train_time:49406ms step_avg:98.81ms
step:501/1750 train_time:49427ms step_avg:98.66ms
step:502/1750 train_time:49515ms step_avg:98.64ms
step:503/1750 train_time:49618ms step_avg:98.64ms
step:504/1750 train_time:49718ms step_avg:98.65ms
step:505/1750 train_time:49818ms step_avg:98.65ms
step:506/1750 train_time:49917ms step_avg:98.65ms
step:507/1750 train_time:50017ms step_avg:98.65ms
step:508/1750 train_time:50116ms step_avg:98.65ms
step:509/1750 train_time:50216ms step_avg:98.66ms
step:510/1750 train_time:50315ms step_avg:98.66ms
step:511/1750 train_time:50414ms step_avg:98.66ms
step:512/1750 train_time:50513ms step_avg:98.66ms
step:513/1750 train_time:50613ms step_avg:98.66ms
step:514/1750 train_time:50713ms step_avg:98.66ms
step:515/1750 train_time:50813ms step_avg:98.67ms
step:516/1750 train_time:50913ms step_avg:98.67ms
step:517/1750 train_time:51012ms step_avg:98.67ms
step:518/1750 train_time:51112ms step_avg:98.67ms
step:519/1750 train_time:51212ms step_avg:98.67ms
step:520/1750 train_time:51312ms step_avg:98.68ms
step:521/1750 train_time:51412ms step_avg:98.68ms
step:522/1750 train_time:51512ms step_avg:98.68ms
step:523/1750 train_time:51611ms step_avg:98.68ms
step:524/1750 train_time:51711ms step_avg:98.68ms
step:525/1750 train_time:51811ms step_avg:98.69ms
step:526/1750 train_time:51912ms step_avg:98.69ms
step:527/1750 train_time:52012ms step_avg:98.69ms
step:528/1750 train_time:52112ms step_avg:98.70ms
step:529/1750 train_time:52212ms step_avg:98.70ms
step:530/1750 train_time:52312ms step_avg:98.70ms
step:531/1750 train_time:52413ms step_avg:98.71ms
step:532/1750 train_time:52512ms step_avg:98.71ms
step:533/1750 train_time:52612ms step_avg:98.71ms
step:534/1750 train_time:52712ms step_avg:98.71ms
step:535/1750 train_time:52812ms step_avg:98.71ms
step:536/1750 train_time:52913ms step_avg:98.72ms
step:537/1750 train_time:53012ms step_avg:98.72ms
step:538/1750 train_time:53112ms step_avg:98.72ms
step:539/1750 train_time:53212ms step_avg:98.72ms
step:540/1750 train_time:53312ms step_avg:98.73ms
step:541/1750 train_time:53413ms step_avg:98.73ms
step:542/1750 train_time:53513ms step_avg:98.73ms
step:543/1750 train_time:53613ms step_avg:98.74ms
step:544/1750 train_time:53714ms step_avg:98.74ms
step:545/1750 train_time:53814ms step_avg:98.74ms
step:546/1750 train_time:53914ms step_avg:98.74ms
step:547/1750 train_time:54014ms step_avg:98.75ms
step:548/1750 train_time:54114ms step_avg:98.75ms
step:549/1750 train_time:54214ms step_avg:98.75ms
step:550/1750 train_time:54313ms step_avg:98.75ms
step:551/1750 train_time:54413ms step_avg:98.75ms
step:552/1750 train_time:54513ms step_avg:98.75ms
step:553/1750 train_time:54613ms step_avg:98.76ms
step:554/1750 train_time:54713ms step_avg:98.76ms
step:555/1750 train_time:54813ms step_avg:98.76ms
step:556/1750 train_time:54913ms step_avg:98.76ms
step:557/1750 train_time:55013ms step_avg:98.77ms
step:558/1750 train_time:55113ms step_avg:98.77ms
step:559/1750 train_time:55213ms step_avg:98.77ms
step:560/1750 train_time:55313ms step_avg:98.77ms
step:561/1750 train_time:55413ms step_avg:98.78ms
step:562/1750 train_time:55513ms step_avg:98.78ms
step:563/1750 train_time:55613ms step_avg:98.78ms
step:564/1750 train_time:55713ms step_avg:98.78ms
step:565/1750 train_time:55813ms step_avg:98.78ms
step:566/1750 train_time:55912ms step_avg:98.79ms
step:567/1750 train_time:56013ms step_avg:98.79ms
step:568/1750 train_time:56112ms step_avg:98.79ms
step:569/1750 train_time:56212ms step_avg:98.79ms
step:570/1750 train_time:56312ms step_avg:98.79ms
step:571/1750 train_time:56413ms step_avg:98.80ms
step:572/1750 train_time:56513ms step_avg:98.80ms
step:573/1750 train_time:56613ms step_avg:98.80ms
step:574/1750 train_time:56713ms step_avg:98.80ms
step:575/1750 train_time:56813ms step_avg:98.81ms
step:576/1750 train_time:56914ms step_avg:98.81ms
step:577/1750 train_time:57014ms step_avg:98.81ms
step:578/1750 train_time:57114ms step_avg:98.81ms
step:579/1750 train_time:57214ms step_avg:98.81ms
step:580/1750 train_time:57314ms step_avg:98.82ms
step:581/1750 train_time:57413ms step_avg:98.82ms
step:582/1750 train_time:57513ms step_avg:98.82ms
step:583/1750 train_time:57613ms step_avg:98.82ms
step:584/1750 train_time:57713ms step_avg:98.82ms
step:585/1750 train_time:57813ms step_avg:98.83ms
step:586/1750 train_time:57913ms step_avg:98.83ms
step:587/1750 train_time:58013ms step_avg:98.83ms
step:588/1750 train_time:58113ms step_avg:98.83ms
step:589/1750 train_time:58213ms step_avg:98.83ms
step:590/1750 train_time:58314ms step_avg:98.84ms
step:591/1750 train_time:58413ms step_avg:98.84ms
step:592/1750 train_time:58513ms step_avg:98.84ms
step:593/1750 train_time:58613ms step_avg:98.84ms
step:594/1750 train_time:58713ms step_avg:98.84ms
step:595/1750 train_time:58813ms step_avg:98.85ms
step:596/1750 train_time:58913ms step_avg:98.85ms
step:597/1750 train_time:59013ms step_avg:98.85ms
step:598/1750 train_time:59113ms step_avg:98.85ms
step:599/1750 train_time:59215ms step_avg:98.86ms
step:600/1750 train_time:59315ms step_avg:98.86ms
step:601/1750 train_time:59415ms step_avg:98.86ms
step:602/1750 train_time:59516ms step_avg:98.86ms
step:603/1750 train_time:59615ms step_avg:98.86ms
step:604/1750 train_time:59716ms step_avg:98.87ms
step:605/1750 train_time:59816ms step_avg:98.87ms
step:606/1750 train_time:59916ms step_avg:98.87ms
step:607/1750 train_time:60016ms step_avg:98.87ms
step:608/1750 train_time:60116ms step_avg:98.88ms
step:609/1750 train_time:60217ms step_avg:98.88ms
step:610/1750 train_time:60316ms step_avg:98.88ms
step:611/1750 train_time:60417ms step_avg:98.88ms
step:612/1750 train_time:60516ms step_avg:98.88ms
step:613/1750 train_time:60616ms step_avg:98.88ms
step:614/1750 train_time:60715ms step_avg:98.88ms
step:615/1750 train_time:60816ms step_avg:98.89ms
step:616/1750 train_time:60916ms step_avg:98.89ms
step:617/1750 train_time:61016ms step_avg:98.89ms
step:618/1750 train_time:61117ms step_avg:98.89ms
step:619/1750 train_time:61218ms step_avg:98.90ms
step:620/1750 train_time:61318ms step_avg:98.90ms
step:621/1750 train_time:61418ms step_avg:98.90ms
step:622/1750 train_time:61518ms step_avg:98.90ms
step:623/1750 train_time:61619ms step_avg:98.91ms
step:624/1750 train_time:61720ms step_avg:98.91ms
step:625/1750 train_time:61821ms step_avg:98.91ms
step:625/1750 val_loss:3.6694 train_time:61918ms step_avg:99.07ms
step:626/1750 train_time:61938ms step_avg:98.94ms
step:627/1750 train_time:62034ms step_avg:98.94ms
step:628/1750 train_time:62136ms step_avg:98.94ms
step:629/1750 train_time:62236ms step_avg:98.94ms
step:630/1750 train_time:62336ms step_avg:98.95ms
step:631/1750 train_time:62436ms step_avg:98.95ms
step:632/1750 train_time:62535ms step_avg:98.95ms
step:633/1750 train_time:62635ms step_avg:98.95ms
step:634/1750 train_time:62735ms step_avg:98.95ms
step:635/1750 train_time:62836ms step_avg:98.95ms
step:636/1750 train_time:62936ms step_avg:98.96ms
step:637/1750 train_time:63039ms step_avg:98.96ms
step:638/1750 train_time:63140ms step_avg:98.97ms
step:639/1750 train_time:63239ms step_avg:98.97ms
step:640/1750 train_time:63339ms step_avg:98.97ms
step:641/1750 train_time:63439ms step_avg:98.97ms
step:642/1750 train_time:63539ms step_avg:98.97ms
step:643/1750 train_time:63639ms step_avg:98.97ms
step:644/1750 train_time:63740ms step_avg:98.97ms
step:645/1750 train_time:63840ms step_avg:98.98ms
step:646/1750 train_time:63941ms step_avg:98.98ms
step:647/1750 train_time:64041ms step_avg:98.98ms
step:648/1750 train_time:64141ms step_avg:98.98ms
step:649/1750 train_time:64241ms step_avg:98.98ms
step:650/1750 train_time:64341ms step_avg:98.99ms
step:651/1750 train_time:64443ms step_avg:98.99ms
step:652/1750 train_time:64544ms step_avg:98.99ms
step:653/1750 train_time:64646ms step_avg:99.00ms
step:654/1750 train_time:64747ms step_avg:99.00ms
step:655/1750 train_time:64849ms step_avg:99.01ms
step:656/1750 train_time:64952ms step_avg:99.01ms
step:657/1750 train_time:65055ms step_avg:99.02ms
step:658/1750 train_time:65157ms step_avg:99.02ms
step:659/1750 train_time:65258ms step_avg:99.03ms
step:660/1750 train_time:65361ms step_avg:99.03ms
step:661/1750 train_time:65460ms step_avg:99.03ms
step:662/1750 train_time:65561ms step_avg:99.04ms
step:663/1750 train_time:65663ms step_avg:99.04ms
step:664/1750 train_time:65764ms step_avg:99.04ms
step:665/1750 train_time:65866ms step_avg:99.05ms
step:666/1750 train_time:65967ms step_avg:99.05ms
step:667/1750 train_time:66069ms step_avg:99.05ms
step:668/1750 train_time:66172ms step_avg:99.06ms
step:669/1750 train_time:66274ms step_avg:99.06ms
step:670/1750 train_time:66376ms step_avg:99.07ms
step:671/1750 train_time:66477ms step_avg:99.07ms
step:672/1750 train_time:66579ms step_avg:99.08ms
step:673/1750 train_time:66680ms step_avg:99.08ms
step:674/1750 train_time:66782ms step_avg:99.08ms
step:675/1750 train_time:66884ms step_avg:99.09ms
step:676/1750 train_time:66986ms step_avg:99.09ms
step:677/1750 train_time:67087ms step_avg:99.09ms
step:678/1750 train_time:67188ms step_avg:99.10ms
step:679/1750 train_time:67291ms step_avg:99.10ms
step:680/1750 train_time:67394ms step_avg:99.11ms
step:681/1750 train_time:67496ms step_avg:99.11ms
step:682/1750 train_time:67598ms step_avg:99.12ms
step:683/1750 train_time:67700ms step_avg:99.12ms
step:684/1750 train_time:67800ms step_avg:99.12ms
step:685/1750 train_time:67901ms step_avg:99.13ms
step:686/1750 train_time:68002ms step_avg:99.13ms
step:687/1750 train_time:68104ms step_avg:99.13ms
step:688/1750 train_time:68206ms step_avg:99.14ms
step:689/1750 train_time:68307ms step_avg:99.14ms
step:690/1750 train_time:68409ms step_avg:99.14ms
step:691/1750 train_time:68512ms step_avg:99.15ms
step:692/1750 train_time:68615ms step_avg:99.15ms
step:693/1750 train_time:68717ms step_avg:99.16ms
step:694/1750 train_time:68819ms step_avg:99.16ms
step:695/1750 train_time:68921ms step_avg:99.17ms
step:696/1750 train_time:69023ms step_avg:99.17ms
step:697/1750 train_time:69125ms step_avg:99.17ms
step:698/1750 train_time:69226ms step_avg:99.18ms
step:699/1750 train_time:69328ms step_avg:99.18ms
step:700/1750 train_time:69430ms step_avg:99.19ms
step:701/1750 train_time:69532ms step_avg:99.19ms
step:702/1750 train_time:69634ms step_avg:99.19ms
step:703/1750 train_time:69737ms step_avg:99.20ms
step:704/1750 train_time:69839ms step_avg:99.20ms
step:705/1750 train_time:69941ms step_avg:99.21ms
step:706/1750 train_time:70043ms step_avg:99.21ms
step:707/1750 train_time:70144ms step_avg:99.21ms
step:708/1750 train_time:70246ms step_avg:99.22ms
step:709/1750 train_time:70348ms step_avg:99.22ms
step:710/1750 train_time:70450ms step_avg:99.23ms
step:711/1750 train_time:70553ms step_avg:99.23ms
step:712/1750 train_time:70654ms step_avg:99.23ms
step:713/1750 train_time:70756ms step_avg:99.24ms
step:714/1750 train_time:70857ms step_avg:99.24ms
step:715/1750 train_time:70958ms step_avg:99.24ms
step:716/1750 train_time:71060ms step_avg:99.25ms
step:717/1750 train_time:71162ms step_avg:99.25ms
step:718/1750 train_time:71263ms step_avg:99.25ms
step:719/1750 train_time:71365ms step_avg:99.26ms
step:720/1750 train_time:71467ms step_avg:99.26ms
step:721/1750 train_time:71568ms step_avg:99.26ms
step:722/1750 train_time:71670ms step_avg:99.27ms
step:723/1750 train_time:71772ms step_avg:99.27ms
step:724/1750 train_time:71874ms step_avg:99.27ms
step:725/1750 train_time:71976ms step_avg:99.28ms
step:726/1750 train_time:72078ms step_avg:99.28ms
step:727/1750 train_time:72181ms step_avg:99.29ms
step:728/1750 train_time:72282ms step_avg:99.29ms
step:729/1750 train_time:72384ms step_avg:99.29ms
step:730/1750 train_time:72486ms step_avg:99.30ms
step:731/1750 train_time:72587ms step_avg:99.30ms
step:732/1750 train_time:72688ms step_avg:99.30ms
step:733/1750 train_time:72790ms step_avg:99.30ms
step:734/1750 train_time:72893ms step_avg:99.31ms
step:735/1750 train_time:72996ms step_avg:99.31ms
step:736/1750 train_time:73098ms step_avg:99.32ms
step:737/1750 train_time:73200ms step_avg:99.32ms
step:738/1750 train_time:73302ms step_avg:99.32ms
step:739/1750 train_time:73403ms step_avg:99.33ms
step:740/1750 train_time:73505ms step_avg:99.33ms
step:741/1750 train_time:73606ms step_avg:99.33ms
step:742/1750 train_time:73707ms step_avg:99.34ms
step:743/1750 train_time:73809ms step_avg:99.34ms
step:744/1750 train_time:73912ms step_avg:99.34ms
step:745/1750 train_time:74015ms step_avg:99.35ms
step:746/1750 train_time:74118ms step_avg:99.35ms
step:747/1750 train_time:74220ms step_avg:99.36ms
step:748/1750 train_time:74323ms step_avg:99.36ms
step:749/1750 train_time:74423ms step_avg:99.36ms
step:750/1750 train_time:74525ms step_avg:99.37ms
step:750/1750 val_loss:3.6046 train_time:74621ms step_avg:99.49ms
step:751/1750 train_time:74641ms step_avg:99.39ms
step:752/1750 train_time:74733ms step_avg:99.38ms
step:753/1750 train_time:74836ms step_avg:99.38ms
step:754/1750 train_time:74938ms step_avg:99.39ms
step:755/1750 train_time:75039ms step_avg:99.39ms
step:756/1750 train_time:75140ms step_avg:99.39ms
step:757/1750 train_time:75241ms step_avg:99.39ms
step:758/1750 train_time:75342ms step_avg:99.40ms
step:759/1750 train_time:75443ms step_avg:99.40ms
step:760/1750 train_time:75545ms step_avg:99.40ms
step:761/1750 train_time:75649ms step_avg:99.41ms
step:762/1750 train_time:75752ms step_avg:99.41ms
step:763/1750 train_time:75856ms step_avg:99.42ms
step:764/1750 train_time:75956ms step_avg:99.42ms
step:765/1750 train_time:76058ms step_avg:99.42ms
step:766/1750 train_time:76159ms step_avg:99.42ms
step:767/1750 train_time:76260ms step_avg:99.43ms
step:768/1750 train_time:76361ms step_avg:99.43ms
step:769/1750 train_time:76463ms step_avg:99.43ms
step:770/1750 train_time:76564ms step_avg:99.43ms
step:771/1750 train_time:76666ms step_avg:99.44ms
step:772/1750 train_time:76770ms step_avg:99.44ms
step:773/1750 train_time:76872ms step_avg:99.45ms
step:774/1750 train_time:76975ms step_avg:99.45ms
step:775/1750 train_time:77077ms step_avg:99.45ms
step:776/1750 train_time:77180ms step_avg:99.46ms
step:777/1750 train_time:77281ms step_avg:99.46ms
step:778/1750 train_time:77383ms step_avg:99.46ms
step:779/1750 train_time:77485ms step_avg:99.47ms
step:780/1750 train_time:77587ms step_avg:99.47ms
step:781/1750 train_time:77690ms step_avg:99.48ms
step:782/1750 train_time:77792ms step_avg:99.48ms
step:783/1750 train_time:77895ms step_avg:99.48ms
step:784/1750 train_time:77998ms step_avg:99.49ms
step:785/1750 train_time:78100ms step_avg:99.49ms
step:786/1750 train_time:78202ms step_avg:99.49ms
step:787/1750 train_time:78304ms step_avg:99.50ms
step:788/1750 train_time:78407ms step_avg:99.50ms
step:789/1750 train_time:78509ms step_avg:99.50ms
step:790/1750 train_time:78611ms step_avg:99.51ms
step:791/1750 train_time:78714ms step_avg:99.51ms
step:792/1750 train_time:78816ms step_avg:99.51ms
step:793/1750 train_time:78919ms step_avg:99.52ms
step:794/1750 train_time:79022ms step_avg:99.52ms
step:795/1750 train_time:79124ms step_avg:99.53ms
step:796/1750 train_time:79226ms step_avg:99.53ms
step:797/1750 train_time:79329ms step_avg:99.53ms
step:798/1750 train_time:79431ms step_avg:99.54ms
step:799/1750 train_time:79533ms step_avg:99.54ms
step:800/1750 train_time:79635ms step_avg:99.54ms
step:801/1750 train_time:79737ms step_avg:99.55ms
step:802/1750 train_time:79840ms step_avg:99.55ms
step:803/1750 train_time:79941ms step_avg:99.55ms
step:804/1750 train_time:80044ms step_avg:99.56ms
step:805/1750 train_time:80146ms step_avg:99.56ms
step:806/1750 train_time:80249ms step_avg:99.56ms
step:807/1750 train_time:80351ms step_avg:99.57ms
step:808/1750 train_time:80453ms step_avg:99.57ms
step:809/1750 train_time:80555ms step_avg:99.57ms
step:810/1750 train_time:80656ms step_avg:99.58ms
step:811/1750 train_time:80758ms step_avg:99.58ms
step:812/1750 train_time:80859ms step_avg:99.58ms
step:813/1750 train_time:80961ms step_avg:99.58ms
step:814/1750 train_time:81062ms step_avg:99.59ms
step:815/1750 train_time:81164ms step_avg:99.59ms
step:816/1750 train_time:81265ms step_avg:99.59ms
step:817/1750 train_time:81368ms step_avg:99.59ms
step:818/1750 train_time:81471ms step_avg:99.60ms
step:819/1750 train_time:81573ms step_avg:99.60ms
step:820/1750 train_time:81674ms step_avg:99.60ms
step:821/1750 train_time:81775ms step_avg:99.60ms
step:822/1750 train_time:81876ms step_avg:99.61ms
step:823/1750 train_time:81978ms step_avg:99.61ms
step:824/1750 train_time:82079ms step_avg:99.61ms
step:825/1750 train_time:82182ms step_avg:99.61ms
step:826/1750 train_time:82283ms step_avg:99.62ms
step:827/1750 train_time:82385ms step_avg:99.62ms
step:828/1750 train_time:82489ms step_avg:99.62ms
step:829/1750 train_time:82593ms step_avg:99.63ms
step:830/1750 train_time:82695ms step_avg:99.63ms
step:831/1750 train_time:82797ms step_avg:99.64ms
step:832/1750 train_time:82900ms step_avg:99.64ms
step:833/1750 train_time:83002ms step_avg:99.64ms
step:834/1750 train_time:83103ms step_avg:99.64ms
step:835/1750 train_time:83205ms step_avg:99.65ms
step:836/1750 train_time:83307ms step_avg:99.65ms
step:837/1750 train_time:83410ms step_avg:99.65ms
step:838/1750 train_time:83512ms step_avg:99.66ms
step:839/1750 train_time:83614ms step_avg:99.66ms
step:840/1750 train_time:83715ms step_avg:99.66ms
step:841/1750 train_time:83817ms step_avg:99.66ms
step:842/1750 train_time:83919ms step_avg:99.67ms
step:843/1750 train_time:84021ms step_avg:99.67ms
step:844/1750 train_time:84123ms step_avg:99.67ms
step:845/1750 train_time:84225ms step_avg:99.67ms
step:846/1750 train_time:84328ms step_avg:99.68ms
step:847/1750 train_time:84431ms step_avg:99.68ms
step:848/1750 train_time:84533ms step_avg:99.69ms
step:849/1750 train_time:84635ms step_avg:99.69ms
step:850/1750 train_time:84736ms step_avg:99.69ms
step:851/1750 train_time:84838ms step_avg:99.69ms
step:852/1750 train_time:84940ms step_avg:99.69ms
step:853/1750 train_time:85041ms step_avg:99.70ms
step:854/1750 train_time:85142ms step_avg:99.70ms
step:855/1750 train_time:85244ms step_avg:99.70ms
step:856/1750 train_time:85347ms step_avg:99.70ms
step:857/1750 train_time:85450ms step_avg:99.71ms
step:858/1750 train_time:85552ms step_avg:99.71ms
step:859/1750 train_time:85655ms step_avg:99.71ms
step:860/1750 train_time:85757ms step_avg:99.72ms
step:861/1750 train_time:85859ms step_avg:99.72ms
step:862/1750 train_time:85961ms step_avg:99.72ms
step:863/1750 train_time:86063ms step_avg:99.72ms
step:864/1750 train_time:86164ms step_avg:99.73ms
step:865/1750 train_time:86267ms step_avg:99.73ms
step:866/1750 train_time:86369ms step_avg:99.73ms
step:867/1750 train_time:86471ms step_avg:99.74ms
step:868/1750 train_time:86573ms step_avg:99.74ms
step:869/1750 train_time:86675ms step_avg:99.74ms
step:870/1750 train_time:86776ms step_avg:99.74ms
step:871/1750 train_time:86878ms step_avg:99.75ms
step:872/1750 train_time:86980ms step_avg:99.75ms
step:873/1750 train_time:87081ms step_avg:99.75ms
step:874/1750 train_time:87183ms step_avg:99.75ms
step:875/1750 train_time:87285ms step_avg:99.75ms
step:875/1750 val_loss:3.5547 train_time:87382ms step_avg:99.87ms
step:876/1750 train_time:87403ms step_avg:99.77ms
step:877/1750 train_time:87496ms step_avg:99.77ms
step:878/1750 train_time:87600ms step_avg:99.77ms
step:879/1750 train_time:87702ms step_avg:99.77ms
step:880/1750 train_time:87803ms step_avg:99.78ms
step:881/1750 train_time:87905ms step_avg:99.78ms
step:882/1750 train_time:88006ms step_avg:99.78ms
step:883/1750 train_time:88108ms step_avg:99.78ms
step:884/1750 train_time:88209ms step_avg:99.78ms
step:885/1750 train_time:88310ms step_avg:99.79ms
step:886/1750 train_time:88411ms step_avg:99.79ms
step:887/1750 train_time:88513ms step_avg:99.79ms
step:888/1750 train_time:88615ms step_avg:99.79ms
step:889/1750 train_time:88718ms step_avg:99.79ms
step:890/1750 train_time:88821ms step_avg:99.80ms
step:891/1750 train_time:88923ms step_avg:99.80ms
step:892/1750 train_time:89025ms step_avg:99.80ms
step:893/1750 train_time:89127ms step_avg:99.81ms
step:894/1750 train_time:89229ms step_avg:99.81ms
step:895/1750 train_time:89330ms step_avg:99.81ms
step:896/1750 train_time:89431ms step_avg:99.81ms
step:897/1750 train_time:89533ms step_avg:99.81ms
step:898/1750 train_time:89635ms step_avg:99.82ms
step:899/1750 train_time:89737ms step_avg:99.82ms
step:900/1750 train_time:89840ms step_avg:99.82ms
step:901/1750 train_time:89943ms step_avg:99.83ms
step:902/1750 train_time:90047ms step_avg:99.83ms
step:903/1750 train_time:90149ms step_avg:99.83ms
step:904/1750 train_time:90251ms step_avg:99.84ms
step:905/1750 train_time:90353ms step_avg:99.84ms
step:906/1750 train_time:90455ms step_avg:99.84ms
step:907/1750 train_time:90556ms step_avg:99.84ms
step:908/1750 train_time:90658ms step_avg:99.84ms
step:909/1750 train_time:90760ms step_avg:99.85ms
step:910/1750 train_time:90864ms step_avg:99.85ms
step:911/1750 train_time:90968ms step_avg:99.85ms
step:912/1750 train_time:91071ms step_avg:99.86ms
step:913/1750 train_time:91174ms step_avg:99.86ms
step:914/1750 train_time:91278ms step_avg:99.87ms
step:915/1750 train_time:91382ms step_avg:99.87ms
step:916/1750 train_time:91486ms step_avg:99.88ms
step:917/1750 train_time:91589ms step_avg:99.88ms
step:918/1750 train_time:91692ms step_avg:99.88ms
step:919/1750 train_time:91796ms step_avg:99.89ms
step:920/1750 train_time:91899ms step_avg:99.89ms
step:921/1750 train_time:92003ms step_avg:99.89ms
step:922/1750 train_time:92106ms step_avg:99.90ms
step:923/1750 train_time:92208ms step_avg:99.90ms
step:924/1750 train_time:92311ms step_avg:99.90ms
step:925/1750 train_time:92414ms step_avg:99.91ms
step:926/1750 train_time:92516ms step_avg:99.91ms
step:927/1750 train_time:92621ms step_avg:99.91ms
step:928/1750 train_time:92724ms step_avg:99.92ms
step:929/1750 train_time:92827ms step_avg:99.92ms
step:930/1750 train_time:92929ms step_avg:99.92ms
step:931/1750 train_time:93032ms step_avg:99.93ms
step:932/1750 train_time:93135ms step_avg:99.93ms
step:933/1750 train_time:93238ms step_avg:99.93ms
step:934/1750 train_time:93341ms step_avg:99.94ms
step:935/1750 train_time:93444ms step_avg:99.94ms
step:936/1750 train_time:93548ms step_avg:99.94ms
step:937/1750 train_time:93651ms step_avg:99.95ms
step:938/1750 train_time:93754ms step_avg:99.95ms
step:939/1750 train_time:93858ms step_avg:99.96ms
step:940/1750 train_time:93964ms step_avg:99.96ms
step:941/1750 train_time:94068ms step_avg:99.97ms
step:942/1750 train_time:94171ms step_avg:99.97ms
step:943/1750 train_time:94276ms step_avg:99.97ms
step:944/1750 train_time:94379ms step_avg:99.98ms
step:945/1750 train_time:94482ms step_avg:99.98ms
step:946/1750 train_time:94586ms step_avg:99.99ms
step:947/1750 train_time:94689ms step_avg:99.99ms
step:948/1750 train_time:94791ms step_avg:99.99ms
step:949/1750 train_time:94894ms step_avg:99.99ms
step:950/1750 train_time:94999ms step_avg:100.00ms
step:951/1750 train_time:95102ms step_avg:100.00ms
step:952/1750 train_time:95206ms step_avg:100.01ms
step:953/1750 train_time:95309ms step_avg:100.01ms
step:954/1750 train_time:95412ms step_avg:100.01ms
step:955/1750 train_time:95515ms step_avg:100.02ms
step:956/1750 train_time:95619ms step_avg:100.02ms
step:957/1750 train_time:95724ms step_avg:100.03ms
step:958/1750 train_time:95827ms step_avg:100.03ms
step:959/1750 train_time:95930ms step_avg:100.03ms
step:960/1750 train_time:96033ms step_avg:100.03ms
step:961/1750 train_time:96136ms step_avg:100.04ms
step:962/1750 train_time:96240ms step_avg:100.04ms
step:963/1750 train_time:96344ms step_avg:100.05ms
step:964/1750 train_time:96447ms step_avg:100.05ms
step:965/1750 train_time:96550ms step_avg:100.05ms
step:966/1750 train_time:96652ms step_avg:100.05ms
step:967/1750 train_time:96756ms step_avg:100.06ms
step:968/1750 train_time:96862ms step_avg:100.06ms
step:969/1750 train_time:96966ms step_avg:100.07ms
step:970/1750 train_time:97069ms step_avg:100.07ms
step:971/1750 train_time:97172ms step_avg:100.07ms
step:972/1750 train_time:97276ms step_avg:100.08ms
step:973/1750 train_time:97380ms step_avg:100.08ms
step:974/1750 train_time:97484ms step_avg:100.09ms
step:975/1750 train_time:97587ms step_avg:100.09ms
step:976/1750 train_time:97690ms step_avg:100.09ms
step:977/1750 train_time:97793ms step_avg:100.10ms
step:978/1750 train_time:97896ms step_avg:100.10ms
step:979/1750 train_time:98002ms step_avg:100.10ms
step:980/1750 train_time:98105ms step_avg:100.11ms
step:981/1750 train_time:98208ms step_avg:100.11ms
step:982/1750 train_time:98310ms step_avg:100.11ms
step:983/1750 train_time:98413ms step_avg:100.12ms
step:984/1750 train_time:98518ms step_avg:100.12ms
step:985/1750 train_time:98622ms step_avg:100.12ms
step:986/1750 train_time:98726ms step_avg:100.13ms
step:987/1750 train_time:98829ms step_avg:100.13ms
step:988/1750 train_time:98932ms step_avg:100.13ms
step:989/1750 train_time:99037ms step_avg:100.14ms
step:990/1750 train_time:99141ms step_avg:100.14ms
step:991/1750 train_time:99244ms step_avg:100.15ms
step:992/1750 train_time:99348ms step_avg:100.15ms
step:993/1750 train_time:99451ms step_avg:100.15ms
step:994/1750 train_time:99555ms step_avg:100.16ms
step:995/1750 train_time:99659ms step_avg:100.16ms
step:996/1750 train_time:99763ms step_avg:100.16ms
step:997/1750 train_time:99866ms step_avg:100.17ms
step:998/1750 train_time:99969ms step_avg:100.17ms
step:999/1750 train_time:100072ms step_avg:100.17ms
step:1000/1750 train_time:100176ms step_avg:100.18ms
step:1000/1750 val_loss:3.5176 train_time:100274ms step_avg:100.27ms
step:1001/1750 train_time:100294ms step_avg:100.19ms
step:1002/1750 train_time:100389ms step_avg:100.19ms
step:1003/1750 train_time:100494ms step_avg:100.19ms
step:1004/1750 train_time:100597ms step_avg:100.20ms
step:1005/1750 train_time:100700ms step_avg:100.20ms
step:1006/1750 train_time:100803ms step_avg:100.20ms
step:1007/1750 train_time:100906ms step_avg:100.20ms
step:1008/1750 train_time:101009ms step_avg:100.21ms
step:1009/1750 train_time:101112ms step_avg:100.21ms
step:1010/1750 train_time:101215ms step_avg:100.21ms
step:1011/1750 train_time:101320ms step_avg:100.22ms
step:1012/1750 train_time:101427ms step_avg:100.22ms
step:1013/1750 train_time:101531ms step_avg:100.23ms
step:1014/1750 train_time:101634ms step_avg:100.23ms
step:1015/1750 train_time:101737ms step_avg:100.23ms
step:1016/1750 train_time:101840ms step_avg:100.24ms
step:1017/1750 train_time:101946ms step_avg:100.24ms
step:1018/1750 train_time:102048ms step_avg:100.24ms
step:1019/1750 train_time:102151ms step_avg:100.25ms
step:1020/1750 train_time:102253ms step_avg:100.25ms
step:1021/1750 train_time:102356ms step_avg:100.25ms
step:1022/1750 train_time:102460ms step_avg:100.25ms
step:1023/1750 train_time:102565ms step_avg:100.26ms
step:1024/1750 train_time:102668ms step_avg:100.26ms
step:1025/1750 train_time:102771ms step_avg:100.26ms
step:1026/1750 train_time:102873ms step_avg:100.27ms
step:1027/1750 train_time:102977ms step_avg:100.27ms
step:1028/1750 train_time:103080ms step_avg:100.27ms
step:1029/1750 train_time:103184ms step_avg:100.28ms
step:1030/1750 train_time:103288ms step_avg:100.28ms
step:1031/1750 train_time:103391ms step_avg:100.28ms
step:1032/1750 train_time:103495ms step_avg:100.29ms
step:1033/1750 train_time:103598ms step_avg:100.29ms
step:1034/1750 train_time:103702ms step_avg:100.29ms
step:1035/1750 train_time:103807ms step_avg:100.30ms
step:1036/1750 train_time:103910ms step_avg:100.30ms
step:1037/1750 train_time:104012ms step_avg:100.30ms
step:1038/1750 train_time:104115ms step_avg:100.30ms
step:1039/1750 train_time:104218ms step_avg:100.31ms
step:1040/1750 train_time:104322ms step_avg:100.31ms
step:1041/1750 train_time:104426ms step_avg:100.31ms
step:1042/1750 train_time:104530ms step_avg:100.32ms
step:1043/1750 train_time:104634ms step_avg:100.32ms
step:1044/1750 train_time:104737ms step_avg:100.32ms
step:1045/1750 train_time:104842ms step_avg:100.33ms
step:1046/1750 train_time:104946ms step_avg:100.33ms
step:1047/1750 train_time:105051ms step_avg:100.33ms
step:1048/1750 train_time:105154ms step_avg:100.34ms
step:1049/1750 train_time:105258ms step_avg:100.34ms
step:1050/1750 train_time:105362ms step_avg:100.34ms
step:1051/1750 train_time:105465ms step_avg:100.35ms
step:1052/1750 train_time:105569ms step_avg:100.35ms
step:1053/1750 train_time:105672ms step_avg:100.35ms
step:1054/1750 train_time:105774ms step_avg:100.36ms
step:1055/1750 train_time:105878ms step_avg:100.36ms
step:1056/1750 train_time:105982ms step_avg:100.36ms
step:1057/1750 train_time:106087ms step_avg:100.37ms
step:1058/1750 train_time:106190ms step_avg:100.37ms
step:1059/1750 train_time:106294ms step_avg:100.37ms
step:1060/1750 train_time:106397ms step_avg:100.37ms
step:1061/1750 train_time:106502ms step_avg:100.38ms
step:1062/1750 train_time:106606ms step_avg:100.38ms
step:1063/1750 train_time:106711ms step_avg:100.39ms
step:1064/1750 train_time:106814ms step_avg:100.39ms
step:1065/1750 train_time:106917ms step_avg:100.39ms
step:1066/1750 train_time:107021ms step_avg:100.40ms
step:1067/1750 train_time:107126ms step_avg:100.40ms
step:1068/1750 train_time:107231ms step_avg:100.40ms
step:1069/1750 train_time:107334ms step_avg:100.41ms
step:1070/1750 train_time:107437ms step_avg:100.41ms
step:1071/1750 train_time:107540ms step_avg:100.41ms
step:1072/1750 train_time:107645ms step_avg:100.41ms
step:1073/1750 train_time:107748ms step_avg:100.42ms
step:1074/1750 train_time:107851ms step_avg:100.42ms
step:1075/1750 train_time:107954ms step_avg:100.42ms
step:1076/1750 train_time:108057ms step_avg:100.42ms
step:1077/1750 train_time:108161ms step_avg:100.43ms
step:1078/1750 train_time:108266ms step_avg:100.43ms
step:1079/1750 train_time:108369ms step_avg:100.43ms
step:1080/1750 train_time:108472ms step_avg:100.44ms
step:1081/1750 train_time:108575ms step_avg:100.44ms
step:1082/1750 train_time:108678ms step_avg:100.44ms
step:1083/1750 train_time:108781ms step_avg:100.44ms
step:1084/1750 train_time:108885ms step_avg:100.45ms
step:1085/1750 train_time:108989ms step_avg:100.45ms
step:1086/1750 train_time:109092ms step_avg:100.45ms
step:1087/1750 train_time:109194ms step_avg:100.45ms
step:1088/1750 train_time:109297ms step_avg:100.46ms
step:1089/1750 train_time:109401ms step_avg:100.46ms
step:1090/1750 train_time:109506ms step_avg:100.46ms
step:1091/1750 train_time:109609ms step_avg:100.47ms
step:1092/1750 train_time:109712ms step_avg:100.47ms
step:1093/1750 train_time:109815ms step_avg:100.47ms
step:1094/1750 train_time:109919ms step_avg:100.47ms
step:1095/1750 train_time:110023ms step_avg:100.48ms
step:1096/1750 train_time:110127ms step_avg:100.48ms
step:1097/1750 train_time:110231ms step_avg:100.48ms
step:1098/1750 train_time:110334ms step_avg:100.49ms
step:1099/1750 train_time:110437ms step_avg:100.49ms
step:1100/1750 train_time:110541ms step_avg:100.49ms
step:1101/1750 train_time:110645ms step_avg:100.49ms
step:1102/1750 train_time:110749ms step_avg:100.50ms
step:1103/1750 train_time:110852ms step_avg:100.50ms
step:1104/1750 train_time:110956ms step_avg:100.50ms
step:1105/1750 train_time:111058ms step_avg:100.51ms
step:1106/1750 train_time:111162ms step_avg:100.51ms
step:1107/1750 train_time:111267ms step_avg:100.51ms
step:1108/1750 train_time:111370ms step_avg:100.51ms
step:1109/1750 train_time:111474ms step_avg:100.52ms
step:1110/1750 train_time:111577ms step_avg:100.52ms
step:1111/1750 train_time:111681ms step_avg:100.52ms
step:1112/1750 train_time:111788ms step_avg:100.53ms
step:1113/1750 train_time:111891ms step_avg:100.53ms
step:1114/1750 train_time:111993ms step_avg:100.53ms
step:1115/1750 train_time:112097ms step_avg:100.54ms
step:1116/1750 train_time:112200ms step_avg:100.54ms
step:1117/1750 train_time:112305ms step_avg:100.54ms
step:1118/1750 train_time:112410ms step_avg:100.55ms
step:1119/1750 train_time:112513ms step_avg:100.55ms
step:1120/1750 train_time:112616ms step_avg:100.55ms
step:1121/1750 train_time:112719ms step_avg:100.55ms
step:1122/1750 train_time:112823ms step_avg:100.56ms
step:1123/1750 train_time:112928ms step_avg:100.56ms
step:1124/1750 train_time:113031ms step_avg:100.56ms
step:1125/1750 train_time:113134ms step_avg:100.56ms
step:1125/1750 val_loss:3.4722 train_time:113232ms step_avg:100.65ms
step:1126/1750 train_time:113252ms step_avg:100.58ms
step:1127/1750 train_time:113344ms step_avg:100.57ms
step:1128/1750 train_time:113449ms step_avg:100.58ms
step:1129/1750 train_time:113552ms step_avg:100.58ms
step:1130/1750 train_time:113655ms step_avg:100.58ms
step:1131/1750 train_time:113759ms step_avg:100.58ms
step:1132/1750 train_time:113862ms step_avg:100.58ms
step:1133/1750 train_time:113965ms step_avg:100.59ms
step:1134/1750 train_time:114068ms step_avg:100.59ms
step:1135/1750 train_time:114172ms step_avg:100.59ms
step:1136/1750 train_time:114276ms step_avg:100.60ms
step:1137/1750 train_time:114381ms step_avg:100.60ms
step:1138/1750 train_time:114485ms step_avg:100.60ms
step:1139/1750 train_time:114590ms step_avg:100.61ms
step:1140/1750 train_time:114694ms step_avg:100.61ms
step:1141/1750 train_time:114798ms step_avg:100.61ms
step:1142/1750 train_time:114903ms step_avg:100.62ms
step:1143/1750 train_time:115005ms step_avg:100.62ms
step:1144/1750 train_time:115108ms step_avg:100.62ms
step:1145/1750 train_time:115211ms step_avg:100.62ms
step:1146/1750 train_time:115315ms step_avg:100.62ms
step:1147/1750 train_time:115419ms step_avg:100.63ms
step:1148/1750 train_time:115524ms step_avg:100.63ms
step:1149/1750 train_time:115629ms step_avg:100.63ms
step:1150/1750 train_time:115731ms step_avg:100.64ms
step:1151/1750 train_time:115834ms step_avg:100.64ms
step:1152/1750 train_time:115937ms step_avg:100.64ms
step:1153/1750 train_time:116041ms step_avg:100.64ms
step:1154/1750 train_time:116145ms step_avg:100.65ms
step:1155/1750 train_time:116248ms step_avg:100.65ms
step:1156/1750 train_time:116352ms step_avg:100.65ms
step:1157/1750 train_time:116456ms step_avg:100.65ms
step:1158/1750 train_time:116560ms step_avg:100.66ms
step:1159/1750 train_time:116664ms step_avg:100.66ms
step:1160/1750 train_time:116767ms step_avg:100.66ms
step:1161/1750 train_time:116871ms step_avg:100.66ms
step:1162/1750 train_time:116975ms step_avg:100.67ms
step:1163/1750 train_time:117078ms step_avg:100.67ms
step:1164/1750 train_time:117182ms step_avg:100.67ms
step:1165/1750 train_time:117285ms step_avg:100.67ms
step:1166/1750 train_time:117389ms step_avg:100.68ms
step:1167/1750 train_time:117492ms step_avg:100.68ms
step:1168/1750 train_time:117595ms step_avg:100.68ms
step:1169/1750 train_time:117699ms step_avg:100.68ms
step:1170/1750 train_time:117805ms step_avg:100.69ms
step:1171/1750 train_time:117910ms step_avg:100.69ms
step:1172/1750 train_time:118014ms step_avg:100.69ms
step:1173/1750 train_time:118119ms step_avg:100.70ms
step:1174/1750 train_time:118224ms step_avg:100.70ms
step:1175/1750 train_time:118328ms step_avg:100.70ms
step:1176/1750 train_time:118432ms step_avg:100.71ms
step:1177/1750 train_time:118536ms step_avg:100.71ms
step:1178/1750 train_time:118641ms step_avg:100.71ms
step:1179/1750 train_time:118747ms step_avg:100.72ms
step:1180/1750 train_time:118852ms step_avg:100.72ms
step:1181/1750 train_time:118956ms step_avg:100.72ms
step:1182/1750 train_time:119062ms step_avg:100.73ms
step:1183/1750 train_time:119167ms step_avg:100.73ms
step:1184/1750 train_time:119272ms step_avg:100.74ms
step:1185/1750 train_time:119375ms step_avg:100.74ms
step:1186/1750 train_time:119482ms step_avg:100.74ms
step:1187/1750 train_time:119587ms step_avg:100.75ms
step:1188/1750 train_time:119692ms step_avg:100.75ms
step:1189/1750 train_time:119796ms step_avg:100.75ms
step:1190/1750 train_time:119902ms step_avg:100.76ms
step:1191/1750 train_time:120006ms step_avg:100.76ms
step:1192/1750 train_time:120110ms step_avg:100.76ms
step:1193/1750 train_time:120214ms step_avg:100.77ms
step:1194/1750 train_time:120318ms step_avg:100.77ms
step:1195/1750 train_time:120425ms step_avg:100.77ms
step:1196/1750 train_time:120530ms step_avg:100.78ms
step:1197/1750 train_time:120634ms step_avg:100.78ms
step:1198/1750 train_time:120737ms step_avg:100.78ms
step:1199/1750 train_time:120844ms step_avg:100.79ms
step:1200/1750 train_time:120949ms step_avg:100.79ms
step:1201/1750 train_time:121054ms step_avg:100.79ms
step:1202/1750 train_time:121158ms step_avg:100.80ms
step:1203/1750 train_time:121263ms step_avg:100.80ms
step:1204/1750 train_time:121368ms step_avg:100.80ms
step:1205/1750 train_time:121472ms step_avg:100.81ms
step:1206/1750 train_time:121578ms step_avg:100.81ms
step:1207/1750 train_time:121683ms step_avg:100.81ms
step:1208/1750 train_time:121788ms step_avg:100.82ms
step:1209/1750 train_time:121892ms step_avg:100.82ms
step:1210/1750 train_time:121996ms step_avg:100.82ms
step:1211/1750 train_time:122101ms step_avg:100.83ms
step:1212/1750 train_time:122209ms step_avg:100.83ms
step:1213/1750 train_time:122313ms step_avg:100.84ms
step:1214/1750 train_time:122418ms step_avg:100.84ms
step:1215/1750 train_time:122523ms step_avg:100.84ms
step:1216/1750 train_time:122630ms step_avg:100.85ms
step:1217/1750 train_time:122735ms step_avg:100.85ms
step:1218/1750 train_time:122840ms step_avg:100.85ms
step:1219/1750 train_time:122946ms step_avg:100.86ms
step:1220/1750 train_time:123050ms step_avg:100.86ms
step:1221/1750 train_time:123155ms step_avg:100.86ms
step:1222/1750 train_time:123261ms step_avg:100.87ms
step:1223/1750 train_time:123366ms step_avg:100.87ms
step:1224/1750 train_time:123470ms step_avg:100.87ms
step:1225/1750 train_time:123576ms step_avg:100.88ms
step:1226/1750 train_time:123680ms step_avg:100.88ms
step:1227/1750 train_time:123787ms step_avg:100.89ms
step:1228/1750 train_time:123893ms step_avg:100.89ms
step:1229/1750 train_time:123997ms step_avg:100.89ms
step:1230/1750 train_time:124103ms step_avg:100.90ms
step:1231/1750 train_time:124208ms step_avg:100.90ms
step:1232/1750 train_time:124312ms step_avg:100.90ms
step:1233/1750 train_time:124416ms step_avg:100.90ms
step:1234/1750 train_time:124521ms step_avg:100.91ms
step:1235/1750 train_time:124625ms step_avg:100.91ms
step:1236/1750 train_time:124731ms step_avg:100.91ms
step:1237/1750 train_time:124835ms step_avg:100.92ms
step:1238/1750 train_time:124942ms step_avg:100.92ms
step:1239/1750 train_time:125046ms step_avg:100.92ms
step:1240/1750 train_time:125151ms step_avg:100.93ms
step:1241/1750 train_time:125256ms step_avg:100.93ms
step:1242/1750 train_time:125361ms step_avg:100.93ms
step:1243/1750 train_time:125467ms step_avg:100.94ms
step:1244/1750 train_time:125572ms step_avg:100.94ms
step:1245/1750 train_time:125676ms step_avg:100.94ms
step:1246/1750 train_time:125782ms step_avg:100.95ms
step:1247/1750 train_time:125887ms step_avg:100.95ms
step:1248/1750 train_time:125991ms step_avg:100.95ms
step:1249/1750 train_time:126095ms step_avg:100.96ms
step:1250/1750 train_time:126200ms step_avg:100.96ms
step:1250/1750 val_loss:3.4247 train_time:126300ms step_avg:101.04ms
step:1251/1750 train_time:126319ms step_avg:100.97ms
step:1252/1750 train_time:126416ms step_avg:100.97ms
step:1253/1750 train_time:126522ms step_avg:100.98ms
step:1254/1750 train_time:126627ms step_avg:100.98ms
step:1255/1750 train_time:126734ms step_avg:100.98ms
step:1256/1750 train_time:126838ms step_avg:100.99ms
step:1257/1750 train_time:126942ms step_avg:100.99ms
step:1258/1750 train_time:127047ms step_avg:100.99ms
step:1259/1750 train_time:127151ms step_avg:100.99ms
step:1260/1750 train_time:127256ms step_avg:101.00ms
step:1261/1750 train_time:127361ms step_avg:101.00ms
step:1262/1750 train_time:127467ms step_avg:101.00ms
step:1263/1750 train_time:127572ms step_avg:101.01ms
step:1264/1750 train_time:127677ms step_avg:101.01ms
step:1265/1750 train_time:127781ms step_avg:101.01ms
step:1266/1750 train_time:127886ms step_avg:101.02ms
step:1267/1750 train_time:127992ms step_avg:101.02ms
step:1268/1750 train_time:128096ms step_avg:101.02ms
step:1269/1750 train_time:128201ms step_avg:101.02ms
step:1270/1750 train_time:128305ms step_avg:101.03ms
step:1271/1750 train_time:128410ms step_avg:101.03ms
step:1272/1750 train_time:128515ms step_avg:101.03ms
step:1273/1750 train_time:128620ms step_avg:101.04ms
step:1274/1750 train_time:128725ms step_avg:101.04ms
step:1275/1750 train_time:128829ms step_avg:101.04ms
step:1276/1750 train_time:128934ms step_avg:101.05ms
step:1277/1750 train_time:129037ms step_avg:101.05ms
step:1278/1750 train_time:129142ms step_avg:101.05ms
step:1279/1750 train_time:129247ms step_avg:101.05ms
step:1280/1750 train_time:129352ms step_avg:101.06ms
step:1281/1750 train_time:129456ms step_avg:101.06ms
step:1282/1750 train_time:129562ms step_avg:101.06ms
step:1283/1750 train_time:129667ms step_avg:101.07ms
step:1284/1750 train_time:129771ms step_avg:101.07ms
step:1285/1750 train_time:129876ms step_avg:101.07ms
step:1286/1750 train_time:129982ms step_avg:101.07ms
step:1287/1750 train_time:130087ms step_avg:101.08ms
step:1288/1750 train_time:130191ms step_avg:101.08ms
step:1289/1750 train_time:130296ms step_avg:101.08ms
step:1290/1750 train_time:130401ms step_avg:101.09ms
step:1291/1750 train_time:130506ms step_avg:101.09ms
step:1292/1750 train_time:130610ms step_avg:101.09ms
step:1293/1750 train_time:130715ms step_avg:101.09ms
step:1294/1750 train_time:130820ms step_avg:101.10ms
step:1295/1750 train_time:130924ms step_avg:101.10ms
step:1296/1750 train_time:131029ms step_avg:101.10ms
step:1297/1750 train_time:131133ms step_avg:101.11ms
step:1298/1750 train_time:131238ms step_avg:101.11ms
step:1299/1750 train_time:131343ms step_avg:101.11ms
step:1300/1750 train_time:131448ms step_avg:101.11ms
step:1301/1750 train_time:131555ms step_avg:101.12ms
step:1302/1750 train_time:131660ms step_avg:101.12ms
step:1303/1750 train_time:131765ms step_avg:101.12ms
step:1304/1750 train_time:131870ms step_avg:101.13ms
step:1305/1750 train_time:131975ms step_avg:101.13ms
step:1306/1750 train_time:132078ms step_avg:101.13ms
step:1307/1750 train_time:132183ms step_avg:101.13ms
step:1308/1750 train_time:132287ms step_avg:101.14ms
step:1309/1750 train_time:132393ms step_avg:101.14ms
step:1310/1750 train_time:132498ms step_avg:101.14ms
step:1311/1750 train_time:132603ms step_avg:101.15ms
step:1312/1750 train_time:132707ms step_avg:101.15ms
step:1313/1750 train_time:132812ms step_avg:101.15ms
step:1314/1750 train_time:132917ms step_avg:101.15ms
step:1315/1750 train_time:133021ms step_avg:101.16ms
step:1316/1750 train_time:133125ms step_avg:101.16ms
step:1317/1750 train_time:133230ms step_avg:101.16ms
step:1318/1750 train_time:133338ms step_avg:101.17ms
step:1319/1750 train_time:133442ms step_avg:101.17ms
step:1320/1750 train_time:133546ms step_avg:101.17ms
step:1321/1750 train_time:133651ms step_avg:101.17ms
step:1322/1750 train_time:133756ms step_avg:101.18ms
step:1323/1750 train_time:133860ms step_avg:101.18ms
step:1324/1750 train_time:133965ms step_avg:101.18ms
step:1325/1750 train_time:134071ms step_avg:101.19ms
step:1326/1750 train_time:134175ms step_avg:101.19ms
step:1327/1750 train_time:134282ms step_avg:101.19ms
step:1328/1750 train_time:134386ms step_avg:101.19ms
step:1329/1750 train_time:134490ms step_avg:101.20ms
step:1330/1750 train_time:134595ms step_avg:101.20ms
step:1331/1750 train_time:134700ms step_avg:101.20ms
step:1332/1750 train_time:134803ms step_avg:101.20ms
step:1333/1750 train_time:134908ms step_avg:101.21ms
step:1334/1750 train_time:135013ms step_avg:101.21ms
step:1335/1750 train_time:135118ms step_avg:101.21ms
step:1336/1750 train_time:135222ms step_avg:101.21ms
step:1337/1750 train_time:135327ms step_avg:101.22ms
step:1338/1750 train_time:135431ms step_avg:101.22ms
step:1339/1750 train_time:135537ms step_avg:101.22ms
step:1340/1750 train_time:135642ms step_avg:101.23ms
step:1341/1750 train_time:135746ms step_avg:101.23ms
step:1342/1750 train_time:135853ms step_avg:101.23ms
step:1343/1750 train_time:135958ms step_avg:101.23ms
step:1344/1750 train_time:136064ms step_avg:101.24ms
step:1345/1750 train_time:136170ms step_avg:101.24ms
step:1346/1750 train_time:136275ms step_avg:101.24ms
step:1347/1750 train_time:136380ms step_avg:101.25ms
step:1348/1750 train_time:136487ms step_avg:101.25ms
step:1349/1750 train_time:136592ms step_avg:101.25ms
step:1350/1750 train_time:136696ms step_avg:101.26ms
step:1351/1750 train_time:136801ms step_avg:101.26ms
step:1352/1750 train_time:136906ms step_avg:101.26ms
step:1353/1750 train_time:137012ms step_avg:101.27ms
step:1354/1750 train_time:137116ms step_avg:101.27ms
step:1355/1750 train_time:137220ms step_avg:101.27ms
step:1356/1750 train_time:137324ms step_avg:101.27ms
step:1357/1750 train_time:137430ms step_avg:101.27ms
step:1358/1750 train_time:137535ms step_avg:101.28ms
step:1359/1750 train_time:137639ms step_avg:101.28ms
step:1360/1750 train_time:137745ms step_avg:101.28ms
step:1361/1750 train_time:137849ms step_avg:101.28ms
step:1362/1750 train_time:137954ms step_avg:101.29ms
step:1363/1750 train_time:138059ms step_avg:101.29ms
step:1364/1750 train_time:138164ms step_avg:101.29ms
step:1365/1750 train_time:138268ms step_avg:101.30ms
step:1366/1750 train_time:138373ms step_avg:101.30ms
step:1367/1750 train_time:138478ms step_avg:101.30ms
step:1368/1750 train_time:138581ms step_avg:101.30ms
step:1369/1750 train_time:138686ms step_avg:101.30ms
step:1370/1750 train_time:138792ms step_avg:101.31ms
step:1371/1750 train_time:138896ms step_avg:101.31ms
step:1372/1750 train_time:139001ms step_avg:101.31ms
step:1373/1750 train_time:139105ms step_avg:101.31ms
step:1374/1750 train_time:139210ms step_avg:101.32ms
step:1375/1750 train_time:139316ms step_avg:101.32ms
step:1375/1750 val_loss:3.3812 train_time:139417ms step_avg:101.39ms
step:1376/1750 train_time:139439ms step_avg:101.34ms
step:1377/1750 train_time:139533ms step_avg:101.33ms
step:1378/1750 train_time:139638ms step_avg:101.33ms
step:1379/1750 train_time:139743ms step_avg:101.34ms
step:1380/1750 train_time:139848ms step_avg:101.34ms
step:1381/1750 train_time:139954ms step_avg:101.34ms
step:1382/1750 train_time:140058ms step_avg:101.34ms
step:1383/1750 train_time:140163ms step_avg:101.35ms
step:1384/1750 train_time:140268ms step_avg:101.35ms
step:1385/1750 train_time:140372ms step_avg:101.35ms
step:1386/1750 train_time:140478ms step_avg:101.36ms
step:1387/1750 train_time:140584ms step_avg:101.36ms
step:1388/1750 train_time:140688ms step_avg:101.36ms
step:1389/1750 train_time:140793ms step_avg:101.36ms
step:1390/1750 train_time:140898ms step_avg:101.37ms
step:1391/1750 train_time:141003ms step_avg:101.37ms
step:1392/1750 train_time:141108ms step_avg:101.37ms
step:1393/1750 train_time:141212ms step_avg:101.37ms
step:1394/1750 train_time:141317ms step_avg:101.38ms
step:1395/1750 train_time:141423ms step_avg:101.38ms
step:1396/1750 train_time:141529ms step_avg:101.38ms
step:1397/1750 train_time:141633ms step_avg:101.38ms
step:1398/1750 train_time:141738ms step_avg:101.39ms
step:1399/1750 train_time:141843ms step_avg:101.39ms
step:1400/1750 train_time:141948ms step_avg:101.39ms
step:1401/1750 train_time:142053ms step_avg:101.39ms
step:1402/1750 train_time:142158ms step_avg:101.40ms
step:1403/1750 train_time:142263ms step_avg:101.40ms
step:1404/1750 train_time:142369ms step_avg:101.40ms
step:1405/1750 train_time:142473ms step_avg:101.40ms
step:1406/1750 train_time:142578ms step_avg:101.41ms
step:1407/1750 train_time:142682ms step_avg:101.41ms
step:1408/1750 train_time:142787ms step_avg:101.41ms
step:1409/1750 train_time:142892ms step_avg:101.41ms
step:1410/1750 train_time:142997ms step_avg:101.42ms
step:1411/1750 train_time:143102ms step_avg:101.42ms
step:1412/1750 train_time:143206ms step_avg:101.42ms
step:1413/1750 train_time:143310ms step_avg:101.42ms
step:1414/1750 train_time:143416ms step_avg:101.43ms
step:1415/1750 train_time:143521ms step_avg:101.43ms
step:1416/1750 train_time:143626ms step_avg:101.43ms
step:1417/1750 train_time:143731ms step_avg:101.43ms
step:1418/1750 train_time:143834ms step_avg:101.43ms
step:1419/1750 train_time:143939ms step_avg:101.44ms
step:1420/1750 train_time:144044ms step_avg:101.44ms
step:1421/1750 train_time:144148ms step_avg:101.44ms
step:1422/1750 train_time:144252ms step_avg:101.44ms
step:1423/1750 train_time:144357ms step_avg:101.45ms
step:1424/1750 train_time:144462ms step_avg:101.45ms
step:1425/1750 train_time:144567ms step_avg:101.45ms
step:1426/1750 train_time:144672ms step_avg:101.45ms
step:1427/1750 train_time:144776ms step_avg:101.45ms
step:1428/1750 train_time:144884ms step_avg:101.46ms
step:1429/1750 train_time:144989ms step_avg:101.46ms
step:1430/1750 train_time:145095ms step_avg:101.46ms
step:1431/1750 train_time:145202ms step_avg:101.47ms
step:1432/1750 train_time:145308ms step_avg:101.47ms
step:1433/1750 train_time:145413ms step_avg:101.47ms
step:1434/1750 train_time:145517ms step_avg:101.48ms
step:1435/1750 train_time:145625ms step_avg:101.48ms
step:1436/1750 train_time:145733ms step_avg:101.49ms
step:1437/1750 train_time:145839ms step_avg:101.49ms
step:1438/1750 train_time:145945ms step_avg:101.49ms
step:1439/1750 train_time:146050ms step_avg:101.49ms
step:1440/1750 train_time:146156ms step_avg:101.50ms
step:1441/1750 train_time:146265ms step_avg:101.50ms
step:1442/1750 train_time:146370ms step_avg:101.50ms
step:1443/1750 train_time:146475ms step_avg:101.51ms
step:1444/1750 train_time:146582ms step_avg:101.51ms
step:1445/1750 train_time:146687ms step_avg:101.51ms
step:1446/1750 train_time:146793ms step_avg:101.52ms
step:1447/1750 train_time:146899ms step_avg:101.52ms
step:1448/1750 train_time:147006ms step_avg:101.52ms
step:1449/1750 train_time:147112ms step_avg:101.53ms
step:1450/1750 train_time:147218ms step_avg:101.53ms
step:1451/1750 train_time:147324ms step_avg:101.53ms
step:1452/1750 train_time:147431ms step_avg:101.54ms
step:1453/1750 train_time:147535ms step_avg:101.54ms
step:1454/1750 train_time:147642ms step_avg:101.54ms
step:1455/1750 train_time:147749ms step_avg:101.55ms
step:1456/1750 train_time:147856ms step_avg:101.55ms
step:1457/1750 train_time:147963ms step_avg:101.55ms
step:1458/1750 train_time:148068ms step_avg:101.56ms
step:1459/1750 train_time:148175ms step_avg:101.56ms
step:1460/1750 train_time:148282ms step_avg:101.56ms
step:1461/1750 train_time:148388ms step_avg:101.57ms
step:1462/1750 train_time:148494ms step_avg:101.57ms
step:1463/1750 train_time:148599ms step_avg:101.57ms
step:1464/1750 train_time:148707ms step_avg:101.58ms
step:1465/1750 train_time:148813ms step_avg:101.58ms
step:1466/1750 train_time:148920ms step_avg:101.58ms
step:1467/1750 train_time:149027ms step_avg:101.59ms
step:1468/1750 train_time:149134ms step_avg:101.59ms
step:1469/1750 train_time:149240ms step_avg:101.59ms
step:1470/1750 train_time:149346ms step_avg:101.60ms
step:1471/1750 train_time:149452ms step_avg:101.60ms
step:1472/1750 train_time:149558ms step_avg:101.60ms
step:1473/1750 train_time:149665ms step_avg:101.61ms
step:1474/1750 train_time:149771ms step_avg:101.61ms
step:1475/1750 train_time:149877ms step_avg:101.61ms
step:1476/1750 train_time:149984ms step_avg:101.62ms
step:1477/1750 train_time:150091ms step_avg:101.62ms
step:1478/1750 train_time:150198ms step_avg:101.62ms
step:1479/1750 train_time:150304ms step_avg:101.63ms
step:1480/1750 train_time:150410ms step_avg:101.63ms
step:1481/1750 train_time:150519ms step_avg:101.63ms
step:1482/1750 train_time:150625ms step_avg:101.64ms
step:1483/1750 train_time:150731ms step_avg:101.64ms
step:1484/1750 train_time:150836ms step_avg:101.64ms
step:1485/1750 train_time:150941ms step_avg:101.64ms
step:1486/1750 train_time:151047ms step_avg:101.65ms
step:1487/1750 train_time:151153ms step_avg:101.65ms
step:1488/1750 train_time:151259ms step_avg:101.65ms
step:1489/1750 train_time:151366ms step_avg:101.66ms
step:1490/1750 train_time:151472ms step_avg:101.66ms
step:1491/1750 train_time:151578ms step_avg:101.66ms
step:1492/1750 train_time:151685ms step_avg:101.67ms
step:1493/1750 train_time:151794ms step_avg:101.67ms
step:1494/1750 train_time:151904ms step_avg:101.68ms
step:1495/1750 train_time:152010ms step_avg:101.68ms
step:1496/1750 train_time:152115ms step_avg:101.68ms
step:1497/1750 train_time:152221ms step_avg:101.68ms
step:1498/1750 train_time:152327ms step_avg:101.69ms
step:1499/1750 train_time:152431ms step_avg:101.69ms
step:1500/1750 train_time:152537ms step_avg:101.69ms
step:1500/1750 val_loss:3.3425 train_time:152638ms step_avg:101.76ms
step:1501/1750 train_time:152659ms step_avg:101.70ms
step:1502/1750 train_time:152754ms step_avg:101.70ms
step:1503/1750 train_time:152860ms step_avg:101.70ms
step:1504/1750 train_time:152966ms step_avg:101.71ms
step:1505/1750 train_time:153074ms step_avg:101.71ms
step:1506/1750 train_time:153179ms step_avg:101.71ms
step:1507/1750 train_time:153284ms step_avg:101.71ms
step:1508/1750 train_time:153391ms step_avg:101.72ms
step:1509/1750 train_time:153497ms step_avg:101.72ms
step:1510/1750 train_time:153603ms step_avg:101.72ms
step:1511/1750 train_time:153709ms step_avg:101.73ms
step:1512/1750 train_time:153814ms step_avg:101.73ms
step:1513/1750 train_time:153921ms step_avg:101.73ms
step:1514/1750 train_time:154026ms step_avg:101.73ms
step:1515/1750 train_time:154132ms step_avg:101.74ms
step:1516/1750 train_time:154239ms step_avg:101.74ms
step:1517/1750 train_time:154347ms step_avg:101.74ms
step:1518/1750 train_time:154455ms step_avg:101.75ms
step:1519/1750 train_time:154560ms step_avg:101.75ms
step:1520/1750 train_time:154667ms step_avg:101.75ms
step:1521/1750 train_time:154773ms step_avg:101.76ms
step:1522/1750 train_time:154879ms step_avg:101.76ms
step:1523/1750 train_time:154985ms step_avg:101.76ms
step:1524/1750 train_time:155091ms step_avg:101.77ms
step:1525/1750 train_time:155197ms step_avg:101.77ms
step:1526/1750 train_time:155302ms step_avg:101.77ms
step:1527/1750 train_time:155408ms step_avg:101.77ms
step:1528/1750 train_time:155515ms step_avg:101.78ms
step:1529/1750 train_time:155621ms step_avg:101.78ms
step:1530/1750 train_time:155728ms step_avg:101.78ms
step:1531/1750 train_time:155835ms step_avg:101.79ms
step:1532/1750 train_time:155940ms step_avg:101.79ms
step:1533/1750 train_time:156047ms step_avg:101.79ms
step:1534/1750 train_time:156152ms step_avg:101.79ms
step:1535/1750 train_time:156257ms step_avg:101.80ms
step:1536/1750 train_time:156363ms step_avg:101.80ms
step:1537/1750 train_time:156470ms step_avg:101.80ms
step:1538/1750 train_time:156577ms step_avg:101.81ms
step:1539/1750 train_time:156682ms step_avg:101.81ms
step:1540/1750 train_time:156791ms step_avg:101.81ms
step:1541/1750 train_time:156897ms step_avg:101.82ms
step:1542/1750 train_time:157003ms step_avg:101.82ms
step:1543/1750 train_time:157109ms step_avg:101.82ms
step:1544/1750 train_time:157217ms step_avg:101.82ms
step:1545/1750 train_time:157322ms step_avg:101.83ms
step:1546/1750 train_time:157428ms step_avg:101.83ms
step:1547/1750 train_time:157534ms step_avg:101.83ms
step:1548/1750 train_time:157639ms step_avg:101.83ms
step:1549/1750 train_time:157745ms step_avg:101.84ms
step:1550/1750 train_time:157851ms step_avg:101.84ms
step:1551/1750 train_time:157956ms step_avg:101.84ms
step:1552/1750 train_time:158063ms step_avg:101.84ms
step:1553/1750 train_time:158170ms step_avg:101.85ms
step:1554/1750 train_time:158275ms step_avg:101.85ms
step:1555/1750 train_time:158382ms step_avg:101.85ms
step:1556/1750 train_time:158488ms step_avg:101.86ms
step:1557/1750 train_time:158594ms step_avg:101.86ms
step:1558/1750 train_time:158700ms step_avg:101.86ms
step:1559/1750 train_time:158808ms step_avg:101.87ms
step:1560/1750 train_time:158913ms step_avg:101.87ms
step:1561/1750 train_time:159022ms step_avg:101.87ms
step:1562/1750 train_time:159128ms step_avg:101.87ms
step:1563/1750 train_time:159234ms step_avg:101.88ms
step:1564/1750 train_time:159340ms step_avg:101.88ms
step:1565/1750 train_time:159446ms step_avg:101.88ms
step:1566/1750 train_time:159551ms step_avg:101.88ms
step:1567/1750 train_time:159657ms step_avg:101.89ms
step:1568/1750 train_time:159763ms step_avg:101.89ms
step:1569/1750 train_time:159873ms step_avg:101.89ms
step:1570/1750 train_time:159979ms step_avg:101.90ms
step:1571/1750 train_time:160086ms step_avg:101.90ms
step:1572/1750 train_time:160193ms step_avg:101.90ms
step:1573/1750 train_time:160303ms step_avg:101.91ms
step:1574/1750 train_time:160410ms step_avg:101.91ms
step:1575/1750 train_time:160515ms step_avg:101.91ms
step:1576/1750 train_time:160621ms step_avg:101.92ms
step:1577/1750 train_time:160729ms step_avg:101.92ms
step:1578/1750 train_time:160836ms step_avg:101.92ms
step:1579/1750 train_time:160941ms step_avg:101.93ms
step:1580/1750 train_time:161047ms step_avg:101.93ms
step:1581/1750 train_time:161156ms step_avg:101.93ms
step:1582/1750 train_time:161262ms step_avg:101.94ms
step:1583/1750 train_time:161369ms step_avg:101.94ms
step:1584/1750 train_time:161475ms step_avg:101.94ms
step:1585/1750 train_time:161580ms step_avg:101.94ms
step:1586/1750 train_time:161690ms step_avg:101.95ms
step:1587/1750 train_time:161797ms step_avg:101.95ms
step:1588/1750 train_time:161903ms step_avg:101.95ms
step:1589/1750 train_time:162010ms step_avg:101.96ms
step:1590/1750 train_time:162115ms step_avg:101.96ms
step:1591/1750 train_time:162221ms step_avg:101.96ms
step:1592/1750 train_time:162329ms step_avg:101.97ms
step:1593/1750 train_time:162435ms step_avg:101.97ms
step:1594/1750 train_time:162541ms step_avg:101.97ms
step:1595/1750 train_time:162648ms step_avg:101.97ms
step:1596/1750 train_time:162755ms step_avg:101.98ms
step:1597/1750 train_time:162859ms step_avg:101.98ms
step:1598/1750 train_time:162967ms step_avg:101.98ms
step:1599/1750 train_time:163074ms step_avg:101.99ms
step:1600/1750 train_time:163182ms step_avg:101.99ms
step:1601/1750 train_time:163290ms step_avg:101.99ms
step:1602/1750 train_time:163396ms step_avg:101.99ms
step:1603/1750 train_time:163502ms step_avg:102.00ms
step:1604/1750 train_time:163608ms step_avg:102.00ms
step:1605/1750 train_time:163714ms step_avg:102.00ms
step:1606/1750 train_time:163819ms step_avg:102.00ms
step:1607/1750 train_time:163929ms step_avg:102.01ms
step:1608/1750 train_time:164035ms step_avg:102.01ms
step:1609/1750 train_time:164142ms step_avg:102.02ms
step:1610/1750 train_time:164249ms step_avg:102.02ms
step:1611/1750 train_time:164355ms step_avg:102.02ms
step:1612/1750 train_time:164463ms step_avg:102.02ms
step:1613/1750 train_time:164568ms step_avg:102.03ms
step:1614/1750 train_time:164674ms step_avg:102.03ms
step:1615/1750 train_time:164781ms step_avg:102.03ms
step:1616/1750 train_time:164887ms step_avg:102.03ms
step:1617/1750 train_time:164995ms step_avg:102.04ms
step:1618/1750 train_time:165101ms step_avg:102.04ms
step:1619/1750 train_time:165209ms step_avg:102.04ms
step:1620/1750 train_time:165316ms step_avg:102.05ms
step:1621/1750 train_time:165423ms step_avg:102.05ms
step:1622/1750 train_time:165530ms step_avg:102.05ms
step:1623/1750 train_time:165639ms step_avg:102.06ms
step:1624/1750 train_time:165744ms step_avg:102.06ms
step:1625/1750 train_time:165850ms step_avg:102.06ms
step:1625/1750 val_loss:3.3082 train_time:165951ms step_avg:102.12ms
step:1626/1750 train_time:165973ms step_avg:102.07ms
step:1627/1750 train_time:166067ms step_avg:102.07ms
step:1628/1750 train_time:166173ms step_avg:102.07ms
step:1629/1750 train_time:166277ms step_avg:102.07ms
step:1630/1750 train_time:166384ms step_avg:102.08ms
step:1631/1750 train_time:166489ms step_avg:102.08ms
step:1632/1750 train_time:166594ms step_avg:102.08ms
step:1633/1750 train_time:166701ms step_avg:102.08ms
step:1634/1750 train_time:166807ms step_avg:102.09ms
step:1635/1750 train_time:166913ms step_avg:102.09ms
step:1636/1750 train_time:167019ms step_avg:102.09ms
step:1637/1750 train_time:167127ms step_avg:102.09ms
step:1638/1750 train_time:167233ms step_avg:102.10ms
step:1639/1750 train_time:167339ms step_avg:102.10ms
step:1640/1750 train_time:167446ms step_avg:102.10ms
step:1641/1750 train_time:167553ms step_avg:102.10ms
step:1642/1750 train_time:167659ms step_avg:102.11ms
step:1643/1750 train_time:167765ms step_avg:102.11ms
step:1644/1750 train_time:167872ms step_avg:102.11ms
step:1645/1750 train_time:167977ms step_avg:102.11ms
step:1646/1750 train_time:168086ms step_avg:102.12ms
step:1647/1750 train_time:168193ms step_avg:102.12ms
step:1648/1750 train_time:168299ms step_avg:102.12ms
step:1649/1750 train_time:168405ms step_avg:102.13ms
step:1650/1750 train_time:168511ms step_avg:102.13ms
step:1651/1750 train_time:168617ms step_avg:102.13ms
step:1652/1750 train_time:168724ms step_avg:102.13ms
step:1653/1750 train_time:168830ms step_avg:102.14ms
step:1654/1750 train_time:168939ms step_avg:102.14ms
step:1655/1750 train_time:169046ms step_avg:102.14ms
step:1656/1750 train_time:169153ms step_avg:102.15ms
step:1657/1750 train_time:169260ms step_avg:102.15ms
step:1658/1750 train_time:169366ms step_avg:102.15ms
step:1659/1750 train_time:169474ms step_avg:102.15ms
step:1660/1750 train_time:169580ms step_avg:102.16ms
step:1661/1750 train_time:169686ms step_avg:102.16ms
step:1662/1750 train_time:169792ms step_avg:102.16ms
step:1663/1750 train_time:169897ms step_avg:102.16ms
step:1664/1750 train_time:170005ms step_avg:102.17ms
step:1665/1750 train_time:170109ms step_avg:102.17ms
step:1666/1750 train_time:170215ms step_avg:102.17ms
step:1667/1750 train_time:170322ms step_avg:102.17ms
step:1668/1750 train_time:170428ms step_avg:102.17ms
step:1669/1750 train_time:170533ms step_avg:102.18ms
step:1670/1750 train_time:170639ms step_avg:102.18ms
step:1671/1750 train_time:170746ms step_avg:102.18ms
step:1672/1750 train_time:170852ms step_avg:102.18ms
step:1673/1750 train_time:170958ms step_avg:102.19ms
step:1674/1750 train_time:171064ms step_avg:102.19ms
step:1675/1750 train_time:171169ms step_avg:102.19ms
step:1676/1750 train_time:171276ms step_avg:102.19ms
step:1677/1750 train_time:171385ms step_avg:102.20ms
step:1678/1750 train_time:171490ms step_avg:102.20ms
step:1679/1750 train_time:171596ms step_avg:102.20ms
step:1680/1750 train_time:171702ms step_avg:102.20ms
step:1681/1750 train_time:171808ms step_avg:102.21ms
step:1682/1750 train_time:171916ms step_avg:102.21ms
step:1683/1750 train_time:172021ms step_avg:102.21ms
step:1684/1750 train_time:172126ms step_avg:102.21ms
step:1685/1750 train_time:172231ms step_avg:102.21ms
step:1686/1750 train_time:172338ms step_avg:102.22ms
step:1687/1750 train_time:172447ms step_avg:102.22ms
step:1688/1750 train_time:172554ms step_avg:102.22ms
step:1689/1750 train_time:172662ms step_avg:102.23ms
step:1690/1750 train_time:172769ms step_avg:102.23ms
step:1691/1750 train_time:172877ms step_avg:102.23ms
step:1692/1750 train_time:172984ms step_avg:102.24ms
step:1693/1750 train_time:173092ms step_avg:102.24ms
step:1694/1750 train_time:173198ms step_avg:102.24ms
step:1695/1750 train_time:173306ms step_avg:102.25ms
step:1696/1750 train_time:173416ms step_avg:102.25ms
step:1697/1750 train_time:173527ms step_avg:102.25ms
step:1698/1750 train_time:173635ms step_avg:102.26ms
step:1699/1750 train_time:173741ms step_avg:102.26ms
step:1700/1750 train_time:173847ms step_avg:102.26ms
step:1701/1750 train_time:173954ms step_avg:102.27ms
step:1702/1750 train_time:174063ms step_avg:102.27ms
step:1703/1750 train_time:174169ms step_avg:102.27ms
step:1704/1750 train_time:174276ms step_avg:102.27ms
step:1705/1750 train_time:174382ms step_avg:102.28ms
step:1706/1750 train_time:174489ms step_avg:102.28ms
step:1707/1750 train_time:174596ms step_avg:102.28ms
step:1708/1750 train_time:174703ms step_avg:102.28ms
step:1709/1750 train_time:174811ms step_avg:102.29ms
step:1710/1750 train_time:174920ms step_avg:102.29ms
step:1711/1750 train_time:175030ms step_avg:102.30ms
step:1712/1750 train_time:175137ms step_avg:102.30ms
step:1713/1750 train_time:175243ms step_avg:102.30ms
step:1714/1750 train_time:175351ms step_avg:102.30ms
step:1715/1750 train_time:175455ms step_avg:102.31ms
step:1716/1750 train_time:175563ms step_avg:102.31ms
step:1717/1750 train_time:175669ms step_avg:102.31ms
step:1718/1750 train_time:175777ms step_avg:102.31ms
step:1719/1750 train_time:175884ms step_avg:102.32ms
step:1720/1750 train_time:175993ms step_avg:102.32ms
step:1721/1750 train_time:176099ms step_avg:102.32ms
step:1722/1750 train_time:176210ms step_avg:102.33ms
step:1723/1750 train_time:176318ms step_avg:102.33ms
step:1724/1750 train_time:176427ms step_avg:102.34ms
step:1725/1750 train_time:176538ms step_avg:102.34ms
step:1726/1750 train_time:176647ms step_avg:102.34ms
step:1727/1750 train_time:176754ms step_avg:102.35ms
step:1728/1750 train_time:176863ms step_avg:102.35ms
step:1729/1750 train_time:176970ms step_avg:102.35ms
step:1730/1750 train_time:177077ms step_avg:102.36ms
step:1731/1750 train_time:177185ms step_avg:102.36ms
step:1732/1750 train_time:177291ms step_avg:102.36ms
step:1733/1750 train_time:177400ms step_avg:102.37ms
step:1734/1750 train_time:177507ms step_avg:102.37ms
step:1735/1750 train_time:177614ms step_avg:102.37ms
step:1736/1750 train_time:177720ms step_avg:102.37ms
step:1737/1750 train_time:177827ms step_avg:102.38ms
step:1738/1750 train_time:177935ms step_avg:102.38ms
step:1739/1750 train_time:178042ms step_avg:102.38ms
step:1740/1750 train_time:178148ms step_avg:102.38ms
step:1741/1750 train_time:178259ms step_avg:102.39ms
step:1742/1750 train_time:178368ms step_avg:102.39ms
step:1743/1750 train_time:178476ms step_avg:102.40ms
step:1744/1750 train_time:178582ms step_avg:102.40ms
step:1745/1750 train_time:178689ms step_avg:102.40ms
step:1746/1750 train_time:178799ms step_avg:102.41ms
step:1747/1750 train_time:178906ms step_avg:102.41ms
step:1748/1750 train_time:179014ms step_avg:102.41ms
step:1749/1750 train_time:179122ms step_avg:102.41ms
step:1750/1750 train_time:179228ms step_avg:102.42ms
step:1750/1750 val_loss:3.2820 train_time:179330ms step_avg:102.47ms
peak memory allocated: 30724 MiB reserved: 45392 MiB
