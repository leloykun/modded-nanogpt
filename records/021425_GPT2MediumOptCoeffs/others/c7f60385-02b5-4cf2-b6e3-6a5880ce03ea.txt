import os
import sys
with open(sys.argv[0]) as f:
    code = f.read() # read the code of this file ASAP, for logging
import uuid
import time
import copy
import glob
from dataclasses import dataclass
from functools import lru_cache
from pathlib import Path

os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True"
import torch
torch.empty(1, device="cuda", requires_grad=True).backward() # prevents a bug on some systems
from torch import Tensor, nn
import torch.nn.functional as F
import torch.distributed as dist
# use of FlexAttention contributed by @KoszarskyB
from torch.nn.attention.flex_attention import BlockMask, flex_attention
#torch._inductor.config.coordinate_descent_tuning = True # we have banned this flag for new records because it causes compilation to take 30min

# -----------------------------------------------------------------------------
# Custom operators: FP8 matmul by @YouJiacheng

@torch.library.custom_op("nanogpt::mm", mutates_args=())
def mm_op(x: Tensor, w: Tensor, x_s: float, w_s: float, grad_s: float) -> tuple[Tensor, Tensor, Tensor]:
    @torch.compile
    def impl(x: Tensor, w: Tensor):
        assert x.is_contiguous() and w.is_contiguous()
        x_f8 = x.div(x_s).to(torch.float8_e4m3fn)
        w_f8 = w.div(w_s).to(torch.float8_e4m3fn)
        out = torch._scaled_mm(
            x_f8,
            w_f8.T,
            out_dtype=torch.bfloat16,
            scale_a=x.new_tensor(x_s, dtype=torch.float32),
            scale_b=x.new_tensor(w_s, dtype=torch.float32),
            use_fast_accum=True,
        )
        return out, x_f8, w_f8

    return impl(x, w)

@mm_op.register_fake
def _(x: Tensor, w: Tensor, *_):
    assert x.ndim == w.ndim == 2
    assert x.shape[1] == w.shape[1]
    assert x.device == w.device
    assert x.is_contiguous() and w.is_contiguous()
    return x @ w.T, x.to(torch.float8_e4m3fn), w.to(torch.float8_e4m3fn)

@torch.library.custom_op("nanogpt::mm_backward", mutates_args=())
def mm_backward_op(g: Tensor, x_f8: Tensor, w_f8: Tensor, x_s: float, w_s: float, grad_s: float) -> tuple[Tensor, Tensor]:
    @torch.compile
    def impl(grad: Tensor, x_f8: Tensor, w_f8: Tensor):
        assert grad.is_contiguous()
        x_inv_s = grad.new_tensor(x_s, dtype=torch.float32)
        w_inv_s = grad.new_tensor(w_s, dtype=torch.float32)
        grad_inv_s = grad.new_tensor(grad_s, dtype=torch.float32)
        grad_f8 = grad.div(grad_s).to(torch.float8_e5m2)
        grad_x = torch._scaled_mm(
            grad_f8,
            w_f8.T.contiguous().T,
            out_dtype=torch.bfloat16,
            scale_a=grad_inv_s,
            scale_b=w_inv_s,
            use_fast_accum=False,
        )
        # faster than grad_f8_t @ x_f8, for (d_out, d_in) == (50304, 768)
        grad_w = torch._scaled_mm(
            x_f8.T.contiguous(),
            grad_f8.T.contiguous().T,
            out_dtype=torch.float32,
            scale_a=x_inv_s,
            scale_b=grad_inv_s,
            use_fast_accum=False,
        ).T
        return grad_x, grad_w

    return impl(g, x_f8, w_f8)

@mm_backward_op.register_fake
def _(g: Tensor, x_f8: Tensor, w_f8: Tensor, *_):
    return x_f8.to(torch.bfloat16), w_f8.to(torch.float32)

def backward(ctx, grad_out: Tensor, *_):
    x_f8, w_f8 = ctx.saved_tensors
    x_s, w_s, grad_s = ctx.scales
    grad_x, grad_w = torch.ops.nanogpt.mm_backward(
        grad_out, x_f8, w_f8, x_s, w_s, grad_s
    )
    return grad_x, grad_w, None, None, None

def setup_context(ctx: torch.autograd.function.FunctionCtx, inputs, output):
    *_, x_s, w_s, grad_s = inputs
    _, x_f8, w_f8 = output
    ctx.save_for_backward(x_f8, w_f8)
    ctx.scales = x_s, w_s, grad_s
    ctx.set_materialize_grads(False)

mm_op.register_autograd(backward, setup_context=setup_context)

# -----------------------------------------------------------------------------
# Muon optimizer

@torch.compile
def zeropower_via_newtonschulz5(G: Tensor, steps: int) -> Tensor:
    """
    Newton-Schulz iteration to compute the zeroth power / orthogonalization of G. We opt to use a
    quintic iteration whose coefficients are selected to maximize the slope at zero. For the purpose
    of minimizing steps, it turns out to be empirically effective to keep increasing the slope at
    zero even beyond the point where the iteration no longer converges all the way to one everywhere
    on the interval. This iteration therefore does not produce UV^T but rather something like US'V^T
    where S' is diagonal with S_{ii}' ~ Uniform(0.5, 1.5), which turns out not to hurt model
    performance at all relative to UV^T, where USV^T = G is the SVD.
    """
    assert G.ndim >= 2 # batched Muon implementation by @scottjmaddox, and put into practice in the record by @YouJiacheng
    X = G.bfloat16()
    if G.size(-2) > G.size(-1):
        X = X.mT

    # Ensure spectral norm is at most 1
    X = X / (X.norm(dim=(-2, -1), keepdim=True) + 1e-7)
    # Perform the NS iterations
    for a, b, c in [
        (3.8839, -3.9828, 1.0989),
        (3.7253, -3.8239, 1.0986),
        (3.5715, -3.6700, 1.0985),
        (3.4220, -3.5202, 1.0983),
        (3.2774, -3.3757, 1.0983),
        (3.1288, -3.2227, 1.0939),
        (2.7203, -2.6642, 0.9439),
    ]:
        A = X @ X.mT
        B = b * A + c * A @ A # quintic computation strategy adapted from suggestion by @jxbz, @leloykun, and @YouJiacheng
        X = a * X + B @ X
    
    if G.size(-2) > G.size(-1):
        X = X.mT
    return X

class Muon(torch.optim.Optimizer):
    """
    Muon - MomentUm Orthogonalized by Newton-schulz

    https://kellerjordan.github.io/posts/muon/

    Muon internally runs standard SGD-momentum, and then performs an orthogonalization post-
    processing step, in which each 2D parameter's update is replaced with the nearest orthogonal
    matrix. To efficiently orthogonalize each update, we use a Newton-Schulz iteration, which has
    the advantage that it can be stably run in bfloat16 on the GPU.

    Some warnings:
    - This optimizer should not be used for the embedding layer, the final fully connected layer,
    or any {0,1}-D parameters; those should all be optimized by a standard method (e.g., AdamW).
    - To use it with 4D convolutional filters, it works well to just flatten their last 3 dimensions.

    Arguments:
        lr: The learning rate used by the internal SGD.
        momentum: The momentum used by the internal SGD.
        nesterov: Whether to use Nesterov-style momentum in the internal SGD. (recommended)
        ns_steps: The number of Newton-Schulz iteration steps to use.
    """
    def __init__(self, params, lr=0.02, momentum=0.95, nesterov=True, ns_steps=5, rank=0, world_size=1):
        self.rank = rank
        self.world_size = world_size
        defaults = dict(lr=lr, momentum=momentum, nesterov=nesterov, ns_steps=ns_steps)
        params: list[Tensor] = [*params]
        param_groups = []
        for size in {p.numel() for p in params}:
            b = torch.empty(world_size, size, dtype=torch.bfloat16, device="cuda")
            group = dict(params=[p for p in params if p.numel() == size],
                         update_buffer=b, update_buffer_views=[b[i] for i in range(world_size)])
            param_groups.append(group)
        super().__init__(param_groups, defaults)

    @torch.no_grad()
    def step(self):
        for group in self.param_groups:
            update_buffer: Tensor = group["update_buffer"]
            update_buffer_views: list[Tensor] = group["update_buffer_views"]
            # generate weight updates in distributed fashion
            params: list[Tensor] = group["params"]
            handle = None
            params_world = None
            def update_prev(): # optimized Muon implementation contributed by @YouJiacheng
                handle.wait()
                for p_world, g_world in zip(params_world, update_buffer_views):
                    p_world.add_(g_world.view_as(p_world),
                                 alpha=-group["lr"] * max(1, p_world.size(-2) / p_world.size(-1))**0.5)
            for base_i in range(len(params))[::self.world_size]:
                if base_i + self.rank < len(params):
                    p = params[base_i + self.rank]
                    g = p.grad
                    assert g is not None
                    state = self.state[p]
                    if "momentum_buffer" not in state:
                        state["momentum_buffer"] = torch.zeros_like(g)
                    buf: Tensor = state["momentum_buffer"]
                    buf.lerp_(g, 1 - group["momentum"])
                    g = g.lerp_(buf, group["momentum"]) if group["nesterov"] else buf
                    g = zeropower_via_newtonschulz5(g, steps=group["ns_steps"]).flatten()
                else:
                    g = update_buffer_views[self.rank]
                if base_i > 0:
                    update_prev() # async all_gather instead of sync all_reduce by @YouJiacheng
                handle = dist.all_gather_into_tensor(update_buffer, g, async_op=True)
                params_world = params[base_i : base_i + self.world_size]
            update_prev()

# -----------------------------------------------------------------------------
# PyTorch nn.Module definitions for the model

def norm(x: Tensor):
    return F.rms_norm(x, (x.size(-1),))

class CastedLinear(nn.Linear):
    def __init__(self, in_features: int, out_features: int, use_fp8=False, x_s=1.0, w_s=1.0, grad_s=1.0):
        super().__init__(in_features, out_features, bias=False)
        self.use_fp8 = use_fp8
        self.x_s = x_s
        self.w_s = w_s
        self.grad_s = grad_s

    def reset_parameters(self) -> None:
        std = 0.5 * (self.in_features ** -0.5) # 0.5 is a bit better than the default 1/sqrt(3)
        bound = (3 ** 0.5) * std
        with torch.no_grad():
            self.weight.uniform_(-bound, bound)

    def forward(self, x: Tensor):
        if self.use_fp8 and self.training:
            _x = x.flatten(0, -2)
            out: Tensor = torch.ops.nanogpt.mm(_x, self.weight, x_s=self.x_s, w_s=self.w_s, grad_s=self.grad_s)[0]
            return out.reshape(*x.shape[:-1], -1)
        else:
            return F.linear(x, self.weight.type_as(x))

class Rotary(nn.Module):
    def __init__(self, dim: int, max_seq_len: int):
        super().__init__()
        # half-truncate RoPE by @YouJiacheng (w/ base freq tuning)
        angular_freq = (1 / 1024) ** torch.linspace(0, 1, steps=dim//4, dtype=torch.float32)
        angular_freq = torch.cat([angular_freq, angular_freq.new_zeros(dim//4)])
        t = torch.arange(max_seq_len, dtype=torch.float32)
        theta = torch.einsum("i,j -> ij", t, angular_freq)
        self.cos = nn.Buffer(theta.cos(), persistent=False)
        self.sin = nn.Buffer(theta.sin(), persistent=False)

    def forward(self, x_BTHD: Tensor):
        assert self.cos.size(0) >= x_BTHD.size(-3)
        cos, sin = self.cos[None, :x_BTHD.size(-3), None, :], self.sin[None, :x_BTHD.size(-3), None, :]
        x1, x2 = x_BTHD.to(dtype=torch.float32).chunk(2, dim=-1)
        y1 = x1 * cos + x2 * sin
        y2 = x1 * (-sin) + x2 * cos
        return torch.cat((y1, y2), 3).type_as(x_BTHD)

class CausalSelfAttention(nn.Module):
    def __init__(self, dim: int, num_heads: int, max_seq_len: int, head_dim=128):
        super().__init__()
        self.num_heads = num_heads
        self.head_dim = head_dim
        hdim = num_heads * head_dim
        std = 0.5 * (dim ** -0.5)
        bound = (3 ** 0.5) * std # improved init scale by @YouJiacheng
        # merged QKV weights: suggested by many, implemented by @fernbear.bsky.social, and further improved by @YouJiacheng
        # https://x.com/hi_tysam/status/1879699187107033311
        self.qkv_w = nn.Parameter(torch.empty(3, hdim, dim).uniform_(-bound, bound))
        self.lambdas = nn.Parameter(torch.tensor([0.5, 0.5]))
        self.rotary = Rotary(head_dim, max_seq_len)
        self.c_proj = CastedLinear(hdim, dim)
        self.c_proj.weight.detach().zero_() # zero init suggested by @Grad62304977

    def forward(self, x: Tensor, ve: Tensor | None, block_mask: BlockMask):
        B, T = x.size(0), x.size(1) # batch size, sequence length
        assert B == 1, "Must use batch size = 1 for FlexAttention"
        q, k, v = F.linear(x, self.qkv_w.flatten(end_dim=1).type_as(x)).view(B, T, 3 * self.num_heads, self.head_dim).chunk(3, dim=-2)
        q, k = norm(q), norm(k) # QK norm @Grad62304977
        q, k = self.rotary(q), self.rotary(k)
        if ve is not None:
            v = self.lambdas[0] * v + self.lambdas[1] * ve.view_as(v) # @KoszarskyB & @Grad62304977
        else: # skip mid-layers token value embeddings by @YouJiacheng
            v = self.lambdas[0] * v
        # scale the attention logits by given constant, instead of the default head_dim**-0.5, by @leloykun
        # inspired by learnable scalars used by @brendanh0gan https://x.com/hi_tysam/status/1879693583898591283
        y = flex_attention(q.transpose(1, 2), k.transpose(1, 2), v.transpose(1, 2), block_mask=block_mask, scale=15/self.head_dim).transpose(1, 2)
        y = y.contiguous().view(B, T, self.num_heads * self.head_dim) # re-assemble all head outputs side by side
        y = self.c_proj(y)
        return y

class MLP(nn.Module):
    def __init__(self, dim: int):
        super().__init__()
        hdim = 4 * dim
        self.c_fc = CastedLinear(dim, hdim)
        self.c_proj = CastedLinear(hdim, dim)
        self.c_proj.weight.detach().zero_() # zero init suggested by @Grad62304977

    def forward(self, x: Tensor):
        x = self.c_fc(x)
        x = F.relu(x).square() # https://arxiv.org/abs/2109.08668v2; ~1-2% better than GELU; suggested by @SKYLINEZ007 and @Grad62304977
        x = self.c_proj(x)
        return x

class Block(nn.Module):
    def __init__(self, dim: int, num_heads: int, max_seq_len: int, layer_idx: int):
        super().__init__()
        # skip attention of blocks.7 (the 8th layer) by @YouJiacheng
        self.attn = CausalSelfAttention(dim, num_heads, max_seq_len) if layer_idx != 7 else None
        self.mlp = MLP(dim)
        self.lambdas = nn.Parameter(torch.tensor([1., 0.]))

    def forward(self, x: Tensor, ve: Tensor | None, x0: Tensor, block_mask: BlockMask):
        x = self.lambdas[0] * x + self.lambdas[1] * x0
        if self.attn is not None:
            x = x + self.attn(norm(x), ve, block_mask)
        x = x + self.mlp(norm(x))
        return x

# -----------------------------------------------------------------------------
# The main model

def next_multiple_of_n(v: float | int, *, n: int):
    return next(x for x in range(n, int(v) + 1 + n, n) if x >= v)

class GPT(nn.Module):
    def __init__(self, vocab_size: int, num_layers: int, num_heads: int, model_dim: int, max_seq_len: int):
        super().__init__()
        self.embed = nn.Embedding(vocab_size, model_dim)
        # token value embeddings by @KoszarskyB - inspired by @Grad62304977's value residual implementation following https://arxiv.org/abs/2410.17897
        # value embedding code simplification inspired by @ragulpr https://github.com/KellerJordan/modded-nanogpt/pull/78
        self.value_embeds = nn.ModuleList([nn.Embedding(vocab_size, model_dim) for _ in range(3)])
        self.blocks = nn.ModuleList([Block(model_dim, num_heads, max_seq_len, i) for i in range(num_layers)])
        # there are only 50257 unique GPT-2 tokens; we extend to nearest multiple of 128 for efficiency.
        # suggested to me by @Grad62304977. this originates from Karpathy's experiments.
        self.lm_head = CastedLinear(model_dim, next_multiple_of_n(vocab_size, n=128), use_fp8=True, x_s=(768**0.5)/448, w_s=2**-9, grad_s=1/448)
        self.lm_head.weight.detach().zero_() # @Grad62304977
        # Add learnable skip connection weights for decoder layers
        assert num_layers % 2 == 0
        self.skip_weights = nn.Parameter(torch.ones(num_layers//2))

    def create_blockmasks(self, input_seq: Tensor, sliding_window_num_blocks: Tensor):
        BLOCK_SIZE = 128
        docs = (input_seq == 50256).cumsum(0)

        def document_causal(b, h, q_idx, kv_idx):
            causal_mask = q_idx >= kv_idx
            document_mask = docs[q_idx] == docs[kv_idx]
            return causal_mask & document_mask

        def dense_to_ordered(dense_blockmask: Tensor):
            num_blocks = dense_blockmask.sum(dim=-1, dtype=torch.int32)
            indices = dense_blockmask.argsort(dim=-1, descending=False, stable=True).flip(-1).to(torch.int32)
            return num_blocks[None, None].contiguous(), indices[None, None].contiguous()

        # manual block mask creation by @YouJiacheng
        assert len(input_seq) % BLOCK_SIZE == 0
        NUM_BLOCKS = len(input_seq) // BLOCK_SIZE
        block_idx = torch.arange(NUM_BLOCKS, dtype=torch.int32, device="cuda")
        causal_blockmask_any = block_idx[:, None] >= block_idx
        causal_blockmask_all = block_idx[:, None] > block_idx
        docs_low = docs.view(-1, BLOCK_SIZE)[:, 0].contiguous()
        docs_high = docs.view(-1, BLOCK_SIZE)[:, -1].contiguous()
        document_blockmask_any = (docs_low[:, None] <= docs_high) & (docs_high[:, None] >= docs_low)
        document_blockmask_all = (docs_low[:, None] == docs_high) & (docs_high[:, None] == docs_low)
        blockmask_any = causal_blockmask_any & document_blockmask_any
        blockmask_all = causal_blockmask_all & document_blockmask_all
        partial_kv_num_blocks, partial_kv_indices = dense_to_ordered(blockmask_any & ~blockmask_all)
        full_kv_num_blocks, full_kv_indices = dense_to_ordered(blockmask_all)
        def build_bm(window_size_blocks: Tensor) -> BlockMask:
            return BlockMask.from_kv_blocks(
                torch.clamp_max(partial_kv_num_blocks, torch.clamp_min(window_size_blocks - full_kv_num_blocks, 1)),
                partial_kv_indices,
                torch.clamp_max(full_kv_num_blocks, window_size_blocks - 1),
                full_kv_indices,
                BLOCK_SIZE=BLOCK_SIZE,
                mask_mod=document_causal,
            )
        # Long-short SWA block masks by @leloykun & @YouJiacheng, adapated from suggestion by @Grad62304977, following Gemma 2 paper
        return build_bm(sliding_window_num_blocks), build_bm(sliding_window_num_blocks // 2)

    def forward(self, input_seq: Tensor, target_seq: Tensor, sliding_window_num_blocks: Tensor):
        assert input_seq.ndim == 1

        ve = [value_embed(input_seq) for value_embed in self.value_embeds]
        # 012 ... 012 structure on token value embeddings by @YouJiacheng, improved on @leloykun's U-net structure
        ve = [ve[0], ve[1], ve[2]] + [None] * (len(self.blocks) - 6) + [ve[0], ve[1], ve[2]]
        assert len(ve) == len(self.blocks)

        long_bm, short_bm = self.create_blockmasks(input_seq, sliding_window_num_blocks)
        block_masks = [long_bm, short_bm, short_bm, short_bm, long_bm, short_bm, short_bm, long_bm, short_bm, short_bm, short_bm, long_bm]
        assert len(block_masks) == len(self.blocks)

        x = x0 = norm(self.embed(input_seq)[None]) # use of norm here by @Grad62304977

        # U-net design by @brendanh0gan
        skip_connections = []
        n = len(self.skip_weights)
        for i in range(len(self.blocks)):
            if i >= n:
                x = x + self.skip_weights[i - n] * skip_connections.pop()
            x = self.blocks[i](x, ve[i], x0, block_masks[i])
            if i < n:
                skip_connections.append(x)

        x = norm(x)
        logits = self.lm_head(x).float()
        # @Grad62304977 added tanh softcapping following Gemma 2 paper, @KoszarskyB reduced it from 30 to 15, @YouJiacheng shifted it by +15 (2*sigmoid(2*x)=tanh(x)+1)
        logits = 30 * torch.sigmoid(logits / 7.5)
        loss = F.cross_entropy(logits.view(-1, logits.size(-1)), target_seq, reduction='sum' if self.training else 'mean')
        return loss

# -----------------------------------------------------------------------------
# Our own simple Distributed Data Loader

def _load_data_shard(file: Path):
    header = torch.from_file(str(file), False, 256, dtype=torch.int32) # header is 256 int32
    assert header[0] == 20240520, "magic number mismatch in the data .bin file"
    assert header[1] == 1, "unsupported version"
    num_tokens = int(header[2]) # number of tokens (claimed)
    with file.open("rb", buffering=0) as f:
        tokens = torch.empty(num_tokens, dtype=torch.uint16, pin_memory=True) # avoid pin_memory copy by @YouJiacheng
        f.seek(256 * 4)
        nbytes = f.readinto(tokens.numpy()) # avoid bytes->array copy by @YouJiacheng
        assert nbytes == 2 * num_tokens, "number of tokens read does not match header"
    return tokens

def distributed_data_generator(filename_pattern: str, batch_size: int, rank : int, world_size : int):
    files = [Path(file) for file in sorted(glob.glob(filename_pattern))]
    assert batch_size % world_size == 0
    local_batch_size = batch_size // world_size
    file_iter = iter(files) # use itertools.cycle(files) instead if you want to do multi-epoch training
    tokens, pos = _load_data_shard(next(file_iter)), 0
    while True:
        if pos + batch_size + 1 >= len(tokens):
            tokens, pos = _load_data_shard(next(file_iter)), 0
        buf = tokens[pos + rank * local_batch_size:][:local_batch_size + 1]
        inputs = buf[:-1].to(device="cuda", dtype=torch.int32, non_blocking=True) # no sync on host side;
        targets = buf[1:].to(device="cuda", dtype=torch.int64, non_blocking=True) # H2D in another stream isn't helpful.
        pos += batch_size
        yield inputs, targets

# -----------------------------------------------------------------------------
# int main

@dataclass
class Hyperparameters:
    # data
    train_files = "data/fineweb10B/fineweb_train_*.bin" # input .bin to train on
    val_files = "data/fineweb10B/fineweb_val_*.bin" # input .bin to eval validation loss on
    val_tokens = 10485760 # how many tokens of validation data? it's important to keep this fixed for consistent comparisons
    train_seq_len = 48*1024 # FlexAttention sequence length
    val_seq_len = 4*64*1024 # FlexAttention sequence length for validation
    # optimization
    num_iterations = 1750 # number of iterations to run
    cooldown_frac = 0.4 # fraction of training spent cooling down the learning rate
    # architecture
    vocab_size = 50257
    # evaluation and logging
    val_loss_every = 125 # every how many steps to evaluate val loss? 0 for only at the end
    save_checkpoint = False
args = Hyperparameters()

# torchrun sets these env variables
rank = int(os.environ["RANK"])
world_size = int(os.environ["WORLD_SIZE"])
assert world_size == 8 # this code is designed for 8xH100
assert torch.cuda.is_available()
device = torch.device("cuda", int(os.environ["LOCAL_RANK"]))
torch.cuda.set_device(device)
dist.init_process_group(backend="nccl", device_id=device)
dist.barrier()
master_process = (rank == 0) # this process will do logging, checkpointing etc.

# begin logging
logfile = None
if master_process:
    run_id = uuid.uuid4()
    os.makedirs("logs", exist_ok=True)
    logfile = f"logs/{run_id}.txt"
    print(logfile)
def print0(s, console=False):
    if master_process:
        with open(logfile, "a") as f:
            if console:
                print(s)
            print(s, file=f)

# begin by printing this file (the Python code)
print0(code)
print0("="*100)
# log information about the hardware/software environment this is running on
print0(f"Running Python {sys.version}")
print0(f"Running PyTorch {torch.version.__version__} compiled for CUDA {torch.version.cuda}")
def nvidia_smi():
    import subprocess  # avoid top level import
    return subprocess.run(["nvidia-smi"], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True).stdout
print0(nvidia_smi())
print0("="*100)

########################################
#    Construct model and optimizer     #
########################################

model: nn.Module = GPT(vocab_size=args.vocab_size, num_layers=12, num_heads=6, model_dim=768,
                       max_seq_len=max(args.train_seq_len, args.val_seq_len)).cuda()
for m in model.modules():
    if isinstance(m, nn.Embedding):
        m.bfloat16()
for param in model.parameters():
    dist.broadcast(param.detach(), 0)

# collect the parameters to optimize
hidden_matrix_params = [p for n, p in model.blocks.named_parameters() if p.ndim >= 2 and "embed" not in n]
embed_params = [p for n, p in model.named_parameters() if "embed" in n]
scalar_params = [p for p in model.parameters() if p.ndim < 2]
head_params = [model.lm_head.weight]

# init the optimizer(s)
adam_params = [dict(params=head_params, lr=0.22/768**0.5), dict(params=embed_params, lr=0.6), dict(params=scalar_params, lr=0.04)]
# small adam epsilon by @YouJiacheng. this is an alternate method of fixing the world_size dependence
# discovered by @fernbear.bsky.social https://x.com/hi_tysam/status/1879692937589875094
optimizer1 = torch.optim.Adam(adam_params, betas=(0.8, 0.95), eps=1e-10, fused=True)
optimizer2 = Muon(hidden_matrix_params, lr=0.05, momentum=0.95, rank=rank, world_size=world_size)
optimizers = [optimizer1, optimizer2]
for opt in optimizers:
    for group in opt.param_groups:
        group["initial_lr"] = group["lr"]

# learning rate schedule: stable then decay
def get_lr(step: int):
    x = step / args.num_iterations # progress in training
    assert 0 <= x < 1
    if x < 1 - args.cooldown_frac:
        return 1.0
    else:
        w = (1 - x) / args.cooldown_frac
        return w * 1.0 + (1 - w) * 0.1

# attention window size schedule: linearly increase
@lru_cache(1)
def get_window_size_blocks_helper(window_size: int):
    return torch.tensor(window_size // 128, dtype=torch.int32, pin_memory=True).cuda(non_blocking=True)
def get_window_size_blocks(step: int):
    x = step / args.num_iterations # progress in training
    assert 0 <= x <= 1
    # Linearly increase the block-wise sliding window size over training 128 -> 1792
    # increase by @fernbear.bsky.social; block-wise by @YouJiacheng
    window_size = next_multiple_of_n(1728 * x, n=128)
    return get_window_size_blocks_helper(window_size)

model: nn.Module = torch.compile(model, dynamic=False)

########################################
#            Warmup kernels            #
########################################

# Warmup the training kernels, then re-initialize the state so we aren't cheating
warmup_steps = 10
initial_state = dict(model=copy.deepcopy(model.state_dict()),
                     optimizers=[copy.deepcopy(opt.state_dict()) for opt in optimizers]) # save the initial state
for _ in range(warmup_steps):
    inputs = targets = torch.randint(0, args.vocab_size, size=(args.train_seq_len,), device="cuda")
    model(inputs.to(torch.int32), targets, get_window_size_blocks(0)).backward()
    for param in model.parameters():
        dist.all_reduce(param.grad, op=dist.ReduceOp.AVG)
    for opt in optimizers:
        opt.step()
    model.zero_grad(set_to_none=True)
model.load_state_dict(initial_state["model"])
for opt, opt_state in zip(optimizers, initial_state["optimizers"]):
    opt.load_state_dict(opt_state)
del initial_state

########################################
#        Training and validation       #
########################################

train_loader = distributed_data_generator(args.train_files, world_size * args.train_seq_len, rank, world_size)
training_time_ms = 0
# start the clock
torch.cuda.synchronize()
t0 = time.perf_counter()
# begin training
train_steps = args.num_iterations
for step in range(train_steps + 1):
    last_step = (step == train_steps)

    # --------------- VALIDATION SECTION -----------------
    if last_step or (args.val_loss_every > 0 and step % args.val_loss_every == 0):
        # stop the clock
        torch.cuda.synchronize()
        training_time_ms += 1000 * (time.perf_counter() - t0)
        model.eval()
        val_batch_size = world_size * args.val_seq_len
        assert args.val_tokens % val_batch_size == 0
        val_steps = args.val_tokens // val_batch_size
        val_loader = distributed_data_generator(args.val_files, val_batch_size, rank, world_size)
        val_loss = 0
        with torch.no_grad():
            for _ in range(val_steps):
                inputs, targets = next(val_loader)
                val_loss += model(inputs, targets, get_window_size_blocks(step))
        val_loss /= val_steps
        del val_loader
        dist.all_reduce(val_loss, op=dist.ReduceOp.AVG)
        print0(f"step:{step}/{train_steps} val_loss:{val_loss:.4f} train_time:{training_time_ms:.0f}ms step_avg:{training_time_ms/max(step, 1):.2f}ms", console=True)
        model.train()
        # start the clock again
        torch.cuda.synchronize()
        t0 = time.perf_counter()

    if last_step:
        if master_process and args.save_checkpoint:
            log = dict(step=step, code=code, model=model.state_dict(), optimizers=[opt.state_dict() for opt in optimizers])
            os.makedirs(f"logs/{run_id}", exist_ok=True)
            torch.save(log, f"logs/{run_id}/state_step{step:06d}.pt")
        # the last step only has the validation loop, so break to avoid training
        break

    # --------------- TRAINING SECTION -----------------
    inputs, targets = next(train_loader)
    model(inputs, targets, get_window_size_blocks(step)).backward()
    for param in model.parameters():
        dist.all_reduce(param.grad, op=dist.ReduceOp.AVG)
    # set optimization hyperparameters
    for opt in optimizers:
        for group in opt.param_groups:
            group["lr"] = group["initial_lr"] * get_lr(step)
    for group in optimizer2.param_groups:
        frac = min(step / 300, 1) # momentum warmup for muon
        group["momentum"] = (1 - frac) * 0.85 + frac * 0.95
    # step the optimizers
    for opt in optimizers:
        opt.step()
    # null the gradients
    model.zero_grad(set_to_none=True)
    # logging
    approx_training_time_ms = training_time_ms + 1000 * (time.perf_counter() - t0)
    print0(f"step:{step+1}/{train_steps} train_time:{approx_training_time_ms:.0f}ms step_avg:{approx_training_time_ms/(step + 1):.2f}ms", console=True)

print0(f"peak memory allocated: {torch.cuda.max_memory_allocated() // 1024 // 1024} MiB "
       f"reserved: {torch.cuda.max_memory_reserved() // 1024 // 1024} MiB", console=True)
dist.destroy_process_group()

====================================================================================================
Running Python 3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]
Running PyTorch 2.7.0.dev20250125+cu126 compiled for CUDA 12.6
Sun Feb 16 18:18:19 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA H100 80GB HBM3          On  |   00000000:19:00.0 Off |                    0 |
| N/A   39C    P0            117W /  700W |    7714MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA H100 80GB HBM3          On  |   00000000:3B:00.0 Off |                    0 |
| N/A   31C    P0            122W /  700W |    3452MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA H100 80GB HBM3          On  |   00000000:4C:00.0 Off |                    0 |
| N/A   30C    P0            115W /  700W |    3452MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA H100 80GB HBM3          On  |   00000000:5D:00.0 Off |                    0 |
| N/A   38C    P0            118W /  700W |    3452MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   4  NVIDIA H100 80GB HBM3          On  |   00000000:9B:00.0 Off |                    0 |
| N/A   38C    P0            121W /  700W |    3452MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   5  NVIDIA H100 80GB HBM3          On  |   00000000:BB:00.0 Off |                    0 |
| N/A   31C    P0            112W /  700W |    3452MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   6  NVIDIA H100 80GB HBM3          On  |   00000000:CB:00.0 Off |                    0 |
| N/A   37C    P0            115W /  700W |    3452MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   7  NVIDIA H100 80GB HBM3          On  |   00000000:DB:00.0 Off |                    0 |
| N/A   29C    P0            114W /  700W |    3212MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
+-----------------------------------------------------------------------------------------+

====================================================================================================
step:0/1750 val_loss:10.8258 train_time:0ms step_avg:0.17ms
step:1/1750 train_time:87ms step_avg:87.26ms
step:2/1750 train_time:165ms step_avg:82.68ms
step:3/1750 train_time:257ms step_avg:85.83ms
step:4/1750 train_time:353ms step_avg:88.32ms
step:5/1750 train_time:450ms step_avg:90.06ms
step:6/1750 train_time:547ms step_avg:91.16ms
step:7/1750 train_time:644ms step_avg:91.93ms
step:8/1750 train_time:740ms step_avg:92.55ms
step:9/1750 train_time:839ms step_avg:93.17ms
step:10/1750 train_time:935ms step_avg:93.50ms
step:11/1750 train_time:1032ms step_avg:93.78ms
step:12/1750 train_time:1129ms step_avg:94.08ms
step:13/1750 train_time:1226ms step_avg:94.34ms
step:14/1750 train_time:1323ms step_avg:94.53ms
step:15/1750 train_time:1421ms step_avg:94.70ms
step:16/1750 train_time:1517ms step_avg:94.81ms
step:17/1750 train_time:1614ms step_avg:94.92ms
step:18/1750 train_time:1711ms step_avg:95.04ms
step:19/1750 train_time:1807ms step_avg:95.11ms
step:20/1750 train_time:1904ms step_avg:95.19ms
step:21/1750 train_time:2001ms step_avg:95.30ms
step:22/1750 train_time:2099ms step_avg:95.39ms
step:23/1750 train_time:2197ms step_avg:95.50ms
step:24/1750 train_time:2294ms step_avg:95.60ms
step:25/1750 train_time:2393ms step_avg:95.71ms
step:26/1750 train_time:2490ms step_avg:95.78ms
step:27/1750 train_time:2588ms step_avg:95.85ms
step:28/1750 train_time:2685ms step_avg:95.91ms
step:29/1750 train_time:2782ms step_avg:95.95ms
step:30/1750 train_time:2880ms step_avg:95.99ms
step:31/1750 train_time:2977ms step_avg:96.04ms
step:32/1750 train_time:3074ms step_avg:96.08ms
step:33/1750 train_time:3172ms step_avg:96.11ms
step:34/1750 train_time:3269ms step_avg:96.16ms
step:35/1750 train_time:3366ms step_avg:96.17ms
step:36/1750 train_time:3463ms step_avg:96.18ms
step:37/1750 train_time:3559ms step_avg:96.20ms
step:38/1750 train_time:3657ms step_avg:96.23ms
step:39/1750 train_time:3754ms step_avg:96.25ms
step:40/1750 train_time:3851ms step_avg:96.27ms
step:41/1750 train_time:3949ms step_avg:96.31ms
step:42/1750 train_time:4045ms step_avg:96.30ms
step:43/1750 train_time:4142ms step_avg:96.32ms
step:44/1750 train_time:4239ms step_avg:96.34ms
step:45/1750 train_time:4336ms step_avg:96.35ms
step:46/1750 train_time:4432ms step_avg:96.36ms
step:47/1750 train_time:4530ms step_avg:96.37ms
step:48/1750 train_time:4626ms step_avg:96.38ms
step:49/1750 train_time:4723ms step_avg:96.39ms
step:50/1750 train_time:4820ms step_avg:96.40ms
step:51/1750 train_time:4917ms step_avg:96.40ms
step:52/1750 train_time:5013ms step_avg:96.41ms
step:53/1750 train_time:5111ms step_avg:96.43ms
step:54/1750 train_time:5208ms step_avg:96.44ms
step:55/1750 train_time:5304ms step_avg:96.44ms
step:56/1750 train_time:5401ms step_avg:96.45ms
step:57/1750 train_time:5498ms step_avg:96.46ms
step:58/1750 train_time:5595ms step_avg:96.47ms
step:59/1750 train_time:5693ms step_avg:96.49ms
step:60/1750 train_time:5791ms step_avg:96.52ms
step:61/1750 train_time:5888ms step_avg:96.52ms
step:62/1750 train_time:5984ms step_avg:96.52ms
step:63/1750 train_time:6082ms step_avg:96.54ms
step:64/1750 train_time:6179ms step_avg:96.55ms
step:65/1750 train_time:6276ms step_avg:96.55ms
step:66/1750 train_time:6372ms step_avg:96.55ms
step:67/1750 train_time:6469ms step_avg:96.56ms
step:68/1750 train_time:6566ms step_avg:96.56ms
step:69/1750 train_time:6663ms step_avg:96.56ms
step:70/1750 train_time:6760ms step_avg:96.57ms
step:71/1750 train_time:6857ms step_avg:96.57ms
step:72/1750 train_time:6954ms step_avg:96.59ms
step:73/1750 train_time:7051ms step_avg:96.58ms
step:74/1750 train_time:7147ms step_avg:96.58ms
step:75/1750 train_time:7244ms step_avg:96.59ms
step:76/1750 train_time:7341ms step_avg:96.59ms
step:77/1750 train_time:7438ms step_avg:96.60ms
step:78/1750 train_time:7535ms step_avg:96.61ms
step:79/1750 train_time:7632ms step_avg:96.61ms
step:80/1750 train_time:7730ms step_avg:96.62ms
step:81/1750 train_time:7827ms step_avg:96.62ms
step:82/1750 train_time:7924ms step_avg:96.63ms
step:83/1750 train_time:8021ms step_avg:96.63ms
step:84/1750 train_time:8118ms step_avg:96.64ms
step:85/1750 train_time:8215ms step_avg:96.65ms
step:86/1750 train_time:8311ms step_avg:96.64ms
step:87/1750 train_time:8408ms step_avg:96.64ms
step:88/1750 train_time:8504ms step_avg:96.63ms
step:89/1750 train_time:8601ms step_avg:96.64ms
step:90/1750 train_time:8699ms step_avg:96.65ms
step:91/1750 train_time:8798ms step_avg:96.68ms
step:92/1750 train_time:8896ms step_avg:96.70ms
step:93/1750 train_time:8993ms step_avg:96.70ms
step:94/1750 train_time:9090ms step_avg:96.70ms
step:95/1750 train_time:9186ms step_avg:96.70ms
step:96/1750 train_time:9283ms step_avg:96.70ms
step:97/1750 train_time:9380ms step_avg:96.70ms
step:98/1750 train_time:9478ms step_avg:96.71ms
step:99/1750 train_time:9575ms step_avg:96.72ms
step:100/1750 train_time:9672ms step_avg:96.72ms
step:101/1750 train_time:9768ms step_avg:96.72ms
step:102/1750 train_time:9865ms step_avg:96.72ms
step:103/1750 train_time:9962ms step_avg:96.72ms
step:104/1750 train_time:10059ms step_avg:96.72ms
step:105/1750 train_time:10157ms step_avg:96.73ms
step:106/1750 train_time:10253ms step_avg:96.73ms
step:107/1750 train_time:10350ms step_avg:96.73ms
step:108/1750 train_time:10447ms step_avg:96.73ms
step:109/1750 train_time:10543ms step_avg:96.73ms
step:110/1750 train_time:10640ms step_avg:96.73ms
step:111/1750 train_time:10737ms step_avg:96.73ms
step:112/1750 train_time:10834ms step_avg:96.73ms
step:113/1750 train_time:10931ms step_avg:96.73ms
step:114/1750 train_time:11028ms step_avg:96.73ms
step:115/1750 train_time:11125ms step_avg:96.74ms
step:116/1750 train_time:11222ms step_avg:96.74ms
step:117/1750 train_time:11319ms step_avg:96.74ms
step:118/1750 train_time:11416ms step_avg:96.74ms
step:119/1750 train_time:11512ms step_avg:96.74ms
step:120/1750 train_time:11609ms step_avg:96.74ms
step:121/1750 train_time:11706ms step_avg:96.74ms
step:122/1750 train_time:12157ms step_avg:99.65ms
step:123/1750 train_time:12268ms step_avg:99.74ms
step:124/1750 train_time:12363ms step_avg:99.70ms
step:125/1750 train_time:12460ms step_avg:99.68ms
step:125/1750 val_loss:4.6432 train_time:12551ms step_avg:100.41ms
step:126/1750 train_time:12571ms step_avg:99.77ms
step:127/1750 train_time:12662ms step_avg:99.70ms
step:128/1750 train_time:12765ms step_avg:99.73ms
step:129/1750 train_time:12862ms step_avg:99.71ms
step:130/1750 train_time:12960ms step_avg:99.69ms
step:131/1750 train_time:13057ms step_avg:99.67ms
step:132/1750 train_time:13154ms step_avg:99.65ms
step:133/1750 train_time:13251ms step_avg:99.63ms
step:134/1750 train_time:13349ms step_avg:99.62ms
step:135/1750 train_time:13446ms step_avg:99.60ms
step:136/1750 train_time:13543ms step_avg:99.58ms
step:137/1750 train_time:13640ms step_avg:99.56ms
step:138/1750 train_time:13738ms step_avg:99.55ms
step:139/1750 train_time:13835ms step_avg:99.53ms
step:140/1750 train_time:13932ms step_avg:99.52ms
step:141/1750 train_time:14031ms step_avg:99.51ms
step:142/1750 train_time:14128ms step_avg:99.50ms
step:143/1750 train_time:14225ms step_avg:99.48ms
step:144/1750 train_time:14323ms step_avg:99.47ms
step:145/1750 train_time:14420ms step_avg:99.45ms
step:146/1750 train_time:14517ms step_avg:99.43ms
step:147/1750 train_time:14615ms step_avg:99.42ms
step:148/1750 train_time:14713ms step_avg:99.41ms
step:149/1750 train_time:14810ms step_avg:99.40ms
step:150/1750 train_time:14908ms step_avg:99.39ms
step:151/1750 train_time:15005ms step_avg:99.37ms
step:152/1750 train_time:15103ms step_avg:99.36ms
step:153/1750 train_time:15199ms step_avg:99.34ms
step:154/1750 train_time:15298ms step_avg:99.34ms
step:155/1750 train_time:15395ms step_avg:99.32ms
step:156/1750 train_time:15493ms step_avg:99.31ms
step:157/1750 train_time:15591ms step_avg:99.31ms
step:158/1750 train_time:15690ms step_avg:99.30ms
step:159/1750 train_time:15787ms step_avg:99.29ms
step:160/1750 train_time:15885ms step_avg:99.28ms
step:161/1750 train_time:15983ms step_avg:99.27ms
step:162/1750 train_time:16080ms step_avg:99.26ms
step:163/1750 train_time:16177ms step_avg:99.24ms
step:164/1750 train_time:16274ms step_avg:99.23ms
step:165/1750 train_time:16372ms step_avg:99.22ms
step:166/1750 train_time:16470ms step_avg:99.21ms
step:167/1750 train_time:16567ms step_avg:99.21ms
step:168/1750 train_time:16666ms step_avg:99.20ms
step:169/1750 train_time:16764ms step_avg:99.19ms
step:170/1750 train_time:16861ms step_avg:99.18ms
step:171/1750 train_time:16958ms step_avg:99.17ms
step:172/1750 train_time:17055ms step_avg:99.16ms
step:173/1750 train_time:17153ms step_avg:99.15ms
step:174/1750 train_time:17251ms step_avg:99.14ms
step:175/1750 train_time:17349ms step_avg:99.14ms
step:176/1750 train_time:17447ms step_avg:99.13ms
step:177/1750 train_time:17544ms step_avg:99.12ms
step:178/1750 train_time:17642ms step_avg:99.11ms
step:179/1750 train_time:17739ms step_avg:99.10ms
step:180/1750 train_time:17836ms step_avg:99.09ms
step:181/1750 train_time:17933ms step_avg:99.08ms
step:182/1750 train_time:18031ms step_avg:99.07ms
step:183/1750 train_time:18128ms step_avg:99.06ms
step:184/1750 train_time:18226ms step_avg:99.05ms
step:185/1750 train_time:18323ms step_avg:99.05ms
step:186/1750 train_time:18420ms step_avg:99.03ms
step:187/1750 train_time:18518ms step_avg:99.03ms
step:188/1750 train_time:18615ms step_avg:99.02ms
step:189/1750 train_time:18712ms step_avg:99.01ms
step:190/1750 train_time:18810ms step_avg:99.00ms
step:191/1750 train_time:18907ms step_avg:98.99ms
step:192/1750 train_time:19005ms step_avg:98.98ms
step:193/1750 train_time:19104ms step_avg:98.98ms
step:194/1750 train_time:19199ms step_avg:98.97ms
step:195/1750 train_time:19296ms step_avg:98.95ms
step:196/1750 train_time:19393ms step_avg:98.94ms
step:197/1750 train_time:19490ms step_avg:98.94ms
step:198/1750 train_time:19589ms step_avg:98.93ms
step:199/1750 train_time:19687ms step_avg:98.93ms
step:200/1750 train_time:19785ms step_avg:98.92ms
step:201/1750 train_time:19882ms step_avg:98.92ms
step:202/1750 train_time:19981ms step_avg:98.91ms
step:203/1750 train_time:20077ms step_avg:98.90ms
step:204/1750 train_time:20174ms step_avg:98.89ms
step:205/1750 train_time:20272ms step_avg:98.89ms
step:206/1750 train_time:20369ms step_avg:98.88ms
step:207/1750 train_time:20466ms step_avg:98.87ms
step:208/1750 train_time:20564ms step_avg:98.86ms
step:209/1750 train_time:20662ms step_avg:98.86ms
step:210/1750 train_time:20759ms step_avg:98.85ms
step:211/1750 train_time:20857ms step_avg:98.85ms
step:212/1750 train_time:20954ms step_avg:98.84ms
step:213/1750 train_time:21052ms step_avg:98.83ms
step:214/1750 train_time:21150ms step_avg:98.83ms
step:215/1750 train_time:21248ms step_avg:98.83ms
step:216/1750 train_time:21347ms step_avg:98.83ms
step:217/1750 train_time:21444ms step_avg:98.82ms
step:218/1750 train_time:21543ms step_avg:98.82ms
step:219/1750 train_time:21640ms step_avg:98.81ms
step:220/1750 train_time:21738ms step_avg:98.81ms
step:221/1750 train_time:21834ms step_avg:98.80ms
step:222/1750 train_time:21932ms step_avg:98.79ms
step:223/1750 train_time:22030ms step_avg:98.79ms
step:224/1750 train_time:22127ms step_avg:98.78ms
step:225/1750 train_time:22225ms step_avg:98.78ms
step:226/1750 train_time:22322ms step_avg:98.77ms
step:227/1750 train_time:22420ms step_avg:98.76ms
step:228/1750 train_time:22518ms step_avg:98.76ms
step:229/1750 train_time:22615ms step_avg:98.76ms
step:230/1750 train_time:22713ms step_avg:98.75ms
step:231/1750 train_time:22811ms step_avg:98.75ms
step:232/1750 train_time:22909ms step_avg:98.75ms
step:233/1750 train_time:23006ms step_avg:98.74ms
step:234/1750 train_time:23103ms step_avg:98.73ms
step:235/1750 train_time:23200ms step_avg:98.72ms
step:236/1750 train_time:23297ms step_avg:98.72ms
step:237/1750 train_time:23394ms step_avg:98.71ms
step:238/1750 train_time:23492ms step_avg:98.70ms
step:239/1750 train_time:23589ms step_avg:98.70ms
step:240/1750 train_time:23687ms step_avg:98.70ms
step:241/1750 train_time:23786ms step_avg:98.70ms
step:242/1750 train_time:23884ms step_avg:98.69ms
step:243/1750 train_time:23981ms step_avg:98.69ms
step:244/1750 train_time:24079ms step_avg:98.68ms
step:245/1750 train_time:24176ms step_avg:98.68ms
step:246/1750 train_time:24273ms step_avg:98.67ms
step:247/1750 train_time:24371ms step_avg:98.67ms
step:248/1750 train_time:24468ms step_avg:98.66ms
step:249/1750 train_time:24567ms step_avg:98.66ms
step:250/1750 train_time:24664ms step_avg:98.66ms
step:250/1750 val_loss:4.1007 train_time:24755ms step_avg:99.02ms
step:251/1750 train_time:24778ms step_avg:98.72ms
step:252/1750 train_time:24868ms step_avg:98.68ms
step:253/1750 train_time:24967ms step_avg:98.68ms
step:254/1750 train_time:25065ms step_avg:98.68ms
step:255/1750 train_time:25163ms step_avg:98.68ms
step:256/1750 train_time:25260ms step_avg:98.67ms
step:257/1750 train_time:25357ms step_avg:98.66ms
step:258/1750 train_time:25454ms step_avg:98.66ms
step:259/1750 train_time:25551ms step_avg:98.65ms
step:260/1750 train_time:25649ms step_avg:98.65ms
step:261/1750 train_time:25747ms step_avg:98.65ms
step:262/1750 train_time:25845ms step_avg:98.64ms
step:263/1750 train_time:25943ms step_avg:98.64ms
step:264/1750 train_time:26040ms step_avg:98.64ms
step:265/1750 train_time:26138ms step_avg:98.64ms
step:266/1750 train_time:26236ms step_avg:98.63ms
step:267/1750 train_time:26334ms step_avg:98.63ms
step:268/1750 train_time:26431ms step_avg:98.62ms
step:269/1750 train_time:26529ms step_avg:98.62ms
step:270/1750 train_time:26627ms step_avg:98.62ms
step:271/1750 train_time:26725ms step_avg:98.62ms
step:272/1750 train_time:26824ms step_avg:98.62ms
step:273/1750 train_time:26922ms step_avg:98.62ms
step:274/1750 train_time:27020ms step_avg:98.61ms
step:275/1750 train_time:27118ms step_avg:98.61ms
step:276/1750 train_time:27216ms step_avg:98.61ms
step:277/1750 train_time:27314ms step_avg:98.61ms
step:278/1750 train_time:27412ms step_avg:98.60ms
step:279/1750 train_time:27510ms step_avg:98.60ms
step:280/1750 train_time:27608ms step_avg:98.60ms
step:281/1750 train_time:27706ms step_avg:98.60ms
step:282/1750 train_time:27804ms step_avg:98.59ms
step:283/1750 train_time:27901ms step_avg:98.59ms
step:284/1750 train_time:27998ms step_avg:98.58ms
step:285/1750 train_time:28095ms step_avg:98.58ms
step:286/1750 train_time:28193ms step_avg:98.58ms
step:287/1750 train_time:28292ms step_avg:98.58ms
step:288/1750 train_time:28391ms step_avg:98.58ms
step:289/1750 train_time:28489ms step_avg:98.58ms
step:290/1750 train_time:28588ms step_avg:98.58ms
step:291/1750 train_time:28686ms step_avg:98.58ms
step:292/1750 train_time:28784ms step_avg:98.58ms
step:293/1750 train_time:28882ms step_avg:98.57ms
step:294/1750 train_time:28980ms step_avg:98.57ms
step:295/1750 train_time:29078ms step_avg:98.57ms
step:296/1750 train_time:29176ms step_avg:98.57ms
step:297/1750 train_time:29274ms step_avg:98.57ms
step:298/1750 train_time:29371ms step_avg:98.56ms
step:299/1750 train_time:29469ms step_avg:98.56ms
step:300/1750 train_time:29568ms step_avg:98.56ms
step:301/1750 train_time:29665ms step_avg:98.56ms
step:302/1750 train_time:29763ms step_avg:98.55ms
step:303/1750 train_time:29862ms step_avg:98.55ms
step:304/1750 train_time:29959ms step_avg:98.55ms
step:305/1750 train_time:30057ms step_avg:98.55ms
step:306/1750 train_time:30155ms step_avg:98.55ms
step:307/1750 train_time:30253ms step_avg:98.55ms
step:308/1750 train_time:30352ms step_avg:98.54ms
step:309/1750 train_time:30450ms step_avg:98.54ms
step:310/1750 train_time:30549ms step_avg:98.54ms
step:311/1750 train_time:30647ms step_avg:98.54ms
step:312/1750 train_time:30745ms step_avg:98.54ms
step:313/1750 train_time:30843ms step_avg:98.54ms
step:314/1750 train_time:30940ms step_avg:98.54ms
step:315/1750 train_time:31038ms step_avg:98.53ms
step:316/1750 train_time:31135ms step_avg:98.53ms
step:317/1750 train_time:31233ms step_avg:98.53ms
step:318/1750 train_time:31333ms step_avg:98.53ms
step:319/1750 train_time:31431ms step_avg:98.53ms
step:320/1750 train_time:31529ms step_avg:98.53ms
step:321/1750 train_time:31627ms step_avg:98.53ms
step:322/1750 train_time:31725ms step_avg:98.52ms
step:323/1750 train_time:31823ms step_avg:98.52ms
step:324/1750 train_time:31920ms step_avg:98.52ms
step:325/1750 train_time:32018ms step_avg:98.52ms
step:326/1750 train_time:32115ms step_avg:98.51ms
step:327/1750 train_time:32213ms step_avg:98.51ms
step:328/1750 train_time:32311ms step_avg:98.51ms
step:329/1750 train_time:32410ms step_avg:98.51ms
step:330/1750 train_time:32508ms step_avg:98.51ms
step:331/1750 train_time:32606ms step_avg:98.51ms
step:332/1750 train_time:32704ms step_avg:98.51ms
step:333/1750 train_time:32802ms step_avg:98.50ms
step:334/1750 train_time:32899ms step_avg:98.50ms
step:335/1750 train_time:32997ms step_avg:98.50ms
step:336/1750 train_time:33095ms step_avg:98.50ms
step:337/1750 train_time:33193ms step_avg:98.50ms
step:338/1750 train_time:33290ms step_avg:98.49ms
step:339/1750 train_time:33389ms step_avg:98.49ms
step:340/1750 train_time:33487ms step_avg:98.49ms
step:341/1750 train_time:33585ms step_avg:98.49ms
step:342/1750 train_time:33683ms step_avg:98.49ms
step:343/1750 train_time:33781ms step_avg:98.49ms
step:344/1750 train_time:33878ms step_avg:98.48ms
step:345/1750 train_time:33976ms step_avg:98.48ms
step:346/1750 train_time:34074ms step_avg:98.48ms
step:347/1750 train_time:34172ms step_avg:98.48ms
step:348/1750 train_time:34269ms step_avg:98.47ms
step:349/1750 train_time:34367ms step_avg:98.47ms
step:350/1750 train_time:34465ms step_avg:98.47ms
step:351/1750 train_time:34564ms step_avg:98.47ms
step:352/1750 train_time:34661ms step_avg:98.47ms
step:353/1750 train_time:34759ms step_avg:98.47ms
step:354/1750 train_time:34858ms step_avg:98.47ms
step:355/1750 train_time:34956ms step_avg:98.47ms
step:356/1750 train_time:35054ms step_avg:98.47ms
step:357/1750 train_time:35152ms step_avg:98.47ms
step:358/1750 train_time:35250ms step_avg:98.46ms
step:359/1750 train_time:35349ms step_avg:98.46ms
step:360/1750 train_time:35447ms step_avg:98.46ms
step:361/1750 train_time:35545ms step_avg:98.46ms
step:362/1750 train_time:35644ms step_avg:98.46ms
step:363/1750 train_time:35742ms step_avg:98.46ms
step:364/1750 train_time:35840ms step_avg:98.46ms
step:365/1750 train_time:35938ms step_avg:98.46ms
step:366/1750 train_time:36036ms step_avg:98.46ms
step:367/1750 train_time:36134ms step_avg:98.46ms
step:368/1750 train_time:36231ms step_avg:98.45ms
step:369/1750 train_time:36329ms step_avg:98.45ms
step:370/1750 train_time:36428ms step_avg:98.45ms
step:371/1750 train_time:36524ms step_avg:98.45ms
step:372/1750 train_time:36622ms step_avg:98.45ms
step:373/1750 train_time:36720ms step_avg:98.44ms
step:374/1750 train_time:36817ms step_avg:98.44ms
step:375/1750 train_time:36915ms step_avg:98.44ms
step:375/1750 val_loss:3.9048 train_time:37007ms step_avg:98.69ms
step:376/1750 train_time:37029ms step_avg:98.48ms
step:377/1750 train_time:37116ms step_avg:98.45ms
step:378/1750 train_time:37221ms step_avg:98.47ms
step:379/1750 train_time:37319ms step_avg:98.47ms
step:380/1750 train_time:37417ms step_avg:98.47ms
step:381/1750 train_time:37515ms step_avg:98.46ms
step:382/1750 train_time:37612ms step_avg:98.46ms
step:383/1750 train_time:37709ms step_avg:98.46ms
step:384/1750 train_time:37807ms step_avg:98.45ms
step:385/1750 train_time:37904ms step_avg:98.45ms
step:386/1750 train_time:38002ms step_avg:98.45ms
step:387/1750 train_time:38100ms step_avg:98.45ms
step:388/1750 train_time:38200ms step_avg:98.45ms
step:389/1750 train_time:38299ms step_avg:98.46ms
step:390/1750 train_time:38398ms step_avg:98.46ms
step:391/1750 train_time:38499ms step_avg:98.46ms
step:392/1750 train_time:38600ms step_avg:98.47ms
step:393/1750 train_time:38701ms step_avg:98.48ms
step:394/1750 train_time:38803ms step_avg:98.48ms
step:395/1750 train_time:38903ms step_avg:98.49ms
step:396/1750 train_time:39004ms step_avg:98.49ms
step:397/1750 train_time:39104ms step_avg:98.50ms
step:398/1750 train_time:39204ms step_avg:98.50ms
step:399/1750 train_time:39304ms step_avg:98.51ms
step:400/1750 train_time:39404ms step_avg:98.51ms
step:401/1750 train_time:39503ms step_avg:98.51ms
step:402/1750 train_time:39604ms step_avg:98.52ms
step:403/1750 train_time:39704ms step_avg:98.52ms
step:404/1750 train_time:39805ms step_avg:98.53ms
step:405/1750 train_time:39905ms step_avg:98.53ms
step:406/1750 train_time:40005ms step_avg:98.53ms
step:407/1750 train_time:40104ms step_avg:98.54ms
step:408/1750 train_time:40205ms step_avg:98.54ms
step:409/1750 train_time:40305ms step_avg:98.54ms
step:410/1750 train_time:40405ms step_avg:98.55ms
step:411/1750 train_time:40505ms step_avg:98.55ms
step:412/1750 train_time:40604ms step_avg:98.55ms
step:413/1750 train_time:40704ms step_avg:98.56ms
step:414/1750 train_time:40803ms step_avg:98.56ms
step:415/1750 train_time:40903ms step_avg:98.56ms
step:416/1750 train_time:41003ms step_avg:98.57ms
step:417/1750 train_time:41103ms step_avg:98.57ms
step:418/1750 train_time:41204ms step_avg:98.57ms
step:419/1750 train_time:41304ms step_avg:98.58ms
step:420/1750 train_time:41404ms step_avg:98.58ms
step:421/1750 train_time:41504ms step_avg:98.59ms
step:422/1750 train_time:41605ms step_avg:98.59ms
step:423/1750 train_time:41705ms step_avg:98.59ms
step:424/1750 train_time:41805ms step_avg:98.60ms
step:425/1750 train_time:41905ms step_avg:98.60ms
step:426/1750 train_time:42004ms step_avg:98.60ms
step:427/1750 train_time:42104ms step_avg:98.60ms
step:428/1750 train_time:42204ms step_avg:98.61ms
step:429/1750 train_time:42304ms step_avg:98.61ms
step:430/1750 train_time:42404ms step_avg:98.61ms
step:431/1750 train_time:42503ms step_avg:98.62ms
step:432/1750 train_time:42603ms step_avg:98.62ms
step:433/1750 train_time:42703ms step_avg:98.62ms
step:434/1750 train_time:42804ms step_avg:98.63ms
step:435/1750 train_time:42903ms step_avg:98.63ms
step:436/1750 train_time:43005ms step_avg:98.63ms
step:437/1750 train_time:43104ms step_avg:98.64ms
step:438/1750 train_time:43205ms step_avg:98.64ms
step:439/1750 train_time:43304ms step_avg:98.64ms
step:440/1750 train_time:43405ms step_avg:98.65ms
step:441/1750 train_time:43505ms step_avg:98.65ms
step:442/1750 train_time:43605ms step_avg:98.65ms
step:443/1750 train_time:43704ms step_avg:98.65ms
step:444/1750 train_time:43803ms step_avg:98.66ms
step:445/1750 train_time:43904ms step_avg:98.66ms
step:446/1750 train_time:44005ms step_avg:98.67ms
step:447/1750 train_time:44105ms step_avg:98.67ms
step:448/1750 train_time:44205ms step_avg:98.67ms
step:449/1750 train_time:44305ms step_avg:98.67ms
step:450/1750 train_time:44405ms step_avg:98.68ms
step:451/1750 train_time:44505ms step_avg:98.68ms
step:452/1750 train_time:44605ms step_avg:98.68ms
step:453/1750 train_time:44704ms step_avg:98.69ms
step:454/1750 train_time:44804ms step_avg:98.69ms
step:455/1750 train_time:44903ms step_avg:98.69ms
step:456/1750 train_time:45003ms step_avg:98.69ms
step:457/1750 train_time:45103ms step_avg:98.69ms
step:458/1750 train_time:45204ms step_avg:98.70ms
step:459/1750 train_time:45304ms step_avg:98.70ms
step:460/1750 train_time:45403ms step_avg:98.70ms
step:461/1750 train_time:45504ms step_avg:98.71ms
step:462/1750 train_time:45604ms step_avg:98.71ms
step:463/1750 train_time:45704ms step_avg:98.71ms
step:464/1750 train_time:45804ms step_avg:98.72ms
step:465/1750 train_time:45904ms step_avg:98.72ms
step:466/1750 train_time:46004ms step_avg:98.72ms
step:467/1750 train_time:46104ms step_avg:98.72ms
step:468/1750 train_time:46204ms step_avg:98.73ms
step:469/1750 train_time:46304ms step_avg:98.73ms
step:470/1750 train_time:46404ms step_avg:98.73ms
step:471/1750 train_time:46504ms step_avg:98.74ms
step:472/1750 train_time:46604ms step_avg:98.74ms
step:473/1750 train_time:46704ms step_avg:98.74ms
step:474/1750 train_time:46804ms step_avg:98.74ms
step:475/1750 train_time:46905ms step_avg:98.75ms
step:476/1750 train_time:47004ms step_avg:98.75ms
step:477/1750 train_time:47105ms step_avg:98.75ms
step:478/1750 train_time:47205ms step_avg:98.76ms
step:479/1750 train_time:47304ms step_avg:98.76ms
step:480/1750 train_time:47405ms step_avg:98.76ms
step:481/1750 train_time:47505ms step_avg:98.76ms
step:482/1750 train_time:47605ms step_avg:98.77ms
step:483/1750 train_time:47705ms step_avg:98.77ms
step:484/1750 train_time:47805ms step_avg:98.77ms
step:485/1750 train_time:47905ms step_avg:98.77ms
step:486/1750 train_time:48005ms step_avg:98.78ms
step:487/1750 train_time:48105ms step_avg:98.78ms
step:488/1750 train_time:48205ms step_avg:98.78ms
step:489/1750 train_time:48305ms step_avg:98.78ms
step:490/1750 train_time:48405ms step_avg:98.79ms
step:491/1750 train_time:48505ms step_avg:98.79ms
step:492/1750 train_time:48605ms step_avg:98.79ms
step:493/1750 train_time:48705ms step_avg:98.79ms
step:494/1750 train_time:48805ms step_avg:98.80ms
step:495/1750 train_time:48905ms step_avg:98.80ms
step:496/1750 train_time:49005ms step_avg:98.80ms
step:497/1750 train_time:49105ms step_avg:98.80ms
step:498/1750 train_time:49205ms step_avg:98.80ms
step:499/1750 train_time:49304ms step_avg:98.81ms
step:500/1750 train_time:49404ms step_avg:98.81ms
step:500/1750 val_loss:3.7574 train_time:49499ms step_avg:99.00ms
step:501/1750 train_time:49519ms step_avg:98.84ms
step:502/1750 train_time:49612ms step_avg:98.83ms
step:503/1750 train_time:49714ms step_avg:98.84ms
step:504/1750 train_time:49814ms step_avg:98.84ms
step:505/1750 train_time:49914ms step_avg:98.84ms
step:506/1750 train_time:50013ms step_avg:98.84ms
step:507/1750 train_time:50113ms step_avg:98.84ms
step:508/1750 train_time:50212ms step_avg:98.84ms
step:509/1750 train_time:50312ms step_avg:98.85ms
step:510/1750 train_time:50411ms step_avg:98.84ms
step:511/1750 train_time:50512ms step_avg:98.85ms
step:512/1750 train_time:50613ms step_avg:98.85ms
step:513/1750 train_time:50715ms step_avg:98.86ms
step:514/1750 train_time:50816ms step_avg:98.86ms
step:515/1750 train_time:50917ms step_avg:98.87ms
step:516/1750 train_time:51017ms step_avg:98.87ms
step:517/1750 train_time:51117ms step_avg:98.87ms
step:518/1750 train_time:51217ms step_avg:98.87ms
step:519/1750 train_time:51318ms step_avg:98.88ms
step:520/1750 train_time:51419ms step_avg:98.88ms
step:521/1750 train_time:51521ms step_avg:98.89ms
step:522/1750 train_time:51622ms step_avg:98.89ms
step:523/1750 train_time:51722ms step_avg:98.89ms
step:524/1750 train_time:51822ms step_avg:98.90ms
step:525/1750 train_time:51922ms step_avg:98.90ms
step:526/1750 train_time:52022ms step_avg:98.90ms
step:527/1750 train_time:52123ms step_avg:98.91ms
step:528/1750 train_time:52223ms step_avg:98.91ms
step:529/1750 train_time:52324ms step_avg:98.91ms
step:530/1750 train_time:52425ms step_avg:98.92ms
step:531/1750 train_time:52526ms step_avg:98.92ms
step:532/1750 train_time:52625ms step_avg:98.92ms
step:533/1750 train_time:52725ms step_avg:98.92ms
step:534/1750 train_time:52825ms step_avg:98.92ms
step:535/1750 train_time:52925ms step_avg:98.93ms
step:536/1750 train_time:53026ms step_avg:98.93ms
step:537/1750 train_time:53126ms step_avg:98.93ms
step:538/1750 train_time:53226ms step_avg:98.93ms
step:539/1750 train_time:53326ms step_avg:98.93ms
step:540/1750 train_time:53426ms step_avg:98.94ms
step:541/1750 train_time:53526ms step_avg:98.94ms
step:542/1750 train_time:53627ms step_avg:98.94ms
step:543/1750 train_time:53728ms step_avg:98.95ms
step:544/1750 train_time:53827ms step_avg:98.95ms
step:545/1750 train_time:53927ms step_avg:98.95ms
step:546/1750 train_time:54028ms step_avg:98.95ms
step:547/1750 train_time:54127ms step_avg:98.95ms
step:548/1750 train_time:54227ms step_avg:98.96ms
step:549/1750 train_time:54327ms step_avg:98.96ms
step:550/1750 train_time:54431ms step_avg:98.97ms
step:551/1750 train_time:54528ms step_avg:98.96ms
step:552/1750 train_time:54627ms step_avg:98.96ms
step:553/1750 train_time:54728ms step_avg:98.97ms
step:554/1750 train_time:54828ms step_avg:98.97ms
step:555/1750 train_time:54929ms step_avg:98.97ms
step:556/1750 train_time:55028ms step_avg:98.97ms
step:557/1750 train_time:55128ms step_avg:98.97ms
step:558/1750 train_time:55229ms step_avg:98.98ms
step:559/1750 train_time:55329ms step_avg:98.98ms
step:560/1750 train_time:55430ms step_avg:98.98ms
step:561/1750 train_time:55530ms step_avg:98.98ms
step:562/1750 train_time:55631ms step_avg:98.99ms
step:563/1750 train_time:55731ms step_avg:98.99ms
step:564/1750 train_time:55830ms step_avg:98.99ms
step:565/1750 train_time:55931ms step_avg:98.99ms
step:566/1750 train_time:56031ms step_avg:99.00ms
step:567/1750 train_time:56131ms step_avg:99.00ms
step:568/1750 train_time:56231ms step_avg:99.00ms
step:569/1750 train_time:56332ms step_avg:99.00ms
step:570/1750 train_time:56433ms step_avg:99.01ms
step:571/1750 train_time:56534ms step_avg:99.01ms
step:572/1750 train_time:56635ms step_avg:99.01ms
step:573/1750 train_time:56735ms step_avg:99.01ms
step:574/1750 train_time:56835ms step_avg:99.02ms
step:575/1750 train_time:56935ms step_avg:99.02ms
step:576/1750 train_time:57035ms step_avg:99.02ms
step:577/1750 train_time:57136ms step_avg:99.02ms
step:578/1750 train_time:57237ms step_avg:99.03ms
step:579/1750 train_time:57339ms step_avg:99.03ms
step:580/1750 train_time:57440ms step_avg:99.03ms
step:581/1750 train_time:57541ms step_avg:99.04ms
step:582/1750 train_time:57641ms step_avg:99.04ms
step:583/1750 train_time:57742ms step_avg:99.04ms
step:584/1750 train_time:57843ms step_avg:99.05ms
step:585/1750 train_time:57943ms step_avg:99.05ms
step:586/1750 train_time:58043ms step_avg:99.05ms
step:587/1750 train_time:58143ms step_avg:99.05ms
step:588/1750 train_time:58243ms step_avg:99.05ms
step:589/1750 train_time:58343ms step_avg:99.05ms
step:590/1750 train_time:58444ms step_avg:99.06ms
step:591/1750 train_time:58545ms step_avg:99.06ms
step:592/1750 train_time:58645ms step_avg:99.06ms
step:593/1750 train_time:58746ms step_avg:99.07ms
step:594/1750 train_time:58845ms step_avg:99.07ms
step:595/1750 train_time:58945ms step_avg:99.07ms
step:596/1750 train_time:59045ms step_avg:99.07ms
step:597/1750 train_time:59145ms step_avg:99.07ms
step:598/1750 train_time:59245ms step_avg:99.07ms
step:599/1750 train_time:59346ms step_avg:99.08ms
step:600/1750 train_time:59448ms step_avg:99.08ms
step:601/1750 train_time:59548ms step_avg:99.08ms
step:602/1750 train_time:59648ms step_avg:99.08ms
step:603/1750 train_time:59749ms step_avg:99.09ms
step:604/1750 train_time:59850ms step_avg:99.09ms
step:605/1750 train_time:59949ms step_avg:99.09ms
step:606/1750 train_time:60049ms step_avg:99.09ms
step:607/1750 train_time:60150ms step_avg:99.09ms
step:608/1750 train_time:60250ms step_avg:99.10ms
step:609/1750 train_time:60350ms step_avg:99.10ms
step:610/1750 train_time:60450ms step_avg:99.10ms
step:611/1750 train_time:60551ms step_avg:99.10ms
step:612/1750 train_time:60651ms step_avg:99.10ms
step:613/1750 train_time:60752ms step_avg:99.11ms
step:614/1750 train_time:60852ms step_avg:99.11ms
step:615/1750 train_time:60953ms step_avg:99.11ms
step:616/1750 train_time:61052ms step_avg:99.11ms
step:617/1750 train_time:61153ms step_avg:99.11ms
step:618/1750 train_time:61253ms step_avg:99.11ms
step:619/1750 train_time:61354ms step_avg:99.12ms
step:620/1750 train_time:61454ms step_avg:99.12ms
step:621/1750 train_time:61555ms step_avg:99.12ms
step:622/1750 train_time:61655ms step_avg:99.12ms
step:623/1750 train_time:61755ms step_avg:99.13ms
step:624/1750 train_time:61855ms step_avg:99.13ms
step:625/1750 train_time:61956ms step_avg:99.13ms
step:625/1750 val_loss:3.6710 train_time:62051ms step_avg:99.28ms
step:626/1750 train_time:62071ms step_avg:99.15ms
step:627/1750 train_time:62166ms step_avg:99.15ms
step:628/1750 train_time:62269ms step_avg:99.15ms
step:629/1750 train_time:62369ms step_avg:99.16ms
step:630/1750 train_time:62470ms step_avg:99.16ms
step:631/1750 train_time:62570ms step_avg:99.16ms
step:632/1750 train_time:62670ms step_avg:99.16ms
step:633/1750 train_time:62770ms step_avg:99.16ms
step:634/1750 train_time:62870ms step_avg:99.16ms
step:635/1750 train_time:62970ms step_avg:99.17ms
step:636/1750 train_time:63071ms step_avg:99.17ms
step:637/1750 train_time:63175ms step_avg:99.18ms
step:638/1750 train_time:63275ms step_avg:99.18ms
step:639/1750 train_time:63375ms step_avg:99.18ms
step:640/1750 train_time:63476ms step_avg:99.18ms
step:641/1750 train_time:63576ms step_avg:99.18ms
step:642/1750 train_time:63676ms step_avg:99.18ms
step:643/1750 train_time:63776ms step_avg:99.19ms
step:644/1750 train_time:63878ms step_avg:99.19ms
step:645/1750 train_time:63978ms step_avg:99.19ms
step:646/1750 train_time:64078ms step_avg:99.19ms
step:647/1750 train_time:64178ms step_avg:99.19ms
step:648/1750 train_time:64278ms step_avg:99.19ms
step:649/1750 train_time:64377ms step_avg:99.19ms
step:650/1750 train_time:64477ms step_avg:99.20ms
step:651/1750 train_time:64579ms step_avg:99.20ms
step:652/1750 train_time:64681ms step_avg:99.20ms
step:653/1750 train_time:64782ms step_avg:99.21ms
step:654/1750 train_time:64884ms step_avg:99.21ms
step:655/1750 train_time:64986ms step_avg:99.22ms
step:656/1750 train_time:65089ms step_avg:99.22ms
step:657/1750 train_time:65192ms step_avg:99.23ms
step:658/1750 train_time:65293ms step_avg:99.23ms
step:659/1750 train_time:65395ms step_avg:99.23ms
step:660/1750 train_time:65497ms step_avg:99.24ms
step:661/1750 train_time:65598ms step_avg:99.24ms
step:662/1750 train_time:65700ms step_avg:99.24ms
step:663/1750 train_time:65801ms step_avg:99.25ms
step:664/1750 train_time:65904ms step_avg:99.25ms
step:665/1750 train_time:66004ms step_avg:99.25ms
step:666/1750 train_time:66106ms step_avg:99.26ms
step:667/1750 train_time:66208ms step_avg:99.26ms
step:668/1750 train_time:66310ms step_avg:99.27ms
step:669/1750 train_time:66413ms step_avg:99.27ms
step:670/1750 train_time:66517ms step_avg:99.28ms
step:671/1750 train_time:66618ms step_avg:99.28ms
step:672/1750 train_time:66719ms step_avg:99.28ms
step:673/1750 train_time:66822ms step_avg:99.29ms
step:674/1750 train_time:66923ms step_avg:99.29ms
step:675/1750 train_time:67025ms step_avg:99.30ms
step:676/1750 train_time:67126ms step_avg:99.30ms
step:677/1750 train_time:67227ms step_avg:99.30ms
step:678/1750 train_time:67329ms step_avg:99.31ms
step:679/1750 train_time:67431ms step_avg:99.31ms
step:680/1750 train_time:67533ms step_avg:99.31ms
step:681/1750 train_time:67635ms step_avg:99.32ms
step:682/1750 train_time:67737ms step_avg:99.32ms
step:683/1750 train_time:67839ms step_avg:99.33ms
step:684/1750 train_time:67940ms step_avg:99.33ms
step:685/1750 train_time:68042ms step_avg:99.33ms
step:686/1750 train_time:68143ms step_avg:99.33ms
step:687/1750 train_time:68245ms step_avg:99.34ms
step:688/1750 train_time:68347ms step_avg:99.34ms
step:689/1750 train_time:68449ms step_avg:99.35ms
step:690/1750 train_time:68551ms step_avg:99.35ms
step:691/1750 train_time:68653ms step_avg:99.35ms
step:692/1750 train_time:68755ms step_avg:99.36ms
step:693/1750 train_time:68857ms step_avg:99.36ms
step:694/1750 train_time:68959ms step_avg:99.37ms
step:695/1750 train_time:69061ms step_avg:99.37ms
step:696/1750 train_time:69163ms step_avg:99.37ms
step:697/1750 train_time:69263ms step_avg:99.37ms
step:698/1750 train_time:69365ms step_avg:99.38ms
step:699/1750 train_time:69467ms step_avg:99.38ms
step:700/1750 train_time:69569ms step_avg:99.38ms
step:701/1750 train_time:69672ms step_avg:99.39ms
step:702/1750 train_time:69773ms step_avg:99.39ms
step:703/1750 train_time:69876ms step_avg:99.40ms
step:704/1750 train_time:69977ms step_avg:99.40ms
step:705/1750 train_time:70079ms step_avg:99.40ms
step:706/1750 train_time:70183ms step_avg:99.41ms
step:707/1750 train_time:70283ms step_avg:99.41ms
step:708/1750 train_time:70386ms step_avg:99.42ms
step:709/1750 train_time:70488ms step_avg:99.42ms
step:710/1750 train_time:70590ms step_avg:99.42ms
step:711/1750 train_time:70691ms step_avg:99.42ms
step:712/1750 train_time:70793ms step_avg:99.43ms
step:713/1750 train_time:70894ms step_avg:99.43ms
step:714/1750 train_time:70997ms step_avg:99.44ms
step:715/1750 train_time:71098ms step_avg:99.44ms
step:716/1750 train_time:71199ms step_avg:99.44ms
step:717/1750 train_time:71303ms step_avg:99.45ms
step:718/1750 train_time:71404ms step_avg:99.45ms
step:719/1750 train_time:71505ms step_avg:99.45ms
step:720/1750 train_time:71607ms step_avg:99.45ms
step:721/1750 train_time:71708ms step_avg:99.46ms
step:722/1750 train_time:71811ms step_avg:99.46ms
step:723/1750 train_time:71913ms step_avg:99.46ms
step:724/1750 train_time:72015ms step_avg:99.47ms
step:725/1750 train_time:72117ms step_avg:99.47ms
step:726/1750 train_time:72219ms step_avg:99.48ms
step:727/1750 train_time:72321ms step_avg:99.48ms
step:728/1750 train_time:72422ms step_avg:99.48ms
step:729/1750 train_time:72524ms step_avg:99.48ms
step:730/1750 train_time:72627ms step_avg:99.49ms
step:731/1750 train_time:72728ms step_avg:99.49ms
step:732/1750 train_time:72829ms step_avg:99.49ms
step:733/1750 train_time:72931ms step_avg:99.50ms
step:734/1750 train_time:73033ms step_avg:99.50ms
step:735/1750 train_time:73136ms step_avg:99.50ms
step:736/1750 train_time:73238ms step_avg:99.51ms
step:737/1750 train_time:73339ms step_avg:99.51ms
step:738/1750 train_time:73441ms step_avg:99.51ms
step:739/1750 train_time:73542ms step_avg:99.52ms
step:740/1750 train_time:73644ms step_avg:99.52ms
step:741/1750 train_time:73745ms step_avg:99.52ms
step:742/1750 train_time:73847ms step_avg:99.52ms
step:743/1750 train_time:73949ms step_avg:99.53ms
step:744/1750 train_time:74052ms step_avg:99.53ms
step:745/1750 train_time:74154ms step_avg:99.53ms
step:746/1750 train_time:74256ms step_avg:99.54ms
step:747/1750 train_time:74357ms step_avg:99.54ms
step:748/1750 train_time:74458ms step_avg:99.54ms
step:749/1750 train_time:74559ms step_avg:99.55ms
step:750/1750 train_time:74660ms step_avg:99.55ms
step:750/1750 val_loss:3.6050 train_time:74756ms step_avg:99.67ms
step:751/1750 train_time:74778ms step_avg:99.57ms
step:752/1750 train_time:74871ms step_avg:99.56ms
step:753/1750 train_time:74974ms step_avg:99.57ms
step:754/1750 train_time:75076ms step_avg:99.57ms
step:755/1750 train_time:75177ms step_avg:99.57ms
step:756/1750 train_time:75279ms step_avg:99.58ms
step:757/1750 train_time:75381ms step_avg:99.58ms
step:758/1750 train_time:75482ms step_avg:99.58ms
step:759/1750 train_time:75583ms step_avg:99.58ms
step:760/1750 train_time:75685ms step_avg:99.59ms
step:761/1750 train_time:75788ms step_avg:99.59ms
step:762/1750 train_time:75891ms step_avg:99.59ms
step:763/1750 train_time:75995ms step_avg:99.60ms
step:764/1750 train_time:76095ms step_avg:99.60ms
step:765/1750 train_time:76197ms step_avg:99.60ms
step:766/1750 train_time:76298ms step_avg:99.61ms
step:767/1750 train_time:76400ms step_avg:99.61ms
step:768/1750 train_time:76501ms step_avg:99.61ms
step:769/1750 train_time:76604ms step_avg:99.61ms
step:770/1750 train_time:76705ms step_avg:99.62ms
step:771/1750 train_time:76808ms step_avg:99.62ms
step:772/1750 train_time:76910ms step_avg:99.62ms
step:773/1750 train_time:77012ms step_avg:99.63ms
step:774/1750 train_time:77114ms step_avg:99.63ms
step:775/1750 train_time:77215ms step_avg:99.63ms
step:776/1750 train_time:77316ms step_avg:99.63ms
step:777/1750 train_time:77417ms step_avg:99.64ms
step:778/1750 train_time:77518ms step_avg:99.64ms
step:779/1750 train_time:77620ms step_avg:99.64ms
step:780/1750 train_time:77724ms step_avg:99.65ms
step:781/1750 train_time:77826ms step_avg:99.65ms
step:782/1750 train_time:77928ms step_avg:99.65ms
step:783/1750 train_time:78031ms step_avg:99.66ms
step:784/1750 train_time:78133ms step_avg:99.66ms
step:785/1750 train_time:78234ms step_avg:99.66ms
step:786/1750 train_time:78335ms step_avg:99.66ms
step:787/1750 train_time:78437ms step_avg:99.67ms
step:788/1750 train_time:78539ms step_avg:99.67ms
step:789/1750 train_time:78640ms step_avg:99.67ms
step:790/1750 train_time:78743ms step_avg:99.67ms
step:791/1750 train_time:78845ms step_avg:99.68ms
step:792/1750 train_time:78948ms step_avg:99.68ms
step:793/1750 train_time:79050ms step_avg:99.69ms
step:794/1750 train_time:79153ms step_avg:99.69ms
step:795/1750 train_time:79254ms step_avg:99.69ms
step:796/1750 train_time:79356ms step_avg:99.69ms
step:797/1750 train_time:79459ms step_avg:99.70ms
step:798/1750 train_time:79560ms step_avg:99.70ms
step:799/1750 train_time:79662ms step_avg:99.70ms
step:800/1750 train_time:79764ms step_avg:99.70ms
step:801/1750 train_time:79866ms step_avg:99.71ms
step:802/1750 train_time:79968ms step_avg:99.71ms
step:803/1750 train_time:80071ms step_avg:99.71ms
step:804/1750 train_time:80173ms step_avg:99.72ms
step:805/1750 train_time:80274ms step_avg:99.72ms
step:806/1750 train_time:80376ms step_avg:99.72ms
step:807/1750 train_time:80478ms step_avg:99.73ms
step:808/1750 train_time:80580ms step_avg:99.73ms
step:809/1750 train_time:80682ms step_avg:99.73ms
step:810/1750 train_time:80784ms step_avg:99.73ms
step:811/1750 train_time:80886ms step_avg:99.74ms
step:812/1750 train_time:80988ms step_avg:99.74ms
step:813/1750 train_time:81090ms step_avg:99.74ms
step:814/1750 train_time:81192ms step_avg:99.74ms
step:815/1750 train_time:81294ms step_avg:99.75ms
step:816/1750 train_time:81396ms step_avg:99.75ms
step:817/1750 train_time:81497ms step_avg:99.75ms
step:818/1750 train_time:81599ms step_avg:99.75ms
step:819/1750 train_time:81701ms step_avg:99.76ms
step:820/1750 train_time:81803ms step_avg:99.76ms
step:821/1750 train_time:81905ms step_avg:99.76ms
step:822/1750 train_time:82007ms step_avg:99.77ms
step:823/1750 train_time:82109ms step_avg:99.77ms
step:824/1750 train_time:82211ms step_avg:99.77ms
step:825/1750 train_time:82313ms step_avg:99.77ms
step:826/1750 train_time:82415ms step_avg:99.78ms
step:827/1750 train_time:82517ms step_avg:99.78ms
step:828/1750 train_time:82619ms step_avg:99.78ms
step:829/1750 train_time:82719ms step_avg:99.78ms
step:830/1750 train_time:82821ms step_avg:99.78ms
step:831/1750 train_time:82924ms step_avg:99.79ms
step:832/1750 train_time:83027ms step_avg:99.79ms
step:833/1750 train_time:83129ms step_avg:99.79ms
step:834/1750 train_time:83231ms step_avg:99.80ms
step:835/1750 train_time:83333ms step_avg:99.80ms
step:836/1750 train_time:83434ms step_avg:99.80ms
step:837/1750 train_time:83536ms step_avg:99.80ms
step:838/1750 train_time:83638ms step_avg:99.81ms
step:839/1750 train_time:83740ms step_avg:99.81ms
step:840/1750 train_time:83841ms step_avg:99.81ms
step:841/1750 train_time:83944ms step_avg:99.81ms
step:842/1750 train_time:84046ms step_avg:99.82ms
step:843/1750 train_time:84149ms step_avg:99.82ms
step:844/1750 train_time:84250ms step_avg:99.82ms
step:845/1750 train_time:84352ms step_avg:99.83ms
step:846/1750 train_time:84454ms step_avg:99.83ms
step:847/1750 train_time:84556ms step_avg:99.83ms
step:848/1750 train_time:84658ms step_avg:99.83ms
step:849/1750 train_time:84760ms step_avg:99.83ms
step:850/1750 train_time:84862ms step_avg:99.84ms
step:851/1750 train_time:84964ms step_avg:99.84ms
step:852/1750 train_time:85066ms step_avg:99.84ms
step:853/1750 train_time:85169ms step_avg:99.85ms
step:854/1750 train_time:85270ms step_avg:99.85ms
step:855/1750 train_time:85372ms step_avg:99.85ms
step:856/1750 train_time:85473ms step_avg:99.85ms
step:857/1750 train_time:85575ms step_avg:99.85ms
step:858/1750 train_time:85677ms step_avg:99.86ms
step:859/1750 train_time:85779ms step_avg:99.86ms
step:860/1750 train_time:85880ms step_avg:99.86ms
step:861/1750 train_time:85982ms step_avg:99.86ms
step:862/1750 train_time:86085ms step_avg:99.87ms
step:863/1750 train_time:86187ms step_avg:99.87ms
step:864/1750 train_time:86290ms step_avg:99.87ms
step:865/1750 train_time:86392ms step_avg:99.87ms
step:866/1750 train_time:86494ms step_avg:99.88ms
step:867/1750 train_time:86595ms step_avg:99.88ms
step:868/1750 train_time:86697ms step_avg:99.88ms
step:869/1750 train_time:86798ms step_avg:99.88ms
step:870/1750 train_time:86899ms step_avg:99.88ms
step:871/1750 train_time:87001ms step_avg:99.89ms
step:872/1750 train_time:87104ms step_avg:99.89ms
step:873/1750 train_time:87206ms step_avg:99.89ms
step:874/1750 train_time:87309ms step_avg:99.90ms
step:875/1750 train_time:87411ms step_avg:99.90ms
step:875/1750 val_loss:3.5556 train_time:87507ms step_avg:100.01ms
step:876/1750 train_time:87529ms step_avg:99.92ms
step:877/1750 train_time:87623ms step_avg:99.91ms
step:878/1750 train_time:87727ms step_avg:99.92ms
step:879/1750 train_time:87829ms step_avg:99.92ms
step:880/1750 train_time:87931ms step_avg:99.92ms
step:881/1750 train_time:88033ms step_avg:99.92ms
step:882/1750 train_time:88135ms step_avg:99.93ms
step:883/1750 train_time:88237ms step_avg:99.93ms
step:884/1750 train_time:88339ms step_avg:99.93ms
step:885/1750 train_time:88440ms step_avg:99.93ms
step:886/1750 train_time:88542ms step_avg:99.93ms
step:887/1750 train_time:88645ms step_avg:99.94ms
step:888/1750 train_time:88748ms step_avg:99.94ms
step:889/1750 train_time:88850ms step_avg:99.94ms
step:890/1750 train_time:88952ms step_avg:99.95ms
step:891/1750 train_time:89054ms step_avg:99.95ms
step:892/1750 train_time:89156ms step_avg:99.95ms
step:893/1750 train_time:89259ms step_avg:99.95ms
step:894/1750 train_time:89361ms step_avg:99.96ms
step:895/1750 train_time:89463ms step_avg:99.96ms
step:896/1750 train_time:89565ms step_avg:99.96ms
step:897/1750 train_time:89667ms step_avg:99.96ms
step:898/1750 train_time:89769ms step_avg:99.97ms
step:899/1750 train_time:89871ms step_avg:99.97ms
step:900/1750 train_time:89973ms step_avg:99.97ms
step:901/1750 train_time:90076ms step_avg:99.97ms
step:902/1750 train_time:90179ms step_avg:99.98ms
step:903/1750 train_time:90280ms step_avg:99.98ms
step:904/1750 train_time:90382ms step_avg:99.98ms
step:905/1750 train_time:90484ms step_avg:99.98ms
step:906/1750 train_time:90586ms step_avg:99.98ms
step:907/1750 train_time:90687ms step_avg:99.99ms
step:908/1750 train_time:90789ms step_avg:99.99ms
step:909/1750 train_time:90892ms step_avg:99.99ms
step:910/1750 train_time:90995ms step_avg:99.99ms
step:911/1750 train_time:91099ms step_avg:100.00ms
step:912/1750 train_time:91202ms step_avg:100.00ms
step:913/1750 train_time:91305ms step_avg:100.01ms
step:914/1750 train_time:91409ms step_avg:100.01ms
step:915/1750 train_time:91512ms step_avg:100.01ms
step:916/1750 train_time:91618ms step_avg:100.02ms
step:917/1750 train_time:91720ms step_avg:100.02ms
step:918/1750 train_time:91823ms step_avg:100.03ms
step:919/1750 train_time:91926ms step_avg:100.03ms
step:920/1750 train_time:92031ms step_avg:100.03ms
step:921/1750 train_time:92135ms step_avg:100.04ms
step:922/1750 train_time:92239ms step_avg:100.04ms
step:923/1750 train_time:92342ms step_avg:100.05ms
step:924/1750 train_time:92445ms step_avg:100.05ms
step:925/1750 train_time:92549ms step_avg:100.05ms
step:926/1750 train_time:92652ms step_avg:100.06ms
step:927/1750 train_time:92755ms step_avg:100.06ms
step:928/1750 train_time:92858ms step_avg:100.06ms
step:929/1750 train_time:92962ms step_avg:100.07ms
step:930/1750 train_time:93066ms step_avg:100.07ms
step:931/1750 train_time:93169ms step_avg:100.07ms
step:932/1750 train_time:93273ms step_avg:100.08ms
step:933/1750 train_time:93377ms step_avg:100.08ms
step:934/1750 train_time:93480ms step_avg:100.09ms
step:935/1750 train_time:93583ms step_avg:100.09ms
step:936/1750 train_time:93688ms step_avg:100.09ms
step:937/1750 train_time:93791ms step_avg:100.10ms
step:938/1750 train_time:93894ms step_avg:100.10ms
step:939/1750 train_time:93997ms step_avg:100.10ms
step:940/1750 train_time:94100ms step_avg:100.11ms
step:941/1750 train_time:94203ms step_avg:100.11ms
step:942/1750 train_time:94308ms step_avg:100.11ms
step:943/1750 train_time:94412ms step_avg:100.12ms
step:944/1750 train_time:94514ms step_avg:100.12ms
step:945/1750 train_time:94618ms step_avg:100.12ms
step:946/1750 train_time:94722ms step_avg:100.13ms
step:947/1750 train_time:94826ms step_avg:100.13ms
step:948/1750 train_time:94930ms step_avg:100.14ms
step:949/1750 train_time:95033ms step_avg:100.14ms
step:950/1750 train_time:95136ms step_avg:100.14ms
step:951/1750 train_time:95239ms step_avg:100.15ms
step:952/1750 train_time:95341ms step_avg:100.15ms
step:953/1750 train_time:95445ms step_avg:100.15ms
step:954/1750 train_time:95549ms step_avg:100.16ms
step:955/1750 train_time:95652ms step_avg:100.16ms
step:956/1750 train_time:95755ms step_avg:100.16ms
step:957/1750 train_time:95858ms step_avg:100.16ms
step:958/1750 train_time:95961ms step_avg:100.17ms
step:959/1750 train_time:96064ms step_avg:100.17ms
step:960/1750 train_time:96168ms step_avg:100.18ms
step:961/1750 train_time:96271ms step_avg:100.18ms
step:962/1750 train_time:96375ms step_avg:100.18ms
step:963/1750 train_time:96477ms step_avg:100.18ms
step:964/1750 train_time:96581ms step_avg:100.19ms
step:965/1750 train_time:96684ms step_avg:100.19ms
step:966/1750 train_time:96788ms step_avg:100.19ms
step:967/1750 train_time:96891ms step_avg:100.20ms
step:968/1750 train_time:96995ms step_avg:100.20ms
step:969/1750 train_time:97098ms step_avg:100.20ms
step:970/1750 train_time:97202ms step_avg:100.21ms
step:971/1750 train_time:97306ms step_avg:100.21ms
step:972/1750 train_time:97409ms step_avg:100.21ms
step:973/1750 train_time:97513ms step_avg:100.22ms
step:974/1750 train_time:97616ms step_avg:100.22ms
step:975/1750 train_time:97720ms step_avg:100.23ms
step:976/1750 train_time:97823ms step_avg:100.23ms
step:977/1750 train_time:97927ms step_avg:100.23ms
step:978/1750 train_time:98031ms step_avg:100.24ms
step:979/1750 train_time:98135ms step_avg:100.24ms
step:980/1750 train_time:98238ms step_avg:100.24ms
step:981/1750 train_time:98342ms step_avg:100.25ms
step:982/1750 train_time:98445ms step_avg:100.25ms
step:983/1750 train_time:98550ms step_avg:100.25ms
step:984/1750 train_time:98652ms step_avg:100.26ms
step:985/1750 train_time:98755ms step_avg:100.26ms
step:986/1750 train_time:98859ms step_avg:100.26ms
step:987/1750 train_time:98962ms step_avg:100.27ms
step:988/1750 train_time:99066ms step_avg:100.27ms
step:989/1750 train_time:99171ms step_avg:100.27ms
step:990/1750 train_time:99274ms step_avg:100.28ms
step:991/1750 train_time:99376ms step_avg:100.28ms
step:992/1750 train_time:99479ms step_avg:100.28ms
step:993/1750 train_time:99583ms step_avg:100.29ms
step:994/1750 train_time:99689ms step_avg:100.29ms
step:995/1750 train_time:99792ms step_avg:100.29ms
step:996/1750 train_time:99894ms step_avg:100.30ms
step:997/1750 train_time:99997ms step_avg:100.30ms
step:998/1750 train_time:100100ms step_avg:100.30ms
step:999/1750 train_time:100205ms step_avg:100.30ms
step:1000/1750 train_time:100311ms step_avg:100.31ms
step:1000/1750 val_loss:3.5158 train_time:100408ms step_avg:100.41ms
step:1001/1750 train_time:100433ms step_avg:100.33ms
step:1002/1750 train_time:100527ms step_avg:100.33ms
step:1003/1750 train_time:100632ms step_avg:100.33ms
step:1004/1750 train_time:100735ms step_avg:100.33ms
step:1005/1750 train_time:100838ms step_avg:100.34ms
step:1006/1750 train_time:100941ms step_avg:100.34ms
step:1007/1750 train_time:101044ms step_avg:100.34ms
step:1008/1750 train_time:101146ms step_avg:100.34ms
step:1009/1750 train_time:101249ms step_avg:100.35ms
step:1010/1750 train_time:101352ms step_avg:100.35ms
step:1011/1750 train_time:101457ms step_avg:100.35ms
step:1012/1750 train_time:101561ms step_avg:100.36ms
step:1013/1750 train_time:101666ms step_avg:100.36ms
step:1014/1750 train_time:101768ms step_avg:100.36ms
step:1015/1750 train_time:101872ms step_avg:100.37ms
step:1016/1750 train_time:101976ms step_avg:100.37ms
step:1017/1750 train_time:102080ms step_avg:100.37ms
step:1018/1750 train_time:102183ms step_avg:100.38ms
step:1019/1750 train_time:102286ms step_avg:100.38ms
step:1020/1750 train_time:102389ms step_avg:100.38ms
step:1021/1750 train_time:102492ms step_avg:100.38ms
step:1022/1750 train_time:102597ms step_avg:100.39ms
step:1023/1750 train_time:102700ms step_avg:100.39ms
step:1024/1750 train_time:102803ms step_avg:100.39ms
step:1025/1750 train_time:102907ms step_avg:100.40ms
step:1026/1750 train_time:103012ms step_avg:100.40ms
step:1027/1750 train_time:103115ms step_avg:100.40ms
step:1028/1750 train_time:103217ms step_avg:100.41ms
step:1029/1750 train_time:103323ms step_avg:100.41ms
step:1030/1750 train_time:103424ms step_avg:100.41ms
step:1031/1750 train_time:103526ms step_avg:100.41ms
step:1032/1750 train_time:103629ms step_avg:100.42ms
step:1033/1750 train_time:103735ms step_avg:100.42ms
step:1034/1750 train_time:103839ms step_avg:100.42ms
step:1035/1750 train_time:103942ms step_avg:100.43ms
step:1036/1750 train_time:104044ms step_avg:100.43ms
step:1037/1750 train_time:104146ms step_avg:100.43ms
step:1038/1750 train_time:104250ms step_avg:100.43ms
step:1039/1750 train_time:104355ms step_avg:100.44ms
step:1040/1750 train_time:104458ms step_avg:100.44ms
step:1041/1750 train_time:104561ms step_avg:100.44ms
step:1042/1750 train_time:104665ms step_avg:100.45ms
step:1043/1750 train_time:104768ms step_avg:100.45ms
step:1044/1750 train_time:104873ms step_avg:100.45ms
step:1045/1750 train_time:104977ms step_avg:100.46ms
step:1046/1750 train_time:105080ms step_avg:100.46ms
step:1047/1750 train_time:105184ms step_avg:100.46ms
step:1048/1750 train_time:105288ms step_avg:100.47ms
step:1049/1750 train_time:105392ms step_avg:100.47ms
step:1050/1750 train_time:105496ms step_avg:100.47ms
step:1051/1750 train_time:105599ms step_avg:100.47ms
step:1052/1750 train_time:105702ms step_avg:100.48ms
step:1053/1750 train_time:105805ms step_avg:100.48ms
step:1054/1750 train_time:105907ms step_avg:100.48ms
step:1055/1750 train_time:106011ms step_avg:100.48ms
step:1056/1750 train_time:106115ms step_avg:100.49ms
step:1057/1750 train_time:106219ms step_avg:100.49ms
step:1058/1750 train_time:106322ms step_avg:100.49ms
step:1059/1750 train_time:106425ms step_avg:100.50ms
step:1060/1750 train_time:106529ms step_avg:100.50ms
step:1061/1750 train_time:106633ms step_avg:100.50ms
step:1062/1750 train_time:106737ms step_avg:100.51ms
step:1063/1750 train_time:106844ms step_avg:100.51ms
step:1064/1750 train_time:106947ms step_avg:100.51ms
step:1065/1750 train_time:107050ms step_avg:100.52ms
step:1066/1750 train_time:107154ms step_avg:100.52ms
step:1067/1750 train_time:107258ms step_avg:100.52ms
step:1068/1750 train_time:107363ms step_avg:100.53ms
step:1069/1750 train_time:107466ms step_avg:100.53ms
step:1070/1750 train_time:107569ms step_avg:100.53ms
step:1071/1750 train_time:107673ms step_avg:100.54ms
step:1072/1750 train_time:107777ms step_avg:100.54ms
step:1073/1750 train_time:107880ms step_avg:100.54ms
step:1074/1750 train_time:107982ms step_avg:100.54ms
step:1075/1750 train_time:108086ms step_avg:100.54ms
step:1076/1750 train_time:108190ms step_avg:100.55ms
step:1077/1750 train_time:108294ms step_avg:100.55ms
step:1078/1750 train_time:108397ms step_avg:100.55ms
step:1079/1750 train_time:108500ms step_avg:100.56ms
step:1080/1750 train_time:108603ms step_avg:100.56ms
step:1081/1750 train_time:108706ms step_avg:100.56ms
step:1082/1750 train_time:108810ms step_avg:100.56ms
step:1083/1750 train_time:108915ms step_avg:100.57ms
step:1084/1750 train_time:109019ms step_avg:100.57ms
step:1085/1750 train_time:109122ms step_avg:100.57ms
step:1086/1750 train_time:109225ms step_avg:100.58ms
step:1087/1750 train_time:109328ms step_avg:100.58ms
step:1088/1750 train_time:109432ms step_avg:100.58ms
step:1089/1750 train_time:109536ms step_avg:100.58ms
step:1090/1750 train_time:109640ms step_avg:100.59ms
step:1091/1750 train_time:109743ms step_avg:100.59ms
step:1092/1750 train_time:109846ms step_avg:100.59ms
step:1093/1750 train_time:109951ms step_avg:100.60ms
step:1094/1750 train_time:110055ms step_avg:100.60ms
step:1095/1750 train_time:110158ms step_avg:100.60ms
step:1096/1750 train_time:110262ms step_avg:100.60ms
step:1097/1750 train_time:110364ms step_avg:100.61ms
step:1098/1750 train_time:110467ms step_avg:100.61ms
step:1099/1750 train_time:110570ms step_avg:100.61ms
step:1100/1750 train_time:110675ms step_avg:100.61ms
step:1101/1750 train_time:110779ms step_avg:100.62ms
step:1102/1750 train_time:110882ms step_avg:100.62ms
step:1103/1750 train_time:110985ms step_avg:100.62ms
step:1104/1750 train_time:111089ms step_avg:100.62ms
step:1105/1750 train_time:111192ms step_avg:100.63ms
step:1106/1750 train_time:111296ms step_avg:100.63ms
step:1107/1750 train_time:111400ms step_avg:100.63ms
step:1108/1750 train_time:111503ms step_avg:100.63ms
step:1109/1750 train_time:111607ms step_avg:100.64ms
step:1110/1750 train_time:111711ms step_avg:100.64ms
step:1111/1750 train_time:111816ms step_avg:100.64ms
step:1112/1750 train_time:111920ms step_avg:100.65ms
step:1113/1750 train_time:112023ms step_avg:100.65ms
step:1114/1750 train_time:112126ms step_avg:100.65ms
step:1115/1750 train_time:112230ms step_avg:100.65ms
step:1116/1750 train_time:112334ms step_avg:100.66ms
step:1117/1750 train_time:112439ms step_avg:100.66ms
step:1118/1750 train_time:112541ms step_avg:100.66ms
step:1119/1750 train_time:112645ms step_avg:100.67ms
step:1120/1750 train_time:112747ms step_avg:100.67ms
step:1121/1750 train_time:112850ms step_avg:100.67ms
step:1122/1750 train_time:112955ms step_avg:100.67ms
step:1123/1750 train_time:113058ms step_avg:100.68ms
step:1124/1750 train_time:113162ms step_avg:100.68ms
step:1125/1750 train_time:113265ms step_avg:100.68ms
step:1125/1750 val_loss:3.4738 train_time:113362ms step_avg:100.77ms
step:1126/1750 train_time:113387ms step_avg:100.70ms
step:1127/1750 train_time:113481ms step_avg:100.69ms
step:1128/1750 train_time:113584ms step_avg:100.70ms
step:1129/1750 train_time:113688ms step_avg:100.70ms
step:1130/1750 train_time:113791ms step_avg:100.70ms
step:1131/1750 train_time:113894ms step_avg:100.70ms
step:1132/1750 train_time:113999ms step_avg:100.71ms
step:1133/1750 train_time:114101ms step_avg:100.71ms
step:1134/1750 train_time:114204ms step_avg:100.71ms
step:1135/1750 train_time:114308ms step_avg:100.71ms
step:1136/1750 train_time:114411ms step_avg:100.71ms
step:1137/1750 train_time:114516ms step_avg:100.72ms
step:1138/1750 train_time:114620ms step_avg:100.72ms
step:1139/1750 train_time:114725ms step_avg:100.72ms
step:1140/1750 train_time:114828ms step_avg:100.73ms
step:1141/1750 train_time:114931ms step_avg:100.73ms
step:1142/1750 train_time:115035ms step_avg:100.73ms
step:1143/1750 train_time:115139ms step_avg:100.73ms
step:1144/1750 train_time:115243ms step_avg:100.74ms
step:1145/1750 train_time:115346ms step_avg:100.74ms
step:1146/1750 train_time:115450ms step_avg:100.74ms
step:1147/1750 train_time:115553ms step_avg:100.74ms
step:1148/1750 train_time:115657ms step_avg:100.75ms
step:1149/1750 train_time:115761ms step_avg:100.75ms
step:1150/1750 train_time:115865ms step_avg:100.75ms
step:1151/1750 train_time:115968ms step_avg:100.75ms
step:1152/1750 train_time:116071ms step_avg:100.76ms
step:1153/1750 train_time:116175ms step_avg:100.76ms
step:1154/1750 train_time:116279ms step_avg:100.76ms
step:1155/1750 train_time:116383ms step_avg:100.76ms
step:1156/1750 train_time:116486ms step_avg:100.77ms
step:1157/1750 train_time:116590ms step_avg:100.77ms
step:1158/1750 train_time:116693ms step_avg:100.77ms
step:1159/1750 train_time:116797ms step_avg:100.77ms
step:1160/1750 train_time:116903ms step_avg:100.78ms
step:1161/1750 train_time:117005ms step_avg:100.78ms
step:1162/1750 train_time:117108ms step_avg:100.78ms
step:1163/1750 train_time:117212ms step_avg:100.78ms
step:1164/1750 train_time:117316ms step_avg:100.79ms
step:1165/1750 train_time:117421ms step_avg:100.79ms
step:1166/1750 train_time:117524ms step_avg:100.79ms
step:1167/1750 train_time:117627ms step_avg:100.79ms
step:1168/1750 train_time:117732ms step_avg:100.80ms
step:1169/1750 train_time:117836ms step_avg:100.80ms
step:1170/1750 train_time:117941ms step_avg:100.80ms
step:1171/1750 train_time:118047ms step_avg:100.81ms
step:1172/1750 train_time:118151ms step_avg:100.81ms
step:1173/1750 train_time:118255ms step_avg:100.81ms
step:1174/1750 train_time:118361ms step_avg:100.82ms
step:1175/1750 train_time:118465ms step_avg:100.82ms
step:1176/1750 train_time:118569ms step_avg:100.82ms
step:1177/1750 train_time:118673ms step_avg:100.83ms
step:1178/1750 train_time:118778ms step_avg:100.83ms
step:1179/1750 train_time:118883ms step_avg:100.83ms
step:1180/1750 train_time:118988ms step_avg:100.84ms
step:1181/1750 train_time:119092ms step_avg:100.84ms
step:1182/1750 train_time:119197ms step_avg:100.84ms
step:1183/1750 train_time:119303ms step_avg:100.85ms
step:1184/1750 train_time:119408ms step_avg:100.85ms
step:1185/1750 train_time:119512ms step_avg:100.85ms
step:1186/1750 train_time:119619ms step_avg:100.86ms
step:1187/1750 train_time:119725ms step_avg:100.86ms
step:1188/1750 train_time:119829ms step_avg:100.87ms
step:1189/1750 train_time:119933ms step_avg:100.87ms
step:1190/1750 train_time:120040ms step_avg:100.87ms
step:1191/1750 train_time:120143ms step_avg:100.88ms
step:1192/1750 train_time:120248ms step_avg:100.88ms
step:1193/1750 train_time:120352ms step_avg:100.88ms
step:1194/1750 train_time:120458ms step_avg:100.89ms
step:1195/1750 train_time:120562ms step_avg:100.89ms
step:1196/1750 train_time:120667ms step_avg:100.89ms
step:1197/1750 train_time:120770ms step_avg:100.89ms
step:1198/1750 train_time:120875ms step_avg:100.90ms
step:1199/1750 train_time:120980ms step_avg:100.90ms
step:1200/1750 train_time:121084ms step_avg:100.90ms
step:1201/1750 train_time:121190ms step_avg:100.91ms
step:1202/1750 train_time:121293ms step_avg:100.91ms
step:1203/1750 train_time:121397ms step_avg:100.91ms
step:1204/1750 train_time:121502ms step_avg:100.92ms
step:1205/1750 train_time:121607ms step_avg:100.92ms
step:1206/1750 train_time:121712ms step_avg:100.92ms
step:1207/1750 train_time:121817ms step_avg:100.93ms
step:1208/1750 train_time:121921ms step_avg:100.93ms
step:1209/1750 train_time:122026ms step_avg:100.93ms
step:1210/1750 train_time:122130ms step_avg:100.93ms
step:1211/1750 train_time:122234ms step_avg:100.94ms
step:1212/1750 train_time:122342ms step_avg:100.94ms
step:1213/1750 train_time:122446ms step_avg:100.94ms
step:1214/1750 train_time:122550ms step_avg:100.95ms
step:1215/1750 train_time:122654ms step_avg:100.95ms
step:1216/1750 train_time:122760ms step_avg:100.95ms
step:1217/1750 train_time:122864ms step_avg:100.96ms
step:1218/1750 train_time:122969ms step_avg:100.96ms
step:1219/1750 train_time:123074ms step_avg:100.96ms
step:1220/1750 train_time:123180ms step_avg:100.97ms
step:1221/1750 train_time:123284ms step_avg:100.97ms
step:1222/1750 train_time:123390ms step_avg:100.97ms
step:1223/1750 train_time:123494ms step_avg:100.98ms
step:1224/1750 train_time:123600ms step_avg:100.98ms
step:1225/1750 train_time:123705ms step_avg:100.98ms
step:1226/1750 train_time:123809ms step_avg:100.99ms
step:1227/1750 train_time:123915ms step_avg:100.99ms
step:1228/1750 train_time:124022ms step_avg:101.00ms
step:1229/1750 train_time:124126ms step_avg:101.00ms
step:1230/1750 train_time:124231ms step_avg:101.00ms
step:1231/1750 train_time:124335ms step_avg:101.00ms
step:1232/1750 train_time:124439ms step_avg:101.01ms
step:1233/1750 train_time:124543ms step_avg:101.01ms
step:1234/1750 train_time:124647ms step_avg:101.01ms
step:1235/1750 train_time:124751ms step_avg:101.01ms
step:1236/1750 train_time:124858ms step_avg:101.02ms
step:1237/1750 train_time:124961ms step_avg:101.02ms
step:1238/1750 train_time:125066ms step_avg:101.02ms
step:1239/1750 train_time:125171ms step_avg:101.03ms
step:1240/1750 train_time:125276ms step_avg:101.03ms
step:1241/1750 train_time:125382ms step_avg:101.03ms
step:1242/1750 train_time:125486ms step_avg:101.04ms
step:1243/1750 train_time:125591ms step_avg:101.04ms
step:1244/1750 train_time:125696ms step_avg:101.04ms
step:1245/1750 train_time:125800ms step_avg:101.04ms
step:1246/1750 train_time:125906ms step_avg:101.05ms
step:1247/1750 train_time:126010ms step_avg:101.05ms
step:1248/1750 train_time:126115ms step_avg:101.05ms
step:1249/1750 train_time:126219ms step_avg:101.06ms
step:1250/1750 train_time:126325ms step_avg:101.06ms
step:1250/1750 val_loss:3.4250 train_time:126425ms step_avg:101.14ms
step:1251/1750 train_time:126445ms step_avg:101.08ms
step:1252/1750 train_time:126545ms step_avg:101.07ms
step:1253/1750 train_time:126649ms step_avg:101.08ms
step:1254/1750 train_time:126753ms step_avg:101.08ms
step:1255/1750 train_time:126860ms step_avg:101.08ms
step:1256/1750 train_time:126964ms step_avg:101.09ms
step:1257/1750 train_time:127069ms step_avg:101.09ms
step:1258/1750 train_time:127174ms step_avg:101.09ms
step:1259/1750 train_time:127279ms step_avg:101.10ms
step:1260/1750 train_time:127382ms step_avg:101.10ms
step:1261/1750 train_time:127490ms step_avg:101.10ms
step:1262/1750 train_time:127595ms step_avg:101.11ms
step:1263/1750 train_time:127698ms step_avg:101.11ms
step:1264/1750 train_time:127803ms step_avg:101.11ms
step:1265/1750 train_time:127908ms step_avg:101.11ms
step:1266/1750 train_time:128013ms step_avg:101.12ms
step:1267/1750 train_time:128119ms step_avg:101.12ms
step:1268/1750 train_time:128223ms step_avg:101.12ms
step:1269/1750 train_time:128327ms step_avg:101.12ms
step:1270/1750 train_time:128432ms step_avg:101.13ms
step:1271/1750 train_time:128538ms step_avg:101.13ms
step:1272/1750 train_time:128641ms step_avg:101.13ms
step:1273/1750 train_time:128749ms step_avg:101.14ms
step:1274/1750 train_time:128853ms step_avg:101.14ms
step:1275/1750 train_time:128957ms step_avg:101.14ms
step:1276/1750 train_time:129061ms step_avg:101.14ms
step:1277/1750 train_time:129166ms step_avg:101.15ms
step:1278/1750 train_time:129270ms step_avg:101.15ms
step:1279/1750 train_time:129375ms step_avg:101.15ms
step:1280/1750 train_time:129480ms step_avg:101.16ms
step:1281/1750 train_time:129585ms step_avg:101.16ms
step:1282/1750 train_time:129690ms step_avg:101.16ms
step:1283/1750 train_time:129794ms step_avg:101.16ms
step:1284/1750 train_time:129898ms step_avg:101.17ms
step:1285/1750 train_time:130004ms step_avg:101.17ms
step:1286/1750 train_time:130111ms step_avg:101.17ms
step:1287/1750 train_time:130216ms step_avg:101.18ms
step:1288/1750 train_time:130320ms step_avg:101.18ms
step:1289/1750 train_time:130425ms step_avg:101.18ms
step:1290/1750 train_time:130529ms step_avg:101.19ms
step:1291/1750 train_time:130634ms step_avg:101.19ms
step:1292/1750 train_time:130738ms step_avg:101.19ms
step:1293/1750 train_time:130842ms step_avg:101.19ms
step:1294/1750 train_time:130947ms step_avg:101.20ms
step:1295/1750 train_time:131053ms step_avg:101.20ms
step:1296/1750 train_time:131157ms step_avg:101.20ms
step:1297/1750 train_time:131262ms step_avg:101.20ms
step:1298/1750 train_time:131367ms step_avg:101.21ms
step:1299/1750 train_time:131472ms step_avg:101.21ms
step:1300/1750 train_time:131576ms step_avg:101.21ms
step:1301/1750 train_time:131682ms step_avg:101.22ms
step:1302/1750 train_time:131787ms step_avg:101.22ms
step:1303/1750 train_time:131892ms step_avg:101.22ms
step:1304/1750 train_time:131996ms step_avg:101.22ms
step:1305/1750 train_time:132100ms step_avg:101.23ms
step:1306/1750 train_time:132204ms step_avg:101.23ms
step:1307/1750 train_time:132309ms step_avg:101.23ms
step:1308/1750 train_time:132414ms step_avg:101.23ms
step:1309/1750 train_time:132518ms step_avg:101.24ms
step:1310/1750 train_time:132623ms step_avg:101.24ms
step:1311/1750 train_time:132728ms step_avg:101.24ms
step:1312/1750 train_time:132832ms step_avg:101.24ms
step:1313/1750 train_time:132937ms step_avg:101.25ms
step:1314/1750 train_time:133041ms step_avg:101.25ms
step:1315/1750 train_time:133146ms step_avg:101.25ms
step:1316/1750 train_time:133251ms step_avg:101.25ms
step:1317/1750 train_time:133356ms step_avg:101.26ms
step:1318/1750 train_time:133465ms step_avg:101.26ms
step:1319/1750 train_time:133569ms step_avg:101.27ms
step:1320/1750 train_time:133673ms step_avg:101.27ms
step:1321/1750 train_time:133777ms step_avg:101.27ms
step:1322/1750 train_time:133881ms step_avg:101.27ms
step:1323/1750 train_time:133986ms step_avg:101.27ms
step:1324/1750 train_time:134090ms step_avg:101.28ms
step:1325/1750 train_time:134197ms step_avg:101.28ms
step:1326/1750 train_time:134301ms step_avg:101.28ms
step:1327/1750 train_time:134409ms step_avg:101.29ms
step:1328/1750 train_time:134513ms step_avg:101.29ms
step:1329/1750 train_time:134618ms step_avg:101.29ms
step:1330/1750 train_time:134722ms step_avg:101.29ms
step:1331/1750 train_time:134826ms step_avg:101.30ms
step:1332/1750 train_time:134931ms step_avg:101.30ms
step:1333/1750 train_time:135034ms step_avg:101.30ms
step:1334/1750 train_time:135138ms step_avg:101.30ms
step:1335/1750 train_time:135243ms step_avg:101.31ms
step:1336/1750 train_time:135348ms step_avg:101.31ms
step:1337/1750 train_time:135453ms step_avg:101.31ms
step:1338/1750 train_time:135558ms step_avg:101.31ms
step:1339/1750 train_time:135663ms step_avg:101.32ms
step:1340/1750 train_time:135769ms step_avg:101.32ms
step:1341/1750 train_time:135873ms step_avg:101.32ms
step:1342/1750 train_time:135979ms step_avg:101.33ms
step:1343/1750 train_time:136084ms step_avg:101.33ms
step:1344/1750 train_time:136189ms step_avg:101.33ms
step:1345/1750 train_time:136294ms step_avg:101.33ms
step:1346/1750 train_time:136398ms step_avg:101.34ms
step:1347/1750 train_time:136503ms step_avg:101.34ms
step:1348/1750 train_time:136610ms step_avg:101.34ms
step:1349/1750 train_time:136714ms step_avg:101.34ms
step:1350/1750 train_time:136818ms step_avg:101.35ms
step:1351/1750 train_time:136923ms step_avg:101.35ms
step:1352/1750 train_time:137027ms step_avg:101.35ms
step:1353/1750 train_time:137134ms step_avg:101.36ms
step:1354/1750 train_time:137237ms step_avg:101.36ms
step:1355/1750 train_time:137342ms step_avg:101.36ms
step:1356/1750 train_time:137446ms step_avg:101.36ms
step:1357/1750 train_time:137552ms step_avg:101.36ms
step:1358/1750 train_time:137657ms step_avg:101.37ms
step:1359/1750 train_time:137761ms step_avg:101.37ms
step:1360/1750 train_time:137867ms step_avg:101.37ms
step:1361/1750 train_time:137972ms step_avg:101.38ms
step:1362/1750 train_time:138077ms step_avg:101.38ms
step:1363/1750 train_time:138182ms step_avg:101.38ms
step:1364/1750 train_time:138287ms step_avg:101.38ms
step:1365/1750 train_time:138390ms step_avg:101.38ms
step:1366/1750 train_time:138495ms step_avg:101.39ms
step:1367/1750 train_time:138600ms step_avg:101.39ms
step:1368/1750 train_time:138704ms step_avg:101.39ms
step:1369/1750 train_time:138811ms step_avg:101.40ms
step:1370/1750 train_time:138916ms step_avg:101.40ms
step:1371/1750 train_time:139020ms step_avg:101.40ms
step:1372/1750 train_time:139124ms step_avg:101.40ms
step:1373/1750 train_time:139229ms step_avg:101.40ms
step:1374/1750 train_time:139335ms step_avg:101.41ms
step:1375/1750 train_time:139440ms step_avg:101.41ms
step:1375/1750 val_loss:3.3810 train_time:139541ms step_avg:101.48ms
step:1376/1750 train_time:139563ms step_avg:101.43ms
step:1377/1750 train_time:139657ms step_avg:101.42ms
step:1378/1750 train_time:139763ms step_avg:101.42ms
step:1379/1750 train_time:139867ms step_avg:101.43ms
step:1380/1750 train_time:139972ms step_avg:101.43ms
step:1381/1750 train_time:140077ms step_avg:101.43ms
step:1382/1750 train_time:140182ms step_avg:101.43ms
step:1383/1750 train_time:140287ms step_avg:101.44ms
step:1384/1750 train_time:140392ms step_avg:101.44ms
step:1385/1750 train_time:140497ms step_avg:101.44ms
step:1386/1750 train_time:140603ms step_avg:101.44ms
step:1387/1750 train_time:140708ms step_avg:101.45ms
step:1388/1750 train_time:140813ms step_avg:101.45ms
step:1389/1750 train_time:140918ms step_avg:101.45ms
step:1390/1750 train_time:141023ms step_avg:101.46ms
step:1391/1750 train_time:141127ms step_avg:101.46ms
step:1392/1750 train_time:141232ms step_avg:101.46ms
step:1393/1750 train_time:141336ms step_avg:101.46ms
step:1394/1750 train_time:141441ms step_avg:101.46ms
step:1395/1750 train_time:141546ms step_avg:101.47ms
step:1396/1750 train_time:141652ms step_avg:101.47ms
step:1397/1750 train_time:141757ms step_avg:101.47ms
step:1398/1750 train_time:141862ms step_avg:101.48ms
step:1399/1750 train_time:141966ms step_avg:101.48ms
step:1400/1750 train_time:142071ms step_avg:101.48ms
step:1401/1750 train_time:142175ms step_avg:101.48ms
step:1402/1750 train_time:142281ms step_avg:101.48ms
step:1403/1750 train_time:142386ms step_avg:101.49ms
step:1404/1750 train_time:142492ms step_avg:101.49ms
step:1405/1750 train_time:142596ms step_avg:101.49ms
step:1406/1750 train_time:142701ms step_avg:101.49ms
step:1407/1750 train_time:142805ms step_avg:101.50ms
step:1408/1750 train_time:142910ms step_avg:101.50ms
step:1409/1750 train_time:143014ms step_avg:101.50ms
step:1410/1750 train_time:143120ms step_avg:101.50ms
step:1411/1750 train_time:143224ms step_avg:101.51ms
step:1412/1750 train_time:143328ms step_avg:101.51ms
step:1413/1750 train_time:143434ms step_avg:101.51ms
step:1414/1750 train_time:143539ms step_avg:101.51ms
step:1415/1750 train_time:143644ms step_avg:101.52ms
step:1416/1750 train_time:143749ms step_avg:101.52ms
step:1417/1750 train_time:143854ms step_avg:101.52ms
step:1418/1750 train_time:143958ms step_avg:101.52ms
step:1419/1750 train_time:144063ms step_avg:101.52ms
step:1420/1750 train_time:144167ms step_avg:101.53ms
step:1421/1750 train_time:144270ms step_avg:101.53ms
step:1422/1750 train_time:144375ms step_avg:101.53ms
step:1423/1750 train_time:144481ms step_avg:101.53ms
step:1424/1750 train_time:144587ms step_avg:101.54ms
step:1425/1750 train_time:144690ms step_avg:101.54ms
step:1426/1750 train_time:144795ms step_avg:101.54ms
step:1427/1750 train_time:144899ms step_avg:101.54ms
step:1428/1750 train_time:145008ms step_avg:101.55ms
step:1429/1750 train_time:145113ms step_avg:101.55ms
step:1430/1750 train_time:145218ms step_avg:101.55ms
step:1431/1750 train_time:145326ms step_avg:101.56ms
step:1432/1750 train_time:145432ms step_avg:101.56ms
step:1433/1750 train_time:145537ms step_avg:101.56ms
step:1434/1750 train_time:145642ms step_avg:101.56ms
step:1435/1750 train_time:145749ms step_avg:101.57ms
step:1436/1750 train_time:145858ms step_avg:101.57ms
step:1437/1750 train_time:145963ms step_avg:101.58ms
step:1438/1750 train_time:146069ms step_avg:101.58ms
step:1439/1750 train_time:146174ms step_avg:101.58ms
step:1440/1750 train_time:146279ms step_avg:101.58ms
step:1441/1750 train_time:146389ms step_avg:101.59ms
step:1442/1750 train_time:146494ms step_avg:101.59ms
step:1443/1750 train_time:146599ms step_avg:101.59ms
step:1444/1750 train_time:146706ms step_avg:101.60ms
step:1445/1750 train_time:146811ms step_avg:101.60ms
step:1446/1750 train_time:146917ms step_avg:101.60ms
step:1447/1750 train_time:147023ms step_avg:101.61ms
step:1448/1750 train_time:147129ms step_avg:101.61ms
step:1449/1750 train_time:147236ms step_avg:101.61ms
step:1450/1750 train_time:147342ms step_avg:101.62ms
step:1451/1750 train_time:147450ms step_avg:101.62ms
step:1452/1750 train_time:147555ms step_avg:101.62ms
step:1453/1750 train_time:147661ms step_avg:101.62ms
step:1454/1750 train_time:147767ms step_avg:101.63ms
step:1455/1750 train_time:147875ms step_avg:101.63ms
step:1456/1750 train_time:147982ms step_avg:101.64ms
step:1457/1750 train_time:148089ms step_avg:101.64ms
step:1458/1750 train_time:148194ms step_avg:101.64ms
step:1459/1750 train_time:148300ms step_avg:101.64ms
step:1460/1750 train_time:148407ms step_avg:101.65ms
step:1461/1750 train_time:148513ms step_avg:101.65ms
step:1462/1750 train_time:148618ms step_avg:101.65ms
step:1463/1750 train_time:148725ms step_avg:101.66ms
step:1464/1750 train_time:148832ms step_avg:101.66ms
step:1465/1750 train_time:148937ms step_avg:101.66ms
step:1466/1750 train_time:149044ms step_avg:101.67ms
step:1467/1750 train_time:149151ms step_avg:101.67ms
step:1468/1750 train_time:149258ms step_avg:101.67ms
step:1469/1750 train_time:149364ms step_avg:101.68ms
step:1470/1750 train_time:149469ms step_avg:101.68ms
step:1471/1750 train_time:149575ms step_avg:101.68ms
step:1472/1750 train_time:149682ms step_avg:101.69ms
step:1473/1750 train_time:149790ms step_avg:101.69ms
step:1474/1750 train_time:149898ms step_avg:101.69ms
step:1475/1750 train_time:150005ms step_avg:101.70ms
step:1476/1750 train_time:150111ms step_avg:101.70ms
step:1477/1750 train_time:150218ms step_avg:101.70ms
step:1478/1750 train_time:150326ms step_avg:101.71ms
step:1479/1750 train_time:150432ms step_avg:101.71ms
step:1480/1750 train_time:150536ms step_avg:101.71ms
step:1481/1750 train_time:150645ms step_avg:101.72ms
step:1482/1750 train_time:150750ms step_avg:101.72ms
step:1483/1750 train_time:150856ms step_avg:101.72ms
step:1484/1750 train_time:150962ms step_avg:101.73ms
step:1485/1750 train_time:151068ms step_avg:101.73ms
step:1486/1750 train_time:151175ms step_avg:101.73ms
step:1487/1750 train_time:151279ms step_avg:101.73ms
step:1488/1750 train_time:151386ms step_avg:101.74ms
step:1489/1750 train_time:151493ms step_avg:101.74ms
step:1490/1750 train_time:151599ms step_avg:101.74ms
step:1491/1750 train_time:151704ms step_avg:101.75ms
step:1492/1750 train_time:151811ms step_avg:101.75ms
step:1493/1750 train_time:151920ms step_avg:101.75ms
step:1494/1750 train_time:152029ms step_avg:101.76ms
step:1495/1750 train_time:152134ms step_avg:101.76ms
step:1496/1750 train_time:152239ms step_avg:101.76ms
step:1497/1750 train_time:152346ms step_avg:101.77ms
step:1498/1750 train_time:152451ms step_avg:101.77ms
step:1499/1750 train_time:152556ms step_avg:101.77ms
step:1500/1750 train_time:152661ms step_avg:101.77ms
step:1500/1750 val_loss:3.3438 train_time:152762ms step_avg:101.84ms
step:1501/1750 train_time:152782ms step_avg:101.79ms
step:1502/1750 train_time:152880ms step_avg:101.78ms
step:1503/1750 train_time:152985ms step_avg:101.79ms
step:1504/1750 train_time:153091ms step_avg:101.79ms
step:1505/1750 train_time:153198ms step_avg:101.79ms
step:1506/1750 train_time:153305ms step_avg:101.80ms
step:1507/1750 train_time:153411ms step_avg:101.80ms
step:1508/1750 train_time:153518ms step_avg:101.80ms
step:1509/1750 train_time:153623ms step_avg:101.80ms
step:1510/1750 train_time:153728ms step_avg:101.81ms
step:1511/1750 train_time:153835ms step_avg:101.81ms
step:1512/1750 train_time:153941ms step_avg:101.81ms
step:1513/1750 train_time:154047ms step_avg:101.82ms
step:1514/1750 train_time:154152ms step_avg:101.82ms
step:1515/1750 train_time:154258ms step_avg:101.82ms
step:1516/1750 train_time:154364ms step_avg:101.82ms
step:1517/1750 train_time:154472ms step_avg:101.83ms
step:1518/1750 train_time:154580ms step_avg:101.83ms
step:1519/1750 train_time:154685ms step_avg:101.83ms
step:1520/1750 train_time:154791ms step_avg:101.84ms
step:1521/1750 train_time:154897ms step_avg:101.84ms
step:1522/1750 train_time:155003ms step_avg:101.84ms
step:1523/1750 train_time:155110ms step_avg:101.85ms
step:1524/1750 train_time:155216ms step_avg:101.85ms
step:1525/1750 train_time:155321ms step_avg:101.85ms
step:1526/1750 train_time:155427ms step_avg:101.85ms
step:1527/1750 train_time:155532ms step_avg:101.85ms
step:1528/1750 train_time:155639ms step_avg:101.86ms
step:1529/1750 train_time:155745ms step_avg:101.86ms
step:1530/1750 train_time:155851ms step_avg:101.86ms
step:1531/1750 train_time:155957ms step_avg:101.87ms
step:1532/1750 train_time:156063ms step_avg:101.87ms
step:1533/1750 train_time:156169ms step_avg:101.87ms
step:1534/1750 train_time:156275ms step_avg:101.87ms
step:1535/1750 train_time:156380ms step_avg:101.88ms
step:1536/1750 train_time:156486ms step_avg:101.88ms
step:1537/1750 train_time:156595ms step_avg:101.88ms
step:1538/1750 train_time:156702ms step_avg:101.89ms
step:1539/1750 train_time:156808ms step_avg:101.89ms
step:1540/1750 train_time:156915ms step_avg:101.89ms
step:1541/1750 train_time:157023ms step_avg:101.90ms
step:1542/1750 train_time:157129ms step_avg:101.90ms
step:1543/1750 train_time:157234ms step_avg:101.90ms
step:1544/1750 train_time:157342ms step_avg:101.91ms
step:1545/1750 train_time:157448ms step_avg:101.91ms
step:1546/1750 train_time:157554ms step_avg:101.91ms
step:1547/1750 train_time:157659ms step_avg:101.91ms
step:1548/1750 train_time:157764ms step_avg:101.91ms
step:1549/1750 train_time:157869ms step_avg:101.92ms
step:1550/1750 train_time:157975ms step_avg:101.92ms
step:1551/1750 train_time:158081ms step_avg:101.92ms
step:1552/1750 train_time:158188ms step_avg:101.93ms
step:1553/1750 train_time:158296ms step_avg:101.93ms
step:1554/1750 train_time:158400ms step_avg:101.93ms
step:1555/1750 train_time:158507ms step_avg:101.93ms
step:1556/1750 train_time:158613ms step_avg:101.94ms
step:1557/1750 train_time:158719ms step_avg:101.94ms
step:1558/1750 train_time:158825ms step_avg:101.94ms
step:1559/1750 train_time:158932ms step_avg:101.94ms
step:1560/1750 train_time:159037ms step_avg:101.95ms
step:1561/1750 train_time:159146ms step_avg:101.95ms
step:1562/1750 train_time:159251ms step_avg:101.95ms
step:1563/1750 train_time:159357ms step_avg:101.96ms
step:1564/1750 train_time:159463ms step_avg:101.96ms
step:1565/1750 train_time:159571ms step_avg:101.96ms
step:1566/1750 train_time:159676ms step_avg:101.96ms
step:1567/1750 train_time:159782ms step_avg:101.97ms
step:1568/1750 train_time:159889ms step_avg:101.97ms
step:1569/1750 train_time:160000ms step_avg:101.98ms
step:1570/1750 train_time:160106ms step_avg:101.98ms
step:1571/1750 train_time:160213ms step_avg:101.98ms
step:1572/1750 train_time:160319ms step_avg:101.98ms
step:1573/1750 train_time:160428ms step_avg:101.99ms
step:1574/1750 train_time:160533ms step_avg:101.99ms
step:1575/1750 train_time:160639ms step_avg:101.99ms
step:1576/1750 train_time:160745ms step_avg:102.00ms
step:1577/1750 train_time:160852ms step_avg:102.00ms
step:1578/1750 train_time:160959ms step_avg:102.00ms
step:1579/1750 train_time:161064ms step_avg:102.00ms
step:1580/1750 train_time:161169ms step_avg:102.01ms
step:1581/1750 train_time:161278ms step_avg:102.01ms
step:1582/1750 train_time:161385ms step_avg:102.01ms
step:1583/1750 train_time:161491ms step_avg:102.02ms
step:1584/1750 train_time:161597ms step_avg:102.02ms
step:1585/1750 train_time:161703ms step_avg:102.02ms
step:1586/1750 train_time:161812ms step_avg:102.03ms
step:1587/1750 train_time:161919ms step_avg:102.03ms
step:1588/1750 train_time:162025ms step_avg:102.03ms
step:1589/1750 train_time:162132ms step_avg:102.03ms
step:1590/1750 train_time:162238ms step_avg:102.04ms
step:1591/1750 train_time:162343ms step_avg:102.04ms
step:1592/1750 train_time:162451ms step_avg:102.04ms
step:1593/1750 train_time:162556ms step_avg:102.04ms
step:1594/1750 train_time:162662ms step_avg:102.05ms
step:1595/1750 train_time:162768ms step_avg:102.05ms
step:1596/1750 train_time:162876ms step_avg:102.05ms
step:1597/1750 train_time:162981ms step_avg:102.05ms
step:1598/1750 train_time:163088ms step_avg:102.06ms
step:1599/1750 train_time:163194ms step_avg:102.06ms
step:1600/1750 train_time:163302ms step_avg:102.06ms
step:1601/1750 train_time:163409ms step_avg:102.07ms
step:1602/1750 train_time:163516ms step_avg:102.07ms
step:1603/1750 train_time:163622ms step_avg:102.07ms
step:1604/1750 train_time:163727ms step_avg:102.07ms
step:1605/1750 train_time:163833ms step_avg:102.08ms
step:1606/1750 train_time:163939ms step_avg:102.08ms
step:1607/1750 train_time:164048ms step_avg:102.08ms
step:1608/1750 train_time:164155ms step_avg:102.09ms
step:1609/1750 train_time:164261ms step_avg:102.09ms
step:1610/1750 train_time:164368ms step_avg:102.09ms
step:1611/1750 train_time:164474ms step_avg:102.09ms
step:1612/1750 train_time:164580ms step_avg:102.10ms
step:1613/1750 train_time:164685ms step_avg:102.10ms
step:1614/1750 train_time:164791ms step_avg:102.10ms
step:1615/1750 train_time:164898ms step_avg:102.10ms
step:1616/1750 train_time:165003ms step_avg:102.11ms
step:1617/1750 train_time:165112ms step_avg:102.11ms
step:1618/1750 train_time:165219ms step_avg:102.11ms
step:1619/1750 train_time:165326ms step_avg:102.12ms
step:1620/1750 train_time:165433ms step_avg:102.12ms
step:1621/1750 train_time:165540ms step_avg:102.12ms
step:1622/1750 train_time:165647ms step_avg:102.13ms
step:1623/1750 train_time:165755ms step_avg:102.13ms
step:1624/1750 train_time:165860ms step_avg:102.13ms
step:1625/1750 train_time:165965ms step_avg:102.13ms
step:1625/1750 val_loss:3.3090 train_time:166067ms step_avg:102.20ms
step:1626/1750 train_time:166087ms step_avg:102.14ms
step:1627/1750 train_time:166183ms step_avg:102.14ms
step:1628/1750 train_time:166291ms step_avg:102.14ms
step:1629/1750 train_time:166395ms step_avg:102.15ms
step:1630/1750 train_time:166502ms step_avg:102.15ms
step:1631/1750 train_time:166607ms step_avg:102.15ms
step:1632/1750 train_time:166713ms step_avg:102.15ms
step:1633/1750 train_time:166820ms step_avg:102.16ms
step:1634/1750 train_time:166926ms step_avg:102.16ms
step:1635/1750 train_time:167033ms step_avg:102.16ms
step:1636/1750 train_time:167140ms step_avg:102.16ms
step:1637/1750 train_time:167246ms step_avg:102.17ms
step:1638/1750 train_time:167352ms step_avg:102.17ms
step:1639/1750 train_time:167459ms step_avg:102.17ms
step:1640/1750 train_time:167565ms step_avg:102.17ms
step:1641/1750 train_time:167672ms step_avg:102.18ms
step:1642/1750 train_time:167779ms step_avg:102.18ms
step:1643/1750 train_time:167884ms step_avg:102.18ms
step:1644/1750 train_time:167992ms step_avg:102.18ms
step:1645/1750 train_time:168097ms step_avg:102.19ms
step:1646/1750 train_time:168205ms step_avg:102.19ms
step:1647/1750 train_time:168311ms step_avg:102.19ms
step:1648/1750 train_time:168417ms step_avg:102.19ms
step:1649/1750 train_time:168522ms step_avg:102.20ms
step:1650/1750 train_time:168629ms step_avg:102.20ms
step:1651/1750 train_time:168735ms step_avg:102.20ms
step:1652/1750 train_time:168842ms step_avg:102.20ms
step:1653/1750 train_time:168947ms step_avg:102.21ms
step:1654/1750 train_time:169057ms step_avg:102.21ms
step:1655/1750 train_time:169165ms step_avg:102.21ms
step:1656/1750 train_time:169271ms step_avg:102.22ms
step:1657/1750 train_time:169380ms step_avg:102.22ms
step:1658/1750 train_time:169486ms step_avg:102.22ms
step:1659/1750 train_time:169593ms step_avg:102.23ms
step:1660/1750 train_time:169698ms step_avg:102.23ms
step:1661/1750 train_time:169804ms step_avg:102.23ms
step:1662/1750 train_time:169911ms step_avg:102.23ms
step:1663/1750 train_time:170016ms step_avg:102.23ms
step:1664/1750 train_time:170123ms step_avg:102.24ms
step:1665/1750 train_time:170228ms step_avg:102.24ms
step:1666/1750 train_time:170335ms step_avg:102.24ms
step:1667/1750 train_time:170441ms step_avg:102.24ms
step:1668/1750 train_time:170547ms step_avg:102.25ms
step:1669/1750 train_time:170652ms step_avg:102.25ms
step:1670/1750 train_time:170758ms step_avg:102.25ms
step:1671/1750 train_time:170864ms step_avg:102.25ms
step:1672/1750 train_time:170971ms step_avg:102.26ms
step:1673/1750 train_time:171077ms step_avg:102.26ms
step:1674/1750 train_time:171182ms step_avg:102.26ms
step:1675/1750 train_time:171287ms step_avg:102.26ms
step:1676/1750 train_time:171393ms step_avg:102.26ms
step:1677/1750 train_time:171502ms step_avg:102.27ms
step:1678/1750 train_time:171608ms step_avg:102.27ms
step:1679/1750 train_time:171714ms step_avg:102.27ms
step:1680/1750 train_time:171821ms step_avg:102.27ms
step:1681/1750 train_time:171927ms step_avg:102.28ms
step:1682/1750 train_time:172036ms step_avg:102.28ms
step:1683/1750 train_time:172141ms step_avg:102.28ms
step:1684/1750 train_time:172246ms step_avg:102.28ms
step:1685/1750 train_time:172351ms step_avg:102.29ms
step:1686/1750 train_time:172459ms step_avg:102.29ms
step:1687/1750 train_time:172566ms step_avg:102.29ms
step:1688/1750 train_time:172675ms step_avg:102.30ms
step:1689/1750 train_time:172782ms step_avg:102.30ms
step:1690/1750 train_time:172888ms step_avg:102.30ms
step:1691/1750 train_time:172995ms step_avg:102.30ms
step:1692/1750 train_time:173103ms step_avg:102.31ms
step:1693/1750 train_time:173211ms step_avg:102.31ms
step:1694/1750 train_time:173318ms step_avg:102.31ms
step:1695/1750 train_time:173425ms step_avg:102.32ms
step:1696/1750 train_time:173536ms step_avg:102.32ms
step:1697/1750 train_time:173646ms step_avg:102.33ms
step:1698/1750 train_time:173755ms step_avg:102.33ms
step:1699/1750 train_time:173861ms step_avg:102.33ms
step:1700/1750 train_time:173966ms step_avg:102.33ms
step:1701/1750 train_time:174074ms step_avg:102.34ms
step:1702/1750 train_time:174181ms step_avg:102.34ms
step:1703/1750 train_time:174287ms step_avg:102.34ms
step:1704/1750 train_time:174394ms step_avg:102.34ms
step:1705/1750 train_time:174500ms step_avg:102.35ms
step:1706/1750 train_time:174607ms step_avg:102.35ms
step:1707/1750 train_time:174715ms step_avg:102.35ms
step:1708/1750 train_time:174822ms step_avg:102.35ms
step:1709/1750 train_time:174929ms step_avg:102.36ms
step:1710/1750 train_time:175039ms step_avg:102.36ms
step:1711/1750 train_time:175149ms step_avg:102.37ms
step:1712/1750 train_time:175255ms step_avg:102.37ms
step:1713/1750 train_time:175361ms step_avg:102.37ms
step:1714/1750 train_time:175467ms step_avg:102.37ms
step:1715/1750 train_time:175573ms step_avg:102.37ms
step:1716/1750 train_time:175681ms step_avg:102.38ms
step:1717/1750 train_time:175786ms step_avg:102.38ms
step:1718/1750 train_time:175894ms step_avg:102.38ms
step:1719/1750 train_time:176002ms step_avg:102.39ms
step:1720/1750 train_time:176110ms step_avg:102.39ms
step:1721/1750 train_time:176217ms step_avg:102.39ms
step:1722/1750 train_time:176328ms step_avg:102.40ms
step:1723/1750 train_time:176435ms step_avg:102.40ms
step:1724/1750 train_time:176545ms step_avg:102.40ms
step:1725/1750 train_time:176655ms step_avg:102.41ms
step:1726/1750 train_time:176763ms step_avg:102.41ms
step:1727/1750 train_time:176869ms step_avg:102.41ms
step:1728/1750 train_time:176980ms step_avg:102.42ms
step:1729/1750 train_time:177087ms step_avg:102.42ms
step:1730/1750 train_time:177195ms step_avg:102.42ms
step:1731/1750 train_time:177303ms step_avg:102.43ms
step:1732/1750 train_time:177409ms step_avg:102.43ms
step:1733/1750 train_time:177518ms step_avg:102.43ms
step:1734/1750 train_time:177624ms step_avg:102.44ms
step:1735/1750 train_time:177732ms step_avg:102.44ms
step:1736/1750 train_time:177839ms step_avg:102.44ms
step:1737/1750 train_time:177946ms step_avg:102.44ms
step:1738/1750 train_time:178053ms step_avg:102.45ms
step:1739/1750 train_time:178160ms step_avg:102.45ms
step:1740/1750 train_time:178266ms step_avg:102.45ms
step:1741/1750 train_time:178376ms step_avg:102.46ms
step:1742/1750 train_time:178486ms step_avg:102.46ms
step:1743/1750 train_time:178594ms step_avg:102.46ms
step:1744/1750 train_time:178700ms step_avg:102.47ms
step:1745/1750 train_time:178806ms step_avg:102.47ms
step:1746/1750 train_time:178916ms step_avg:102.47ms
step:1747/1750 train_time:179022ms step_avg:102.47ms
step:1748/1750 train_time:179131ms step_avg:102.48ms
step:1749/1750 train_time:179239ms step_avg:102.48ms
step:1750/1750 train_time:179344ms step_avg:102.48ms
step:1750/1750 val_loss:3.2832 train_time:179446ms step_avg:102.54ms
peak memory allocated: 30724 MiB reserved: 45392 MiB
