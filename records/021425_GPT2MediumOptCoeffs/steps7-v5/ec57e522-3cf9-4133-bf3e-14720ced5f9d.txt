import os
import sys
with open(sys.argv[0]) as f:
    code = f.read() # read the code of this file ASAP, for logging
import uuid
import time
import copy
import glob
from dataclasses import dataclass
from functools import lru_cache
from pathlib import Path

os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True"
import torch
torch.empty(1, device="cuda", requires_grad=True).backward() # prevents a bug on some systems
from torch import Tensor, nn
import torch.nn.functional as F
import torch.distributed as dist
# use of FlexAttention contributed by @KoszarskyB
from torch.nn.attention.flex_attention import BlockMask, flex_attention
#torch._inductor.config.coordinate_descent_tuning = True # we have banned this flag for new records because it causes compilation to take 30min

# -----------------------------------------------------------------------------
# Custom operators: FP8 matmul by @YouJiacheng

@torch.library.custom_op("nanogpt::mm", mutates_args=())
def mm_op(x: Tensor, w: Tensor, x_s: float, w_s: float, grad_s: float) -> tuple[Tensor, Tensor, Tensor]:
    @torch.compile
    def impl(x: Tensor, w: Tensor):
        assert x.is_contiguous() and w.is_contiguous()
        x_f8 = x.div(x_s).to(torch.float8_e4m3fn)
        w_f8 = w.div(w_s).to(torch.float8_e4m3fn)
        out = torch._scaled_mm(
            x_f8,
            w_f8.T,
            out_dtype=torch.bfloat16,
            scale_a=x.new_tensor(x_s, dtype=torch.float32),
            scale_b=x.new_tensor(w_s, dtype=torch.float32),
            use_fast_accum=True,
        )
        return out, x_f8, w_f8

    return impl(x, w)

@mm_op.register_fake
def _(x: Tensor, w: Tensor, *_):
    assert x.ndim == w.ndim == 2
    assert x.shape[1] == w.shape[1]
    assert x.device == w.device
    assert x.is_contiguous() and w.is_contiguous()
    return x @ w.T, x.to(torch.float8_e4m3fn), w.to(torch.float8_e4m3fn)

@torch.library.custom_op("nanogpt::mm_backward", mutates_args=())
def mm_backward_op(g: Tensor, x_f8: Tensor, w_f8: Tensor, x_s: float, w_s: float, grad_s: float) -> tuple[Tensor, Tensor]:
    @torch.compile
    def impl(grad: Tensor, x_f8: Tensor, w_f8: Tensor):
        assert grad.is_contiguous()
        x_inv_s = grad.new_tensor(x_s, dtype=torch.float32)
        w_inv_s = grad.new_tensor(w_s, dtype=torch.float32)
        grad_inv_s = grad.new_tensor(grad_s, dtype=torch.float32)
        grad_f8 = grad.div(grad_s).to(torch.float8_e5m2)
        grad_x = torch._scaled_mm(
            grad_f8,
            w_f8.T.contiguous().T,
            out_dtype=torch.bfloat16,
            scale_a=grad_inv_s,
            scale_b=w_inv_s,
            use_fast_accum=False,
        )
        # faster than grad_f8_t @ x_f8, for (d_out, d_in) == (50304, 768)
        grad_w = torch._scaled_mm(
            x_f8.T.contiguous(),
            grad_f8.T.contiguous().T,
            out_dtype=torch.float32,
            scale_a=x_inv_s,
            scale_b=grad_inv_s,
            use_fast_accum=False,
        ).T
        return grad_x, grad_w

    return impl(g, x_f8, w_f8)

@mm_backward_op.register_fake
def _(g: Tensor, x_f8: Tensor, w_f8: Tensor, *_):
    return x_f8.to(torch.bfloat16), w_f8.to(torch.float32)

def backward(ctx, grad_out: Tensor, *_):
    x_f8, w_f8 = ctx.saved_tensors
    x_s, w_s, grad_s = ctx.scales
    grad_x, grad_w = torch.ops.nanogpt.mm_backward(
        grad_out, x_f8, w_f8, x_s, w_s, grad_s
    )
    return grad_x, grad_w, None, None, None

def setup_context(ctx: torch.autograd.function.FunctionCtx, inputs, output):
    *_, x_s, w_s, grad_s = inputs
    _, x_f8, w_f8 = output
    ctx.save_for_backward(x_f8, w_f8)
    ctx.scales = x_s, w_s, grad_s
    ctx.set_materialize_grads(False)

mm_op.register_autograd(backward, setup_context=setup_context)

# -----------------------------------------------------------------------------
# Muon optimizer

@torch.compile
def zeropower_via_newtonschulz5(G: Tensor, steps: int) -> Tensor:
    """
    Newton-Schulz iteration to compute the zeroth power / orthogonalization of G. We opt to use a
    quintic iteration whose coefficients are selected to maximize the slope at zero. For the purpose
    of minimizing steps, it turns out to be empirically effective to keep increasing the slope at
    zero even beyond the point where the iteration no longer converges all the way to one everywhere
    on the interval. This iteration therefore does not produce UV^T but rather something like US'V^T
    where S' is diagonal with S_{ii}' ~ Uniform(0.5, 1.5), which turns out not to hurt model
    performance at all relative to UV^T, where USV^T = G is the SVD.
    """
    assert G.ndim >= 2 # batched Muon implementation by @scottjmaddox, and put into practice in the record by @YouJiacheng
    X = G.bfloat16()
    if G.size(-2) > G.size(-1):
        X = X.mT

    # Ensure spectral norm is at most 1
    X = X / (X.norm(dim=(-2, -1), keepdim=True) + 1e-7)
    # Perform the NS iterations
    for a, b, c in [
        (3.8839, -3.9828, 1.0989),
        (3.7253, -3.8239, 1.0986),
        (3.5715, -3.6700, 1.0985),
        (3.4220, -3.5202, 1.0983),
        (3.2774, -3.3757, 1.0983),
        (3.1288, -3.2227, 1.0939),
        (2.7203, -2.6642, 0.9439),
    ]:
        A = X @ X.mT
        B = b * A + c * A @ A # quintic computation strategy adapted from suggestion by @jxbz, @leloykun, and @YouJiacheng
        X = a * X + B @ X
    
    if G.size(-2) > G.size(-1):
        X = X.mT
    return X

class Muon(torch.optim.Optimizer):
    """
    Muon - MomentUm Orthogonalized by Newton-schulz

    https://kellerjordan.github.io/posts/muon/

    Muon internally runs standard SGD-momentum, and then performs an orthogonalization post-
    processing step, in which each 2D parameter's update is replaced with the nearest orthogonal
    matrix. To efficiently orthogonalize each update, we use a Newton-Schulz iteration, which has
    the advantage that it can be stably run in bfloat16 on the GPU.

    Some warnings:
    - This optimizer should not be used for the embedding layer, the final fully connected layer,
    or any {0,1}-D parameters; those should all be optimized by a standard method (e.g., AdamW).
    - To use it with 4D convolutional filters, it works well to just flatten their last 3 dimensions.

    Arguments:
        lr: The learning rate used by the internal SGD.
        momentum: The momentum used by the internal SGD.
        nesterov: Whether to use Nesterov-style momentum in the internal SGD. (recommended)
        ns_steps: The number of Newton-Schulz iteration steps to use.
    """
    def __init__(self, params, lr=0.02, momentum=0.95, nesterov=True, ns_steps=5, rank=0, world_size=1):
        self.rank = rank
        self.world_size = world_size
        defaults = dict(lr=lr, momentum=momentum, nesterov=nesterov, ns_steps=ns_steps)
        params: list[Tensor] = [*params]
        param_groups = []
        for size in {p.numel() for p in params}:
            b = torch.empty(world_size, size, dtype=torch.bfloat16, device="cuda")
            group = dict(params=[p for p in params if p.numel() == size],
                         update_buffer=b, update_buffer_views=[b[i] for i in range(world_size)])
            param_groups.append(group)
        super().__init__(param_groups, defaults)

    @torch.no_grad()
    def step(self):
        for group in self.param_groups:
            update_buffer: Tensor = group["update_buffer"]
            update_buffer_views: list[Tensor] = group["update_buffer_views"]
            # generate weight updates in distributed fashion
            params: list[Tensor] = group["params"]
            handle = None
            params_world = None
            def update_prev(): # optimized Muon implementation contributed by @YouJiacheng
                handle.wait()
                for p_world, g_world in zip(params_world, update_buffer_views):
                    p_world.add_(g_world.view_as(p_world),
                                 alpha=-group["lr"] * max(1, p_world.size(-2) / p_world.size(-1))**0.5)
            for base_i in range(len(params))[::self.world_size]:
                if base_i + self.rank < len(params):
                    p = params[base_i + self.rank]
                    g = p.grad
                    assert g is not None
                    state = self.state[p]
                    if "momentum_buffer" not in state:
                        state["momentum_buffer"] = torch.zeros_like(g)
                    buf: Tensor = state["momentum_buffer"]
                    buf.lerp_(g, 1 - group["momentum"])
                    g = g.lerp_(buf, group["momentum"]) if group["nesterov"] else buf
                    g = zeropower_via_newtonschulz5(g, steps=group["ns_steps"]).flatten()
                else:
                    g = update_buffer_views[self.rank]
                if base_i > 0:
                    update_prev() # async all_gather instead of sync all_reduce by @YouJiacheng
                handle = dist.all_gather_into_tensor(update_buffer, g, async_op=True)
                params_world = params[base_i : base_i + self.world_size]
            update_prev()

# -----------------------------------------------------------------------------
# PyTorch nn.Module definitions for the model

def norm(x: Tensor):
    return F.rms_norm(x, (x.size(-1),))

class CastedLinear(nn.Linear):
    def __init__(self, in_features: int, out_features: int, use_fp8=False, x_s=1.0, w_s=1.0, grad_s=1.0):
        super().__init__(in_features, out_features, bias=False)
        self.use_fp8 = use_fp8
        self.x_s = x_s
        self.w_s = w_s
        self.grad_s = grad_s

    def reset_parameters(self) -> None:
        std = 0.5 * (self.in_features ** -0.5) # 0.5 is a bit better than the default 1/sqrt(3)
        bound = (3 ** 0.5) * std
        with torch.no_grad():
            self.weight.uniform_(-bound, bound)

    def forward(self, x: Tensor):
        if self.use_fp8 and self.training:
            _x = x.flatten(0, -2)
            out: Tensor = torch.ops.nanogpt.mm(_x, self.weight, x_s=self.x_s, w_s=self.w_s, grad_s=self.grad_s)[0]
            return out.reshape(*x.shape[:-1], -1)
        else:
            return F.linear(x, self.weight.type_as(x))

class Rotary(nn.Module):
    def __init__(self, dim: int, max_seq_len: int):
        super().__init__()
        # half-truncate RoPE by @YouJiacheng (w/ base freq tuning)
        angular_freq = (1 / 1024) ** torch.linspace(0, 1, steps=dim//4, dtype=torch.float32)
        angular_freq = torch.cat([angular_freq, angular_freq.new_zeros(dim//4)])
        t = torch.arange(max_seq_len, dtype=torch.float32)
        theta = torch.einsum("i,j -> ij", t, angular_freq)
        self.cos = nn.Buffer(theta.cos(), persistent=False)
        self.sin = nn.Buffer(theta.sin(), persistent=False)

    def forward(self, x_BTHD: Tensor):
        assert self.cos.size(0) >= x_BTHD.size(-3)
        cos, sin = self.cos[None, :x_BTHD.size(-3), None, :], self.sin[None, :x_BTHD.size(-3), None, :]
        x1, x2 = x_BTHD.to(dtype=torch.float32).chunk(2, dim=-1)
        y1 = x1 * cos + x2 * sin
        y2 = x1 * (-sin) + x2 * cos
        return torch.cat((y1, y2), 3).type_as(x_BTHD)

class CausalSelfAttention(nn.Module):
    def __init__(self, dim: int, num_heads: int, max_seq_len: int, head_dim=128):
        super().__init__()
        self.num_heads = num_heads
        self.head_dim = head_dim
        hdim = num_heads * head_dim
        std = 0.5 * (dim ** -0.5)
        bound = (3 ** 0.5) * std # improved init scale by @YouJiacheng
        # merged QKV weights: suggested by many, implemented by @fernbear.bsky.social, and further improved by @YouJiacheng
        # https://x.com/hi_tysam/status/1879699187107033311
        self.qkv_w = nn.Parameter(torch.empty(3, hdim, dim).uniform_(-bound, bound))
        self.lambdas = nn.Parameter(torch.tensor([0.5, 0.5]))
        self.rotary = Rotary(head_dim, max_seq_len)
        self.c_proj = CastedLinear(hdim, dim)
        self.c_proj.weight.detach().zero_() # zero init suggested by @Grad62304977

    def forward(self, x: Tensor, ve: Tensor | None, block_mask: BlockMask):
        B, T = x.size(0), x.size(1) # batch size, sequence length
        assert B == 1, "Must use batch size = 1 for FlexAttention"
        q, k, v = F.linear(x, self.qkv_w.flatten(end_dim=1).type_as(x)).view(B, T, 3 * self.num_heads, self.head_dim).chunk(3, dim=-2)
        q, k = norm(q), norm(k) # QK norm @Grad62304977
        q, k = self.rotary(q), self.rotary(k)
        if ve is not None:
            v = self.lambdas[0] * v + self.lambdas[1] * ve.view_as(v) # @KoszarskyB & @Grad62304977
        else: # skip mid-layers token value embeddings by @YouJiacheng
            v = self.lambdas[0] * v
        # scale the attention logits by given constant, instead of the default head_dim**-0.5, by @leloykun
        # inspired by learnable scalars used by @brendanh0gan https://x.com/hi_tysam/status/1879693583898591283
        y = flex_attention(q.transpose(1, 2), k.transpose(1, 2), v.transpose(1, 2), block_mask=block_mask, scale=15/self.head_dim).transpose(1, 2)
        y = y.contiguous().view(B, T, self.num_heads * self.head_dim) # re-assemble all head outputs side by side
        y = self.c_proj(y)
        return y

class MLP(nn.Module):
    def __init__(self, dim: int):
        super().__init__()
        hdim = 4 * dim
        self.c_fc = CastedLinear(dim, hdim)
        self.c_proj = CastedLinear(hdim, dim)
        self.c_proj.weight.detach().zero_() # zero init suggested by @Grad62304977

    def forward(self, x: Tensor):
        x = self.c_fc(x)
        x = F.relu(x).square() # https://arxiv.org/abs/2109.08668v2; ~1-2% better than GELU; suggested by @SKYLINEZ007 and @Grad62304977
        x = self.c_proj(x)
        return x

class Block(nn.Module):
    def __init__(self, dim: int, num_heads: int, max_seq_len: int, layer_idx: int):
        super().__init__()
        # skip attention of blocks.7 (the 8th layer) by @YouJiacheng
        self.attn = CausalSelfAttention(dim, num_heads, max_seq_len) if layer_idx != 7 else None
        self.mlp = MLP(dim)
        self.lambdas = nn.Parameter(torch.tensor([1., 0.]))

    def forward(self, x: Tensor, ve: Tensor | None, x0: Tensor, block_mask: BlockMask):
        x = self.lambdas[0] * x + self.lambdas[1] * x0
        if self.attn is not None:
            x = x + self.attn(norm(x), ve, block_mask)
        x = x + self.mlp(norm(x))
        return x

# -----------------------------------------------------------------------------
# The main model

def next_multiple_of_n(v: float | int, *, n: int):
    return next(x for x in range(n, int(v) + 1 + n, n) if x >= v)

class GPT(nn.Module):
    def __init__(self, vocab_size: int, num_layers: int, num_heads: int, model_dim: int, max_seq_len: int):
        super().__init__()
        self.embed = nn.Embedding(vocab_size, model_dim)
        # token value embeddings by @KoszarskyB - inspired by @Grad62304977's value residual implementation following https://arxiv.org/abs/2410.17897
        # value embedding code simplification inspired by @ragulpr https://github.com/KellerJordan/modded-nanogpt/pull/78
        self.value_embeds = nn.ModuleList([nn.Embedding(vocab_size, model_dim) for _ in range(3)])
        self.blocks = nn.ModuleList([Block(model_dim, num_heads, max_seq_len, i) for i in range(num_layers)])
        # there are only 50257 unique GPT-2 tokens; we extend to nearest multiple of 128 for efficiency.
        # suggested to me by @Grad62304977. this originates from Karpathy's experiments.
        self.lm_head = CastedLinear(model_dim, next_multiple_of_n(vocab_size, n=128), use_fp8=True, x_s=(768**0.5)/448, w_s=2**-9, grad_s=1/448)
        self.lm_head.weight.detach().zero_() # @Grad62304977
        # Add learnable skip connection weights for decoder layers
        assert num_layers % 2 == 0
        self.skip_weights = nn.Parameter(torch.ones(num_layers//2))

    def create_blockmasks(self, input_seq: Tensor, sliding_window_num_blocks: Tensor):
        BLOCK_SIZE = 128
        docs = (input_seq == 50256).cumsum(0)

        def document_causal(b, h, q_idx, kv_idx):
            causal_mask = q_idx >= kv_idx
            document_mask = docs[q_idx] == docs[kv_idx]
            return causal_mask & document_mask

        def dense_to_ordered(dense_blockmask: Tensor):
            num_blocks = dense_blockmask.sum(dim=-1, dtype=torch.int32)
            indices = dense_blockmask.argsort(dim=-1, descending=False, stable=True).flip(-1).to(torch.int32)
            return num_blocks[None, None].contiguous(), indices[None, None].contiguous()

        # manual block mask creation by @YouJiacheng
        assert len(input_seq) % BLOCK_SIZE == 0
        NUM_BLOCKS = len(input_seq) // BLOCK_SIZE
        block_idx = torch.arange(NUM_BLOCKS, dtype=torch.int32, device="cuda")
        causal_blockmask_any = block_idx[:, None] >= block_idx
        causal_blockmask_all = block_idx[:, None] > block_idx
        docs_low = docs.view(-1, BLOCK_SIZE)[:, 0].contiguous()
        docs_high = docs.view(-1, BLOCK_SIZE)[:, -1].contiguous()
        document_blockmask_any = (docs_low[:, None] <= docs_high) & (docs_high[:, None] >= docs_low)
        document_blockmask_all = (docs_low[:, None] == docs_high) & (docs_high[:, None] == docs_low)
        blockmask_any = causal_blockmask_any & document_blockmask_any
        blockmask_all = causal_blockmask_all & document_blockmask_all
        partial_kv_num_blocks, partial_kv_indices = dense_to_ordered(blockmask_any & ~blockmask_all)
        full_kv_num_blocks, full_kv_indices = dense_to_ordered(blockmask_all)
        def build_bm(window_size_blocks: Tensor) -> BlockMask:
            return BlockMask.from_kv_blocks(
                torch.clamp_max(partial_kv_num_blocks, torch.clamp_min(window_size_blocks - full_kv_num_blocks, 1)),
                partial_kv_indices,
                torch.clamp_max(full_kv_num_blocks, window_size_blocks - 1),
                full_kv_indices,
                BLOCK_SIZE=BLOCK_SIZE,
                mask_mod=document_causal,
            )
        # Long-short SWA block masks by @leloykun & @YouJiacheng, adapated from suggestion by @Grad62304977, following Gemma 2 paper
        return build_bm(sliding_window_num_blocks), build_bm(sliding_window_num_blocks // 2)

    def forward(self, input_seq: Tensor, target_seq: Tensor, sliding_window_num_blocks: Tensor):
        assert input_seq.ndim == 1

        ve = [value_embed(input_seq) for value_embed in self.value_embeds]
        # 012 ... 012 structure on token value embeddings by @YouJiacheng, improved on @leloykun's U-net structure
        ve = [ve[0], ve[1], ve[2]] + [None] * (len(self.blocks) - 6) + [ve[0], ve[1], ve[2]]
        assert len(ve) == len(self.blocks)

        long_bm, short_bm = self.create_blockmasks(input_seq, sliding_window_num_blocks)
        block_masks = [long_bm, short_bm, short_bm, short_bm, long_bm, short_bm, short_bm, long_bm, short_bm, short_bm, short_bm, long_bm]
        assert len(block_masks) == len(self.blocks)

        x = x0 = norm(self.embed(input_seq)[None]) # use of norm here by @Grad62304977

        # U-net design by @brendanh0gan
        skip_connections = []
        n = len(self.skip_weights)
        for i in range(len(self.blocks)):
            if i >= n:
                x = x + self.skip_weights[i - n] * skip_connections.pop()
            x = self.blocks[i](x, ve[i], x0, block_masks[i])
            if i < n:
                skip_connections.append(x)

        x = norm(x)
        logits = self.lm_head(x).float()
        # @Grad62304977 added tanh softcapping following Gemma 2 paper, @KoszarskyB reduced it from 30 to 15, @YouJiacheng shifted it by +15 (2*sigmoid(2*x)=tanh(x)+1)
        logits = 30 * torch.sigmoid(logits / 7.5)
        loss = F.cross_entropy(logits.view(-1, logits.size(-1)), target_seq, reduction='sum' if self.training else 'mean')
        return loss

# -----------------------------------------------------------------------------
# Our own simple Distributed Data Loader

def _load_data_shard(file: Path):
    header = torch.from_file(str(file), False, 256, dtype=torch.int32) # header is 256 int32
    assert header[0] == 20240520, "magic number mismatch in the data .bin file"
    assert header[1] == 1, "unsupported version"
    num_tokens = int(header[2]) # number of tokens (claimed)
    with file.open("rb", buffering=0) as f:
        tokens = torch.empty(num_tokens, dtype=torch.uint16, pin_memory=True) # avoid pin_memory copy by @YouJiacheng
        f.seek(256 * 4)
        nbytes = f.readinto(tokens.numpy()) # avoid bytes->array copy by @YouJiacheng
        assert nbytes == 2 * num_tokens, "number of tokens read does not match header"
    return tokens

def distributed_data_generator(filename_pattern: str, batch_size: int, rank : int, world_size : int):
    files = [Path(file) for file in sorted(glob.glob(filename_pattern))]
    assert batch_size % world_size == 0
    local_batch_size = batch_size // world_size
    file_iter = iter(files) # use itertools.cycle(files) instead if you want to do multi-epoch training
    tokens, pos = _load_data_shard(next(file_iter)), 0
    while True:
        if pos + batch_size + 1 >= len(tokens):
            tokens, pos = _load_data_shard(next(file_iter)), 0
        buf = tokens[pos + rank * local_batch_size:][:local_batch_size + 1]
        inputs = buf[:-1].to(device="cuda", dtype=torch.int32, non_blocking=True) # no sync on host side;
        targets = buf[1:].to(device="cuda", dtype=torch.int64, non_blocking=True) # H2D in another stream isn't helpful.
        pos += batch_size
        yield inputs, targets

# -----------------------------------------------------------------------------
# int main

@dataclass
class Hyperparameters:
    # data
    train_files = "data/fineweb10B/fineweb_train_*.bin" # input .bin to train on
    val_files = "data/fineweb10B/fineweb_val_*.bin" # input .bin to eval validation loss on
    val_tokens = 10485760 # how many tokens of validation data? it's important to keep this fixed for consistent comparisons
    train_seq_len = 48*1024 # FlexAttention sequence length
    val_seq_len = 4*64*1024 # FlexAttention sequence length for validation
    # optimization
    num_iterations = 1750 # number of iterations to run
    cooldown_frac = 0.4 # fraction of training spent cooling down the learning rate
    # architecture
    vocab_size = 50257
    # evaluation and logging
    val_loss_every = 125 # every how many steps to evaluate val loss? 0 for only at the end
    save_checkpoint = False
args = Hyperparameters()

# torchrun sets these env variables
rank = int(os.environ["RANK"])
world_size = int(os.environ["WORLD_SIZE"])
assert world_size == 8 # this code is designed for 8xH100
assert torch.cuda.is_available()
device = torch.device("cuda", int(os.environ["LOCAL_RANK"]))
torch.cuda.set_device(device)
dist.init_process_group(backend="nccl", device_id=device)
dist.barrier()
master_process = (rank == 0) # this process will do logging, checkpointing etc.

# begin logging
logfile = None
if master_process:
    run_id = uuid.uuid4()
    os.makedirs("logs", exist_ok=True)
    logfile = f"logs/{run_id}.txt"
    print(logfile)
def print0(s, console=False):
    if master_process:
        with open(logfile, "a") as f:
            if console:
                print(s)
            print(s, file=f)

# begin by printing this file (the Python code)
print0(code)
print0("="*100)
# log information about the hardware/software environment this is running on
print0(f"Running Python {sys.version}")
print0(f"Running PyTorch {torch.version.__version__} compiled for CUDA {torch.version.cuda}")
def nvidia_smi():
    import subprocess  # avoid top level import
    return subprocess.run(["nvidia-smi"], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True).stdout
print0(nvidia_smi())
print0("="*100)

########################################
#    Construct model and optimizer     #
########################################

model: nn.Module = GPT(vocab_size=args.vocab_size, num_layers=12, num_heads=6, model_dim=768,
                       max_seq_len=max(args.train_seq_len, args.val_seq_len)).cuda()
for m in model.modules():
    if isinstance(m, nn.Embedding):
        m.bfloat16()
for param in model.parameters():
    dist.broadcast(param.detach(), 0)

# collect the parameters to optimize
hidden_matrix_params = [p for n, p in model.blocks.named_parameters() if p.ndim >= 2 and "embed" not in n]
embed_params = [p for n, p in model.named_parameters() if "embed" in n]
scalar_params = [p for p in model.parameters() if p.ndim < 2]
head_params = [model.lm_head.weight]

# init the optimizer(s)
adam_params = [dict(params=head_params, lr=0.22/768**0.5), dict(params=embed_params, lr=0.6), dict(params=scalar_params, lr=0.04)]
# small adam epsilon by @YouJiacheng. this is an alternate method of fixing the world_size dependence
# discovered by @fernbear.bsky.social https://x.com/hi_tysam/status/1879692937589875094
optimizer1 = torch.optim.Adam(adam_params, betas=(0.8, 0.95), eps=1e-10, fused=True)
optimizer2 = Muon(hidden_matrix_params, lr=0.05, momentum=0.95, rank=rank, world_size=world_size)
optimizers = [optimizer1, optimizer2]
for opt in optimizers:
    for group in opt.param_groups:
        group["initial_lr"] = group["lr"]

# learning rate schedule: stable then decay
def get_lr(step: int):
    x = step / args.num_iterations # progress in training
    assert 0 <= x < 1
    if x < 1 - args.cooldown_frac:
        return 1.0
    else:
        w = (1 - x) / args.cooldown_frac
        return w * 1.0 + (1 - w) * 0.1

# attention window size schedule: linearly increase
@lru_cache(1)
def get_window_size_blocks_helper(window_size: int):
    return torch.tensor(window_size // 128, dtype=torch.int32, pin_memory=True).cuda(non_blocking=True)
def get_window_size_blocks(step: int):
    x = step / args.num_iterations # progress in training
    assert 0 <= x <= 1
    # Linearly increase the block-wise sliding window size over training 128 -> 1792
    # increase by @fernbear.bsky.social; block-wise by @YouJiacheng
    window_size = next_multiple_of_n(1728 * x, n=128)
    return get_window_size_blocks_helper(window_size)

model: nn.Module = torch.compile(model, dynamic=False)

########################################
#            Warmup kernels            #
########################################

# Warmup the training kernels, then re-initialize the state so we aren't cheating
warmup_steps = 10
initial_state = dict(model=copy.deepcopy(model.state_dict()),
                     optimizers=[copy.deepcopy(opt.state_dict()) for opt in optimizers]) # save the initial state
for _ in range(warmup_steps):
    inputs = targets = torch.randint(0, args.vocab_size, size=(args.train_seq_len,), device="cuda")
    model(inputs.to(torch.int32), targets, get_window_size_blocks(0)).backward()
    for param in model.parameters():
        dist.all_reduce(param.grad, op=dist.ReduceOp.AVG)
    for opt in optimizers:
        opt.step()
    model.zero_grad(set_to_none=True)
model.load_state_dict(initial_state["model"])
for opt, opt_state in zip(optimizers, initial_state["optimizers"]):
    opt.load_state_dict(opt_state)
del initial_state

########################################
#        Training and validation       #
########################################

train_loader = distributed_data_generator(args.train_files, world_size * args.train_seq_len, rank, world_size)
training_time_ms = 0
# start the clock
torch.cuda.synchronize()
t0 = time.perf_counter()
# begin training
train_steps = args.num_iterations
for step in range(train_steps + 1):
    last_step = (step == train_steps)

    # --------------- VALIDATION SECTION -----------------
    if last_step or (args.val_loss_every > 0 and step % args.val_loss_every == 0):
        # stop the clock
        torch.cuda.synchronize()
        training_time_ms += 1000 * (time.perf_counter() - t0)
        model.eval()
        val_batch_size = world_size * args.val_seq_len
        assert args.val_tokens % val_batch_size == 0
        val_steps = args.val_tokens // val_batch_size
        val_loader = distributed_data_generator(args.val_files, val_batch_size, rank, world_size)
        val_loss = 0
        with torch.no_grad():
            for _ in range(val_steps):
                inputs, targets = next(val_loader)
                val_loss += model(inputs, targets, get_window_size_blocks(step))
        val_loss /= val_steps
        del val_loader
        dist.all_reduce(val_loss, op=dist.ReduceOp.AVG)
        print0(f"step:{step}/{train_steps} val_loss:{val_loss:.4f} train_time:{training_time_ms:.0f}ms step_avg:{training_time_ms/max(step, 1):.2f}ms", console=True)
        model.train()
        # start the clock again
        torch.cuda.synchronize()
        t0 = time.perf_counter()

    if last_step:
        if master_process and args.save_checkpoint:
            log = dict(step=step, code=code, model=model.state_dict(), optimizers=[opt.state_dict() for opt in optimizers])
            os.makedirs(f"logs/{run_id}", exist_ok=True)
            torch.save(log, f"logs/{run_id}/state_step{step:06d}.pt")
        # the last step only has the validation loop, so break to avoid training
        break

    # --------------- TRAINING SECTION -----------------
    inputs, targets = next(train_loader)
    model(inputs, targets, get_window_size_blocks(step)).backward()
    for param in model.parameters():
        dist.all_reduce(param.grad, op=dist.ReduceOp.AVG)
    # set optimization hyperparameters
    for opt in optimizers:
        for group in opt.param_groups:
            group["lr"] = group["initial_lr"] * get_lr(step)
    for group in optimizer2.param_groups:
        frac = min(step / 300, 1) # momentum warmup for muon
        group["momentum"] = (1 - frac) * 0.85 + frac * 0.95
    # step the optimizers
    for opt in optimizers:
        opt.step()
    # null the gradients
    model.zero_grad(set_to_none=True)
    # logging
    approx_training_time_ms = training_time_ms + 1000 * (time.perf_counter() - t0)
    print0(f"step:{step+1}/{train_steps} train_time:{approx_training_time_ms:.0f}ms step_avg:{approx_training_time_ms/(step + 1):.2f}ms", console=True)

print0(f"peak memory allocated: {torch.cuda.max_memory_allocated() // 1024 // 1024} MiB "
       f"reserved: {torch.cuda.max_memory_reserved() // 1024 // 1024} MiB", console=True)
dist.destroy_process_group()

====================================================================================================
Running Python 3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]
Running PyTorch 2.7.0.dev20250125+cu126 compiled for CUDA 12.6
Sun Feb 16 18:08:37 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA H100 80GB HBM3          On  |   00000000:19:00.0 Off |                    0 |
| N/A   33C    P0            115W /  700W |    7714MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA H100 80GB HBM3          On  |   00000000:3B:00.0 Off |                    0 |
| N/A   28C    P0            119W /  700W |    3452MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA H100 80GB HBM3          On  |   00000000:4C:00.0 Off |                    0 |
| N/A   27C    P0            112W /  700W |    3452MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA H100 80GB HBM3          On  |   00000000:5D:00.0 Off |                    0 |
| N/A   32C    P0            114W /  700W |    3452MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   4  NVIDIA H100 80GB HBM3          On  |   00000000:9B:00.0 Off |                    0 |
| N/A   32C    P0            116W /  700W |    3452MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   5  NVIDIA H100 80GB HBM3          On  |   00000000:BB:00.0 Off |                    0 |
| N/A   28C    P0            111W /  700W |    3452MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   6  NVIDIA H100 80GB HBM3          On  |   00000000:CB:00.0 Off |                    0 |
| N/A   31C    P0            111W /  700W |    3452MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   7  NVIDIA H100 80GB HBM3          On  |   00000000:DB:00.0 Off |                    0 |
| N/A   27C    P0            113W /  700W |    3212MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
+-----------------------------------------------------------------------------------------+

====================================================================================================
step:0/1750 val_loss:10.8258 train_time:0ms step_avg:0.02ms
step:1/1750 train_time:68ms step_avg:68.20ms
step:2/1750 train_time:144ms step_avg:71.93ms
step:3/1750 train_time:237ms step_avg:78.88ms
step:4/1750 train_time:333ms step_avg:83.23ms
step:5/1750 train_time:430ms step_avg:85.99ms
step:6/1750 train_time:528ms step_avg:88.00ms
step:7/1750 train_time:624ms step_avg:89.15ms
step:8/1750 train_time:721ms step_avg:90.15ms
step:9/1750 train_time:818ms step_avg:90.91ms
step:10/1750 train_time:914ms step_avg:91.40ms
step:11/1750 train_time:1011ms step_avg:91.90ms
step:12/1750 train_time:1108ms step_avg:92.31ms
step:13/1750 train_time:1205ms step_avg:92.68ms
step:14/1750 train_time:1302ms step_avg:92.97ms
step:15/1750 train_time:1399ms step_avg:93.24ms
step:16/1750 train_time:1495ms step_avg:93.41ms
step:17/1750 train_time:1592ms step_avg:93.62ms
step:18/1750 train_time:1689ms step_avg:93.86ms
step:19/1750 train_time:1787ms step_avg:94.06ms
step:20/1750 train_time:1886ms step_avg:94.29ms
step:21/1750 train_time:1983ms step_avg:94.41ms
step:22/1750 train_time:2080ms step_avg:94.55ms
step:23/1750 train_time:2178ms step_avg:94.71ms
step:24/1750 train_time:2274ms step_avg:94.74ms
step:25/1750 train_time:2371ms step_avg:94.82ms
step:26/1750 train_time:2468ms step_avg:94.92ms
step:27/1750 train_time:2565ms step_avg:94.99ms
step:28/1750 train_time:2662ms step_avg:95.06ms
step:29/1750 train_time:2759ms step_avg:95.13ms
step:30/1750 train_time:2855ms step_avg:95.18ms
step:31/1750 train_time:2952ms step_avg:95.23ms
step:32/1750 train_time:3049ms step_avg:95.29ms
step:33/1750 train_time:3147ms step_avg:95.36ms
step:34/1750 train_time:3244ms step_avg:95.42ms
step:35/1750 train_time:3340ms step_avg:95.43ms
step:36/1750 train_time:3437ms step_avg:95.47ms
step:37/1750 train_time:3534ms step_avg:95.51ms
step:38/1750 train_time:3631ms step_avg:95.56ms
step:39/1750 train_time:3727ms step_avg:95.58ms
step:40/1750 train_time:3824ms step_avg:95.61ms
step:41/1750 train_time:3921ms step_avg:95.64ms
step:42/1750 train_time:4018ms step_avg:95.66ms
step:43/1750 train_time:4115ms step_avg:95.71ms
step:44/1750 train_time:4213ms step_avg:95.74ms
step:45/1750 train_time:4310ms step_avg:95.78ms
step:46/1750 train_time:4408ms step_avg:95.82ms
step:47/1750 train_time:4506ms step_avg:95.86ms
step:48/1750 train_time:4602ms step_avg:95.88ms
step:49/1750 train_time:4700ms step_avg:95.91ms
step:50/1750 train_time:4796ms step_avg:95.92ms
step:51/1750 train_time:4893ms step_avg:95.94ms
step:52/1750 train_time:4990ms step_avg:95.96ms
step:53/1750 train_time:5086ms step_avg:95.97ms
step:54/1750 train_time:5183ms step_avg:95.98ms
step:55/1750 train_time:5280ms step_avg:96.00ms
step:56/1750 train_time:5377ms step_avg:96.02ms
step:57/1750 train_time:5474ms step_avg:96.03ms
step:58/1750 train_time:5571ms step_avg:96.04ms
step:59/1750 train_time:5668ms step_avg:96.06ms
step:60/1750 train_time:5764ms step_avg:96.07ms
step:61/1750 train_time:5862ms step_avg:96.10ms
step:62/1750 train_time:5958ms step_avg:96.10ms
step:63/1750 train_time:6055ms step_avg:96.11ms
step:64/1750 train_time:6152ms step_avg:96.12ms
step:65/1750 train_time:6249ms step_avg:96.13ms
step:66/1750 train_time:6345ms step_avg:96.14ms
step:67/1750 train_time:6443ms step_avg:96.17ms
step:68/1750 train_time:6539ms step_avg:96.17ms
step:69/1750 train_time:6636ms step_avg:96.18ms
step:70/1750 train_time:6733ms step_avg:96.19ms
step:71/1750 train_time:6830ms step_avg:96.20ms
step:72/1750 train_time:6927ms step_avg:96.21ms
step:73/1750 train_time:7024ms step_avg:96.22ms
step:74/1750 train_time:7120ms step_avg:96.22ms
step:75/1750 train_time:7217ms step_avg:96.23ms
step:76/1750 train_time:7314ms step_avg:96.24ms
step:77/1750 train_time:7411ms step_avg:96.25ms
step:78/1750 train_time:7509ms step_avg:96.27ms
step:79/1750 train_time:7608ms step_avg:96.30ms
step:80/1750 train_time:7704ms step_avg:96.31ms
step:81/1750 train_time:7801ms step_avg:96.30ms
step:82/1750 train_time:7898ms step_avg:96.31ms
step:83/1750 train_time:7995ms step_avg:96.32ms
step:84/1750 train_time:8092ms step_avg:96.33ms
step:85/1750 train_time:8189ms step_avg:96.34ms
step:86/1750 train_time:8286ms step_avg:96.34ms
step:87/1750 train_time:8382ms step_avg:96.35ms
step:88/1750 train_time:8479ms step_avg:96.35ms
step:89/1750 train_time:8575ms step_avg:96.35ms
step:90/1750 train_time:8673ms step_avg:96.36ms
step:91/1750 train_time:8769ms step_avg:96.37ms
step:92/1750 train_time:8867ms step_avg:96.38ms
step:93/1750 train_time:8964ms step_avg:96.39ms
step:94/1750 train_time:9061ms step_avg:96.39ms
step:95/1750 train_time:9157ms step_avg:96.39ms
step:96/1750 train_time:9254ms step_avg:96.40ms
step:97/1750 train_time:9351ms step_avg:96.40ms
step:98/1750 train_time:9448ms step_avg:96.41ms
step:99/1750 train_time:9545ms step_avg:96.41ms
step:100/1750 train_time:9642ms step_avg:96.42ms
step:101/1750 train_time:9738ms step_avg:96.42ms
step:102/1750 train_time:9835ms step_avg:96.42ms
step:103/1750 train_time:9932ms step_avg:96.43ms
step:104/1750 train_time:10030ms step_avg:96.45ms
step:105/1750 train_time:10127ms step_avg:96.44ms
step:106/1750 train_time:10223ms step_avg:96.45ms
step:107/1750 train_time:10320ms step_avg:96.45ms
step:108/1750 train_time:10416ms step_avg:96.44ms
step:109/1750 train_time:10512ms step_avg:96.44ms
step:110/1750 train_time:10610ms step_avg:96.46ms
step:111/1750 train_time:10707ms step_avg:96.46ms
step:112/1750 train_time:10804ms step_avg:96.46ms
step:113/1750 train_time:10901ms step_avg:96.47ms
step:114/1750 train_time:10998ms step_avg:96.47ms
step:115/1750 train_time:11095ms step_avg:96.48ms
step:116/1750 train_time:11192ms step_avg:96.48ms
step:117/1750 train_time:11289ms step_avg:96.49ms
step:118/1750 train_time:11385ms step_avg:96.49ms
step:119/1750 train_time:11482ms step_avg:96.49ms
step:120/1750 train_time:11579ms step_avg:96.49ms
step:121/1750 train_time:11676ms step_avg:96.49ms
step:122/1750 train_time:11773ms step_avg:96.50ms
step:123/1750 train_time:11870ms step_avg:96.50ms
step:124/1750 train_time:11967ms step_avg:96.51ms
step:125/1750 train_time:12063ms step_avg:96.51ms
step:125/1750 val_loss:4.6420 train_time:12155ms step_avg:97.24ms
step:126/1750 train_time:12176ms step_avg:96.63ms
step:127/1750 train_time:12265ms step_avg:96.58ms
step:128/1750 train_time:12365ms step_avg:96.60ms
step:129/1750 train_time:12465ms step_avg:96.63ms
step:130/1750 train_time:12562ms step_avg:96.63ms
step:131/1750 train_time:12659ms step_avg:96.63ms
step:132/1750 train_time:12757ms step_avg:96.64ms
step:133/1750 train_time:12853ms step_avg:96.64ms
step:134/1750 train_time:12950ms step_avg:96.64ms
step:135/1750 train_time:13047ms step_avg:96.64ms
step:136/1750 train_time:13144ms step_avg:96.65ms
step:137/1750 train_time:13241ms step_avg:96.65ms
step:138/1750 train_time:13338ms step_avg:96.65ms
step:139/1750 train_time:13435ms step_avg:96.65ms
step:140/1750 train_time:13533ms step_avg:96.66ms
step:141/1750 train_time:13629ms step_avg:96.66ms
step:142/1750 train_time:13727ms step_avg:96.67ms
step:143/1750 train_time:13826ms step_avg:96.68ms
step:144/1750 train_time:13924ms step_avg:96.70ms
step:145/1750 train_time:14022ms step_avg:96.70ms
step:146/1750 train_time:14119ms step_avg:96.71ms
step:147/1750 train_time:14217ms step_avg:96.71ms
step:148/1750 train_time:14315ms step_avg:96.72ms
step:149/1750 train_time:14411ms step_avg:96.72ms
step:150/1750 train_time:14509ms step_avg:96.72ms
step:151/1750 train_time:14607ms step_avg:96.73ms
step:152/1750 train_time:14704ms step_avg:96.73ms
step:153/1750 train_time:14800ms step_avg:96.73ms
step:154/1750 train_time:14897ms step_avg:96.74ms
step:155/1750 train_time:14995ms step_avg:96.74ms
step:156/1750 train_time:15093ms step_avg:96.75ms
step:157/1750 train_time:15190ms step_avg:96.75ms
step:158/1750 train_time:15288ms step_avg:96.76ms
step:159/1750 train_time:15386ms step_avg:96.77ms
step:160/1750 train_time:15484ms step_avg:96.77ms
step:161/1750 train_time:15581ms step_avg:96.78ms
step:162/1750 train_time:15678ms step_avg:96.78ms
step:163/1750 train_time:15775ms step_avg:96.78ms
step:164/1750 train_time:15872ms step_avg:96.78ms
step:165/1750 train_time:15969ms step_avg:96.78ms
step:166/1750 train_time:16067ms step_avg:96.79ms
step:167/1750 train_time:16164ms step_avg:96.79ms
step:168/1750 train_time:16263ms step_avg:96.80ms
step:169/1750 train_time:16360ms step_avg:96.81ms
step:170/1750 train_time:16458ms step_avg:96.81ms
step:171/1750 train_time:16555ms step_avg:96.81ms
step:172/1750 train_time:16653ms step_avg:96.82ms
step:173/1750 train_time:16749ms step_avg:96.81ms
step:174/1750 train_time:16847ms step_avg:96.82ms
step:175/1750 train_time:16945ms step_avg:96.83ms
step:176/1750 train_time:17043ms step_avg:96.84ms
step:177/1750 train_time:17140ms step_avg:96.84ms
step:178/1750 train_time:17237ms step_avg:96.84ms
step:179/1750 train_time:17334ms step_avg:96.84ms
step:180/1750 train_time:17432ms step_avg:96.85ms
step:181/1750 train_time:17530ms step_avg:96.85ms
step:182/1750 train_time:17627ms step_avg:96.85ms
step:183/1750 train_time:17725ms step_avg:96.86ms
step:184/1750 train_time:17823ms step_avg:96.87ms
step:185/1750 train_time:17920ms step_avg:96.87ms
step:186/1750 train_time:18017ms step_avg:96.87ms
step:187/1750 train_time:18115ms step_avg:96.87ms
step:188/1750 train_time:18213ms step_avg:96.88ms
step:189/1750 train_time:18310ms step_avg:96.88ms
step:190/1750 train_time:18407ms step_avg:96.88ms
step:191/1750 train_time:18505ms step_avg:96.89ms
step:192/1750 train_time:18603ms step_avg:96.89ms
step:193/1750 train_time:18701ms step_avg:96.89ms
step:194/1750 train_time:18798ms step_avg:96.90ms
step:195/1750 train_time:18896ms step_avg:96.90ms
step:196/1750 train_time:18993ms step_avg:96.90ms
step:197/1750 train_time:19091ms step_avg:96.91ms
step:198/1750 train_time:19188ms step_avg:96.91ms
step:199/1750 train_time:19287ms step_avg:96.92ms
step:200/1750 train_time:19385ms step_avg:96.92ms
step:201/1750 train_time:19483ms step_avg:96.93ms
step:202/1750 train_time:19581ms step_avg:96.94ms
step:203/1750 train_time:19679ms step_avg:96.94ms
step:204/1750 train_time:19777ms step_avg:96.94ms
step:205/1750 train_time:19874ms step_avg:96.94ms
step:206/1750 train_time:19971ms step_avg:96.95ms
step:207/1750 train_time:20068ms step_avg:96.95ms
step:208/1750 train_time:20166ms step_avg:96.95ms
step:209/1750 train_time:20264ms step_avg:96.96ms
step:210/1750 train_time:20361ms step_avg:96.96ms
step:211/1750 train_time:20459ms step_avg:96.96ms
step:212/1750 train_time:20557ms step_avg:96.97ms
step:213/1750 train_time:20654ms step_avg:96.97ms
step:214/1750 train_time:20752ms step_avg:96.97ms
step:215/1750 train_time:20850ms step_avg:96.98ms
step:216/1750 train_time:20946ms step_avg:96.97ms
step:217/1750 train_time:21044ms step_avg:96.98ms
step:218/1750 train_time:21142ms step_avg:96.98ms
step:219/1750 train_time:21238ms step_avg:96.98ms
step:220/1750 train_time:21335ms step_avg:96.98ms
step:221/1750 train_time:21433ms step_avg:96.98ms
step:222/1750 train_time:21529ms step_avg:96.98ms
step:223/1750 train_time:21627ms step_avg:96.98ms
step:224/1750 train_time:21725ms step_avg:96.99ms
step:225/1750 train_time:21822ms step_avg:96.99ms
step:226/1750 train_time:21920ms step_avg:96.99ms
step:227/1750 train_time:22017ms step_avg:96.99ms
step:228/1750 train_time:22114ms step_avg:96.99ms
step:229/1750 train_time:22212ms step_avg:96.99ms
step:230/1750 train_time:22308ms step_avg:96.99ms
step:231/1750 train_time:22407ms step_avg:97.00ms
step:232/1750 train_time:22505ms step_avg:97.01ms
step:233/1750 train_time:22604ms step_avg:97.01ms
step:234/1750 train_time:22702ms step_avg:97.02ms
step:235/1750 train_time:22799ms step_avg:97.02ms
step:236/1750 train_time:22896ms step_avg:97.02ms
step:237/1750 train_time:22993ms step_avg:97.02ms
step:238/1750 train_time:23091ms step_avg:97.02ms
step:239/1750 train_time:23189ms step_avg:97.03ms
step:240/1750 train_time:23287ms step_avg:97.03ms
step:241/1750 train_time:23385ms step_avg:97.03ms
step:242/1750 train_time:23482ms step_avg:97.03ms
step:243/1750 train_time:23580ms step_avg:97.04ms
step:244/1750 train_time:23677ms step_avg:97.03ms
step:245/1750 train_time:23774ms step_avg:97.04ms
step:246/1750 train_time:23871ms step_avg:97.04ms
step:247/1750 train_time:23969ms step_avg:97.04ms
step:248/1750 train_time:24066ms step_avg:97.04ms
step:249/1750 train_time:24164ms step_avg:97.05ms
step:250/1750 train_time:24262ms step_avg:97.05ms
step:250/1750 val_loss:4.0974 train_time:24354ms step_avg:97.41ms
step:251/1750 train_time:24375ms step_avg:97.11ms
step:252/1750 train_time:24464ms step_avg:97.08ms
step:253/1750 train_time:24562ms step_avg:97.08ms
step:254/1750 train_time:24659ms step_avg:97.08ms
step:255/1750 train_time:24758ms step_avg:97.09ms
step:256/1750 train_time:24855ms step_avg:97.09ms
step:257/1750 train_time:24952ms step_avg:97.09ms
step:258/1750 train_time:25049ms step_avg:97.09ms
step:259/1750 train_time:25146ms step_avg:97.09ms
step:260/1750 train_time:25243ms step_avg:97.09ms
step:261/1750 train_time:25339ms step_avg:97.09ms
step:262/1750 train_time:25438ms step_avg:97.09ms
step:263/1750 train_time:25537ms step_avg:97.10ms
step:264/1750 train_time:25637ms step_avg:97.11ms
step:265/1750 train_time:25736ms step_avg:97.12ms
step:266/1750 train_time:25834ms step_avg:97.12ms
step:267/1750 train_time:25932ms step_avg:97.13ms
step:268/1750 train_time:26030ms step_avg:97.13ms
step:269/1750 train_time:26127ms step_avg:97.13ms
step:270/1750 train_time:26225ms step_avg:97.13ms
step:271/1750 train_time:26323ms step_avg:97.13ms
step:272/1750 train_time:26421ms step_avg:97.14ms
step:273/1750 train_time:26518ms step_avg:97.14ms
step:274/1750 train_time:26616ms step_avg:97.14ms
step:275/1750 train_time:26715ms step_avg:97.14ms
step:276/1750 train_time:26813ms step_avg:97.15ms
step:277/1750 train_time:26910ms step_avg:97.15ms
step:278/1750 train_time:27008ms step_avg:97.15ms
step:279/1750 train_time:27106ms step_avg:97.15ms
step:280/1750 train_time:27203ms step_avg:97.15ms
step:281/1750 train_time:27301ms step_avg:97.16ms
step:282/1750 train_time:27399ms step_avg:97.16ms
step:283/1750 train_time:27497ms step_avg:97.16ms
step:284/1750 train_time:27596ms step_avg:97.17ms
step:285/1750 train_time:27694ms step_avg:97.17ms
step:286/1750 train_time:27792ms step_avg:97.18ms
step:287/1750 train_time:27890ms step_avg:97.18ms
step:288/1750 train_time:27988ms step_avg:97.18ms
step:289/1750 train_time:28086ms step_avg:97.18ms
step:290/1750 train_time:28184ms step_avg:97.18ms
step:291/1750 train_time:28281ms step_avg:97.19ms
step:292/1750 train_time:28379ms step_avg:97.19ms
step:293/1750 train_time:28477ms step_avg:97.19ms
step:294/1750 train_time:28575ms step_avg:97.19ms
step:295/1750 train_time:28672ms step_avg:97.19ms
step:296/1750 train_time:28770ms step_avg:97.19ms
step:297/1750 train_time:28867ms step_avg:97.20ms
step:298/1750 train_time:28965ms step_avg:97.20ms
step:299/1750 train_time:29063ms step_avg:97.20ms
step:300/1750 train_time:29161ms step_avg:97.20ms
step:301/1750 train_time:29260ms step_avg:97.21ms
step:302/1750 train_time:29358ms step_avg:97.21ms
step:303/1750 train_time:29457ms step_avg:97.22ms
step:304/1750 train_time:29555ms step_avg:97.22ms
step:305/1750 train_time:29653ms step_avg:97.22ms
step:306/1750 train_time:29751ms step_avg:97.22ms
step:307/1750 train_time:29848ms step_avg:97.23ms
step:308/1750 train_time:29947ms step_avg:97.23ms
step:309/1750 train_time:30045ms step_avg:97.23ms
step:310/1750 train_time:30143ms step_avg:97.24ms
step:311/1750 train_time:30241ms step_avg:97.24ms
step:312/1750 train_time:30338ms step_avg:97.24ms
step:313/1750 train_time:30437ms step_avg:97.24ms
step:314/1750 train_time:30535ms step_avg:97.25ms
step:315/1750 train_time:30633ms step_avg:97.25ms
step:316/1750 train_time:30731ms step_avg:97.25ms
step:317/1750 train_time:30828ms step_avg:97.25ms
step:318/1750 train_time:30926ms step_avg:97.25ms
step:319/1750 train_time:31024ms step_avg:97.25ms
step:320/1750 train_time:31122ms step_avg:97.26ms
step:321/1750 train_time:31220ms step_avg:97.26ms
step:322/1750 train_time:31319ms step_avg:97.26ms
step:323/1750 train_time:31417ms step_avg:97.27ms
step:324/1750 train_time:31516ms step_avg:97.27ms
step:325/1750 train_time:31614ms step_avg:97.27ms
step:326/1750 train_time:31712ms step_avg:97.28ms
step:327/1750 train_time:31810ms step_avg:97.28ms
step:328/1750 train_time:31909ms step_avg:97.28ms
step:329/1750 train_time:32007ms step_avg:97.28ms
step:330/1750 train_time:32104ms step_avg:97.29ms
step:331/1750 train_time:32202ms step_avg:97.29ms
step:332/1750 train_time:32300ms step_avg:97.29ms
step:333/1750 train_time:32398ms step_avg:97.29ms
step:334/1750 train_time:32496ms step_avg:97.29ms
step:335/1750 train_time:32595ms step_avg:97.30ms
step:336/1750 train_time:32693ms step_avg:97.30ms
step:337/1750 train_time:32790ms step_avg:97.30ms
step:338/1750 train_time:32888ms step_avg:97.30ms
step:339/1750 train_time:32986ms step_avg:97.30ms
step:340/1750 train_time:33083ms step_avg:97.30ms
step:341/1750 train_time:33181ms step_avg:97.31ms
step:342/1750 train_time:33279ms step_avg:97.31ms
step:343/1750 train_time:33377ms step_avg:97.31ms
step:344/1750 train_time:33476ms step_avg:97.31ms
step:345/1750 train_time:33573ms step_avg:97.31ms
step:346/1750 train_time:33670ms step_avg:97.31ms
step:347/1750 train_time:33768ms step_avg:97.31ms
step:348/1750 train_time:33866ms step_avg:97.31ms
step:349/1750 train_time:33964ms step_avg:97.32ms
step:350/1750 train_time:34062ms step_avg:97.32ms
step:351/1750 train_time:34159ms step_avg:97.32ms
step:352/1750 train_time:34257ms step_avg:97.32ms
step:353/1750 train_time:34356ms step_avg:97.32ms
step:354/1750 train_time:34454ms step_avg:97.33ms
step:355/1750 train_time:34552ms step_avg:97.33ms
step:356/1750 train_time:34649ms step_avg:97.33ms
step:357/1750 train_time:34747ms step_avg:97.33ms
step:358/1750 train_time:34844ms step_avg:97.33ms
step:359/1750 train_time:34942ms step_avg:97.33ms
step:360/1750 train_time:35041ms step_avg:97.34ms
step:361/1750 train_time:35139ms step_avg:97.34ms
step:362/1750 train_time:35238ms step_avg:97.34ms
step:363/1750 train_time:35336ms step_avg:97.35ms
step:364/1750 train_time:35435ms step_avg:97.35ms
step:365/1750 train_time:35535ms step_avg:97.35ms
step:366/1750 train_time:35632ms step_avg:97.35ms
step:367/1750 train_time:35730ms step_avg:97.36ms
step:368/1750 train_time:35828ms step_avg:97.36ms
step:369/1750 train_time:35925ms step_avg:97.36ms
step:370/1750 train_time:36023ms step_avg:97.36ms
step:371/1750 train_time:36122ms step_avg:97.36ms
step:372/1750 train_time:36219ms step_avg:97.36ms
step:373/1750 train_time:36317ms step_avg:97.37ms
step:374/1750 train_time:36416ms step_avg:97.37ms
step:375/1750 train_time:36514ms step_avg:97.37ms
step:375/1750 val_loss:3.8932 train_time:36606ms step_avg:97.62ms
step:376/1750 train_time:36626ms step_avg:97.41ms
step:377/1750 train_time:36717ms step_avg:97.39ms
step:378/1750 train_time:36819ms step_avg:97.41ms
step:379/1750 train_time:36919ms step_avg:97.41ms
step:380/1750 train_time:37016ms step_avg:97.41ms
step:381/1750 train_time:37114ms step_avg:97.41ms
step:382/1750 train_time:37211ms step_avg:97.41ms
step:383/1750 train_time:37310ms step_avg:97.41ms
step:384/1750 train_time:37408ms step_avg:97.42ms
step:385/1750 train_time:37506ms step_avg:97.42ms
step:386/1750 train_time:37604ms step_avg:97.42ms
step:387/1750 train_time:37702ms step_avg:97.42ms
step:388/1750 train_time:37799ms step_avg:97.42ms
step:389/1750 train_time:37898ms step_avg:97.42ms
step:390/1750 train_time:37995ms step_avg:97.42ms
step:391/1750 train_time:38094ms step_avg:97.43ms
step:392/1750 train_time:38193ms step_avg:97.43ms
step:393/1750 train_time:38293ms step_avg:97.44ms
step:394/1750 train_time:38392ms step_avg:97.44ms
step:395/1750 train_time:38493ms step_avg:97.45ms
step:396/1750 train_time:38593ms step_avg:97.46ms
step:397/1750 train_time:38695ms step_avg:97.47ms
step:398/1750 train_time:38795ms step_avg:97.48ms
step:399/1750 train_time:38896ms step_avg:97.48ms
step:400/1750 train_time:38996ms step_avg:97.49ms
step:401/1750 train_time:39095ms step_avg:97.49ms
step:402/1750 train_time:39194ms step_avg:97.50ms
step:403/1750 train_time:39294ms step_avg:97.50ms
step:404/1750 train_time:39393ms step_avg:97.51ms
step:405/1750 train_time:39492ms step_avg:97.51ms
step:406/1750 train_time:39592ms step_avg:97.52ms
step:407/1750 train_time:39692ms step_avg:97.52ms
step:408/1750 train_time:39791ms step_avg:97.53ms
step:409/1750 train_time:39891ms step_avg:97.53ms
step:410/1750 train_time:39992ms step_avg:97.54ms
step:411/1750 train_time:40093ms step_avg:97.55ms
step:412/1750 train_time:40192ms step_avg:97.55ms
step:413/1750 train_time:40292ms step_avg:97.56ms
step:414/1750 train_time:40392ms step_avg:97.57ms
step:415/1750 train_time:40493ms step_avg:97.57ms
step:416/1750 train_time:40593ms step_avg:97.58ms
step:417/1750 train_time:40693ms step_avg:97.58ms
step:418/1750 train_time:40793ms step_avg:97.59ms
step:419/1750 train_time:40894ms step_avg:97.60ms
step:420/1750 train_time:40993ms step_avg:97.60ms
step:421/1750 train_time:41093ms step_avg:97.61ms
step:422/1750 train_time:41194ms step_avg:97.62ms
step:423/1750 train_time:41292ms step_avg:97.62ms
step:424/1750 train_time:41392ms step_avg:97.62ms
step:425/1750 train_time:41491ms step_avg:97.63ms
step:426/1750 train_time:41591ms step_avg:97.63ms
step:427/1750 train_time:41692ms step_avg:97.64ms
step:428/1750 train_time:41791ms step_avg:97.64ms
step:429/1750 train_time:41891ms step_avg:97.65ms
step:430/1750 train_time:41991ms step_avg:97.65ms
step:431/1750 train_time:42091ms step_avg:97.66ms
step:432/1750 train_time:42191ms step_avg:97.67ms
step:433/1750 train_time:42291ms step_avg:97.67ms
step:434/1750 train_time:42392ms step_avg:97.68ms
step:435/1750 train_time:42490ms step_avg:97.68ms
step:436/1750 train_time:42590ms step_avg:97.68ms
step:437/1750 train_time:42689ms step_avg:97.69ms
step:438/1750 train_time:42788ms step_avg:97.69ms
step:439/1750 train_time:42888ms step_avg:97.70ms
step:440/1750 train_time:42988ms step_avg:97.70ms
step:441/1750 train_time:43089ms step_avg:97.71ms
step:442/1750 train_time:43190ms step_avg:97.72ms
step:443/1750 train_time:43291ms step_avg:97.72ms
step:444/1750 train_time:43394ms step_avg:97.73ms
step:445/1750 train_time:43494ms step_avg:97.74ms
step:446/1750 train_time:43595ms step_avg:97.75ms
step:447/1750 train_time:43693ms step_avg:97.75ms
step:448/1750 train_time:43792ms step_avg:97.75ms
step:449/1750 train_time:43892ms step_avg:97.76ms
step:450/1750 train_time:43991ms step_avg:97.76ms
step:451/1750 train_time:44091ms step_avg:97.76ms
step:452/1750 train_time:44191ms step_avg:97.77ms
step:453/1750 train_time:44291ms step_avg:97.77ms
step:454/1750 train_time:44391ms step_avg:97.78ms
step:455/1750 train_time:44491ms step_avg:97.78ms
step:456/1750 train_time:44590ms step_avg:97.79ms
step:457/1750 train_time:44691ms step_avg:97.79ms
step:458/1750 train_time:44791ms step_avg:97.80ms
step:459/1750 train_time:44891ms step_avg:97.80ms
step:460/1750 train_time:44991ms step_avg:97.81ms
step:461/1750 train_time:45091ms step_avg:97.81ms
step:462/1750 train_time:45191ms step_avg:97.82ms
step:463/1750 train_time:45291ms step_avg:97.82ms
step:464/1750 train_time:45391ms step_avg:97.83ms
step:465/1750 train_time:45491ms step_avg:97.83ms
step:466/1750 train_time:45592ms step_avg:97.84ms
step:467/1750 train_time:45691ms step_avg:97.84ms
step:468/1750 train_time:45791ms step_avg:97.84ms
step:469/1750 train_time:45891ms step_avg:97.85ms
step:470/1750 train_time:45991ms step_avg:97.85ms
step:471/1750 train_time:46092ms step_avg:97.86ms
step:472/1750 train_time:46192ms step_avg:97.87ms
step:473/1750 train_time:46293ms step_avg:97.87ms
step:474/1750 train_time:46393ms step_avg:97.87ms
step:475/1750 train_time:46492ms step_avg:97.88ms
step:476/1750 train_time:46591ms step_avg:97.88ms
step:477/1750 train_time:46691ms step_avg:97.88ms
step:478/1750 train_time:46790ms step_avg:97.89ms
step:479/1750 train_time:46889ms step_avg:97.89ms
step:480/1750 train_time:46989ms step_avg:97.89ms
step:481/1750 train_time:47089ms step_avg:97.90ms
step:482/1750 train_time:47189ms step_avg:97.90ms
step:483/1750 train_time:47290ms step_avg:97.91ms
step:484/1750 train_time:47389ms step_avg:97.91ms
step:485/1750 train_time:47490ms step_avg:97.92ms
step:486/1750 train_time:47590ms step_avg:97.92ms
step:487/1750 train_time:47691ms step_avg:97.93ms
step:488/1750 train_time:47790ms step_avg:97.93ms
step:489/1750 train_time:47891ms step_avg:97.94ms
step:490/1750 train_time:47991ms step_avg:97.94ms
step:491/1750 train_time:48091ms step_avg:97.95ms
step:492/1750 train_time:48192ms step_avg:97.95ms
step:493/1750 train_time:48291ms step_avg:97.95ms
step:494/1750 train_time:48391ms step_avg:97.96ms
step:495/1750 train_time:48492ms step_avg:97.96ms
step:496/1750 train_time:48593ms step_avg:97.97ms
step:497/1750 train_time:48693ms step_avg:97.97ms
step:498/1750 train_time:48792ms step_avg:97.98ms
step:499/1750 train_time:48891ms step_avg:97.98ms
step:500/1750 train_time:48991ms step_avg:97.98ms
step:500/1750 val_loss:3.7457 train_time:49085ms step_avg:98.17ms
step:501/1750 train_time:49105ms step_avg:98.01ms
step:502/1750 train_time:49199ms step_avg:98.01ms
step:503/1750 train_time:49301ms step_avg:98.01ms
step:504/1750 train_time:49402ms step_avg:98.02ms
step:505/1750 train_time:49501ms step_avg:98.02ms
step:506/1750 train_time:49601ms step_avg:98.03ms
step:507/1750 train_time:49700ms step_avg:98.03ms
step:508/1750 train_time:49800ms step_avg:98.03ms
step:509/1750 train_time:49899ms step_avg:98.03ms
step:510/1750 train_time:49999ms step_avg:98.04ms
step:511/1750 train_time:50099ms step_avg:98.04ms
step:512/1750 train_time:50199ms step_avg:98.05ms
step:513/1750 train_time:50299ms step_avg:98.05ms
step:514/1750 train_time:50400ms step_avg:98.05ms
step:515/1750 train_time:50500ms step_avg:98.06ms
step:516/1750 train_time:50601ms step_avg:98.06ms
step:517/1750 train_time:50701ms step_avg:98.07ms
step:518/1750 train_time:50801ms step_avg:98.07ms
step:519/1750 train_time:50902ms step_avg:98.08ms
step:520/1750 train_time:51002ms step_avg:98.08ms
step:521/1750 train_time:51102ms step_avg:98.08ms
step:522/1750 train_time:51202ms step_avg:98.09ms
step:523/1750 train_time:51302ms step_avg:98.09ms
step:524/1750 train_time:51403ms step_avg:98.10ms
step:525/1750 train_time:51503ms step_avg:98.10ms
step:526/1750 train_time:51603ms step_avg:98.10ms
step:527/1750 train_time:51703ms step_avg:98.11ms
step:528/1750 train_time:51804ms step_avg:98.11ms
step:529/1750 train_time:51904ms step_avg:98.12ms
step:530/1750 train_time:52005ms step_avg:98.12ms
step:531/1750 train_time:52105ms step_avg:98.13ms
step:532/1750 train_time:52205ms step_avg:98.13ms
step:533/1750 train_time:52305ms step_avg:98.13ms
step:534/1750 train_time:52406ms step_avg:98.14ms
step:535/1750 train_time:52507ms step_avg:98.14ms
step:536/1750 train_time:52609ms step_avg:98.15ms
step:537/1750 train_time:52710ms step_avg:98.16ms
step:538/1750 train_time:52810ms step_avg:98.16ms
step:539/1750 train_time:52911ms step_avg:98.16ms
step:540/1750 train_time:53010ms step_avg:98.17ms
step:541/1750 train_time:53110ms step_avg:98.17ms
step:542/1750 train_time:53210ms step_avg:98.17ms
step:543/1750 train_time:53311ms step_avg:98.18ms
step:544/1750 train_time:53411ms step_avg:98.18ms
step:545/1750 train_time:53511ms step_avg:98.19ms
step:546/1750 train_time:53611ms step_avg:98.19ms
step:547/1750 train_time:53711ms step_avg:98.19ms
step:548/1750 train_time:53812ms step_avg:98.20ms
step:549/1750 train_time:53912ms step_avg:98.20ms
step:550/1750 train_time:54013ms step_avg:98.20ms
step:551/1750 train_time:54112ms step_avg:98.21ms
step:552/1750 train_time:54212ms step_avg:98.21ms
step:553/1750 train_time:54312ms step_avg:98.21ms
step:554/1750 train_time:54412ms step_avg:98.22ms
step:555/1750 train_time:54512ms step_avg:98.22ms
step:556/1750 train_time:54612ms step_avg:98.22ms
step:557/1750 train_time:54712ms step_avg:98.23ms
step:558/1750 train_time:54812ms step_avg:98.23ms
step:559/1750 train_time:54913ms step_avg:98.23ms
step:560/1750 train_time:55014ms step_avg:98.24ms
step:561/1750 train_time:55113ms step_avg:98.24ms
step:562/1750 train_time:55213ms step_avg:98.24ms
step:563/1750 train_time:55313ms step_avg:98.25ms
step:564/1750 train_time:55413ms step_avg:98.25ms
step:565/1750 train_time:55514ms step_avg:98.25ms
step:566/1750 train_time:55613ms step_avg:98.26ms
step:567/1750 train_time:55713ms step_avg:98.26ms
step:568/1750 train_time:55814ms step_avg:98.26ms
step:569/1750 train_time:55915ms step_avg:98.27ms
step:570/1750 train_time:56016ms step_avg:98.27ms
step:571/1750 train_time:56118ms step_avg:98.28ms
step:572/1750 train_time:56220ms step_avg:98.29ms
step:573/1750 train_time:56320ms step_avg:98.29ms
step:574/1750 train_time:56421ms step_avg:98.29ms
step:575/1750 train_time:56521ms step_avg:98.30ms
step:576/1750 train_time:56621ms step_avg:98.30ms
step:577/1750 train_time:56721ms step_avg:98.30ms
step:578/1750 train_time:56821ms step_avg:98.31ms
step:579/1750 train_time:56921ms step_avg:98.31ms
step:580/1750 train_time:57022ms step_avg:98.31ms
step:581/1750 train_time:57121ms step_avg:98.32ms
step:582/1750 train_time:57222ms step_avg:98.32ms
step:583/1750 train_time:57322ms step_avg:98.32ms
step:584/1750 train_time:57422ms step_avg:98.32ms
step:585/1750 train_time:57522ms step_avg:98.33ms
step:586/1750 train_time:57622ms step_avg:98.33ms
step:587/1750 train_time:57722ms step_avg:98.33ms
step:588/1750 train_time:57823ms step_avg:98.34ms
step:589/1750 train_time:57923ms step_avg:98.34ms
step:590/1750 train_time:58024ms step_avg:98.35ms
step:591/1750 train_time:58125ms step_avg:98.35ms
step:592/1750 train_time:58226ms step_avg:98.36ms
step:593/1750 train_time:58327ms step_avg:98.36ms
step:594/1750 train_time:58428ms step_avg:98.36ms
step:595/1750 train_time:58528ms step_avg:98.37ms
step:596/1750 train_time:58629ms step_avg:98.37ms
step:597/1750 train_time:58730ms step_avg:98.37ms
step:598/1750 train_time:58830ms step_avg:98.38ms
step:599/1750 train_time:58930ms step_avg:98.38ms
step:600/1750 train_time:59030ms step_avg:98.38ms
step:601/1750 train_time:59131ms step_avg:98.39ms
step:602/1750 train_time:59231ms step_avg:98.39ms
step:603/1750 train_time:59332ms step_avg:98.39ms
step:604/1750 train_time:59432ms step_avg:98.40ms
step:605/1750 train_time:59532ms step_avg:98.40ms
step:606/1750 train_time:59632ms step_avg:98.40ms
step:607/1750 train_time:59732ms step_avg:98.41ms
step:608/1750 train_time:59833ms step_avg:98.41ms
step:609/1750 train_time:59934ms step_avg:98.41ms
step:610/1750 train_time:60033ms step_avg:98.42ms
step:611/1750 train_time:60133ms step_avg:98.42ms
step:612/1750 train_time:60234ms step_avg:98.42ms
step:613/1750 train_time:60335ms step_avg:98.43ms
step:614/1750 train_time:60436ms step_avg:98.43ms
step:615/1750 train_time:60536ms step_avg:98.43ms
step:616/1750 train_time:60637ms step_avg:98.44ms
step:617/1750 train_time:60739ms step_avg:98.44ms
step:618/1750 train_time:60840ms step_avg:98.45ms
step:619/1750 train_time:60940ms step_avg:98.45ms
step:620/1750 train_time:61041ms step_avg:98.45ms
step:621/1750 train_time:61141ms step_avg:98.46ms
step:622/1750 train_time:61242ms step_avg:98.46ms
step:623/1750 train_time:61341ms step_avg:98.46ms
step:624/1750 train_time:61443ms step_avg:98.47ms
step:625/1750 train_time:61542ms step_avg:98.47ms
step:625/1750 val_loss:3.6622 train_time:61636ms step_avg:98.62ms
step:626/1750 train_time:61656ms step_avg:98.49ms
step:627/1750 train_time:61749ms step_avg:98.48ms
step:628/1750 train_time:61851ms step_avg:98.49ms
step:629/1750 train_time:61952ms step_avg:98.49ms
step:630/1750 train_time:62052ms step_avg:98.50ms
step:631/1750 train_time:62152ms step_avg:98.50ms
step:632/1750 train_time:62252ms step_avg:98.50ms
step:633/1750 train_time:62353ms step_avg:98.50ms
step:634/1750 train_time:62452ms step_avg:98.51ms
step:635/1750 train_time:62551ms step_avg:98.51ms
step:636/1750 train_time:62652ms step_avg:98.51ms
step:637/1750 train_time:62753ms step_avg:98.51ms
step:638/1750 train_time:62855ms step_avg:98.52ms
step:639/1750 train_time:62955ms step_avg:98.52ms
step:640/1750 train_time:63056ms step_avg:98.53ms
step:641/1750 train_time:63157ms step_avg:98.53ms
step:642/1750 train_time:63257ms step_avg:98.53ms
step:643/1750 train_time:63358ms step_avg:98.53ms
step:644/1750 train_time:63458ms step_avg:98.54ms
step:645/1750 train_time:63559ms step_avg:98.54ms
step:646/1750 train_time:63658ms step_avg:98.54ms
step:647/1750 train_time:63759ms step_avg:98.55ms
step:648/1750 train_time:63859ms step_avg:98.55ms
step:649/1750 train_time:63959ms step_avg:98.55ms
step:650/1750 train_time:64059ms step_avg:98.55ms
step:651/1750 train_time:64161ms step_avg:98.56ms
step:652/1750 train_time:64263ms step_avg:98.56ms
step:653/1750 train_time:64365ms step_avg:98.57ms
step:654/1750 train_time:64468ms step_avg:98.57ms
step:655/1750 train_time:64571ms step_avg:98.58ms
step:656/1750 train_time:64672ms step_avg:98.59ms
step:657/1750 train_time:64774ms step_avg:98.59ms
step:658/1750 train_time:64875ms step_avg:98.59ms
step:659/1750 train_time:64976ms step_avg:98.60ms
step:660/1750 train_time:65078ms step_avg:98.60ms
step:661/1750 train_time:65179ms step_avg:98.61ms
step:662/1750 train_time:65281ms step_avg:98.61ms
step:663/1750 train_time:65383ms step_avg:98.62ms
step:664/1750 train_time:65484ms step_avg:98.62ms
step:665/1750 train_time:65586ms step_avg:98.62ms
step:666/1750 train_time:65687ms step_avg:98.63ms
step:667/1750 train_time:65791ms step_avg:98.64ms
step:668/1750 train_time:65892ms step_avg:98.64ms
step:669/1750 train_time:65995ms step_avg:98.65ms
step:670/1750 train_time:66096ms step_avg:98.65ms
step:671/1750 train_time:66198ms step_avg:98.66ms
step:672/1750 train_time:66300ms step_avg:98.66ms
step:673/1750 train_time:66401ms step_avg:98.66ms
step:674/1750 train_time:66502ms step_avg:98.67ms
step:675/1750 train_time:66604ms step_avg:98.67ms
step:676/1750 train_time:66705ms step_avg:98.68ms
step:677/1750 train_time:66808ms step_avg:98.68ms
step:678/1750 train_time:66910ms step_avg:98.69ms
step:679/1750 train_time:67012ms step_avg:98.69ms
step:680/1750 train_time:67114ms step_avg:98.70ms
step:681/1750 train_time:67216ms step_avg:98.70ms
step:682/1750 train_time:67318ms step_avg:98.71ms
step:683/1750 train_time:67419ms step_avg:98.71ms
step:684/1750 train_time:67522ms step_avg:98.72ms
step:685/1750 train_time:67623ms step_avg:98.72ms
step:686/1750 train_time:67724ms step_avg:98.72ms
step:687/1750 train_time:67827ms step_avg:98.73ms
step:688/1750 train_time:67930ms step_avg:98.74ms
step:689/1750 train_time:68033ms step_avg:98.74ms
step:690/1750 train_time:68135ms step_avg:98.75ms
step:691/1750 train_time:68237ms step_avg:98.75ms
step:692/1750 train_time:68338ms step_avg:98.75ms
step:693/1750 train_time:68440ms step_avg:98.76ms
step:694/1750 train_time:68541ms step_avg:98.76ms
step:695/1750 train_time:68642ms step_avg:98.77ms
step:696/1750 train_time:68744ms step_avg:98.77ms
step:697/1750 train_time:68845ms step_avg:98.77ms
step:698/1750 train_time:68948ms step_avg:98.78ms
step:699/1750 train_time:69051ms step_avg:98.79ms
step:700/1750 train_time:69154ms step_avg:98.79ms
step:701/1750 train_time:69257ms step_avg:98.80ms
step:702/1750 train_time:69360ms step_avg:98.80ms
step:703/1750 train_time:69461ms step_avg:98.81ms
step:704/1750 train_time:69564ms step_avg:98.81ms
step:705/1750 train_time:69664ms step_avg:98.81ms
step:706/1750 train_time:69766ms step_avg:98.82ms
step:707/1750 train_time:69867ms step_avg:98.82ms
step:708/1750 train_time:69969ms step_avg:98.83ms
step:709/1750 train_time:70072ms step_avg:98.83ms
step:710/1750 train_time:70174ms step_avg:98.84ms
step:711/1750 train_time:70276ms step_avg:98.84ms
step:712/1750 train_time:70377ms step_avg:98.84ms
step:713/1750 train_time:70479ms step_avg:98.85ms
step:714/1750 train_time:70580ms step_avg:98.85ms
step:715/1750 train_time:70681ms step_avg:98.86ms
step:716/1750 train_time:70783ms step_avg:98.86ms
step:717/1750 train_time:70884ms step_avg:98.86ms
step:718/1750 train_time:70987ms step_avg:98.87ms
step:719/1750 train_time:71090ms step_avg:98.87ms
step:720/1750 train_time:71192ms step_avg:98.88ms
step:721/1750 train_time:71294ms step_avg:98.88ms
step:722/1750 train_time:71396ms step_avg:98.89ms
step:723/1750 train_time:71497ms step_avg:98.89ms
step:724/1750 train_time:71599ms step_avg:98.89ms
step:725/1750 train_time:71701ms step_avg:98.90ms
step:726/1750 train_time:71803ms step_avg:98.90ms
step:727/1750 train_time:71905ms step_avg:98.91ms
step:728/1750 train_time:72006ms step_avg:98.91ms
step:729/1750 train_time:72109ms step_avg:98.91ms
step:730/1750 train_time:72211ms step_avg:98.92ms
step:731/1750 train_time:72314ms step_avg:98.92ms
step:732/1750 train_time:72415ms step_avg:98.93ms
step:733/1750 train_time:72516ms step_avg:98.93ms
step:734/1750 train_time:72617ms step_avg:98.93ms
step:735/1750 train_time:72718ms step_avg:98.94ms
step:736/1750 train_time:72821ms step_avg:98.94ms
step:737/1750 train_time:72922ms step_avg:98.94ms
step:738/1750 train_time:73024ms step_avg:98.95ms
step:739/1750 train_time:73125ms step_avg:98.95ms
step:740/1750 train_time:73227ms step_avg:98.96ms
step:741/1750 train_time:73330ms step_avg:98.96ms
step:742/1750 train_time:73432ms step_avg:98.96ms
step:743/1750 train_time:73534ms step_avg:98.97ms
step:744/1750 train_time:73635ms step_avg:98.97ms
step:745/1750 train_time:73736ms step_avg:98.97ms
step:746/1750 train_time:73838ms step_avg:98.98ms
step:747/1750 train_time:73940ms step_avg:98.98ms
step:748/1750 train_time:74043ms step_avg:98.99ms
step:749/1750 train_time:74145ms step_avg:98.99ms
step:750/1750 train_time:74247ms step_avg:99.00ms
step:750/1750 val_loss:3.5976 train_time:74343ms step_avg:99.12ms
step:751/1750 train_time:74364ms step_avg:99.02ms
step:752/1750 train_time:74460ms step_avg:99.02ms
step:753/1750 train_time:74563ms step_avg:99.02ms
step:754/1750 train_time:74667ms step_avg:99.03ms
step:755/1750 train_time:74769ms step_avg:99.03ms
step:756/1750 train_time:74870ms step_avg:99.03ms
step:757/1750 train_time:74972ms step_avg:99.04ms
step:758/1750 train_time:75074ms step_avg:99.04ms
step:759/1750 train_time:75175ms step_avg:99.04ms
step:760/1750 train_time:75276ms step_avg:99.05ms
step:761/1750 train_time:75379ms step_avg:99.05ms
step:762/1750 train_time:75481ms step_avg:99.06ms
step:763/1750 train_time:75583ms step_avg:99.06ms
step:764/1750 train_time:75684ms step_avg:99.06ms
step:765/1750 train_time:75787ms step_avg:99.07ms
step:766/1750 train_time:75890ms step_avg:99.07ms
step:767/1750 train_time:75992ms step_avg:99.08ms
step:768/1750 train_time:76094ms step_avg:99.08ms
step:769/1750 train_time:76195ms step_avg:99.08ms
step:770/1750 train_time:76297ms step_avg:99.09ms
step:771/1750 train_time:76398ms step_avg:99.09ms
step:772/1750 train_time:76499ms step_avg:99.09ms
step:773/1750 train_time:76601ms step_avg:99.10ms
step:774/1750 train_time:76703ms step_avg:99.10ms
step:775/1750 train_time:76804ms step_avg:99.10ms
step:776/1750 train_time:76907ms step_avg:99.11ms
step:777/1750 train_time:77010ms step_avg:99.11ms
step:778/1750 train_time:77112ms step_avg:99.12ms
step:779/1750 train_time:77214ms step_avg:99.12ms
step:780/1750 train_time:77315ms step_avg:99.12ms
step:781/1750 train_time:77417ms step_avg:99.13ms
step:782/1750 train_time:77519ms step_avg:99.13ms
step:783/1750 train_time:77620ms step_avg:99.13ms
step:784/1750 train_time:77722ms step_avg:99.14ms
step:785/1750 train_time:77825ms step_avg:99.14ms
step:786/1750 train_time:77928ms step_avg:99.15ms
step:787/1750 train_time:78031ms step_avg:99.15ms
step:788/1750 train_time:78134ms step_avg:99.15ms
step:789/1750 train_time:78237ms step_avg:99.16ms
step:790/1750 train_time:78337ms step_avg:99.16ms
step:791/1750 train_time:78440ms step_avg:99.17ms
step:792/1750 train_time:78541ms step_avg:99.17ms
step:793/1750 train_time:78643ms step_avg:99.17ms
step:794/1750 train_time:78746ms step_avg:99.18ms
step:795/1750 train_time:78848ms step_avg:99.18ms
step:796/1750 train_time:78950ms step_avg:99.18ms
step:797/1750 train_time:79052ms step_avg:99.19ms
step:798/1750 train_time:79154ms step_avg:99.19ms
step:799/1750 train_time:79256ms step_avg:99.19ms
step:800/1750 train_time:79358ms step_avg:99.20ms
step:801/1750 train_time:79460ms step_avg:99.20ms
step:802/1750 train_time:79562ms step_avg:99.20ms
step:803/1750 train_time:79664ms step_avg:99.21ms
step:804/1750 train_time:79765ms step_avg:99.21ms
step:805/1750 train_time:79868ms step_avg:99.21ms
step:806/1750 train_time:79971ms step_avg:99.22ms
step:807/1750 train_time:80073ms step_avg:99.22ms
step:808/1750 train_time:80175ms step_avg:99.23ms
step:809/1750 train_time:80278ms step_avg:99.23ms
step:810/1750 train_time:80380ms step_avg:99.23ms
step:811/1750 train_time:80482ms step_avg:99.24ms
step:812/1750 train_time:80583ms step_avg:99.24ms
step:813/1750 train_time:80686ms step_avg:99.24ms
step:814/1750 train_time:80788ms step_avg:99.25ms
step:815/1750 train_time:80890ms step_avg:99.25ms
step:816/1750 train_time:80992ms step_avg:99.25ms
step:817/1750 train_time:81094ms step_avg:99.26ms
step:818/1750 train_time:81195ms step_avg:99.26ms
step:819/1750 train_time:81297ms step_avg:99.26ms
step:820/1750 train_time:81399ms step_avg:99.27ms
step:821/1750 train_time:81501ms step_avg:99.27ms
step:822/1750 train_time:81602ms step_avg:99.27ms
step:823/1750 train_time:81704ms step_avg:99.28ms
step:824/1750 train_time:81807ms step_avg:99.28ms
step:825/1750 train_time:81910ms step_avg:99.28ms
step:826/1750 train_time:82012ms step_avg:99.29ms
step:827/1750 train_time:82114ms step_avg:99.29ms
step:828/1750 train_time:82216ms step_avg:99.29ms
step:829/1750 train_time:82318ms step_avg:99.30ms
step:830/1750 train_time:82420ms step_avg:99.30ms
step:831/1750 train_time:82521ms step_avg:99.30ms
step:832/1750 train_time:82623ms step_avg:99.31ms
step:833/1750 train_time:82726ms step_avg:99.31ms
step:834/1750 train_time:82829ms step_avg:99.31ms
step:835/1750 train_time:82930ms step_avg:99.32ms
step:836/1750 train_time:83032ms step_avg:99.32ms
step:837/1750 train_time:83136ms step_avg:99.33ms
step:838/1750 train_time:83238ms step_avg:99.33ms
step:839/1750 train_time:83340ms step_avg:99.33ms
step:840/1750 train_time:83441ms step_avg:99.33ms
step:841/1750 train_time:83543ms step_avg:99.34ms
step:842/1750 train_time:83645ms step_avg:99.34ms
step:843/1750 train_time:83747ms step_avg:99.34ms
step:844/1750 train_time:83850ms step_avg:99.35ms
step:845/1750 train_time:83951ms step_avg:99.35ms
step:846/1750 train_time:84053ms step_avg:99.35ms
step:847/1750 train_time:84156ms step_avg:99.36ms
step:848/1750 train_time:84258ms step_avg:99.36ms
step:849/1750 train_time:84360ms step_avg:99.36ms
step:850/1750 train_time:84462ms step_avg:99.37ms
step:851/1750 train_time:84564ms step_avg:99.37ms
step:852/1750 train_time:84667ms step_avg:99.37ms
step:853/1750 train_time:84769ms step_avg:99.38ms
step:854/1750 train_time:84871ms step_avg:99.38ms
step:855/1750 train_time:84973ms step_avg:99.38ms
step:856/1750 train_time:85075ms step_avg:99.39ms
step:857/1750 train_time:85177ms step_avg:99.39ms
step:858/1750 train_time:85279ms step_avg:99.39ms
step:859/1750 train_time:85380ms step_avg:99.40ms
step:860/1750 train_time:85482ms step_avg:99.40ms
step:861/1750 train_time:85584ms step_avg:99.40ms
step:862/1750 train_time:85688ms step_avg:99.41ms
step:863/1750 train_time:85790ms step_avg:99.41ms
step:864/1750 train_time:85892ms step_avg:99.41ms
step:865/1750 train_time:85994ms step_avg:99.41ms
step:866/1750 train_time:86095ms step_avg:99.42ms
step:867/1750 train_time:86198ms step_avg:99.42ms
step:868/1750 train_time:86300ms step_avg:99.42ms
step:869/1750 train_time:86402ms step_avg:99.43ms
step:870/1750 train_time:86503ms step_avg:99.43ms
step:871/1750 train_time:86605ms step_avg:99.43ms
step:872/1750 train_time:86708ms step_avg:99.44ms
step:873/1750 train_time:86810ms step_avg:99.44ms
step:874/1750 train_time:86912ms step_avg:99.44ms
step:875/1750 train_time:87013ms step_avg:99.44ms
step:875/1750 val_loss:3.5483 train_time:87110ms step_avg:99.55ms
step:876/1750 train_time:87130ms step_avg:99.46ms
step:877/1750 train_time:87224ms step_avg:99.46ms
step:878/1750 train_time:87330ms step_avg:99.47ms
step:879/1750 train_time:87433ms step_avg:99.47ms
step:880/1750 train_time:87534ms step_avg:99.47ms
step:881/1750 train_time:87636ms step_avg:99.47ms
step:882/1750 train_time:87738ms step_avg:99.48ms
step:883/1750 train_time:87841ms step_avg:99.48ms
step:884/1750 train_time:87943ms step_avg:99.48ms
step:885/1750 train_time:88045ms step_avg:99.49ms
step:886/1750 train_time:88146ms step_avg:99.49ms
step:887/1750 train_time:88248ms step_avg:99.49ms
step:888/1750 train_time:88351ms step_avg:99.49ms
step:889/1750 train_time:88454ms step_avg:99.50ms
step:890/1750 train_time:88555ms step_avg:99.50ms
step:891/1750 train_time:88657ms step_avg:99.50ms
step:892/1750 train_time:88759ms step_avg:99.51ms
step:893/1750 train_time:88862ms step_avg:99.51ms
step:894/1750 train_time:88965ms step_avg:99.51ms
step:895/1750 train_time:89067ms step_avg:99.52ms
step:896/1750 train_time:89169ms step_avg:99.52ms
step:897/1750 train_time:89271ms step_avg:99.52ms
step:898/1750 train_time:89374ms step_avg:99.53ms
step:899/1750 train_time:89475ms step_avg:99.53ms
step:900/1750 train_time:89577ms step_avg:99.53ms
step:901/1750 train_time:89679ms step_avg:99.53ms
step:902/1750 train_time:89782ms step_avg:99.54ms
step:903/1750 train_time:89884ms step_avg:99.54ms
step:904/1750 train_time:89985ms step_avg:99.54ms
step:905/1750 train_time:90088ms step_avg:99.54ms
step:906/1750 train_time:90189ms step_avg:99.55ms
step:907/1750 train_time:90291ms step_avg:99.55ms
step:908/1750 train_time:90394ms step_avg:99.55ms
step:909/1750 train_time:90495ms step_avg:99.55ms
step:910/1750 train_time:90598ms step_avg:99.56ms
step:911/1750 train_time:90702ms step_avg:99.56ms
step:912/1750 train_time:90806ms step_avg:99.57ms
step:913/1750 train_time:90909ms step_avg:99.57ms
step:914/1750 train_time:91013ms step_avg:99.58ms
step:915/1750 train_time:91116ms step_avg:99.58ms
step:916/1750 train_time:91219ms step_avg:99.58ms
step:917/1750 train_time:91323ms step_avg:99.59ms
step:918/1750 train_time:91427ms step_avg:99.59ms
step:919/1750 train_time:91530ms step_avg:99.60ms
step:920/1750 train_time:91634ms step_avg:99.60ms
step:921/1750 train_time:91737ms step_avg:99.61ms
step:922/1750 train_time:91840ms step_avg:99.61ms
step:923/1750 train_time:91944ms step_avg:99.61ms
step:924/1750 train_time:92047ms step_avg:99.62ms
step:925/1750 train_time:92149ms step_avg:99.62ms
step:926/1750 train_time:92253ms step_avg:99.62ms
step:927/1750 train_time:92357ms step_avg:99.63ms
step:928/1750 train_time:92459ms step_avg:99.63ms
step:929/1750 train_time:92563ms step_avg:99.64ms
step:930/1750 train_time:92665ms step_avg:99.64ms
step:931/1750 train_time:92768ms step_avg:99.64ms
step:932/1750 train_time:92872ms step_avg:99.65ms
step:933/1750 train_time:92975ms step_avg:99.65ms
step:934/1750 train_time:93079ms step_avg:99.66ms
step:935/1750 train_time:93183ms step_avg:99.66ms
step:936/1750 train_time:93286ms step_avg:99.66ms
step:937/1750 train_time:93389ms step_avg:99.67ms
step:938/1750 train_time:93492ms step_avg:99.67ms
step:939/1750 train_time:93595ms step_avg:99.68ms
step:940/1750 train_time:93698ms step_avg:99.68ms
step:941/1750 train_time:93803ms step_avg:99.68ms
step:942/1750 train_time:93907ms step_avg:99.69ms
step:943/1750 train_time:94011ms step_avg:99.69ms
step:944/1750 train_time:94114ms step_avg:99.70ms
step:945/1750 train_time:94217ms step_avg:99.70ms
step:946/1750 train_time:94321ms step_avg:99.71ms
step:947/1750 train_time:94424ms step_avg:99.71ms
step:948/1750 train_time:94527ms step_avg:99.71ms
step:949/1750 train_time:94630ms step_avg:99.72ms
step:950/1750 train_time:94733ms step_avg:99.72ms
step:951/1750 train_time:94837ms step_avg:99.72ms
step:952/1750 train_time:94940ms step_avg:99.73ms
step:953/1750 train_time:95044ms step_avg:99.73ms
step:954/1750 train_time:95148ms step_avg:99.74ms
step:955/1750 train_time:95250ms step_avg:99.74ms
step:956/1750 train_time:95354ms step_avg:99.74ms
step:957/1750 train_time:95457ms step_avg:99.75ms
step:958/1750 train_time:95560ms step_avg:99.75ms
step:959/1750 train_time:95664ms step_avg:99.75ms
step:960/1750 train_time:95767ms step_avg:99.76ms
step:961/1750 train_time:95870ms step_avg:99.76ms
step:962/1750 train_time:95973ms step_avg:99.76ms
step:963/1750 train_time:96077ms step_avg:99.77ms
step:964/1750 train_time:96179ms step_avg:99.77ms
step:965/1750 train_time:96283ms step_avg:99.78ms
step:966/1750 train_time:96387ms step_avg:99.78ms
step:967/1750 train_time:96490ms step_avg:99.78ms
step:968/1750 train_time:96594ms step_avg:99.79ms
step:969/1750 train_time:96698ms step_avg:99.79ms
step:970/1750 train_time:96801ms step_avg:99.79ms
step:971/1750 train_time:96905ms step_avg:99.80ms
step:972/1750 train_time:97008ms step_avg:99.80ms
step:973/1750 train_time:97112ms step_avg:99.81ms
step:974/1750 train_time:97215ms step_avg:99.81ms
step:975/1750 train_time:97318ms step_avg:99.81ms
step:976/1750 train_time:97422ms step_avg:99.82ms
step:977/1750 train_time:97526ms step_avg:99.82ms
step:978/1750 train_time:97629ms step_avg:99.82ms
step:979/1750 train_time:97733ms step_avg:99.83ms
step:980/1750 train_time:97837ms step_avg:99.83ms
step:981/1750 train_time:97939ms step_avg:99.84ms
step:982/1750 train_time:98043ms step_avg:99.84ms
step:983/1750 train_time:98147ms step_avg:99.84ms
step:984/1750 train_time:98251ms step_avg:99.85ms
step:985/1750 train_time:98355ms step_avg:99.85ms
step:986/1750 train_time:98457ms step_avg:99.86ms
step:987/1750 train_time:98562ms step_avg:99.86ms
step:988/1750 train_time:98664ms step_avg:99.86ms
step:989/1750 train_time:98769ms step_avg:99.87ms
step:990/1750 train_time:98872ms step_avg:99.87ms
step:991/1750 train_time:98976ms step_avg:99.88ms
step:992/1750 train_time:99079ms step_avg:99.88ms
step:993/1750 train_time:99184ms step_avg:99.88ms
step:994/1750 train_time:99287ms step_avg:99.89ms
step:995/1750 train_time:99391ms step_avg:99.89ms
step:996/1750 train_time:99494ms step_avg:99.89ms
step:997/1750 train_time:99597ms step_avg:99.90ms
step:998/1750 train_time:99700ms step_avg:99.90ms
step:999/1750 train_time:99804ms step_avg:99.90ms
step:1000/1750 train_time:99908ms step_avg:99.91ms
step:1000/1750 val_loss:3.5124 train_time:100005ms step_avg:100.01ms
step:1001/1750 train_time:100026ms step_avg:99.93ms
step:1002/1750 train_time:100119ms step_avg:99.92ms
step:1003/1750 train_time:100223ms step_avg:99.92ms
step:1004/1750 train_time:100326ms step_avg:99.93ms
step:1005/1750 train_time:100429ms step_avg:99.93ms
step:1006/1750 train_time:100532ms step_avg:99.93ms
step:1007/1750 train_time:100635ms step_avg:99.94ms
step:1008/1750 train_time:100738ms step_avg:99.94ms
step:1009/1750 train_time:100841ms step_avg:99.94ms
step:1010/1750 train_time:100944ms step_avg:99.94ms
step:1011/1750 train_time:101049ms step_avg:99.95ms
step:1012/1750 train_time:101154ms step_avg:99.95ms
step:1013/1750 train_time:101258ms step_avg:99.96ms
step:1014/1750 train_time:101362ms step_avg:99.96ms
step:1015/1750 train_time:101466ms step_avg:99.97ms
step:1016/1750 train_time:101570ms step_avg:99.97ms
step:1017/1750 train_time:101674ms step_avg:99.97ms
step:1018/1750 train_time:101776ms step_avg:99.98ms
step:1019/1750 train_time:101879ms step_avg:99.98ms
step:1020/1750 train_time:101983ms step_avg:99.98ms
step:1021/1750 train_time:102086ms step_avg:99.99ms
step:1022/1750 train_time:102190ms step_avg:99.99ms
step:1023/1750 train_time:102294ms step_avg:99.99ms
step:1024/1750 train_time:102399ms step_avg:100.00ms
step:1025/1750 train_time:102503ms step_avg:100.00ms
step:1026/1750 train_time:102607ms step_avg:100.01ms
step:1027/1750 train_time:102711ms step_avg:100.01ms
step:1028/1750 train_time:102814ms step_avg:100.01ms
step:1029/1750 train_time:102918ms step_avg:100.02ms
step:1030/1750 train_time:103021ms step_avg:100.02ms
step:1031/1750 train_time:103124ms step_avg:100.02ms
step:1032/1750 train_time:103227ms step_avg:100.03ms
step:1033/1750 train_time:103331ms step_avg:100.03ms
step:1034/1750 train_time:103435ms step_avg:100.03ms
step:1035/1750 train_time:103538ms step_avg:100.04ms
step:1036/1750 train_time:103642ms step_avg:100.04ms
step:1037/1750 train_time:103746ms step_avg:100.04ms
step:1038/1750 train_time:103848ms step_avg:100.05ms
step:1039/1750 train_time:103951ms step_avg:100.05ms
step:1040/1750 train_time:104055ms step_avg:100.05ms
step:1041/1750 train_time:104158ms step_avg:100.06ms
step:1042/1750 train_time:104263ms step_avg:100.06ms
step:1043/1750 train_time:104367ms step_avg:100.06ms
step:1044/1750 train_time:104470ms step_avg:100.07ms
step:1045/1750 train_time:104574ms step_avg:100.07ms
step:1046/1750 train_time:104678ms step_avg:100.07ms
step:1047/1750 train_time:104783ms step_avg:100.08ms
step:1048/1750 train_time:104886ms step_avg:100.08ms
step:1049/1750 train_time:104990ms step_avg:100.09ms
step:1050/1750 train_time:105093ms step_avg:100.09ms
step:1051/1750 train_time:105196ms step_avg:100.09ms
step:1052/1750 train_time:105300ms step_avg:100.10ms
step:1053/1750 train_time:105404ms step_avg:100.10ms
step:1054/1750 train_time:105508ms step_avg:100.10ms
step:1055/1750 train_time:105612ms step_avg:100.11ms
step:1056/1750 train_time:105715ms step_avg:100.11ms
step:1057/1750 train_time:105819ms step_avg:100.11ms
step:1058/1750 train_time:105924ms step_avg:100.12ms
step:1059/1750 train_time:106028ms step_avg:100.12ms
step:1060/1750 train_time:106132ms step_avg:100.12ms
step:1061/1750 train_time:106236ms step_avg:100.13ms
step:1062/1750 train_time:106340ms step_avg:100.13ms
step:1063/1750 train_time:106446ms step_avg:100.14ms
step:1064/1750 train_time:106550ms step_avg:100.14ms
step:1065/1750 train_time:106652ms step_avg:100.14ms
step:1066/1750 train_time:106756ms step_avg:100.15ms
step:1067/1750 train_time:106861ms step_avg:100.15ms
step:1068/1750 train_time:106967ms step_avg:100.16ms
step:1069/1750 train_time:107071ms step_avg:100.16ms
step:1070/1750 train_time:107174ms step_avg:100.16ms
step:1071/1750 train_time:107277ms step_avg:100.17ms
step:1072/1750 train_time:107382ms step_avg:100.17ms
step:1073/1750 train_time:107484ms step_avg:100.17ms
step:1074/1750 train_time:107587ms step_avg:100.17ms
step:1075/1750 train_time:107691ms step_avg:100.18ms
step:1076/1750 train_time:107795ms step_avg:100.18ms
step:1077/1750 train_time:107898ms step_avg:100.18ms
step:1078/1750 train_time:108002ms step_avg:100.19ms
step:1079/1750 train_time:108104ms step_avg:100.19ms
step:1080/1750 train_time:108209ms step_avg:100.19ms
step:1081/1750 train_time:108313ms step_avg:100.20ms
step:1082/1750 train_time:108416ms step_avg:100.20ms
step:1083/1750 train_time:108520ms step_avg:100.20ms
step:1084/1750 train_time:108624ms step_avg:100.21ms
step:1085/1750 train_time:108727ms step_avg:100.21ms
step:1086/1750 train_time:108830ms step_avg:100.21ms
step:1087/1750 train_time:108933ms step_avg:100.21ms
step:1088/1750 train_time:109036ms step_avg:100.22ms
step:1089/1750 train_time:109141ms step_avg:100.22ms
step:1090/1750 train_time:109245ms step_avg:100.22ms
step:1091/1750 train_time:109348ms step_avg:100.23ms
step:1092/1750 train_time:109451ms step_avg:100.23ms
step:1093/1750 train_time:109554ms step_avg:100.23ms
step:1094/1750 train_time:109658ms step_avg:100.24ms
step:1095/1750 train_time:109764ms step_avg:100.24ms
step:1096/1750 train_time:109866ms step_avg:100.24ms
step:1097/1750 train_time:109969ms step_avg:100.25ms
step:1098/1750 train_time:110073ms step_avg:100.25ms
step:1099/1750 train_time:110176ms step_avg:100.25ms
step:1100/1750 train_time:110280ms step_avg:100.25ms
step:1101/1750 train_time:110384ms step_avg:100.26ms
step:1102/1750 train_time:110487ms step_avg:100.26ms
step:1103/1750 train_time:110590ms step_avg:100.26ms
step:1104/1750 train_time:110694ms step_avg:100.27ms
step:1105/1750 train_time:110797ms step_avg:100.27ms
step:1106/1750 train_time:110901ms step_avg:100.27ms
step:1107/1750 train_time:111005ms step_avg:100.28ms
step:1108/1750 train_time:111109ms step_avg:100.28ms
step:1109/1750 train_time:111213ms step_avg:100.28ms
step:1110/1750 train_time:111316ms step_avg:100.28ms
step:1111/1750 train_time:111421ms step_avg:100.29ms
step:1112/1750 train_time:111526ms step_avg:100.29ms
step:1113/1750 train_time:111629ms step_avg:100.30ms
step:1114/1750 train_time:111732ms step_avg:100.30ms
step:1115/1750 train_time:111835ms step_avg:100.30ms
step:1116/1750 train_time:111940ms step_avg:100.30ms
step:1117/1750 train_time:112046ms step_avg:100.31ms
step:1118/1750 train_time:112148ms step_avg:100.31ms
step:1119/1750 train_time:112252ms step_avg:100.31ms
step:1120/1750 train_time:112355ms step_avg:100.32ms
step:1121/1750 train_time:112459ms step_avg:100.32ms
step:1122/1750 train_time:112562ms step_avg:100.32ms
step:1123/1750 train_time:112666ms step_avg:100.33ms
step:1124/1750 train_time:112770ms step_avg:100.33ms
step:1125/1750 train_time:112873ms step_avg:100.33ms
step:1125/1750 val_loss:3.4678 train_time:112970ms step_avg:100.42ms
step:1126/1750 train_time:112990ms step_avg:100.35ms
step:1127/1750 train_time:113084ms step_avg:100.34ms
step:1128/1750 train_time:113188ms step_avg:100.34ms
step:1129/1750 train_time:113292ms step_avg:100.35ms
step:1130/1750 train_time:113396ms step_avg:100.35ms
step:1131/1750 train_time:113499ms step_avg:100.35ms
step:1132/1750 train_time:113602ms step_avg:100.36ms
step:1133/1750 train_time:113705ms step_avg:100.36ms
step:1134/1750 train_time:113808ms step_avg:100.36ms
step:1135/1750 train_time:113912ms step_avg:100.36ms
step:1136/1750 train_time:114017ms step_avg:100.37ms
step:1137/1750 train_time:114121ms step_avg:100.37ms
step:1138/1750 train_time:114225ms step_avg:100.37ms
step:1139/1750 train_time:114329ms step_avg:100.38ms
step:1140/1750 train_time:114433ms step_avg:100.38ms
step:1141/1750 train_time:114538ms step_avg:100.38ms
step:1142/1750 train_time:114642ms step_avg:100.39ms
step:1143/1750 train_time:114744ms step_avg:100.39ms
step:1144/1750 train_time:114847ms step_avg:100.39ms
step:1145/1750 train_time:114951ms step_avg:100.39ms
step:1146/1750 train_time:115055ms step_avg:100.40ms
step:1147/1750 train_time:115158ms step_avg:100.40ms
step:1148/1750 train_time:115262ms step_avg:100.40ms
step:1149/1750 train_time:115365ms step_avg:100.41ms
step:1150/1750 train_time:115468ms step_avg:100.41ms
step:1151/1750 train_time:115573ms step_avg:100.41ms
step:1152/1750 train_time:115677ms step_avg:100.41ms
step:1153/1750 train_time:115780ms step_avg:100.42ms
step:1154/1750 train_time:115885ms step_avg:100.42ms
step:1155/1750 train_time:115988ms step_avg:100.42ms
step:1156/1750 train_time:116092ms step_avg:100.43ms
step:1157/1750 train_time:116196ms step_avg:100.43ms
step:1158/1750 train_time:116300ms step_avg:100.43ms
step:1159/1750 train_time:116403ms step_avg:100.43ms
step:1160/1750 train_time:116506ms step_avg:100.44ms
step:1161/1750 train_time:116609ms step_avg:100.44ms
step:1162/1750 train_time:116714ms step_avg:100.44ms
step:1163/1750 train_time:116817ms step_avg:100.44ms
step:1164/1750 train_time:116920ms step_avg:100.45ms
step:1165/1750 train_time:117025ms step_avg:100.45ms
step:1166/1750 train_time:117129ms step_avg:100.45ms
step:1167/1750 train_time:117232ms step_avg:100.46ms
step:1168/1750 train_time:117335ms step_avg:100.46ms
step:1169/1750 train_time:117439ms step_avg:100.46ms
step:1170/1750 train_time:117544ms step_avg:100.47ms
step:1171/1750 train_time:117650ms step_avg:100.47ms
step:1172/1750 train_time:117755ms step_avg:100.47ms
step:1173/1750 train_time:117859ms step_avg:100.48ms
step:1174/1750 train_time:117963ms step_avg:100.48ms
step:1175/1750 train_time:118067ms step_avg:100.48ms
step:1176/1750 train_time:118172ms step_avg:100.49ms
step:1177/1750 train_time:118276ms step_avg:100.49ms
step:1178/1750 train_time:118380ms step_avg:100.49ms
step:1179/1750 train_time:118485ms step_avg:100.50ms
step:1180/1750 train_time:118590ms step_avg:100.50ms
step:1181/1750 train_time:118695ms step_avg:100.50ms
step:1182/1750 train_time:118800ms step_avg:100.51ms
step:1183/1750 train_time:118905ms step_avg:100.51ms
step:1184/1750 train_time:119011ms step_avg:100.52ms
step:1185/1750 train_time:119115ms step_avg:100.52ms
step:1186/1750 train_time:119221ms step_avg:100.52ms
step:1187/1750 train_time:119327ms step_avg:100.53ms
step:1188/1750 train_time:119431ms step_avg:100.53ms
step:1189/1750 train_time:119536ms step_avg:100.53ms
step:1190/1750 train_time:119641ms step_avg:100.54ms
step:1191/1750 train_time:119745ms step_avg:100.54ms
step:1192/1750 train_time:119849ms step_avg:100.54ms
step:1193/1750 train_time:119955ms step_avg:100.55ms
step:1194/1750 train_time:120059ms step_avg:100.55ms
step:1195/1750 train_time:120163ms step_avg:100.56ms
step:1196/1750 train_time:120268ms step_avg:100.56ms
step:1197/1750 train_time:120372ms step_avg:100.56ms
step:1198/1750 train_time:120477ms step_avg:100.56ms
step:1199/1750 train_time:120581ms step_avg:100.57ms
step:1200/1750 train_time:120686ms step_avg:100.57ms
step:1201/1750 train_time:120790ms step_avg:100.57ms
step:1202/1750 train_time:120895ms step_avg:100.58ms
step:1203/1750 train_time:120999ms step_avg:100.58ms
step:1204/1750 train_time:121104ms step_avg:100.58ms
step:1205/1750 train_time:121209ms step_avg:100.59ms
step:1206/1750 train_time:121314ms step_avg:100.59ms
step:1207/1750 train_time:121418ms step_avg:100.60ms
step:1208/1750 train_time:121522ms step_avg:100.60ms
step:1209/1750 train_time:121627ms step_avg:100.60ms
step:1210/1750 train_time:121731ms step_avg:100.60ms
step:1211/1750 train_time:121836ms step_avg:100.61ms
step:1212/1750 train_time:121944ms step_avg:100.61ms
step:1213/1750 train_time:122049ms step_avg:100.62ms
step:1214/1750 train_time:122153ms step_avg:100.62ms
step:1215/1750 train_time:122258ms step_avg:100.62ms
step:1216/1750 train_time:122363ms step_avg:100.63ms
step:1217/1750 train_time:122468ms step_avg:100.63ms
step:1218/1750 train_time:122573ms step_avg:100.63ms
step:1219/1750 train_time:122678ms step_avg:100.64ms
step:1220/1750 train_time:122783ms step_avg:100.64ms
step:1221/1750 train_time:122887ms step_avg:100.64ms
step:1222/1750 train_time:122992ms step_avg:100.65ms
step:1223/1750 train_time:123098ms step_avg:100.65ms
step:1224/1750 train_time:123204ms step_avg:100.66ms
step:1225/1750 train_time:123309ms step_avg:100.66ms
step:1226/1750 train_time:123413ms step_avg:100.66ms
step:1227/1750 train_time:123520ms step_avg:100.67ms
step:1228/1750 train_time:123625ms step_avg:100.67ms
step:1229/1750 train_time:123730ms step_avg:100.68ms
step:1230/1750 train_time:123837ms step_avg:100.68ms
step:1231/1750 train_time:123941ms step_avg:100.68ms
step:1232/1750 train_time:124046ms step_avg:100.69ms
step:1233/1750 train_time:124149ms step_avg:100.69ms
step:1234/1750 train_time:124255ms step_avg:100.69ms
step:1235/1750 train_time:124359ms step_avg:100.70ms
step:1236/1750 train_time:124466ms step_avg:100.70ms
step:1237/1750 train_time:124571ms step_avg:100.70ms
step:1238/1750 train_time:124676ms step_avg:100.71ms
step:1239/1750 train_time:124780ms step_avg:100.71ms
step:1240/1750 train_time:124885ms step_avg:100.71ms
step:1241/1750 train_time:124990ms step_avg:100.72ms
step:1242/1750 train_time:125095ms step_avg:100.72ms
step:1243/1750 train_time:125199ms step_avg:100.72ms
step:1244/1750 train_time:125304ms step_avg:100.73ms
step:1245/1750 train_time:125408ms step_avg:100.73ms
step:1246/1750 train_time:125515ms step_avg:100.73ms
step:1247/1750 train_time:125619ms step_avg:100.74ms
step:1248/1750 train_time:125723ms step_avg:100.74ms
step:1249/1750 train_time:125828ms step_avg:100.74ms
step:1250/1750 train_time:125932ms step_avg:100.75ms
step:1250/1750 val_loss:3.4201 train_time:126032ms step_avg:100.83ms
step:1251/1750 train_time:126052ms step_avg:100.76ms
step:1252/1750 train_time:126147ms step_avg:100.76ms
step:1253/1750 train_time:126252ms step_avg:100.76ms
step:1254/1750 train_time:126357ms step_avg:100.76ms
step:1255/1750 train_time:126464ms step_avg:100.77ms
step:1256/1750 train_time:126567ms step_avg:100.77ms
step:1257/1750 train_time:126671ms step_avg:100.77ms
step:1258/1750 train_time:126776ms step_avg:100.78ms
step:1259/1750 train_time:126881ms step_avg:100.78ms
step:1260/1750 train_time:126985ms step_avg:100.78ms
step:1261/1750 train_time:127092ms step_avg:100.79ms
step:1262/1750 train_time:127196ms step_avg:100.79ms
step:1263/1750 train_time:127300ms step_avg:100.79ms
step:1264/1750 train_time:127405ms step_avg:100.80ms
step:1265/1750 train_time:127510ms step_avg:100.80ms
step:1266/1750 train_time:127614ms step_avg:100.80ms
step:1267/1750 train_time:127719ms step_avg:100.80ms
step:1268/1750 train_time:127824ms step_avg:100.81ms
step:1269/1750 train_time:127928ms step_avg:100.81ms
step:1270/1750 train_time:128033ms step_avg:100.81ms
step:1271/1750 train_time:128139ms step_avg:100.82ms
step:1272/1750 train_time:128243ms step_avg:100.82ms
step:1273/1750 train_time:128348ms step_avg:100.82ms
step:1274/1750 train_time:128452ms step_avg:100.83ms
step:1275/1750 train_time:128557ms step_avg:100.83ms
step:1276/1750 train_time:128662ms step_avg:100.83ms
step:1277/1750 train_time:128766ms step_avg:100.83ms
step:1278/1750 train_time:128871ms step_avg:100.84ms
step:1279/1750 train_time:128975ms step_avg:100.84ms
step:1280/1750 train_time:129081ms step_avg:100.84ms
step:1281/1750 train_time:129186ms step_avg:100.85ms
step:1282/1750 train_time:129291ms step_avg:100.85ms
step:1283/1750 train_time:129397ms step_avg:100.85ms
step:1284/1750 train_time:129501ms step_avg:100.86ms
step:1285/1750 train_time:129606ms step_avg:100.86ms
step:1286/1750 train_time:129712ms step_avg:100.86ms
step:1287/1750 train_time:129818ms step_avg:100.87ms
step:1288/1750 train_time:129922ms step_avg:100.87ms
step:1289/1750 train_time:130028ms step_avg:100.87ms
step:1290/1750 train_time:130132ms step_avg:100.88ms
step:1291/1750 train_time:130237ms step_avg:100.88ms
step:1292/1750 train_time:130343ms step_avg:100.88ms
step:1293/1750 train_time:130447ms step_avg:100.89ms
step:1294/1750 train_time:130551ms step_avg:100.89ms
step:1295/1750 train_time:130655ms step_avg:100.89ms
step:1296/1750 train_time:130760ms step_avg:100.90ms
step:1297/1750 train_time:130865ms step_avg:100.90ms
step:1298/1750 train_time:130970ms step_avg:100.90ms
step:1299/1750 train_time:131074ms step_avg:100.90ms
step:1300/1750 train_time:131179ms step_avg:100.91ms
step:1301/1750 train_time:131285ms step_avg:100.91ms
step:1302/1750 train_time:131390ms step_avg:100.91ms
step:1303/1750 train_time:131495ms step_avg:100.92ms
step:1304/1750 train_time:131600ms step_avg:100.92ms
step:1305/1750 train_time:131705ms step_avg:100.92ms
step:1306/1750 train_time:131809ms step_avg:100.93ms
step:1307/1750 train_time:131914ms step_avg:100.93ms
step:1308/1750 train_time:132019ms step_avg:100.93ms
step:1309/1750 train_time:132123ms step_avg:100.93ms
step:1310/1750 train_time:132228ms step_avg:100.94ms
step:1311/1750 train_time:132333ms step_avg:100.94ms
step:1312/1750 train_time:132437ms step_avg:100.94ms
step:1313/1750 train_time:132541ms step_avg:100.94ms
step:1314/1750 train_time:132645ms step_avg:100.95ms
step:1315/1750 train_time:132750ms step_avg:100.95ms
step:1316/1750 train_time:132855ms step_avg:100.95ms
step:1317/1750 train_time:132960ms step_avg:100.96ms
step:1318/1750 train_time:133067ms step_avg:100.96ms
step:1319/1750 train_time:133172ms step_avg:100.96ms
step:1320/1750 train_time:133276ms step_avg:100.97ms
step:1321/1750 train_time:133381ms step_avg:100.97ms
step:1322/1750 train_time:133485ms step_avg:100.97ms
step:1323/1750 train_time:133590ms step_avg:100.98ms
step:1324/1750 train_time:133694ms step_avg:100.98ms
step:1325/1750 train_time:133800ms step_avg:100.98ms
step:1326/1750 train_time:133905ms step_avg:100.98ms
step:1327/1750 train_time:134013ms step_avg:100.99ms
step:1328/1750 train_time:134117ms step_avg:100.99ms
step:1329/1750 train_time:134221ms step_avg:100.99ms
step:1330/1750 train_time:134326ms step_avg:101.00ms
step:1331/1750 train_time:134430ms step_avg:101.00ms
step:1332/1750 train_time:134535ms step_avg:101.00ms
step:1333/1750 train_time:134639ms step_avg:101.00ms
step:1334/1750 train_time:134743ms step_avg:101.01ms
step:1335/1750 train_time:134848ms step_avg:101.01ms
step:1336/1750 train_time:134952ms step_avg:101.01ms
step:1337/1750 train_time:135058ms step_avg:101.02ms
step:1338/1750 train_time:135162ms step_avg:101.02ms
step:1339/1750 train_time:135267ms step_avg:101.02ms
step:1340/1750 train_time:135373ms step_avg:101.02ms
step:1341/1750 train_time:135477ms step_avg:101.03ms
step:1342/1750 train_time:135583ms step_avg:101.03ms
step:1343/1750 train_time:135688ms step_avg:101.03ms
step:1344/1750 train_time:135792ms step_avg:101.04ms
step:1345/1750 train_time:135896ms step_avg:101.04ms
step:1346/1750 train_time:136003ms step_avg:101.04ms
step:1347/1750 train_time:136108ms step_avg:101.05ms
step:1348/1750 train_time:136215ms step_avg:101.05ms
step:1349/1750 train_time:136319ms step_avg:101.05ms
step:1350/1750 train_time:136424ms step_avg:101.05ms
step:1351/1750 train_time:136529ms step_avg:101.06ms
step:1352/1750 train_time:136633ms step_avg:101.06ms
step:1353/1750 train_time:136739ms step_avg:101.06ms
step:1354/1750 train_time:136843ms step_avg:101.07ms
step:1355/1750 train_time:136947ms step_avg:101.07ms
step:1356/1750 train_time:137051ms step_avg:101.07ms
step:1357/1750 train_time:137156ms step_avg:101.07ms
step:1358/1750 train_time:137261ms step_avg:101.08ms
step:1359/1750 train_time:137367ms step_avg:101.08ms
step:1360/1750 train_time:137473ms step_avg:101.08ms
step:1361/1750 train_time:137577ms step_avg:101.09ms
step:1362/1750 train_time:137682ms step_avg:101.09ms
step:1363/1750 train_time:137787ms step_avg:101.09ms
step:1364/1750 train_time:137892ms step_avg:101.09ms
step:1365/1750 train_time:137996ms step_avg:101.10ms
step:1366/1750 train_time:138102ms step_avg:101.10ms
step:1367/1750 train_time:138207ms step_avg:101.10ms
step:1368/1750 train_time:138311ms step_avg:101.10ms
step:1369/1750 train_time:138416ms step_avg:101.11ms
step:1370/1750 train_time:138521ms step_avg:101.11ms
step:1371/1750 train_time:138625ms step_avg:101.11ms
step:1372/1750 train_time:138729ms step_avg:101.11ms
step:1373/1750 train_time:138835ms step_avg:101.12ms
step:1374/1750 train_time:138940ms step_avg:101.12ms
step:1375/1750 train_time:139045ms step_avg:101.12ms
step:1375/1750 val_loss:3.3770 train_time:139144ms step_avg:101.20ms
step:1376/1750 train_time:139164ms step_avg:101.14ms
step:1377/1750 train_time:139261ms step_avg:101.13ms
step:1378/1750 train_time:139366ms step_avg:101.14ms
step:1379/1750 train_time:139471ms step_avg:101.14ms
step:1380/1750 train_time:139576ms step_avg:101.14ms
step:1381/1750 train_time:139681ms step_avg:101.14ms
step:1382/1750 train_time:139786ms step_avg:101.15ms
step:1383/1750 train_time:139891ms step_avg:101.15ms
step:1384/1750 train_time:139995ms step_avg:101.15ms
step:1385/1750 train_time:140100ms step_avg:101.16ms
step:1386/1750 train_time:140206ms step_avg:101.16ms
step:1387/1750 train_time:140312ms step_avg:101.16ms
step:1388/1750 train_time:140416ms step_avg:101.16ms
step:1389/1750 train_time:140521ms step_avg:101.17ms
step:1390/1750 train_time:140626ms step_avg:101.17ms
step:1391/1750 train_time:140730ms step_avg:101.17ms
step:1392/1750 train_time:140835ms step_avg:101.17ms
step:1393/1750 train_time:140940ms step_avg:101.18ms
step:1394/1750 train_time:141044ms step_avg:101.18ms
step:1395/1750 train_time:141150ms step_avg:101.18ms
step:1396/1750 train_time:141256ms step_avg:101.19ms
step:1397/1750 train_time:141361ms step_avg:101.19ms
step:1398/1750 train_time:141466ms step_avg:101.19ms
step:1399/1750 train_time:141571ms step_avg:101.19ms
step:1400/1750 train_time:141675ms step_avg:101.20ms
step:1401/1750 train_time:141780ms step_avg:101.20ms
step:1402/1750 train_time:141885ms step_avg:101.20ms
step:1403/1750 train_time:141991ms step_avg:101.21ms
step:1404/1750 train_time:142097ms step_avg:101.21ms
step:1405/1750 train_time:142201ms step_avg:101.21ms
step:1406/1750 train_time:142305ms step_avg:101.21ms
step:1407/1750 train_time:142409ms step_avg:101.21ms
step:1408/1750 train_time:142514ms step_avg:101.22ms
step:1409/1750 train_time:142619ms step_avg:101.22ms
step:1410/1750 train_time:142724ms step_avg:101.22ms
step:1411/1750 train_time:142829ms step_avg:101.23ms
step:1412/1750 train_time:142934ms step_avg:101.23ms
step:1413/1750 train_time:143039ms step_avg:101.23ms
step:1414/1750 train_time:143145ms step_avg:101.23ms
step:1415/1750 train_time:143249ms step_avg:101.24ms
step:1416/1750 train_time:143355ms step_avg:101.24ms
step:1417/1750 train_time:143459ms step_avg:101.24ms
step:1418/1750 train_time:143563ms step_avg:101.24ms
step:1419/1750 train_time:143668ms step_avg:101.25ms
step:1420/1750 train_time:143772ms step_avg:101.25ms
step:1421/1750 train_time:143877ms step_avg:101.25ms
step:1422/1750 train_time:143982ms step_avg:101.25ms
step:1423/1750 train_time:144087ms step_avg:101.26ms
step:1424/1750 train_time:144192ms step_avg:101.26ms
step:1425/1750 train_time:144297ms step_avg:101.26ms
step:1426/1750 train_time:144402ms step_avg:101.26ms
step:1427/1750 train_time:144506ms step_avg:101.27ms
step:1428/1750 train_time:144614ms step_avg:101.27ms
step:1429/1750 train_time:144719ms step_avg:101.27ms
step:1430/1750 train_time:144825ms step_avg:101.28ms
step:1431/1750 train_time:144932ms step_avg:101.28ms
step:1432/1750 train_time:145038ms step_avg:101.28ms
step:1433/1750 train_time:145144ms step_avg:101.29ms
step:1434/1750 train_time:145249ms step_avg:101.29ms
step:1435/1750 train_time:145356ms step_avg:101.29ms
step:1436/1750 train_time:145465ms step_avg:101.30ms
step:1437/1750 train_time:145570ms step_avg:101.30ms
step:1438/1750 train_time:145676ms step_avg:101.30ms
step:1439/1750 train_time:145781ms step_avg:101.31ms
step:1440/1750 train_time:145887ms step_avg:101.31ms
step:1441/1750 train_time:145996ms step_avg:101.32ms
step:1442/1750 train_time:146101ms step_avg:101.32ms
step:1443/1750 train_time:146206ms step_avg:101.32ms
step:1444/1750 train_time:146313ms step_avg:101.32ms
step:1445/1750 train_time:146418ms step_avg:101.33ms
step:1446/1750 train_time:146523ms step_avg:101.33ms
step:1447/1750 train_time:146629ms step_avg:101.33ms
step:1448/1750 train_time:146735ms step_avg:101.34ms
step:1449/1750 train_time:146842ms step_avg:101.34ms
step:1450/1750 train_time:146948ms step_avg:101.34ms
step:1451/1750 train_time:147055ms step_avg:101.35ms
step:1452/1750 train_time:147162ms step_avg:101.35ms
step:1453/1750 train_time:147268ms step_avg:101.35ms
step:1454/1750 train_time:147374ms step_avg:101.36ms
step:1455/1750 train_time:147482ms step_avg:101.36ms
step:1456/1750 train_time:147589ms step_avg:101.37ms
step:1457/1750 train_time:147696ms step_avg:101.37ms
step:1458/1750 train_time:147802ms step_avg:101.37ms
step:1459/1750 train_time:147908ms step_avg:101.38ms
step:1460/1750 train_time:148014ms step_avg:101.38ms
step:1461/1750 train_time:148120ms step_avg:101.38ms
step:1462/1750 train_time:148226ms step_avg:101.39ms
step:1463/1750 train_time:148332ms step_avg:101.39ms
step:1464/1750 train_time:148439ms step_avg:101.39ms
step:1465/1750 train_time:148544ms step_avg:101.40ms
step:1466/1750 train_time:148652ms step_avg:101.40ms
step:1467/1750 train_time:148758ms step_avg:101.40ms
step:1468/1750 train_time:148865ms step_avg:101.41ms
step:1469/1750 train_time:148972ms step_avg:101.41ms
step:1470/1750 train_time:149077ms step_avg:101.41ms
step:1471/1750 train_time:149182ms step_avg:101.42ms
step:1472/1750 train_time:149289ms step_avg:101.42ms
step:1473/1750 train_time:149397ms step_avg:101.42ms
step:1474/1750 train_time:149503ms step_avg:101.43ms
step:1475/1750 train_time:149610ms step_avg:101.43ms
step:1476/1750 train_time:149716ms step_avg:101.43ms
step:1477/1750 train_time:149823ms step_avg:101.44ms
step:1478/1750 train_time:149930ms step_avg:101.44ms
step:1479/1750 train_time:150036ms step_avg:101.44ms
step:1480/1750 train_time:150142ms step_avg:101.45ms
step:1481/1750 train_time:150250ms step_avg:101.45ms
step:1482/1750 train_time:150355ms step_avg:101.45ms
step:1483/1750 train_time:150461ms step_avg:101.46ms
step:1484/1750 train_time:150567ms step_avg:101.46ms
step:1485/1750 train_time:150673ms step_avg:101.46ms
step:1486/1750 train_time:150779ms step_avg:101.47ms
step:1487/1750 train_time:150884ms step_avg:101.47ms
step:1488/1750 train_time:150990ms step_avg:101.47ms
step:1489/1750 train_time:151096ms step_avg:101.48ms
step:1490/1750 train_time:151203ms step_avg:101.48ms
step:1491/1750 train_time:151310ms step_avg:101.48ms
step:1492/1750 train_time:151416ms step_avg:101.49ms
step:1493/1750 train_time:151524ms step_avg:101.49ms
step:1494/1750 train_time:151634ms step_avg:101.50ms
step:1495/1750 train_time:151740ms step_avg:101.50ms
step:1496/1750 train_time:151845ms step_avg:101.50ms
step:1497/1750 train_time:151951ms step_avg:101.50ms
step:1498/1750 train_time:152056ms step_avg:101.51ms
step:1499/1750 train_time:152162ms step_avg:101.51ms
step:1500/1750 train_time:152267ms step_avg:101.51ms
step:1500/1750 val_loss:3.3392 train_time:152367ms step_avg:101.58ms
step:1501/1750 train_time:152388ms step_avg:101.52ms
step:1502/1750 train_time:152488ms step_avg:101.52ms
step:1503/1750 train_time:152592ms step_avg:101.53ms
step:1504/1750 train_time:152698ms step_avg:101.53ms
step:1505/1750 train_time:152805ms step_avg:101.53ms
step:1506/1750 train_time:152911ms step_avg:101.53ms
step:1507/1750 train_time:153017ms step_avg:101.54ms
step:1508/1750 train_time:153124ms step_avg:101.54ms
step:1509/1750 train_time:153229ms step_avg:101.54ms
step:1510/1750 train_time:153335ms step_avg:101.55ms
step:1511/1750 train_time:153441ms step_avg:101.55ms
step:1512/1750 train_time:153547ms step_avg:101.55ms
step:1513/1750 train_time:153653ms step_avg:101.56ms
step:1514/1750 train_time:153758ms step_avg:101.56ms
step:1515/1750 train_time:153864ms step_avg:101.56ms
step:1516/1750 train_time:153971ms step_avg:101.56ms
step:1517/1750 train_time:154078ms step_avg:101.57ms
step:1518/1750 train_time:154185ms step_avg:101.57ms
step:1519/1750 train_time:154290ms step_avg:101.57ms
step:1520/1750 train_time:154397ms step_avg:101.58ms
step:1521/1750 train_time:154503ms step_avg:101.58ms
step:1522/1750 train_time:154609ms step_avg:101.58ms
step:1523/1750 train_time:154716ms step_avg:101.59ms
step:1524/1750 train_time:154821ms step_avg:101.59ms
step:1525/1750 train_time:154928ms step_avg:101.59ms
step:1526/1750 train_time:155034ms step_avg:101.59ms
step:1527/1750 train_time:155140ms step_avg:101.60ms
step:1528/1750 train_time:155246ms step_avg:101.60ms
step:1529/1750 train_time:155352ms step_avg:101.60ms
step:1530/1750 train_time:155457ms step_avg:101.61ms
step:1531/1750 train_time:155564ms step_avg:101.61ms
step:1532/1750 train_time:155672ms step_avg:101.61ms
step:1533/1750 train_time:155777ms step_avg:101.62ms
step:1534/1750 train_time:155882ms step_avg:101.62ms
step:1535/1750 train_time:155988ms step_avg:101.62ms
step:1536/1750 train_time:156093ms step_avg:101.62ms
step:1537/1750 train_time:156200ms step_avg:101.63ms
step:1538/1750 train_time:156308ms step_avg:101.63ms
step:1539/1750 train_time:156413ms step_avg:101.63ms
step:1540/1750 train_time:156521ms step_avg:101.64ms
step:1541/1750 train_time:156628ms step_avg:101.64ms
step:1542/1750 train_time:156734ms step_avg:101.64ms
step:1543/1750 train_time:156839ms step_avg:101.65ms
step:1544/1750 train_time:156947ms step_avg:101.65ms
step:1545/1750 train_time:157052ms step_avg:101.65ms
step:1546/1750 train_time:157158ms step_avg:101.65ms
step:1547/1750 train_time:157264ms step_avg:101.66ms
step:1548/1750 train_time:157369ms step_avg:101.66ms
step:1549/1750 train_time:157475ms step_avg:101.66ms
step:1550/1750 train_time:157582ms step_avg:101.67ms
step:1551/1750 train_time:157688ms step_avg:101.67ms
step:1552/1750 train_time:157795ms step_avg:101.67ms
step:1553/1750 train_time:157901ms step_avg:101.67ms
step:1554/1750 train_time:158007ms step_avg:101.68ms
step:1555/1750 train_time:158114ms step_avg:101.68ms
step:1556/1750 train_time:158219ms step_avg:101.68ms
step:1557/1750 train_time:158325ms step_avg:101.69ms
step:1558/1750 train_time:158432ms step_avg:101.69ms
step:1559/1750 train_time:158538ms step_avg:101.69ms
step:1560/1750 train_time:158644ms step_avg:101.69ms
step:1561/1750 train_time:158753ms step_avg:101.70ms
step:1562/1750 train_time:158859ms step_avg:101.70ms
step:1563/1750 train_time:158965ms step_avg:101.70ms
step:1564/1750 train_time:159070ms step_avg:101.71ms
step:1565/1750 train_time:159177ms step_avg:101.71ms
step:1566/1750 train_time:159282ms step_avg:101.71ms
step:1567/1750 train_time:159388ms step_avg:101.72ms
step:1568/1750 train_time:159495ms step_avg:101.72ms
step:1569/1750 train_time:159605ms step_avg:101.72ms
step:1570/1750 train_time:159712ms step_avg:101.73ms
step:1571/1750 train_time:159817ms step_avg:101.73ms
step:1572/1750 train_time:159923ms step_avg:101.73ms
step:1573/1750 train_time:160033ms step_avg:101.74ms
step:1574/1750 train_time:160138ms step_avg:101.74ms
step:1575/1750 train_time:160243ms step_avg:101.74ms
step:1576/1750 train_time:160349ms step_avg:101.74ms
step:1577/1750 train_time:160457ms step_avg:101.75ms
step:1578/1750 train_time:160564ms step_avg:101.75ms
step:1579/1750 train_time:160669ms step_avg:101.75ms
step:1580/1750 train_time:160774ms step_avg:101.76ms
step:1581/1750 train_time:160882ms step_avg:101.76ms
step:1582/1750 train_time:160990ms step_avg:101.76ms
step:1583/1750 train_time:161096ms step_avg:101.77ms
step:1584/1750 train_time:161203ms step_avg:101.77ms
step:1585/1750 train_time:161308ms step_avg:101.77ms
step:1586/1750 train_time:161417ms step_avg:101.78ms
step:1587/1750 train_time:161525ms step_avg:101.78ms
step:1588/1750 train_time:161631ms step_avg:101.78ms
step:1589/1750 train_time:161738ms step_avg:101.79ms
step:1590/1750 train_time:161843ms step_avg:101.79ms
step:1591/1750 train_time:161948ms step_avg:101.79ms
step:1592/1750 train_time:162057ms step_avg:101.79ms
step:1593/1750 train_time:162162ms step_avg:101.80ms
step:1594/1750 train_time:162269ms step_avg:101.80ms
step:1595/1750 train_time:162375ms step_avg:101.80ms
step:1596/1750 train_time:162482ms step_avg:101.81ms
step:1597/1750 train_time:162587ms step_avg:101.81ms
step:1598/1750 train_time:162694ms step_avg:101.81ms
step:1599/1750 train_time:162801ms step_avg:101.81ms
step:1600/1750 train_time:162909ms step_avg:101.82ms
step:1601/1750 train_time:163016ms step_avg:101.82ms
step:1602/1750 train_time:163123ms step_avg:101.82ms
step:1603/1750 train_time:163229ms step_avg:101.83ms
step:1604/1750 train_time:163335ms step_avg:101.83ms
step:1605/1750 train_time:163440ms step_avg:101.83ms
step:1606/1750 train_time:163546ms step_avg:101.83ms
step:1607/1750 train_time:163656ms step_avg:101.84ms
step:1608/1750 train_time:163762ms step_avg:101.84ms
step:1609/1750 train_time:163869ms step_avg:101.85ms
step:1610/1750 train_time:163975ms step_avg:101.85ms
step:1611/1750 train_time:164081ms step_avg:101.85ms
step:1612/1750 train_time:164188ms step_avg:101.85ms
step:1613/1750 train_time:164294ms step_avg:101.86ms
step:1614/1750 train_time:164399ms step_avg:101.86ms
step:1615/1750 train_time:164506ms step_avg:101.86ms
step:1616/1750 train_time:164612ms step_avg:101.86ms
step:1617/1750 train_time:164720ms step_avg:101.87ms
step:1618/1750 train_time:164827ms step_avg:101.87ms
step:1619/1750 train_time:164935ms step_avg:101.87ms
step:1620/1750 train_time:165042ms step_avg:101.88ms
step:1621/1750 train_time:165148ms step_avg:101.88ms
step:1622/1750 train_time:165256ms step_avg:101.88ms
step:1623/1750 train_time:165364ms step_avg:101.89ms
step:1624/1750 train_time:165470ms step_avg:101.89ms
step:1625/1750 train_time:165575ms step_avg:101.89ms
step:1625/1750 val_loss:3.3052 train_time:165676ms step_avg:101.95ms
step:1626/1750 train_time:165696ms step_avg:101.90ms
step:1627/1750 train_time:165792ms step_avg:101.90ms
step:1628/1750 train_time:165899ms step_avg:101.90ms
step:1629/1750 train_time:166003ms step_avg:101.90ms
step:1630/1750 train_time:166109ms step_avg:101.91ms
step:1631/1750 train_time:166215ms step_avg:101.91ms
step:1632/1750 train_time:166321ms step_avg:101.91ms
step:1633/1750 train_time:166428ms step_avg:101.92ms
step:1634/1750 train_time:166534ms step_avg:101.92ms
step:1635/1750 train_time:166640ms step_avg:101.92ms
step:1636/1750 train_time:166748ms step_avg:101.92ms
step:1637/1750 train_time:166854ms step_avg:101.93ms
step:1638/1750 train_time:166959ms step_avg:101.93ms
step:1639/1750 train_time:167066ms step_avg:101.93ms
step:1640/1750 train_time:167172ms step_avg:101.93ms
step:1641/1750 train_time:167279ms step_avg:101.94ms
step:1642/1750 train_time:167384ms step_avg:101.94ms
step:1643/1750 train_time:167490ms step_avg:101.94ms
step:1644/1750 train_time:167598ms step_avg:101.95ms
step:1645/1750 train_time:167704ms step_avg:101.95ms
step:1646/1750 train_time:167812ms step_avg:101.95ms
step:1647/1750 train_time:167919ms step_avg:101.95ms
step:1648/1750 train_time:168024ms step_avg:101.96ms
step:1649/1750 train_time:168131ms step_avg:101.96ms
step:1650/1750 train_time:168237ms step_avg:101.96ms
step:1651/1750 train_time:168344ms step_avg:101.96ms
step:1652/1750 train_time:168450ms step_avg:101.97ms
step:1653/1750 train_time:168556ms step_avg:101.97ms
step:1654/1750 train_time:168664ms step_avg:101.97ms
step:1655/1750 train_time:168773ms step_avg:101.98ms
step:1656/1750 train_time:168879ms step_avg:101.98ms
step:1657/1750 train_time:168986ms step_avg:101.98ms
step:1658/1750 train_time:169092ms step_avg:101.99ms
step:1659/1750 train_time:169200ms step_avg:101.99ms
step:1660/1750 train_time:169305ms step_avg:101.99ms
step:1661/1750 train_time:169412ms step_avg:101.99ms
step:1662/1750 train_time:169518ms step_avg:102.00ms
step:1663/1750 train_time:169625ms step_avg:102.00ms
step:1664/1750 train_time:169732ms step_avg:102.00ms
step:1665/1750 train_time:169837ms step_avg:102.00ms
step:1666/1750 train_time:169943ms step_avg:102.01ms
step:1667/1750 train_time:170050ms step_avg:102.01ms
step:1668/1750 train_time:170156ms step_avg:102.01ms
step:1669/1750 train_time:170260ms step_avg:102.01ms
step:1670/1750 train_time:170366ms step_avg:102.02ms
step:1671/1750 train_time:170472ms step_avg:102.02ms
step:1672/1750 train_time:170577ms step_avg:102.02ms
step:1673/1750 train_time:170685ms step_avg:102.02ms
step:1674/1750 train_time:170790ms step_avg:102.02ms
step:1675/1750 train_time:170896ms step_avg:102.03ms
step:1676/1750 train_time:171003ms step_avg:102.03ms
step:1677/1750 train_time:171112ms step_avg:102.03ms
step:1678/1750 train_time:171218ms step_avg:102.04ms
step:1679/1750 train_time:171323ms step_avg:102.04ms
step:1680/1750 train_time:171430ms step_avg:102.04ms
step:1681/1750 train_time:171537ms step_avg:102.04ms
step:1682/1750 train_time:171646ms step_avg:102.05ms
step:1683/1750 train_time:171751ms step_avg:102.05ms
step:1684/1750 train_time:171856ms step_avg:102.05ms
step:1685/1750 train_time:171961ms step_avg:102.05ms
step:1686/1750 train_time:172068ms step_avg:102.06ms
step:1687/1750 train_time:172177ms step_avg:102.06ms
step:1688/1750 train_time:172284ms step_avg:102.06ms
step:1689/1750 train_time:172391ms step_avg:102.07ms
step:1690/1750 train_time:172499ms step_avg:102.07ms
step:1691/1750 train_time:172606ms step_avg:102.07ms
step:1692/1750 train_time:172713ms step_avg:102.08ms
step:1693/1750 train_time:172821ms step_avg:102.08ms
step:1694/1750 train_time:172928ms step_avg:102.08ms
step:1695/1750 train_time:173036ms step_avg:102.09ms
step:1696/1750 train_time:173145ms step_avg:102.09ms
step:1697/1750 train_time:173256ms step_avg:102.10ms
step:1698/1750 train_time:173364ms step_avg:102.10ms
step:1699/1750 train_time:173470ms step_avg:102.10ms
step:1700/1750 train_time:173576ms step_avg:102.10ms
step:1701/1750 train_time:173683ms step_avg:102.11ms
step:1702/1750 train_time:173790ms step_avg:102.11ms
step:1703/1750 train_time:173896ms step_avg:102.11ms
step:1704/1750 train_time:174005ms step_avg:102.12ms
step:1705/1750 train_time:174111ms step_avg:102.12ms
step:1706/1750 train_time:174218ms step_avg:102.12ms
step:1707/1750 train_time:174326ms step_avg:102.12ms
step:1708/1750 train_time:174433ms step_avg:102.13ms
step:1709/1750 train_time:174541ms step_avg:102.13ms
step:1710/1750 train_time:174650ms step_avg:102.13ms
step:1711/1750 train_time:174761ms step_avg:102.14ms
step:1712/1750 train_time:174868ms step_avg:102.14ms
step:1713/1750 train_time:174975ms step_avg:102.15ms
step:1714/1750 train_time:175081ms step_avg:102.15ms
step:1715/1750 train_time:175187ms step_avg:102.15ms
step:1716/1750 train_time:175295ms step_avg:102.15ms
step:1717/1750 train_time:175401ms step_avg:102.16ms
step:1718/1750 train_time:175508ms step_avg:102.16ms
step:1719/1750 train_time:175616ms step_avg:102.16ms
step:1720/1750 train_time:175725ms step_avg:102.17ms
step:1721/1750 train_time:175831ms step_avg:102.17ms
step:1722/1750 train_time:175942ms step_avg:102.17ms
step:1723/1750 train_time:176050ms step_avg:102.18ms
step:1724/1750 train_time:176160ms step_avg:102.18ms
step:1725/1750 train_time:176269ms step_avg:102.19ms
step:1726/1750 train_time:176378ms step_avg:102.19ms
step:1727/1750 train_time:176485ms step_avg:102.19ms
step:1728/1750 train_time:176594ms step_avg:102.20ms
step:1729/1750 train_time:176700ms step_avg:102.20ms
step:1730/1750 train_time:176807ms step_avg:102.20ms
step:1731/1750 train_time:176916ms step_avg:102.20ms
step:1732/1750 train_time:177022ms step_avg:102.21ms
step:1733/1750 train_time:177132ms step_avg:102.21ms
step:1734/1750 train_time:177238ms step_avg:102.21ms
step:1735/1750 train_time:177346ms step_avg:102.22ms
step:1736/1750 train_time:177455ms step_avg:102.22ms
step:1737/1750 train_time:177561ms step_avg:102.22ms
step:1738/1750 train_time:177668ms step_avg:102.23ms
step:1739/1750 train_time:177775ms step_avg:102.23ms
step:1740/1750 train_time:177881ms step_avg:102.23ms
step:1741/1750 train_time:177991ms step_avg:102.24ms
step:1742/1750 train_time:178101ms step_avg:102.24ms
step:1743/1750 train_time:178208ms step_avg:102.24ms
step:1744/1750 train_time:178315ms step_avg:102.24ms
step:1745/1750 train_time:178421ms step_avg:102.25ms
step:1746/1750 train_time:178531ms step_avg:102.25ms
step:1747/1750 train_time:178638ms step_avg:102.25ms
step:1748/1750 train_time:178746ms step_avg:102.26ms
step:1749/1750 train_time:178854ms step_avg:102.26ms
step:1750/1750 train_time:178960ms step_avg:102.26ms
step:1750/1750 val_loss:3.2793 train_time:179060ms step_avg:102.32ms
peak memory allocated: 30724 MiB reserved: 45392 MiB
