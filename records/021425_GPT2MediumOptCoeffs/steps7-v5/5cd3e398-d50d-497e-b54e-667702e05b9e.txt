import os
import sys
with open(sys.argv[0]) as f:
    code = f.read() # read the code of this file ASAP, for logging
import uuid
import time
import copy
import glob
from dataclasses import dataclass
from functools import lru_cache
from pathlib import Path

os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True"
import torch
torch.empty(1, device="cuda", requires_grad=True).backward() # prevents a bug on some systems
from torch import Tensor, nn
import torch.nn.functional as F
import torch.distributed as dist
# use of FlexAttention contributed by @KoszarskyB
from torch.nn.attention.flex_attention import BlockMask, flex_attention
#torch._inductor.config.coordinate_descent_tuning = True # we have banned this flag for new records because it causes compilation to take 30min

# -----------------------------------------------------------------------------
# Custom operators: FP8 matmul by @YouJiacheng

@torch.library.custom_op("nanogpt::mm", mutates_args=())
def mm_op(x: Tensor, w: Tensor, x_s: float, w_s: float, grad_s: float) -> tuple[Tensor, Tensor, Tensor]:
    @torch.compile
    def impl(x: Tensor, w: Tensor):
        assert x.is_contiguous() and w.is_contiguous()
        x_f8 = x.div(x_s).to(torch.float8_e4m3fn)
        w_f8 = w.div(w_s).to(torch.float8_e4m3fn)
        out = torch._scaled_mm(
            x_f8,
            w_f8.T,
            out_dtype=torch.bfloat16,
            scale_a=x.new_tensor(x_s, dtype=torch.float32),
            scale_b=x.new_tensor(w_s, dtype=torch.float32),
            use_fast_accum=True,
        )
        return out, x_f8, w_f8

    return impl(x, w)

@mm_op.register_fake
def _(x: Tensor, w: Tensor, *_):
    assert x.ndim == w.ndim == 2
    assert x.shape[1] == w.shape[1]
    assert x.device == w.device
    assert x.is_contiguous() and w.is_contiguous()
    return x @ w.T, x.to(torch.float8_e4m3fn), w.to(torch.float8_e4m3fn)

@torch.library.custom_op("nanogpt::mm_backward", mutates_args=())
def mm_backward_op(g: Tensor, x_f8: Tensor, w_f8: Tensor, x_s: float, w_s: float, grad_s: float) -> tuple[Tensor, Tensor]:
    @torch.compile
    def impl(grad: Tensor, x_f8: Tensor, w_f8: Tensor):
        assert grad.is_contiguous()
        x_inv_s = grad.new_tensor(x_s, dtype=torch.float32)
        w_inv_s = grad.new_tensor(w_s, dtype=torch.float32)
        grad_inv_s = grad.new_tensor(grad_s, dtype=torch.float32)
        grad_f8 = grad.div(grad_s).to(torch.float8_e5m2)
        grad_x = torch._scaled_mm(
            grad_f8,
            w_f8.T.contiguous().T,
            out_dtype=torch.bfloat16,
            scale_a=grad_inv_s,
            scale_b=w_inv_s,
            use_fast_accum=False,
        )
        # faster than grad_f8_t @ x_f8, for (d_out, d_in) == (50304, 768)
        grad_w = torch._scaled_mm(
            x_f8.T.contiguous(),
            grad_f8.T.contiguous().T,
            out_dtype=torch.float32,
            scale_a=x_inv_s,
            scale_b=grad_inv_s,
            use_fast_accum=False,
        ).T
        return grad_x, grad_w

    return impl(g, x_f8, w_f8)

@mm_backward_op.register_fake
def _(g: Tensor, x_f8: Tensor, w_f8: Tensor, *_):
    return x_f8.to(torch.bfloat16), w_f8.to(torch.float32)

def backward(ctx, grad_out: Tensor, *_):
    x_f8, w_f8 = ctx.saved_tensors
    x_s, w_s, grad_s = ctx.scales
    grad_x, grad_w = torch.ops.nanogpt.mm_backward(
        grad_out, x_f8, w_f8, x_s, w_s, grad_s
    )
    return grad_x, grad_w, None, None, None

def setup_context(ctx: torch.autograd.function.FunctionCtx, inputs, output):
    *_, x_s, w_s, grad_s = inputs
    _, x_f8, w_f8 = output
    ctx.save_for_backward(x_f8, w_f8)
    ctx.scales = x_s, w_s, grad_s
    ctx.set_materialize_grads(False)

mm_op.register_autograd(backward, setup_context=setup_context)

# -----------------------------------------------------------------------------
# Muon optimizer

@torch.compile
def zeropower_via_newtonschulz5(G: Tensor, steps: int) -> Tensor:
    """
    Newton-Schulz iteration to compute the zeroth power / orthogonalization of G. We opt to use a
    quintic iteration whose coefficients are selected to maximize the slope at zero. For the purpose
    of minimizing steps, it turns out to be empirically effective to keep increasing the slope at
    zero even beyond the point where the iteration no longer converges all the way to one everywhere
    on the interval. This iteration therefore does not produce UV^T but rather something like US'V^T
    where S' is diagonal with S_{ii}' ~ Uniform(0.5, 1.5), which turns out not to hurt model
    performance at all relative to UV^T, where USV^T = G is the SVD.
    """
    assert G.ndim >= 2 # batched Muon implementation by @scottjmaddox, and put into practice in the record by @YouJiacheng
    X = G.bfloat16()
    if G.size(-2) > G.size(-1):
        X = X.mT

    # Ensure spectral norm is at most 1
    X = X / (X.norm(dim=(-2, -1), keepdim=True) + 1e-7)
    # Perform the NS iterations
    for a, b, c in [
        (3.8839, -3.9828, 1.0989),
        (3.7253, -3.8239, 1.0986),
        (3.5715, -3.6700, 1.0985),
        (3.4220, -3.5202, 1.0983),
        (3.2774, -3.3757, 1.0983),
        (3.1288, -3.2227, 1.0939),
        (2.7203, -2.6642, 0.9439),
    ]:
        A = X @ X.mT
        B = b * A + c * A @ A # quintic computation strategy adapted from suggestion by @jxbz, @leloykun, and @YouJiacheng
        X = a * X + B @ X
    
    if G.size(-2) > G.size(-1):
        X = X.mT
    return X

class Muon(torch.optim.Optimizer):
    """
    Muon - MomentUm Orthogonalized by Newton-schulz

    https://kellerjordan.github.io/posts/muon/

    Muon internally runs standard SGD-momentum, and then performs an orthogonalization post-
    processing step, in which each 2D parameter's update is replaced with the nearest orthogonal
    matrix. To efficiently orthogonalize each update, we use a Newton-Schulz iteration, which has
    the advantage that it can be stably run in bfloat16 on the GPU.

    Some warnings:
    - This optimizer should not be used for the embedding layer, the final fully connected layer,
    or any {0,1}-D parameters; those should all be optimized by a standard method (e.g., AdamW).
    - To use it with 4D convolutional filters, it works well to just flatten their last 3 dimensions.

    Arguments:
        lr: The learning rate used by the internal SGD.
        momentum: The momentum used by the internal SGD.
        nesterov: Whether to use Nesterov-style momentum in the internal SGD. (recommended)
        ns_steps: The number of Newton-Schulz iteration steps to use.
    """
    def __init__(self, params, lr=0.02, momentum=0.95, nesterov=True, ns_steps=5, rank=0, world_size=1):
        self.rank = rank
        self.world_size = world_size
        defaults = dict(lr=lr, momentum=momentum, nesterov=nesterov, ns_steps=ns_steps)
        params: list[Tensor] = [*params]
        param_groups = []
        for size in {p.numel() for p in params}:
            b = torch.empty(world_size, size, dtype=torch.bfloat16, device="cuda")
            group = dict(params=[p for p in params if p.numel() == size],
                         update_buffer=b, update_buffer_views=[b[i] for i in range(world_size)])
            param_groups.append(group)
        super().__init__(param_groups, defaults)

    @torch.no_grad()
    def step(self):
        for group in self.param_groups:
            update_buffer: Tensor = group["update_buffer"]
            update_buffer_views: list[Tensor] = group["update_buffer_views"]
            # generate weight updates in distributed fashion
            params: list[Tensor] = group["params"]
            handle = None
            params_world = None
            def update_prev(): # optimized Muon implementation contributed by @YouJiacheng
                handle.wait()
                for p_world, g_world in zip(params_world, update_buffer_views):
                    p_world.add_(g_world.view_as(p_world),
                                 alpha=-group["lr"] * max(1, p_world.size(-2) / p_world.size(-1))**0.5)
            for base_i in range(len(params))[::self.world_size]:
                if base_i + self.rank < len(params):
                    p = params[base_i + self.rank]
                    g = p.grad
                    assert g is not None
                    state = self.state[p]
                    if "momentum_buffer" not in state:
                        state["momentum_buffer"] = torch.zeros_like(g)
                    buf: Tensor = state["momentum_buffer"]
                    buf.lerp_(g, 1 - group["momentum"])
                    g = g.lerp_(buf, group["momentum"]) if group["nesterov"] else buf
                    g = zeropower_via_newtonschulz5(g, steps=group["ns_steps"]).flatten()
                else:
                    g = update_buffer_views[self.rank]
                if base_i > 0:
                    update_prev() # async all_gather instead of sync all_reduce by @YouJiacheng
                handle = dist.all_gather_into_tensor(update_buffer, g, async_op=True)
                params_world = params[base_i : base_i + self.world_size]
            update_prev()

# -----------------------------------------------------------------------------
# PyTorch nn.Module definitions for the model

def norm(x: Tensor):
    return F.rms_norm(x, (x.size(-1),))

class CastedLinear(nn.Linear):
    def __init__(self, in_features: int, out_features: int, use_fp8=False, x_s=1.0, w_s=1.0, grad_s=1.0):
        super().__init__(in_features, out_features, bias=False)
        self.use_fp8 = use_fp8
        self.x_s = x_s
        self.w_s = w_s
        self.grad_s = grad_s

    def reset_parameters(self) -> None:
        std = 0.5 * (self.in_features ** -0.5) # 0.5 is a bit better than the default 1/sqrt(3)
        bound = (3 ** 0.5) * std
        with torch.no_grad():
            self.weight.uniform_(-bound, bound)

    def forward(self, x: Tensor):
        if self.use_fp8 and self.training:
            _x = x.flatten(0, -2)
            out: Tensor = torch.ops.nanogpt.mm(_x, self.weight, x_s=self.x_s, w_s=self.w_s, grad_s=self.grad_s)[0]
            return out.reshape(*x.shape[:-1], -1)
        else:
            return F.linear(x, self.weight.type_as(x))

class Rotary(nn.Module):
    def __init__(self, dim: int, max_seq_len: int):
        super().__init__()
        # half-truncate RoPE by @YouJiacheng (w/ base freq tuning)
        angular_freq = (1 / 1024) ** torch.linspace(0, 1, steps=dim//4, dtype=torch.float32)
        angular_freq = torch.cat([angular_freq, angular_freq.new_zeros(dim//4)])
        t = torch.arange(max_seq_len, dtype=torch.float32)
        theta = torch.einsum("i,j -> ij", t, angular_freq)
        self.cos = nn.Buffer(theta.cos(), persistent=False)
        self.sin = nn.Buffer(theta.sin(), persistent=False)

    def forward(self, x_BTHD: Tensor):
        assert self.cos.size(0) >= x_BTHD.size(-3)
        cos, sin = self.cos[None, :x_BTHD.size(-3), None, :], self.sin[None, :x_BTHD.size(-3), None, :]
        x1, x2 = x_BTHD.to(dtype=torch.float32).chunk(2, dim=-1)
        y1 = x1 * cos + x2 * sin
        y2 = x1 * (-sin) + x2 * cos
        return torch.cat((y1, y2), 3).type_as(x_BTHD)

class CausalSelfAttention(nn.Module):
    def __init__(self, dim: int, num_heads: int, max_seq_len: int, head_dim=128):
        super().__init__()
        self.num_heads = num_heads
        self.head_dim = head_dim
        hdim = num_heads * head_dim
        std = 0.5 * (dim ** -0.5)
        bound = (3 ** 0.5) * std # improved init scale by @YouJiacheng
        # merged QKV weights: suggested by many, implemented by @fernbear.bsky.social, and further improved by @YouJiacheng
        # https://x.com/hi_tysam/status/1879699187107033311
        self.qkv_w = nn.Parameter(torch.empty(3, hdim, dim).uniform_(-bound, bound))
        self.lambdas = nn.Parameter(torch.tensor([0.5, 0.5]))
        self.rotary = Rotary(head_dim, max_seq_len)
        self.c_proj = CastedLinear(hdim, dim)
        self.c_proj.weight.detach().zero_() # zero init suggested by @Grad62304977

    def forward(self, x: Tensor, ve: Tensor | None, block_mask: BlockMask):
        B, T = x.size(0), x.size(1) # batch size, sequence length
        assert B == 1, "Must use batch size = 1 for FlexAttention"
        q, k, v = F.linear(x, self.qkv_w.flatten(end_dim=1).type_as(x)).view(B, T, 3 * self.num_heads, self.head_dim).chunk(3, dim=-2)
        q, k = norm(q), norm(k) # QK norm @Grad62304977
        q, k = self.rotary(q), self.rotary(k)
        if ve is not None:
            v = self.lambdas[0] * v + self.lambdas[1] * ve.view_as(v) # @KoszarskyB & @Grad62304977
        else: # skip mid-layers token value embeddings by @YouJiacheng
            v = self.lambdas[0] * v
        # scale the attention logits by given constant, instead of the default head_dim**-0.5, by @leloykun
        # inspired by learnable scalars used by @brendanh0gan https://x.com/hi_tysam/status/1879693583898591283
        y = flex_attention(q.transpose(1, 2), k.transpose(1, 2), v.transpose(1, 2), block_mask=block_mask, scale=15/self.head_dim).transpose(1, 2)
        y = y.contiguous().view(B, T, self.num_heads * self.head_dim) # re-assemble all head outputs side by side
        y = self.c_proj(y)
        return y

class MLP(nn.Module):
    def __init__(self, dim: int):
        super().__init__()
        hdim = 4 * dim
        self.c_fc = CastedLinear(dim, hdim)
        self.c_proj = CastedLinear(hdim, dim)
        self.c_proj.weight.detach().zero_() # zero init suggested by @Grad62304977

    def forward(self, x: Tensor):
        x = self.c_fc(x)
        x = F.relu(x).square() # https://arxiv.org/abs/2109.08668v2; ~1-2% better than GELU; suggested by @SKYLINEZ007 and @Grad62304977
        x = self.c_proj(x)
        return x

class Block(nn.Module):
    def __init__(self, dim: int, num_heads: int, max_seq_len: int, layer_idx: int):
        super().__init__()
        # skip attention of blocks.7 (the 8th layer) by @YouJiacheng
        self.attn = CausalSelfAttention(dim, num_heads, max_seq_len) if layer_idx != 7 else None
        self.mlp = MLP(dim)
        self.lambdas = nn.Parameter(torch.tensor([1., 0.]))

    def forward(self, x: Tensor, ve: Tensor | None, x0: Tensor, block_mask: BlockMask):
        x = self.lambdas[0] * x + self.lambdas[1] * x0
        if self.attn is not None:
            x = x + self.attn(norm(x), ve, block_mask)
        x = x + self.mlp(norm(x))
        return x

# -----------------------------------------------------------------------------
# The main model

def next_multiple_of_n(v: float | int, *, n: int):
    return next(x for x in range(n, int(v) + 1 + n, n) if x >= v)

class GPT(nn.Module):
    def __init__(self, vocab_size: int, num_layers: int, num_heads: int, model_dim: int, max_seq_len: int):
        super().__init__()
        self.embed = nn.Embedding(vocab_size, model_dim)
        # token value embeddings by @KoszarskyB - inspired by @Grad62304977's value residual implementation following https://arxiv.org/abs/2410.17897
        # value embedding code simplification inspired by @ragulpr https://github.com/KellerJordan/modded-nanogpt/pull/78
        self.value_embeds = nn.ModuleList([nn.Embedding(vocab_size, model_dim) for _ in range(3)])
        self.blocks = nn.ModuleList([Block(model_dim, num_heads, max_seq_len, i) for i in range(num_layers)])
        # there are only 50257 unique GPT-2 tokens; we extend to nearest multiple of 128 for efficiency.
        # suggested to me by @Grad62304977. this originates from Karpathy's experiments.
        self.lm_head = CastedLinear(model_dim, next_multiple_of_n(vocab_size, n=128), use_fp8=True, x_s=(768**0.5)/448, w_s=2**-9, grad_s=1/448)
        self.lm_head.weight.detach().zero_() # @Grad62304977
        # Add learnable skip connection weights for decoder layers
        assert num_layers % 2 == 0
        self.skip_weights = nn.Parameter(torch.ones(num_layers//2))

    def create_blockmasks(self, input_seq: Tensor, sliding_window_num_blocks: Tensor):
        BLOCK_SIZE = 128
        docs = (input_seq == 50256).cumsum(0)

        def document_causal(b, h, q_idx, kv_idx):
            causal_mask = q_idx >= kv_idx
            document_mask = docs[q_idx] == docs[kv_idx]
            return causal_mask & document_mask

        def dense_to_ordered(dense_blockmask: Tensor):
            num_blocks = dense_blockmask.sum(dim=-1, dtype=torch.int32)
            indices = dense_blockmask.argsort(dim=-1, descending=False, stable=True).flip(-1).to(torch.int32)
            return num_blocks[None, None].contiguous(), indices[None, None].contiguous()

        # manual block mask creation by @YouJiacheng
        assert len(input_seq) % BLOCK_SIZE == 0
        NUM_BLOCKS = len(input_seq) // BLOCK_SIZE
        block_idx = torch.arange(NUM_BLOCKS, dtype=torch.int32, device="cuda")
        causal_blockmask_any = block_idx[:, None] >= block_idx
        causal_blockmask_all = block_idx[:, None] > block_idx
        docs_low = docs.view(-1, BLOCK_SIZE)[:, 0].contiguous()
        docs_high = docs.view(-1, BLOCK_SIZE)[:, -1].contiguous()
        document_blockmask_any = (docs_low[:, None] <= docs_high) & (docs_high[:, None] >= docs_low)
        document_blockmask_all = (docs_low[:, None] == docs_high) & (docs_high[:, None] == docs_low)
        blockmask_any = causal_blockmask_any & document_blockmask_any
        blockmask_all = causal_blockmask_all & document_blockmask_all
        partial_kv_num_blocks, partial_kv_indices = dense_to_ordered(blockmask_any & ~blockmask_all)
        full_kv_num_blocks, full_kv_indices = dense_to_ordered(blockmask_all)
        def build_bm(window_size_blocks: Tensor) -> BlockMask:
            return BlockMask.from_kv_blocks(
                torch.clamp_max(partial_kv_num_blocks, torch.clamp_min(window_size_blocks - full_kv_num_blocks, 1)),
                partial_kv_indices,
                torch.clamp_max(full_kv_num_blocks, window_size_blocks - 1),
                full_kv_indices,
                BLOCK_SIZE=BLOCK_SIZE,
                mask_mod=document_causal,
            )
        # Long-short SWA block masks by @leloykun & @YouJiacheng, adapated from suggestion by @Grad62304977, following Gemma 2 paper
        return build_bm(sliding_window_num_blocks), build_bm(sliding_window_num_blocks // 2)

    def forward(self, input_seq: Tensor, target_seq: Tensor, sliding_window_num_blocks: Tensor):
        assert input_seq.ndim == 1

        ve = [value_embed(input_seq) for value_embed in self.value_embeds]
        # 012 ... 012 structure on token value embeddings by @YouJiacheng, improved on @leloykun's U-net structure
        ve = [ve[0], ve[1], ve[2]] + [None] * (len(self.blocks) - 6) + [ve[0], ve[1], ve[2]]
        assert len(ve) == len(self.blocks)

        long_bm, short_bm = self.create_blockmasks(input_seq, sliding_window_num_blocks)
        block_masks = [long_bm, short_bm, short_bm, short_bm, long_bm, short_bm, short_bm, long_bm, short_bm, short_bm, short_bm, long_bm]
        assert len(block_masks) == len(self.blocks)

        x = x0 = norm(self.embed(input_seq)[None]) # use of norm here by @Grad62304977

        # U-net design by @brendanh0gan
        skip_connections = []
        n = len(self.skip_weights)
        for i in range(len(self.blocks)):
            if i >= n:
                x = x + self.skip_weights[i - n] * skip_connections.pop()
            x = self.blocks[i](x, ve[i], x0, block_masks[i])
            if i < n:
                skip_connections.append(x)

        x = norm(x)
        logits = self.lm_head(x).float()
        # @Grad62304977 added tanh softcapping following Gemma 2 paper, @KoszarskyB reduced it from 30 to 15, @YouJiacheng shifted it by +15 (2*sigmoid(2*x)=tanh(x)+1)
        logits = 30 * torch.sigmoid(logits / 7.5)
        loss = F.cross_entropy(logits.view(-1, logits.size(-1)), target_seq, reduction='sum' if self.training else 'mean')
        return loss

# -----------------------------------------------------------------------------
# Our own simple Distributed Data Loader

def _load_data_shard(file: Path):
    header = torch.from_file(str(file), False, 256, dtype=torch.int32) # header is 256 int32
    assert header[0] == 20240520, "magic number mismatch in the data .bin file"
    assert header[1] == 1, "unsupported version"
    num_tokens = int(header[2]) # number of tokens (claimed)
    with file.open("rb", buffering=0) as f:
        tokens = torch.empty(num_tokens, dtype=torch.uint16, pin_memory=True) # avoid pin_memory copy by @YouJiacheng
        f.seek(256 * 4)
        nbytes = f.readinto(tokens.numpy()) # avoid bytes->array copy by @YouJiacheng
        assert nbytes == 2 * num_tokens, "number of tokens read does not match header"
    return tokens

def distributed_data_generator(filename_pattern: str, batch_size: int, rank : int, world_size : int):
    files = [Path(file) for file in sorted(glob.glob(filename_pattern))]
    assert batch_size % world_size == 0
    local_batch_size = batch_size // world_size
    file_iter = iter(files) # use itertools.cycle(files) instead if you want to do multi-epoch training
    tokens, pos = _load_data_shard(next(file_iter)), 0
    while True:
        if pos + batch_size + 1 >= len(tokens):
            tokens, pos = _load_data_shard(next(file_iter)), 0
        buf = tokens[pos + rank * local_batch_size:][:local_batch_size + 1]
        inputs = buf[:-1].to(device="cuda", dtype=torch.int32, non_blocking=True) # no sync on host side;
        targets = buf[1:].to(device="cuda", dtype=torch.int64, non_blocking=True) # H2D in another stream isn't helpful.
        pos += batch_size
        yield inputs, targets

# -----------------------------------------------------------------------------
# int main

@dataclass
class Hyperparameters:
    # data
    train_files = "data/fineweb10B/fineweb_train_*.bin" # input .bin to train on
    val_files = "data/fineweb10B/fineweb_val_*.bin" # input .bin to eval validation loss on
    val_tokens = 10485760 # how many tokens of validation data? it's important to keep this fixed for consistent comparisons
    train_seq_len = 48*1024 # FlexAttention sequence length
    val_seq_len = 4*64*1024 # FlexAttention sequence length for validation
    # optimization
    num_iterations = 1750 # number of iterations to run
    cooldown_frac = 0.4 # fraction of training spent cooling down the learning rate
    # architecture
    vocab_size = 50257
    # evaluation and logging
    val_loss_every = 125 # every how many steps to evaluate val loss? 0 for only at the end
    save_checkpoint = False
args = Hyperparameters()

# torchrun sets these env variables
rank = int(os.environ["RANK"])
world_size = int(os.environ["WORLD_SIZE"])
assert world_size == 8 # this code is designed for 8xH100
assert torch.cuda.is_available()
device = torch.device("cuda", int(os.environ["LOCAL_RANK"]))
torch.cuda.set_device(device)
dist.init_process_group(backend="nccl", device_id=device)
dist.barrier()
master_process = (rank == 0) # this process will do logging, checkpointing etc.

# begin logging
logfile = None
if master_process:
    run_id = uuid.uuid4()
    os.makedirs("logs", exist_ok=True)
    logfile = f"logs/{run_id}.txt"
    print(logfile)
def print0(s, console=False):
    if master_process:
        with open(logfile, "a") as f:
            if console:
                print(s)
            print(s, file=f)

# begin by printing this file (the Python code)
print0(code)
print0("="*100)
# log information about the hardware/software environment this is running on
print0(f"Running Python {sys.version}")
print0(f"Running PyTorch {torch.version.__version__} compiled for CUDA {torch.version.cuda}")
def nvidia_smi():
    import subprocess  # avoid top level import
    return subprocess.run(["nvidia-smi"], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True).stdout
print0(nvidia_smi())
print0("="*100)

########################################
#    Construct model and optimizer     #
########################################

model: nn.Module = GPT(vocab_size=args.vocab_size, num_layers=12, num_heads=6, model_dim=768,
                       max_seq_len=max(args.train_seq_len, args.val_seq_len)).cuda()
for m in model.modules():
    if isinstance(m, nn.Embedding):
        m.bfloat16()
for param in model.parameters():
    dist.broadcast(param.detach(), 0)

# collect the parameters to optimize
hidden_matrix_params = [p for n, p in model.blocks.named_parameters() if p.ndim >= 2 and "embed" not in n]
embed_params = [p for n, p in model.named_parameters() if "embed" in n]
scalar_params = [p for p in model.parameters() if p.ndim < 2]
head_params = [model.lm_head.weight]

# init the optimizer(s)
adam_params = [dict(params=head_params, lr=0.22/768**0.5), dict(params=embed_params, lr=0.6), dict(params=scalar_params, lr=0.04)]
# small adam epsilon by @YouJiacheng. this is an alternate method of fixing the world_size dependence
# discovered by @fernbear.bsky.social https://x.com/hi_tysam/status/1879692937589875094
optimizer1 = torch.optim.Adam(adam_params, betas=(0.8, 0.95), eps=1e-10, fused=True)
optimizer2 = Muon(hidden_matrix_params, lr=0.05, momentum=0.95, rank=rank, world_size=world_size)
optimizers = [optimizer1, optimizer2]
for opt in optimizers:
    for group in opt.param_groups:
        group["initial_lr"] = group["lr"]

# learning rate schedule: stable then decay
def get_lr(step: int):
    x = step / args.num_iterations # progress in training
    assert 0 <= x < 1
    if x < 1 - args.cooldown_frac:
        return 1.0
    else:
        w = (1 - x) / args.cooldown_frac
        return w * 1.0 + (1 - w) * 0.1

# attention window size schedule: linearly increase
@lru_cache(1)
def get_window_size_blocks_helper(window_size: int):
    return torch.tensor(window_size // 128, dtype=torch.int32, pin_memory=True).cuda(non_blocking=True)
def get_window_size_blocks(step: int):
    x = step / args.num_iterations # progress in training
    assert 0 <= x <= 1
    # Linearly increase the block-wise sliding window size over training 128 -> 1792
    # increase by @fernbear.bsky.social; block-wise by @YouJiacheng
    window_size = next_multiple_of_n(1728 * x, n=128)
    return get_window_size_blocks_helper(window_size)

model: nn.Module = torch.compile(model, dynamic=False)

########################################
#            Warmup kernels            #
########################################

# Warmup the training kernels, then re-initialize the state so we aren't cheating
warmup_steps = 10
initial_state = dict(model=copy.deepcopy(model.state_dict()),
                     optimizers=[copy.deepcopy(opt.state_dict()) for opt in optimizers]) # save the initial state
for _ in range(warmup_steps):
    inputs = targets = torch.randint(0, args.vocab_size, size=(args.train_seq_len,), device="cuda")
    model(inputs.to(torch.int32), targets, get_window_size_blocks(0)).backward()
    for param in model.parameters():
        dist.all_reduce(param.grad, op=dist.ReduceOp.AVG)
    for opt in optimizers:
        opt.step()
    model.zero_grad(set_to_none=True)
model.load_state_dict(initial_state["model"])
for opt, opt_state in zip(optimizers, initial_state["optimizers"]):
    opt.load_state_dict(opt_state)
del initial_state

########################################
#        Training and validation       #
########################################

train_loader = distributed_data_generator(args.train_files, world_size * args.train_seq_len, rank, world_size)
training_time_ms = 0
# start the clock
torch.cuda.synchronize()
t0 = time.perf_counter()
# begin training
train_steps = args.num_iterations
for step in range(train_steps + 1):
    last_step = (step == train_steps)

    # --------------- VALIDATION SECTION -----------------
    if last_step or (args.val_loss_every > 0 and step % args.val_loss_every == 0):
        # stop the clock
        torch.cuda.synchronize()
        training_time_ms += 1000 * (time.perf_counter() - t0)
        model.eval()
        val_batch_size = world_size * args.val_seq_len
        assert args.val_tokens % val_batch_size == 0
        val_steps = args.val_tokens // val_batch_size
        val_loader = distributed_data_generator(args.val_files, val_batch_size, rank, world_size)
        val_loss = 0
        with torch.no_grad():
            for _ in range(val_steps):
                inputs, targets = next(val_loader)
                val_loss += model(inputs, targets, get_window_size_blocks(step))
        val_loss /= val_steps
        del val_loader
        dist.all_reduce(val_loss, op=dist.ReduceOp.AVG)
        print0(f"step:{step}/{train_steps} val_loss:{val_loss:.4f} train_time:{training_time_ms:.0f}ms step_avg:{training_time_ms/max(step, 1):.2f}ms", console=True)
        model.train()
        # start the clock again
        torch.cuda.synchronize()
        t0 = time.perf_counter()

    if last_step:
        if master_process and args.save_checkpoint:
            log = dict(step=step, code=code, model=model.state_dict(), optimizers=[opt.state_dict() for opt in optimizers])
            os.makedirs(f"logs/{run_id}", exist_ok=True)
            torch.save(log, f"logs/{run_id}/state_step{step:06d}.pt")
        # the last step only has the validation loop, so break to avoid training
        break

    # --------------- TRAINING SECTION -----------------
    inputs, targets = next(train_loader)
    model(inputs, targets, get_window_size_blocks(step)).backward()
    for param in model.parameters():
        dist.all_reduce(param.grad, op=dist.ReduceOp.AVG)
    # set optimization hyperparameters
    for opt in optimizers:
        for group in opt.param_groups:
            group["lr"] = group["initial_lr"] * get_lr(step)
    for group in optimizer2.param_groups:
        frac = min(step / 300, 1) # momentum warmup for muon
        group["momentum"] = (1 - frac) * 0.85 + frac * 0.95
    # step the optimizers
    for opt in optimizers:
        opt.step()
    # null the gradients
    model.zero_grad(set_to_none=True)
    # logging
    approx_training_time_ms = training_time_ms + 1000 * (time.perf_counter() - t0)
    print0(f"step:{step+1}/{train_steps} train_time:{approx_training_time_ms:.0f}ms step_avg:{approx_training_time_ms/(step + 1):.2f}ms", console=True)

print0(f"peak memory allocated: {torch.cuda.max_memory_allocated() // 1024 // 1024} MiB "
       f"reserved: {torch.cuda.max_memory_reserved() // 1024 // 1024} MiB", console=True)
dist.destroy_process_group()

====================================================================================================
Running Python 3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]
Running PyTorch 2.7.0.dev20250125+cu126 compiled for CUDA 12.6
Sun Feb 16 18:22:44 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA H100 80GB HBM3          On  |   00000000:19:00.0 Off |                    0 |
| N/A   37C    P0            117W /  700W |    7714MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA H100 80GB HBM3          On  |   00000000:3B:00.0 Off |                    0 |
| N/A   30C    P0            122W /  700W |    3452MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA H100 80GB HBM3          On  |   00000000:4C:00.0 Off |                    0 |
| N/A   29C    P0            114W /  700W |    3452MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA H100 80GB HBM3          On  |   00000000:5D:00.0 Off |                    0 |
| N/A   37C    P0            117W /  700W |    3452MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   4  NVIDIA H100 80GB HBM3          On  |   00000000:9B:00.0 Off |                    0 |
| N/A   37C    P0            118W /  700W |    3452MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   5  NVIDIA H100 80GB HBM3          On  |   00000000:BB:00.0 Off |                    0 |
| N/A   31C    P0            111W /  700W |    3452MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   6  NVIDIA H100 80GB HBM3          On  |   00000000:CB:00.0 Off |                    0 |
| N/A   36C    P0            115W /  700W |    3452MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   7  NVIDIA H100 80GB HBM3          On  |   00000000:DB:00.0 Off |                    0 |
| N/A   29C    P0            113W /  700W |    3212MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
+-----------------------------------------------------------------------------------------+

====================================================================================================
step:0/1750 val_loss:10.8258 train_time:0ms step_avg:0.02ms
step:1/1750 train_time:63ms step_avg:62.76ms
step:2/1750 train_time:139ms step_avg:69.49ms
step:3/1750 train_time:231ms step_avg:77.11ms
step:4/1750 train_time:327ms step_avg:81.86ms
step:5/1750 train_time:424ms step_avg:84.85ms
step:6/1750 train_time:521ms step_avg:86.89ms
step:7/1750 train_time:618ms step_avg:88.26ms
step:8/1750 train_time:716ms step_avg:89.46ms
step:9/1750 train_time:812ms step_avg:90.17ms
step:10/1750 train_time:908ms step_avg:90.80ms
step:11/1750 train_time:1005ms step_avg:91.32ms
step:12/1750 train_time:1101ms step_avg:91.77ms
step:13/1750 train_time:1198ms step_avg:92.16ms
step:14/1750 train_time:1296ms step_avg:92.60ms
step:15/1750 train_time:1395ms step_avg:92.97ms
step:16/1750 train_time:1492ms step_avg:93.26ms
step:17/1750 train_time:1589ms step_avg:93.50ms
step:18/1750 train_time:1686ms step_avg:93.67ms
step:19/1750 train_time:1782ms step_avg:93.81ms
step:20/1750 train_time:1879ms step_avg:93.97ms
step:21/1750 train_time:1977ms step_avg:94.12ms
step:22/1750 train_time:2074ms step_avg:94.26ms
step:23/1750 train_time:2170ms step_avg:94.37ms
step:24/1750 train_time:2267ms step_avg:94.47ms
step:25/1750 train_time:2364ms step_avg:94.56ms
step:26/1750 train_time:2461ms step_avg:94.66ms
step:27/1750 train_time:2558ms step_avg:94.74ms
step:28/1750 train_time:2655ms step_avg:94.83ms
step:29/1750 train_time:2752ms step_avg:94.90ms
step:30/1750 train_time:2850ms step_avg:94.99ms
step:31/1750 train_time:2947ms step_avg:95.05ms
step:32/1750 train_time:3044ms step_avg:95.13ms
step:33/1750 train_time:3140ms step_avg:95.16ms
step:34/1750 train_time:3238ms step_avg:95.23ms
step:35/1750 train_time:3335ms step_avg:95.28ms
step:36/1750 train_time:3432ms step_avg:95.33ms
step:37/1750 train_time:3528ms step_avg:95.35ms
step:38/1750 train_time:3625ms step_avg:95.39ms
step:39/1750 train_time:3721ms step_avg:95.42ms
step:40/1750 train_time:3819ms step_avg:95.47ms
step:41/1750 train_time:3916ms step_avg:95.50ms
step:42/1750 train_time:4013ms step_avg:95.54ms
step:43/1750 train_time:4109ms step_avg:95.57ms
step:44/1750 train_time:4206ms step_avg:95.60ms
step:45/1750 train_time:4303ms step_avg:95.62ms
step:46/1750 train_time:4400ms step_avg:95.65ms
step:47/1750 train_time:4497ms step_avg:95.69ms
step:48/1750 train_time:4595ms step_avg:95.72ms
step:49/1750 train_time:4691ms step_avg:95.74ms
step:50/1750 train_time:4789ms step_avg:95.79ms
step:51/1750 train_time:4885ms step_avg:95.78ms
step:52/1750 train_time:4982ms step_avg:95.80ms
step:53/1750 train_time:5078ms step_avg:95.81ms
step:54/1750 train_time:5175ms step_avg:95.83ms
step:55/1750 train_time:5272ms step_avg:95.85ms
step:56/1750 train_time:5369ms step_avg:95.87ms
step:57/1750 train_time:5465ms step_avg:95.88ms
step:58/1750 train_time:5562ms step_avg:95.90ms
step:59/1750 train_time:5659ms step_avg:95.91ms
step:60/1750 train_time:5756ms step_avg:95.94ms
step:61/1750 train_time:5853ms step_avg:95.95ms
step:62/1750 train_time:5950ms step_avg:95.97ms
step:63/1750 train_time:6047ms step_avg:95.98ms
step:64/1750 train_time:6144ms step_avg:96.00ms
step:65/1750 train_time:6240ms step_avg:96.00ms
step:66/1750 train_time:6337ms step_avg:96.02ms
step:67/1750 train_time:6434ms step_avg:96.03ms
step:68/1750 train_time:6532ms step_avg:96.06ms
step:69/1750 train_time:6629ms step_avg:96.07ms
step:70/1750 train_time:6726ms step_avg:96.08ms
step:71/1750 train_time:6822ms step_avg:96.09ms
step:72/1750 train_time:6920ms step_avg:96.10ms
step:73/1750 train_time:7017ms step_avg:96.12ms
step:74/1750 train_time:7115ms step_avg:96.14ms
step:75/1750 train_time:7211ms step_avg:96.14ms
step:76/1750 train_time:7307ms step_avg:96.15ms
step:77/1750 train_time:7404ms step_avg:96.16ms
step:78/1750 train_time:7501ms step_avg:96.16ms
step:79/1750 train_time:7598ms step_avg:96.18ms
step:80/1750 train_time:7696ms step_avg:96.20ms
step:81/1750 train_time:7793ms step_avg:96.21ms
step:82/1750 train_time:7890ms step_avg:96.22ms
step:83/1750 train_time:7987ms step_avg:96.23ms
step:84/1750 train_time:8084ms step_avg:96.23ms
step:85/1750 train_time:8180ms step_avg:96.23ms
step:86/1750 train_time:8278ms step_avg:96.26ms
step:87/1750 train_time:8375ms step_avg:96.26ms
step:88/1750 train_time:8472ms step_avg:96.27ms
step:89/1750 train_time:8568ms step_avg:96.27ms
step:90/1750 train_time:8665ms step_avg:96.28ms
step:91/1750 train_time:8762ms step_avg:96.28ms
step:92/1750 train_time:8859ms step_avg:96.30ms
step:93/1750 train_time:8957ms step_avg:96.31ms
step:94/1750 train_time:9054ms step_avg:96.32ms
step:95/1750 train_time:9151ms step_avg:96.33ms
step:96/1750 train_time:9248ms step_avg:96.33ms
step:97/1750 train_time:9344ms step_avg:96.33ms
step:98/1750 train_time:9441ms step_avg:96.33ms
step:99/1750 train_time:9537ms step_avg:96.34ms
step:100/1750 train_time:9634ms step_avg:96.34ms
step:101/1750 train_time:9731ms step_avg:96.35ms
step:102/1750 train_time:9827ms step_avg:96.35ms
step:103/1750 train_time:9924ms step_avg:96.35ms
step:104/1750 train_time:10020ms step_avg:96.35ms
step:105/1750 train_time:10117ms step_avg:96.35ms
step:106/1750 train_time:10214ms step_avg:96.36ms
step:107/1750 train_time:10311ms step_avg:96.37ms
step:108/1750 train_time:10408ms step_avg:96.37ms
step:109/1750 train_time:10504ms step_avg:96.37ms
step:110/1750 train_time:10601ms step_avg:96.38ms
step:111/1750 train_time:10698ms step_avg:96.38ms
step:112/1750 train_time:10796ms step_avg:96.39ms
step:113/1750 train_time:10893ms step_avg:96.40ms
step:114/1750 train_time:10991ms step_avg:96.41ms
step:115/1750 train_time:11087ms step_avg:96.41ms
step:116/1750 train_time:11183ms step_avg:96.41ms
step:117/1750 train_time:11280ms step_avg:96.41ms
step:118/1750 train_time:11377ms step_avg:96.42ms
step:119/1750 train_time:11474ms step_avg:96.42ms
step:120/1750 train_time:11571ms step_avg:96.43ms
step:121/1750 train_time:11668ms step_avg:96.43ms
step:122/1750 train_time:12077ms step_avg:98.99ms
step:123/1750 train_time:12158ms step_avg:98.85ms
step:124/1750 train_time:12254ms step_avg:98.82ms
step:125/1750 train_time:12351ms step_avg:98.81ms
step:125/1750 val_loss:4.6324 train_time:12443ms step_avg:99.55ms
step:126/1750 train_time:12463ms step_avg:98.91ms
step:127/1750 train_time:12551ms step_avg:98.83ms
step:128/1750 train_time:12651ms step_avg:98.83ms
step:129/1750 train_time:12749ms step_avg:98.83ms
step:130/1750 train_time:12846ms step_avg:98.81ms
step:131/1750 train_time:12943ms step_avg:98.80ms
step:132/1750 train_time:13040ms step_avg:98.78ms
step:133/1750 train_time:13137ms step_avg:98.77ms
step:134/1750 train_time:13234ms step_avg:98.76ms
step:135/1750 train_time:13330ms step_avg:98.74ms
step:136/1750 train_time:13427ms step_avg:98.73ms
step:137/1750 train_time:13524ms step_avg:98.72ms
step:138/1750 train_time:13622ms step_avg:98.71ms
step:139/1750 train_time:13720ms step_avg:98.71ms
step:140/1750 train_time:13819ms step_avg:98.70ms
step:141/1750 train_time:13916ms step_avg:98.70ms
step:142/1750 train_time:14013ms step_avg:98.68ms
step:143/1750 train_time:14110ms step_avg:98.67ms
step:144/1750 train_time:14207ms step_avg:98.66ms
step:145/1750 train_time:14305ms step_avg:98.65ms
step:146/1750 train_time:14402ms step_avg:98.65ms
step:147/1750 train_time:14500ms step_avg:98.64ms
step:148/1750 train_time:14598ms step_avg:98.63ms
step:149/1750 train_time:14695ms step_avg:98.62ms
step:150/1750 train_time:14791ms step_avg:98.61ms
step:151/1750 train_time:14888ms step_avg:98.60ms
step:152/1750 train_time:14985ms step_avg:98.59ms
step:153/1750 train_time:15084ms step_avg:98.59ms
step:154/1750 train_time:15181ms step_avg:98.58ms
step:155/1750 train_time:15279ms step_avg:98.57ms
step:156/1750 train_time:15376ms step_avg:98.57ms
step:157/1750 train_time:15474ms step_avg:98.56ms
step:158/1750 train_time:15571ms step_avg:98.55ms
step:159/1750 train_time:15668ms step_avg:98.54ms
step:160/1750 train_time:15765ms step_avg:98.53ms
step:161/1750 train_time:15863ms step_avg:98.53ms
step:162/1750 train_time:15962ms step_avg:98.53ms
step:163/1750 train_time:16059ms step_avg:98.52ms
step:164/1750 train_time:16156ms step_avg:98.51ms
step:165/1750 train_time:16253ms step_avg:98.50ms
step:166/1750 train_time:16350ms step_avg:98.49ms
step:167/1750 train_time:16447ms step_avg:98.48ms
step:168/1750 train_time:16544ms step_avg:98.47ms
step:169/1750 train_time:16642ms step_avg:98.48ms
step:170/1750 train_time:16740ms step_avg:98.47ms
step:171/1750 train_time:16838ms step_avg:98.47ms
step:172/1750 train_time:16935ms step_avg:98.46ms
step:173/1750 train_time:17032ms step_avg:98.45ms
step:174/1750 train_time:17129ms step_avg:98.44ms
step:175/1750 train_time:17227ms step_avg:98.44ms
step:176/1750 train_time:17324ms step_avg:98.43ms
step:177/1750 train_time:17421ms step_avg:98.43ms
step:178/1750 train_time:17518ms step_avg:98.42ms
step:179/1750 train_time:17617ms step_avg:98.42ms
step:180/1750 train_time:17714ms step_avg:98.41ms
step:181/1750 train_time:17812ms step_avg:98.41ms
step:182/1750 train_time:17909ms step_avg:98.40ms
step:183/1750 train_time:18006ms step_avg:98.39ms
step:184/1750 train_time:18104ms step_avg:98.39ms
step:185/1750 train_time:18202ms step_avg:98.39ms
step:186/1750 train_time:18300ms step_avg:98.39ms
step:187/1750 train_time:18398ms step_avg:98.39ms
step:188/1750 train_time:18495ms step_avg:98.38ms
step:189/1750 train_time:18592ms step_avg:98.37ms
step:190/1750 train_time:18689ms step_avg:98.36ms
step:191/1750 train_time:18786ms step_avg:98.36ms
step:192/1750 train_time:18883ms step_avg:98.35ms
step:193/1750 train_time:18982ms step_avg:98.35ms
step:194/1750 train_time:19079ms step_avg:98.34ms
step:195/1750 train_time:19176ms step_avg:98.34ms
step:196/1750 train_time:19273ms step_avg:98.33ms
step:197/1750 train_time:19371ms step_avg:98.33ms
step:198/1750 train_time:19467ms step_avg:98.32ms
step:199/1750 train_time:19565ms step_avg:98.31ms
step:200/1750 train_time:19662ms step_avg:98.31ms
step:201/1750 train_time:19760ms step_avg:98.31ms
step:202/1750 train_time:19858ms step_avg:98.31ms
step:203/1750 train_time:19955ms step_avg:98.30ms
step:204/1750 train_time:20052ms step_avg:98.29ms
step:205/1750 train_time:20149ms step_avg:98.29ms
step:206/1750 train_time:20246ms step_avg:98.28ms
step:207/1750 train_time:20344ms step_avg:98.28ms
step:208/1750 train_time:20442ms step_avg:98.28ms
step:209/1750 train_time:20540ms step_avg:98.28ms
step:210/1750 train_time:20638ms step_avg:98.28ms
step:211/1750 train_time:20735ms step_avg:98.27ms
step:212/1750 train_time:20832ms step_avg:98.26ms
step:213/1750 train_time:20929ms step_avg:98.26ms
step:214/1750 train_time:21027ms step_avg:98.26ms
step:215/1750 train_time:21124ms step_avg:98.25ms
step:216/1750 train_time:21222ms step_avg:98.25ms
step:217/1750 train_time:21320ms step_avg:98.25ms
step:218/1750 train_time:21417ms step_avg:98.24ms
step:219/1750 train_time:21514ms step_avg:98.24ms
step:220/1750 train_time:21611ms step_avg:98.23ms
step:221/1750 train_time:21707ms step_avg:98.22ms
step:222/1750 train_time:21805ms step_avg:98.22ms
step:223/1750 train_time:21903ms step_avg:98.22ms
step:224/1750 train_time:22002ms step_avg:98.22ms
step:225/1750 train_time:22102ms step_avg:98.23ms
step:226/1750 train_time:22199ms step_avg:98.23ms
step:227/1750 train_time:22297ms step_avg:98.22ms
step:228/1750 train_time:22394ms step_avg:98.22ms
step:229/1750 train_time:22490ms step_avg:98.21ms
step:230/1750 train_time:22588ms step_avg:98.21ms
step:231/1750 train_time:22685ms step_avg:98.20ms
step:232/1750 train_time:22782ms step_avg:98.20ms
step:233/1750 train_time:22880ms step_avg:98.20ms
step:234/1750 train_time:22977ms step_avg:98.19ms
step:235/1750 train_time:23074ms step_avg:98.19ms
step:236/1750 train_time:23171ms step_avg:98.18ms
step:237/1750 train_time:23269ms step_avg:98.18ms
step:238/1750 train_time:23366ms step_avg:98.18ms
step:239/1750 train_time:23464ms step_avg:98.18ms
step:240/1750 train_time:23562ms step_avg:98.18ms
step:241/1750 train_time:23661ms step_avg:98.18ms
step:242/1750 train_time:23760ms step_avg:98.18ms
step:243/1750 train_time:23859ms step_avg:98.18ms
step:244/1750 train_time:23956ms step_avg:98.18ms
step:245/1750 train_time:24053ms step_avg:98.18ms
step:246/1750 train_time:24151ms step_avg:98.17ms
step:247/1750 train_time:24249ms step_avg:98.18ms
step:248/1750 train_time:24346ms step_avg:98.17ms
step:249/1750 train_time:24443ms step_avg:98.17ms
step:250/1750 train_time:24540ms step_avg:98.16ms
step:250/1750 val_loss:4.0977 train_time:24632ms step_avg:98.53ms
step:251/1750 train_time:24654ms step_avg:98.22ms
step:252/1750 train_time:24741ms step_avg:98.18ms
step:253/1750 train_time:24841ms step_avg:98.18ms
step:254/1750 train_time:24938ms step_avg:98.18ms
step:255/1750 train_time:25035ms step_avg:98.18ms
step:256/1750 train_time:25132ms step_avg:98.17ms
step:257/1750 train_time:25228ms step_avg:98.17ms
step:258/1750 train_time:25325ms step_avg:98.16ms
step:259/1750 train_time:25422ms step_avg:98.16ms
step:260/1750 train_time:25520ms step_avg:98.15ms
step:261/1750 train_time:25617ms step_avg:98.15ms
step:262/1750 train_time:25717ms step_avg:98.16ms
step:263/1750 train_time:25818ms step_avg:98.17ms
step:264/1750 train_time:25917ms step_avg:98.17ms
step:265/1750 train_time:26016ms step_avg:98.17ms
step:266/1750 train_time:26114ms step_avg:98.17ms
step:267/1750 train_time:26212ms step_avg:98.17ms
step:268/1750 train_time:26310ms step_avg:98.17ms
step:269/1750 train_time:26407ms step_avg:98.17ms
step:270/1750 train_time:26504ms step_avg:98.16ms
step:271/1750 train_time:26601ms step_avg:98.16ms
step:272/1750 train_time:26699ms step_avg:98.16ms
step:273/1750 train_time:26797ms step_avg:98.16ms
step:274/1750 train_time:26896ms step_avg:98.16ms
step:275/1750 train_time:26993ms step_avg:98.16ms
step:276/1750 train_time:27091ms step_avg:98.16ms
step:277/1750 train_time:27189ms step_avg:98.16ms
step:278/1750 train_time:27289ms step_avg:98.16ms
step:279/1750 train_time:27386ms step_avg:98.16ms
step:280/1750 train_time:27485ms step_avg:98.16ms
step:281/1750 train_time:27582ms step_avg:98.16ms
step:282/1750 train_time:27680ms step_avg:98.16ms
step:283/1750 train_time:27778ms step_avg:98.16ms
step:284/1750 train_time:27877ms step_avg:98.16ms
step:285/1750 train_time:27975ms step_avg:98.16ms
step:286/1750 train_time:28073ms step_avg:98.16ms
step:287/1750 train_time:28170ms step_avg:98.15ms
step:288/1750 train_time:28268ms step_avg:98.15ms
step:289/1750 train_time:28365ms step_avg:98.15ms
step:290/1750 train_time:28463ms step_avg:98.15ms
step:291/1750 train_time:28561ms step_avg:98.15ms
step:292/1750 train_time:28659ms step_avg:98.15ms
step:293/1750 train_time:28756ms step_avg:98.14ms
step:294/1750 train_time:28854ms step_avg:98.14ms
step:295/1750 train_time:28951ms step_avg:98.14ms
step:296/1750 train_time:29049ms step_avg:98.14ms
step:297/1750 train_time:29146ms step_avg:98.14ms
step:298/1750 train_time:29244ms step_avg:98.13ms
step:299/1750 train_time:29342ms step_avg:98.13ms
step:300/1750 train_time:29440ms step_avg:98.13ms
step:301/1750 train_time:29538ms step_avg:98.13ms
step:302/1750 train_time:29636ms step_avg:98.13ms
step:303/1750 train_time:29734ms step_avg:98.13ms
step:304/1750 train_time:29833ms step_avg:98.13ms
step:305/1750 train_time:29930ms step_avg:98.13ms
step:306/1750 train_time:30028ms step_avg:98.13ms
step:307/1750 train_time:30126ms step_avg:98.13ms
step:308/1750 train_time:30224ms step_avg:98.13ms
step:309/1750 train_time:30321ms step_avg:98.13ms
step:310/1750 train_time:30419ms step_avg:98.13ms
step:311/1750 train_time:30517ms step_avg:98.13ms
step:312/1750 train_time:30616ms step_avg:98.13ms
step:313/1750 train_time:30713ms step_avg:98.13ms
step:314/1750 train_time:30811ms step_avg:98.13ms
step:315/1750 train_time:30909ms step_avg:98.12ms
step:316/1750 train_time:31007ms step_avg:98.12ms
step:317/1750 train_time:31104ms step_avg:98.12ms
step:318/1750 train_time:31202ms step_avg:98.12ms
step:319/1750 train_time:31299ms step_avg:98.12ms
step:320/1750 train_time:31397ms step_avg:98.11ms
step:321/1750 train_time:31495ms step_avg:98.11ms
step:322/1750 train_time:31592ms step_avg:98.11ms
step:323/1750 train_time:31690ms step_avg:98.11ms
step:324/1750 train_time:31787ms step_avg:98.11ms
step:325/1750 train_time:31884ms step_avg:98.11ms
step:326/1750 train_time:31982ms step_avg:98.10ms
step:327/1750 train_time:32080ms step_avg:98.10ms
step:328/1750 train_time:32179ms step_avg:98.11ms
step:329/1750 train_time:32276ms step_avg:98.10ms
step:330/1750 train_time:32374ms step_avg:98.10ms
step:331/1750 train_time:32472ms step_avg:98.10ms
step:332/1750 train_time:32569ms step_avg:98.10ms
step:333/1750 train_time:32666ms step_avg:98.10ms
step:334/1750 train_time:32764ms step_avg:98.10ms
step:335/1750 train_time:32862ms step_avg:98.09ms
step:336/1750 train_time:32960ms step_avg:98.09ms
step:337/1750 train_time:33057ms step_avg:98.09ms
step:338/1750 train_time:33156ms step_avg:98.09ms
step:339/1750 train_time:33254ms step_avg:98.09ms
step:340/1750 train_time:33351ms step_avg:98.09ms
step:341/1750 train_time:33449ms step_avg:98.09ms
step:342/1750 train_time:33547ms step_avg:98.09ms
step:343/1750 train_time:33644ms step_avg:98.09ms
step:344/1750 train_time:33742ms step_avg:98.09ms
step:345/1750 train_time:33839ms step_avg:98.09ms
step:346/1750 train_time:33938ms step_avg:98.09ms
step:347/1750 train_time:34036ms step_avg:98.09ms
step:348/1750 train_time:34134ms step_avg:98.09ms
step:349/1750 train_time:34232ms step_avg:98.09ms
step:350/1750 train_time:34330ms step_avg:98.08ms
step:351/1750 train_time:34427ms step_avg:98.08ms
step:352/1750 train_time:34524ms step_avg:98.08ms
step:353/1750 train_time:34621ms step_avg:98.08ms
step:354/1750 train_time:34720ms step_avg:98.08ms
step:355/1750 train_time:34817ms step_avg:98.08ms
step:356/1750 train_time:34916ms step_avg:98.08ms
step:357/1750 train_time:35015ms step_avg:98.08ms
step:358/1750 train_time:35113ms step_avg:98.08ms
step:359/1750 train_time:35210ms step_avg:98.08ms
step:360/1750 train_time:35307ms step_avg:98.08ms
step:361/1750 train_time:35405ms step_avg:98.07ms
step:362/1750 train_time:35502ms step_avg:98.07ms
step:363/1750 train_time:35600ms step_avg:98.07ms
step:364/1750 train_time:35698ms step_avg:98.07ms
step:365/1750 train_time:35796ms step_avg:98.07ms
step:366/1750 train_time:35895ms step_avg:98.07ms
step:367/1750 train_time:35994ms step_avg:98.08ms
step:368/1750 train_time:36092ms step_avg:98.08ms
step:369/1750 train_time:36191ms step_avg:98.08ms
step:370/1750 train_time:36289ms step_avg:98.08ms
step:371/1750 train_time:36387ms step_avg:98.08ms
step:372/1750 train_time:36485ms step_avg:98.08ms
step:373/1750 train_time:36582ms step_avg:98.08ms
step:374/1750 train_time:36680ms step_avg:98.08ms
step:375/1750 train_time:36778ms step_avg:98.08ms
step:375/1750 val_loss:3.8931 train_time:36871ms step_avg:98.32ms
step:376/1750 train_time:36892ms step_avg:98.12ms
step:377/1750 train_time:36978ms step_avg:98.09ms
step:378/1750 train_time:37076ms step_avg:98.09ms
step:379/1750 train_time:37175ms step_avg:98.09ms
step:380/1750 train_time:37273ms step_avg:98.09ms
step:381/1750 train_time:37370ms step_avg:98.08ms
step:382/1750 train_time:37468ms step_avg:98.08ms
step:383/1750 train_time:37565ms step_avg:98.08ms
step:384/1750 train_time:37662ms step_avg:98.08ms
step:385/1750 train_time:37760ms step_avg:98.08ms
step:386/1750 train_time:37857ms step_avg:98.08ms
step:387/1750 train_time:37955ms step_avg:98.08ms
step:388/1750 train_time:38053ms step_avg:98.07ms
step:389/1750 train_time:38152ms step_avg:98.08ms
step:390/1750 train_time:38249ms step_avg:98.07ms
step:391/1750 train_time:38349ms step_avg:98.08ms
step:392/1750 train_time:38449ms step_avg:98.08ms
step:393/1750 train_time:38549ms step_avg:98.09ms
step:394/1750 train_time:38648ms step_avg:98.09ms
step:395/1750 train_time:38749ms step_avg:98.10ms
step:396/1750 train_time:38848ms step_avg:98.10ms
step:397/1750 train_time:38947ms step_avg:98.10ms
step:398/1750 train_time:39047ms step_avg:98.11ms
step:399/1750 train_time:39147ms step_avg:98.11ms
step:400/1750 train_time:39247ms step_avg:98.12ms
step:401/1750 train_time:39347ms step_avg:98.12ms
step:402/1750 train_time:39447ms step_avg:98.13ms
step:403/1750 train_time:39548ms step_avg:98.13ms
step:404/1750 train_time:39648ms step_avg:98.14ms
step:405/1750 train_time:39748ms step_avg:98.14ms
step:406/1750 train_time:39848ms step_avg:98.15ms
step:407/1750 train_time:39948ms step_avg:98.15ms
step:408/1750 train_time:40047ms step_avg:98.16ms
step:409/1750 train_time:40148ms step_avg:98.16ms
step:410/1750 train_time:40248ms step_avg:98.17ms
step:411/1750 train_time:40349ms step_avg:98.17ms
step:412/1750 train_time:40448ms step_avg:98.18ms
step:413/1750 train_time:40548ms step_avg:98.18ms
step:414/1750 train_time:40648ms step_avg:98.18ms
step:415/1750 train_time:40749ms step_avg:98.19ms
step:416/1750 train_time:40848ms step_avg:98.19ms
step:417/1750 train_time:40948ms step_avg:98.20ms
step:418/1750 train_time:41047ms step_avg:98.20ms
step:419/1750 train_time:41147ms step_avg:98.20ms
step:420/1750 train_time:41247ms step_avg:98.21ms
step:421/1750 train_time:41347ms step_avg:98.21ms
step:422/1750 train_time:41447ms step_avg:98.22ms
step:423/1750 train_time:41547ms step_avg:98.22ms
step:424/1750 train_time:41647ms step_avg:98.22ms
step:425/1750 train_time:41748ms step_avg:98.23ms
step:426/1750 train_time:41848ms step_avg:98.23ms
step:427/1750 train_time:41948ms step_avg:98.24ms
step:428/1750 train_time:42048ms step_avg:98.24ms
step:429/1750 train_time:42148ms step_avg:98.25ms
step:430/1750 train_time:42248ms step_avg:98.25ms
step:431/1750 train_time:42349ms step_avg:98.26ms
step:432/1750 train_time:42449ms step_avg:98.26ms
step:433/1750 train_time:42549ms step_avg:98.27ms
step:434/1750 train_time:42649ms step_avg:98.27ms
step:435/1750 train_time:42749ms step_avg:98.27ms
step:436/1750 train_time:42850ms step_avg:98.28ms
step:437/1750 train_time:42950ms step_avg:98.28ms
step:438/1750 train_time:43050ms step_avg:98.29ms
step:439/1750 train_time:43150ms step_avg:98.29ms
step:440/1750 train_time:43250ms step_avg:98.30ms
step:441/1750 train_time:43350ms step_avg:98.30ms
step:442/1750 train_time:43450ms step_avg:98.30ms
step:443/1750 train_time:43550ms step_avg:98.31ms
step:444/1750 train_time:43650ms step_avg:98.31ms
step:445/1750 train_time:43750ms step_avg:98.31ms
step:446/1750 train_time:43851ms step_avg:98.32ms
step:447/1750 train_time:43951ms step_avg:98.32ms
step:448/1750 train_time:44051ms step_avg:98.33ms
step:449/1750 train_time:44151ms step_avg:98.33ms
step:450/1750 train_time:44250ms step_avg:98.33ms
step:451/1750 train_time:44350ms step_avg:98.34ms
step:452/1750 train_time:44450ms step_avg:98.34ms
step:453/1750 train_time:44551ms step_avg:98.35ms
step:454/1750 train_time:44651ms step_avg:98.35ms
step:455/1750 train_time:44751ms step_avg:98.35ms
step:456/1750 train_time:44851ms step_avg:98.36ms
step:457/1750 train_time:44950ms step_avg:98.36ms
step:458/1750 train_time:45050ms step_avg:98.36ms
step:459/1750 train_time:45151ms step_avg:98.37ms
step:460/1750 train_time:45251ms step_avg:98.37ms
step:461/1750 train_time:45351ms step_avg:98.37ms
step:462/1750 train_time:45451ms step_avg:98.38ms
step:463/1750 train_time:45551ms step_avg:98.38ms
step:464/1750 train_time:45651ms step_avg:98.38ms
step:465/1750 train_time:45751ms step_avg:98.39ms
step:466/1750 train_time:45850ms step_avg:98.39ms
step:467/1750 train_time:45950ms step_avg:98.39ms
step:468/1750 train_time:46050ms step_avg:98.40ms
step:469/1750 train_time:46150ms step_avg:98.40ms
step:470/1750 train_time:46250ms step_avg:98.40ms
step:471/1750 train_time:46350ms step_avg:98.41ms
step:472/1750 train_time:46450ms step_avg:98.41ms
step:473/1750 train_time:46549ms step_avg:98.41ms
step:474/1750 train_time:46648ms step_avg:98.41ms
step:475/1750 train_time:46748ms step_avg:98.42ms
step:476/1750 train_time:46848ms step_avg:98.42ms
step:477/1750 train_time:46947ms step_avg:98.42ms
step:478/1750 train_time:47047ms step_avg:98.43ms
step:479/1750 train_time:47148ms step_avg:98.43ms
step:480/1750 train_time:47249ms step_avg:98.43ms
step:481/1750 train_time:47349ms step_avg:98.44ms
step:482/1750 train_time:47449ms step_avg:98.44ms
step:483/1750 train_time:47551ms step_avg:98.45ms
step:484/1750 train_time:47650ms step_avg:98.45ms
step:485/1750 train_time:47750ms step_avg:98.45ms
step:486/1750 train_time:47849ms step_avg:98.45ms
step:487/1750 train_time:47949ms step_avg:98.46ms
step:488/1750 train_time:48049ms step_avg:98.46ms
step:489/1750 train_time:48148ms step_avg:98.46ms
step:490/1750 train_time:48247ms step_avg:98.46ms
step:491/1750 train_time:48347ms step_avg:98.47ms
step:492/1750 train_time:48447ms step_avg:98.47ms
step:493/1750 train_time:48546ms step_avg:98.47ms
step:494/1750 train_time:48647ms step_avg:98.47ms
step:495/1750 train_time:48747ms step_avg:98.48ms
step:496/1750 train_time:48847ms step_avg:98.48ms
step:497/1750 train_time:48948ms step_avg:98.49ms
step:498/1750 train_time:49048ms step_avg:98.49ms
step:499/1750 train_time:49148ms step_avg:98.49ms
step:500/1750 train_time:49247ms step_avg:98.49ms
step:500/1750 val_loss:3.7471 train_time:49341ms step_avg:98.68ms
step:501/1750 train_time:49362ms step_avg:98.53ms
step:502/1750 train_time:49450ms step_avg:98.51ms
step:503/1750 train_time:49551ms step_avg:98.51ms
step:504/1750 train_time:49650ms step_avg:98.51ms
step:505/1750 train_time:49749ms step_avg:98.51ms
step:506/1750 train_time:49849ms step_avg:98.52ms
step:507/1750 train_time:49948ms step_avg:98.52ms
step:508/1750 train_time:50048ms step_avg:98.52ms
step:509/1750 train_time:50147ms step_avg:98.52ms
step:510/1750 train_time:50246ms step_avg:98.52ms
step:511/1750 train_time:50345ms step_avg:98.52ms
step:512/1750 train_time:50445ms step_avg:98.53ms
step:513/1750 train_time:50544ms step_avg:98.53ms
step:514/1750 train_time:50645ms step_avg:98.53ms
step:515/1750 train_time:50745ms step_avg:98.53ms
step:516/1750 train_time:50844ms step_avg:98.54ms
step:517/1750 train_time:50944ms step_avg:98.54ms
step:518/1750 train_time:51044ms step_avg:98.54ms
step:519/1750 train_time:51144ms step_avg:98.54ms
step:520/1750 train_time:51245ms step_avg:98.55ms
step:521/1750 train_time:51345ms step_avg:98.55ms
step:522/1750 train_time:51445ms step_avg:98.55ms
step:523/1750 train_time:51545ms step_avg:98.56ms
step:524/1750 train_time:51645ms step_avg:98.56ms
step:525/1750 train_time:51744ms step_avg:98.56ms
step:526/1750 train_time:51845ms step_avg:98.56ms
step:527/1750 train_time:51945ms step_avg:98.57ms
step:528/1750 train_time:52046ms step_avg:98.57ms
step:529/1750 train_time:52145ms step_avg:98.57ms
step:530/1750 train_time:52245ms step_avg:98.58ms
step:531/1750 train_time:52346ms step_avg:98.58ms
step:532/1750 train_time:52447ms step_avg:98.58ms
step:533/1750 train_time:52546ms step_avg:98.59ms
step:534/1750 train_time:52647ms step_avg:98.59ms
step:535/1750 train_time:52747ms step_avg:98.59ms
step:536/1750 train_time:52847ms step_avg:98.60ms
step:537/1750 train_time:52947ms step_avg:98.60ms
step:538/1750 train_time:53047ms step_avg:98.60ms
step:539/1750 train_time:53147ms step_avg:98.60ms
step:540/1750 train_time:53247ms step_avg:98.60ms
step:541/1750 train_time:53346ms step_avg:98.61ms
step:542/1750 train_time:53446ms step_avg:98.61ms
step:543/1750 train_time:53546ms step_avg:98.61ms
step:544/1750 train_time:53646ms step_avg:98.61ms
step:545/1750 train_time:53746ms step_avg:98.62ms
step:546/1750 train_time:53847ms step_avg:98.62ms
step:547/1750 train_time:53947ms step_avg:98.62ms
step:548/1750 train_time:54047ms step_avg:98.63ms
step:549/1750 train_time:54147ms step_avg:98.63ms
step:550/1750 train_time:54247ms step_avg:98.63ms
step:551/1750 train_time:54346ms step_avg:98.63ms
step:552/1750 train_time:54447ms step_avg:98.64ms
step:553/1750 train_time:54546ms step_avg:98.64ms
step:554/1750 train_time:54647ms step_avg:98.64ms
step:555/1750 train_time:54746ms step_avg:98.64ms
step:556/1750 train_time:54846ms step_avg:98.64ms
step:557/1750 train_time:54946ms step_avg:98.65ms
step:558/1750 train_time:55046ms step_avg:98.65ms
step:559/1750 train_time:55146ms step_avg:98.65ms
step:560/1750 train_time:55247ms step_avg:98.65ms
step:561/1750 train_time:55347ms step_avg:98.66ms
step:562/1750 train_time:55446ms step_avg:98.66ms
step:563/1750 train_time:55546ms step_avg:98.66ms
step:564/1750 train_time:55646ms step_avg:98.66ms
step:565/1750 train_time:55746ms step_avg:98.66ms
step:566/1750 train_time:55846ms step_avg:98.67ms
step:567/1750 train_time:55946ms step_avg:98.67ms
step:568/1750 train_time:56045ms step_avg:98.67ms
step:569/1750 train_time:56145ms step_avg:98.67ms
step:570/1750 train_time:56245ms step_avg:98.68ms
step:571/1750 train_time:56346ms step_avg:98.68ms
step:572/1750 train_time:56446ms step_avg:98.68ms
step:573/1750 train_time:56547ms step_avg:98.69ms
step:574/1750 train_time:56647ms step_avg:98.69ms
step:575/1750 train_time:56747ms step_avg:98.69ms
step:576/1750 train_time:56848ms step_avg:98.69ms
step:577/1750 train_time:56948ms step_avg:98.70ms
step:578/1750 train_time:57047ms step_avg:98.70ms
step:579/1750 train_time:57148ms step_avg:98.70ms
step:580/1750 train_time:57248ms step_avg:98.70ms
step:581/1750 train_time:57348ms step_avg:98.70ms
step:582/1750 train_time:57447ms step_avg:98.71ms
step:583/1750 train_time:57547ms step_avg:98.71ms
step:584/1750 train_time:57648ms step_avg:98.71ms
step:585/1750 train_time:57748ms step_avg:98.71ms
step:586/1750 train_time:57848ms step_avg:98.72ms
step:587/1750 train_time:57948ms step_avg:98.72ms
step:588/1750 train_time:58048ms step_avg:98.72ms
step:589/1750 train_time:58147ms step_avg:98.72ms
step:590/1750 train_time:58248ms step_avg:98.72ms
step:591/1750 train_time:58347ms step_avg:98.73ms
step:592/1750 train_time:58447ms step_avg:98.73ms
step:593/1750 train_time:58547ms step_avg:98.73ms
step:594/1750 train_time:58647ms step_avg:98.73ms
step:595/1750 train_time:58747ms step_avg:98.73ms
step:596/1750 train_time:58847ms step_avg:98.74ms
step:597/1750 train_time:58946ms step_avg:98.74ms
step:598/1750 train_time:59046ms step_avg:98.74ms
step:599/1750 train_time:59147ms step_avg:98.74ms
step:600/1750 train_time:59247ms step_avg:98.74ms
step:601/1750 train_time:59347ms step_avg:98.75ms
step:602/1750 train_time:59447ms step_avg:98.75ms
step:603/1750 train_time:59547ms step_avg:98.75ms
step:604/1750 train_time:59648ms step_avg:98.75ms
step:605/1750 train_time:59747ms step_avg:98.76ms
step:606/1750 train_time:59847ms step_avg:98.76ms
step:607/1750 train_time:59947ms step_avg:98.76ms
step:608/1750 train_time:60047ms step_avg:98.76ms
step:609/1750 train_time:60147ms step_avg:98.76ms
step:610/1750 train_time:60247ms step_avg:98.77ms
step:611/1750 train_time:60347ms step_avg:98.77ms
step:612/1750 train_time:60447ms step_avg:98.77ms
step:613/1750 train_time:60547ms step_avg:98.77ms
step:614/1750 train_time:60647ms step_avg:98.77ms
step:615/1750 train_time:60748ms step_avg:98.78ms
step:616/1750 train_time:60847ms step_avg:98.78ms
step:617/1750 train_time:60947ms step_avg:98.78ms
step:618/1750 train_time:61047ms step_avg:98.78ms
step:619/1750 train_time:61147ms step_avg:98.78ms
step:620/1750 train_time:61247ms step_avg:98.79ms
step:621/1750 train_time:61347ms step_avg:98.79ms
step:622/1750 train_time:61447ms step_avg:98.79ms
step:623/1750 train_time:61547ms step_avg:98.79ms
step:624/1750 train_time:61647ms step_avg:98.79ms
step:625/1750 train_time:61747ms step_avg:98.79ms
step:625/1750 val_loss:3.6613 train_time:61841ms step_avg:98.95ms
step:626/1750 train_time:61861ms step_avg:98.82ms
step:627/1750 train_time:61955ms step_avg:98.81ms
step:628/1750 train_time:62056ms step_avg:98.82ms
step:629/1750 train_time:62156ms step_avg:98.82ms
step:630/1750 train_time:62255ms step_avg:98.82ms
step:631/1750 train_time:62355ms step_avg:98.82ms
step:632/1750 train_time:62454ms step_avg:98.82ms
step:633/1750 train_time:62554ms step_avg:98.82ms
step:634/1750 train_time:62653ms step_avg:98.82ms
step:635/1750 train_time:62753ms step_avg:98.82ms
step:636/1750 train_time:62853ms step_avg:98.83ms
step:637/1750 train_time:62955ms step_avg:98.83ms
step:638/1750 train_time:63058ms step_avg:98.84ms
step:639/1750 train_time:63159ms step_avg:98.84ms
step:640/1750 train_time:63258ms step_avg:98.84ms
step:641/1750 train_time:63359ms step_avg:98.84ms
step:642/1750 train_time:63458ms step_avg:98.84ms
step:643/1750 train_time:63559ms step_avg:98.85ms
step:644/1750 train_time:63658ms step_avg:98.85ms
step:645/1750 train_time:63758ms step_avg:98.85ms
step:646/1750 train_time:63859ms step_avg:98.85ms
step:647/1750 train_time:63958ms step_avg:98.85ms
step:648/1750 train_time:64058ms step_avg:98.86ms
step:649/1750 train_time:64158ms step_avg:98.86ms
step:650/1750 train_time:64258ms step_avg:98.86ms
step:651/1750 train_time:64360ms step_avg:98.86ms
step:652/1750 train_time:64462ms step_avg:98.87ms
step:653/1750 train_time:64563ms step_avg:98.87ms
step:654/1750 train_time:64665ms step_avg:98.88ms
step:655/1750 train_time:64767ms step_avg:98.88ms
step:656/1750 train_time:64869ms step_avg:98.89ms
step:657/1750 train_time:64972ms step_avg:98.89ms
step:658/1750 train_time:65073ms step_avg:98.90ms
step:659/1750 train_time:65175ms step_avg:98.90ms
step:660/1750 train_time:65276ms step_avg:98.90ms
step:661/1750 train_time:65378ms step_avg:98.91ms
step:662/1750 train_time:65479ms step_avg:98.91ms
step:663/1750 train_time:65581ms step_avg:98.92ms
step:664/1750 train_time:65682ms step_avg:98.92ms
step:665/1750 train_time:65784ms step_avg:98.92ms
step:666/1750 train_time:65885ms step_avg:98.93ms
step:667/1750 train_time:65987ms step_avg:98.93ms
step:668/1750 train_time:66089ms step_avg:98.94ms
step:669/1750 train_time:66192ms step_avg:98.94ms
step:670/1750 train_time:66295ms step_avg:98.95ms
step:671/1750 train_time:66397ms step_avg:98.95ms
step:672/1750 train_time:66498ms step_avg:98.96ms
step:673/1750 train_time:66599ms step_avg:98.96ms
step:674/1750 train_time:66700ms step_avg:98.96ms
step:675/1750 train_time:66801ms step_avg:98.96ms
step:676/1750 train_time:66903ms step_avg:98.97ms
step:677/1750 train_time:67004ms step_avg:98.97ms
step:678/1750 train_time:67105ms step_avg:98.97ms
step:679/1750 train_time:67208ms step_avg:98.98ms
step:680/1750 train_time:67311ms step_avg:98.99ms
step:681/1750 train_time:67413ms step_avg:98.99ms
step:682/1750 train_time:67514ms step_avg:98.99ms
step:683/1750 train_time:67616ms step_avg:99.00ms
step:684/1750 train_time:67718ms step_avg:99.00ms
step:685/1750 train_time:67819ms step_avg:99.01ms
step:686/1750 train_time:67920ms step_avg:99.01ms
step:687/1750 train_time:68021ms step_avg:99.01ms
step:688/1750 train_time:68123ms step_avg:99.02ms
step:689/1750 train_time:68224ms step_avg:99.02ms
step:690/1750 train_time:68327ms step_avg:99.02ms
step:691/1750 train_time:68429ms step_avg:99.03ms
step:692/1750 train_time:68531ms step_avg:99.03ms
step:693/1750 train_time:68633ms step_avg:99.04ms
step:694/1750 train_time:68735ms step_avg:99.04ms
step:695/1750 train_time:68837ms step_avg:99.05ms
step:696/1750 train_time:68938ms step_avg:99.05ms
step:697/1750 train_time:69039ms step_avg:99.05ms
step:698/1750 train_time:69140ms step_avg:99.05ms
step:699/1750 train_time:69242ms step_avg:99.06ms
step:700/1750 train_time:69343ms step_avg:99.06ms
step:701/1750 train_time:69445ms step_avg:99.07ms
step:702/1750 train_time:69546ms step_avg:99.07ms
step:703/1750 train_time:69648ms step_avg:99.07ms
step:704/1750 train_time:69751ms step_avg:99.08ms
step:705/1750 train_time:69855ms step_avg:99.08ms
step:706/1750 train_time:69957ms step_avg:99.09ms
step:707/1750 train_time:70058ms step_avg:99.09ms
step:708/1750 train_time:70160ms step_avg:99.10ms
step:709/1750 train_time:70262ms step_avg:99.10ms
step:710/1750 train_time:70363ms step_avg:99.10ms
step:711/1750 train_time:70464ms step_avg:99.10ms
step:712/1750 train_time:70565ms step_avg:99.11ms
step:713/1750 train_time:70666ms step_avg:99.11ms
step:714/1750 train_time:70769ms step_avg:99.12ms
step:715/1750 train_time:70873ms step_avg:99.12ms
step:716/1750 train_time:70974ms step_avg:99.13ms
step:717/1750 train_time:71077ms step_avg:99.13ms
step:718/1750 train_time:71178ms step_avg:99.13ms
step:719/1750 train_time:71280ms step_avg:99.14ms
step:720/1750 train_time:71381ms step_avg:99.14ms
step:721/1750 train_time:71483ms step_avg:99.14ms
step:722/1750 train_time:71584ms step_avg:99.15ms
step:723/1750 train_time:71685ms step_avg:99.15ms
step:724/1750 train_time:71787ms step_avg:99.15ms
step:725/1750 train_time:71890ms step_avg:99.16ms
step:726/1750 train_time:71992ms step_avg:99.16ms
step:727/1750 train_time:72094ms step_avg:99.17ms
step:728/1750 train_time:72195ms step_avg:99.17ms
step:729/1750 train_time:72296ms step_avg:99.17ms
step:730/1750 train_time:72398ms step_avg:99.17ms
step:731/1750 train_time:72499ms step_avg:99.18ms
step:732/1750 train_time:72600ms step_avg:99.18ms
step:733/1750 train_time:72703ms step_avg:99.19ms
step:734/1750 train_time:72803ms step_avg:99.19ms
step:735/1750 train_time:72904ms step_avg:99.19ms
step:736/1750 train_time:73006ms step_avg:99.19ms
step:737/1750 train_time:73108ms step_avg:99.20ms
step:738/1750 train_time:73211ms step_avg:99.20ms
step:739/1750 train_time:73314ms step_avg:99.21ms
step:740/1750 train_time:73415ms step_avg:99.21ms
step:741/1750 train_time:73516ms step_avg:99.21ms
step:742/1750 train_time:73617ms step_avg:99.21ms
step:743/1750 train_time:73719ms step_avg:99.22ms
step:744/1750 train_time:73820ms step_avg:99.22ms
step:745/1750 train_time:73922ms step_avg:99.22ms
step:746/1750 train_time:74023ms step_avg:99.23ms
step:747/1750 train_time:74125ms step_avg:99.23ms
step:748/1750 train_time:74227ms step_avg:99.23ms
step:749/1750 train_time:74329ms step_avg:99.24ms
step:750/1750 train_time:74432ms step_avg:99.24ms
step:750/1750 val_loss:3.5997 train_time:74528ms step_avg:99.37ms
step:751/1750 train_time:74548ms step_avg:99.26ms
step:752/1750 train_time:74642ms step_avg:99.26ms
step:753/1750 train_time:74744ms step_avg:99.26ms
step:754/1750 train_time:74846ms step_avg:99.27ms
step:755/1750 train_time:74948ms step_avg:99.27ms
step:756/1750 train_time:75050ms step_avg:99.27ms
step:757/1750 train_time:75152ms step_avg:99.28ms
step:758/1750 train_time:75254ms step_avg:99.28ms
step:759/1750 train_time:75355ms step_avg:99.28ms
step:760/1750 train_time:75456ms step_avg:99.28ms
step:761/1750 train_time:75557ms step_avg:99.29ms
step:762/1750 train_time:75659ms step_avg:99.29ms
step:763/1750 train_time:75761ms step_avg:99.29ms
step:764/1750 train_time:75862ms step_avg:99.30ms
step:765/1750 train_time:75963ms step_avg:99.30ms
step:766/1750 train_time:76065ms step_avg:99.30ms
step:767/1750 train_time:76166ms step_avg:99.30ms
step:768/1750 train_time:76270ms step_avg:99.31ms
step:769/1750 train_time:76372ms step_avg:99.31ms
step:770/1750 train_time:76474ms step_avg:99.32ms
step:771/1750 train_time:76576ms step_avg:99.32ms
step:772/1750 train_time:76677ms step_avg:99.32ms
step:773/1750 train_time:76777ms step_avg:99.32ms
step:774/1750 train_time:76879ms step_avg:99.33ms
step:775/1750 train_time:76980ms step_avg:99.33ms
step:776/1750 train_time:77081ms step_avg:99.33ms
step:777/1750 train_time:77183ms step_avg:99.33ms
step:778/1750 train_time:77285ms step_avg:99.34ms
step:779/1750 train_time:77386ms step_avg:99.34ms
step:780/1750 train_time:77489ms step_avg:99.35ms
step:781/1750 train_time:77592ms step_avg:99.35ms
step:782/1750 train_time:77695ms step_avg:99.35ms
step:783/1750 train_time:77796ms step_avg:99.36ms
step:784/1750 train_time:77898ms step_avg:99.36ms
step:785/1750 train_time:77999ms step_avg:99.36ms
step:786/1750 train_time:78101ms step_avg:99.37ms
step:787/1750 train_time:78202ms step_avg:99.37ms
step:788/1750 train_time:78304ms step_avg:99.37ms
step:789/1750 train_time:78406ms step_avg:99.37ms
step:790/1750 train_time:78509ms step_avg:99.38ms
step:791/1750 train_time:78612ms step_avg:99.38ms
step:792/1750 train_time:78714ms step_avg:99.39ms
step:793/1750 train_time:78815ms step_avg:99.39ms
step:794/1750 train_time:78917ms step_avg:99.39ms
step:795/1750 train_time:79019ms step_avg:99.39ms
step:796/1750 train_time:79121ms step_avg:99.40ms
step:797/1750 train_time:79222ms step_avg:99.40ms
step:798/1750 train_time:79324ms step_avg:99.40ms
step:799/1750 train_time:79426ms step_avg:99.41ms
step:800/1750 train_time:79528ms step_avg:99.41ms
step:801/1750 train_time:79631ms step_avg:99.41ms
step:802/1750 train_time:79733ms step_avg:99.42ms
step:803/1750 train_time:79836ms step_avg:99.42ms
step:804/1750 train_time:79938ms step_avg:99.43ms
step:805/1750 train_time:80039ms step_avg:99.43ms
step:806/1750 train_time:80141ms step_avg:99.43ms
step:807/1750 train_time:80243ms step_avg:99.43ms
step:808/1750 train_time:80345ms step_avg:99.44ms
step:809/1750 train_time:80446ms step_avg:99.44ms
step:810/1750 train_time:80550ms step_avg:99.44ms
step:811/1750 train_time:80652ms step_avg:99.45ms
step:812/1750 train_time:80754ms step_avg:99.45ms
step:813/1750 train_time:80855ms step_avg:99.45ms
step:814/1750 train_time:80957ms step_avg:99.46ms
step:815/1750 train_time:81059ms step_avg:99.46ms
step:816/1750 train_time:81161ms step_avg:99.46ms
step:817/1750 train_time:81262ms step_avg:99.46ms
step:818/1750 train_time:81364ms step_avg:99.47ms
step:819/1750 train_time:81466ms step_avg:99.47ms
step:820/1750 train_time:81568ms step_avg:99.47ms
step:821/1750 train_time:81670ms step_avg:99.48ms
step:822/1750 train_time:81773ms step_avg:99.48ms
step:823/1750 train_time:81874ms step_avg:99.48ms
step:824/1750 train_time:81976ms step_avg:99.49ms
step:825/1750 train_time:82078ms step_avg:99.49ms
step:826/1750 train_time:82180ms step_avg:99.49ms
step:827/1750 train_time:82282ms step_avg:99.49ms
step:828/1750 train_time:82383ms step_avg:99.50ms
step:829/1750 train_time:82485ms step_avg:99.50ms
step:830/1750 train_time:82587ms step_avg:99.50ms
step:831/1750 train_time:82689ms step_avg:99.51ms
step:832/1750 train_time:82792ms step_avg:99.51ms
step:833/1750 train_time:82894ms step_avg:99.51ms
step:834/1750 train_time:82996ms step_avg:99.52ms
step:835/1750 train_time:83098ms step_avg:99.52ms
step:836/1750 train_time:83199ms step_avg:99.52ms
step:837/1750 train_time:83301ms step_avg:99.52ms
step:838/1750 train_time:83402ms step_avg:99.53ms
step:839/1750 train_time:83504ms step_avg:99.53ms
step:840/1750 train_time:83606ms step_avg:99.53ms
step:841/1750 train_time:83707ms step_avg:99.53ms
step:842/1750 train_time:83810ms step_avg:99.54ms
step:843/1750 train_time:83913ms step_avg:99.54ms
step:844/1750 train_time:84016ms step_avg:99.54ms
step:845/1750 train_time:84117ms step_avg:99.55ms
step:846/1750 train_time:84219ms step_avg:99.55ms
step:847/1750 train_time:84320ms step_avg:99.55ms
step:848/1750 train_time:84423ms step_avg:99.56ms
step:849/1750 train_time:84524ms step_avg:99.56ms
step:850/1750 train_time:84626ms step_avg:99.56ms
step:851/1750 train_time:84728ms step_avg:99.56ms
step:852/1750 train_time:84830ms step_avg:99.57ms
step:853/1750 train_time:84932ms step_avg:99.57ms
step:854/1750 train_time:85034ms step_avg:99.57ms
step:855/1750 train_time:85136ms step_avg:99.57ms
step:856/1750 train_time:85238ms step_avg:99.58ms
step:857/1750 train_time:85339ms step_avg:99.58ms
step:858/1750 train_time:85440ms step_avg:99.58ms
step:859/1750 train_time:85541ms step_avg:99.58ms
step:860/1750 train_time:85643ms step_avg:99.58ms
step:861/1750 train_time:85745ms step_avg:99.59ms
step:862/1750 train_time:85847ms step_avg:99.59ms
step:863/1750 train_time:85950ms step_avg:99.59ms
step:864/1750 train_time:86053ms step_avg:99.60ms
step:865/1750 train_time:86155ms step_avg:99.60ms
step:866/1750 train_time:86258ms step_avg:99.60ms
step:867/1750 train_time:86359ms step_avg:99.61ms
step:868/1750 train_time:86460ms step_avg:99.61ms
step:869/1750 train_time:86561ms step_avg:99.61ms
step:870/1750 train_time:86663ms step_avg:99.61ms
step:871/1750 train_time:86764ms step_avg:99.61ms
step:872/1750 train_time:86866ms step_avg:99.62ms
step:873/1750 train_time:86969ms step_avg:99.62ms
step:874/1750 train_time:87072ms step_avg:99.62ms
step:875/1750 train_time:87174ms step_avg:99.63ms
step:875/1750 val_loss:3.5516 train_time:87270ms step_avg:99.74ms
step:876/1750 train_time:87290ms step_avg:99.65ms
step:877/1750 train_time:87383ms step_avg:99.64ms
step:878/1750 train_time:87487ms step_avg:99.64ms
step:879/1750 train_time:87589ms step_avg:99.65ms
step:880/1750 train_time:87691ms step_avg:99.65ms
step:881/1750 train_time:87793ms step_avg:99.65ms
step:882/1750 train_time:87895ms step_avg:99.65ms
step:883/1750 train_time:87997ms step_avg:99.66ms
step:884/1750 train_time:88098ms step_avg:99.66ms
step:885/1750 train_time:88200ms step_avg:99.66ms
step:886/1750 train_time:88300ms step_avg:99.66ms
step:887/1750 train_time:88402ms step_avg:99.66ms
step:888/1750 train_time:88504ms step_avg:99.67ms
step:889/1750 train_time:88607ms step_avg:99.67ms
step:890/1750 train_time:88710ms step_avg:99.67ms
step:891/1750 train_time:88812ms step_avg:99.68ms
step:892/1750 train_time:88914ms step_avg:99.68ms
step:893/1750 train_time:89016ms step_avg:99.68ms
step:894/1750 train_time:89118ms step_avg:99.68ms
step:895/1750 train_time:89219ms step_avg:99.69ms
step:896/1750 train_time:89320ms step_avg:99.69ms
step:897/1750 train_time:89422ms step_avg:99.69ms
step:898/1750 train_time:89524ms step_avg:99.69ms
step:899/1750 train_time:89626ms step_avg:99.70ms
step:900/1750 train_time:89729ms step_avg:99.70ms
step:901/1750 train_time:89832ms step_avg:99.70ms
step:902/1750 train_time:89935ms step_avg:99.71ms
step:903/1750 train_time:90038ms step_avg:99.71ms
step:904/1750 train_time:90140ms step_avg:99.71ms
step:905/1750 train_time:90241ms step_avg:99.71ms
step:906/1750 train_time:90342ms step_avg:99.72ms
step:907/1750 train_time:90445ms step_avg:99.72ms
step:908/1750 train_time:90547ms step_avg:99.72ms
step:909/1750 train_time:90649ms step_avg:99.72ms
step:910/1750 train_time:90753ms step_avg:99.73ms
step:911/1750 train_time:90856ms step_avg:99.73ms
step:912/1750 train_time:90959ms step_avg:99.74ms
step:913/1750 train_time:91062ms step_avg:99.74ms
step:914/1750 train_time:91166ms step_avg:99.74ms
step:915/1750 train_time:91271ms step_avg:99.75ms
step:916/1750 train_time:91374ms step_avg:99.75ms
step:917/1750 train_time:91476ms step_avg:99.76ms
step:918/1750 train_time:91579ms step_avg:99.76ms
step:919/1750 train_time:91683ms step_avg:99.76ms
step:920/1750 train_time:91787ms step_avg:99.77ms
step:921/1750 train_time:91891ms step_avg:99.77ms
step:922/1750 train_time:91994ms step_avg:99.78ms
step:923/1750 train_time:92097ms step_avg:99.78ms
step:924/1750 train_time:92199ms step_avg:99.78ms
step:925/1750 train_time:92303ms step_avg:99.79ms
step:926/1750 train_time:92406ms step_avg:99.79ms
step:927/1750 train_time:92510ms step_avg:99.79ms
step:928/1750 train_time:92612ms step_avg:99.80ms
step:929/1750 train_time:92715ms step_avg:99.80ms
step:930/1750 train_time:92818ms step_avg:99.80ms
step:931/1750 train_time:92921ms step_avg:99.81ms
step:932/1750 train_time:93024ms step_avg:99.81ms
step:933/1750 train_time:93128ms step_avg:99.82ms
step:934/1750 train_time:93232ms step_avg:99.82ms
step:935/1750 train_time:93335ms step_avg:99.82ms
step:936/1750 train_time:93438ms step_avg:99.83ms
step:937/1750 train_time:93541ms step_avg:99.83ms
step:938/1750 train_time:93645ms step_avg:99.83ms
step:939/1750 train_time:93750ms step_avg:99.84ms
step:940/1750 train_time:93853ms step_avg:99.84ms
step:941/1750 train_time:93956ms step_avg:99.85ms
step:942/1750 train_time:94059ms step_avg:99.85ms
step:943/1750 train_time:94163ms step_avg:99.85ms
step:944/1750 train_time:94267ms step_avg:99.86ms
step:945/1750 train_time:94372ms step_avg:99.86ms
step:946/1750 train_time:94474ms step_avg:99.87ms
step:947/1750 train_time:94577ms step_avg:99.87ms
step:948/1750 train_time:94680ms step_avg:99.87ms
step:949/1750 train_time:94783ms step_avg:99.88ms
step:950/1750 train_time:94887ms step_avg:99.88ms
step:951/1750 train_time:94990ms step_avg:99.88ms
step:952/1750 train_time:95093ms step_avg:99.89ms
step:953/1750 train_time:95196ms step_avg:99.89ms
step:954/1750 train_time:95298ms step_avg:99.89ms
step:955/1750 train_time:95402ms step_avg:99.90ms
step:956/1750 train_time:95505ms step_avg:99.90ms
step:957/1750 train_time:95609ms step_avg:99.90ms
step:958/1750 train_time:95712ms step_avg:99.91ms
step:959/1750 train_time:95814ms step_avg:99.91ms
step:960/1750 train_time:95917ms step_avg:99.91ms
step:961/1750 train_time:96021ms step_avg:99.92ms
step:962/1750 train_time:96124ms step_avg:99.92ms
step:963/1750 train_time:96227ms step_avg:99.92ms
step:964/1750 train_time:96331ms step_avg:99.93ms
step:965/1750 train_time:96434ms step_avg:99.93ms
step:966/1750 train_time:96537ms step_avg:99.93ms
step:967/1750 train_time:96641ms step_avg:99.94ms
step:968/1750 train_time:96746ms step_avg:99.94ms
step:969/1750 train_time:96850ms step_avg:99.95ms
step:970/1750 train_time:96953ms step_avg:99.95ms
step:971/1750 train_time:97056ms step_avg:99.96ms
step:972/1750 train_time:97159ms step_avg:99.96ms
step:973/1750 train_time:97262ms step_avg:99.96ms
step:974/1750 train_time:97365ms step_avg:99.96ms
step:975/1750 train_time:97469ms step_avg:99.97ms
step:976/1750 train_time:97573ms step_avg:99.97ms
step:977/1750 train_time:97676ms step_avg:99.98ms
step:978/1750 train_time:97779ms step_avg:99.98ms
step:979/1750 train_time:97883ms step_avg:99.98ms
step:980/1750 train_time:97986ms step_avg:99.99ms
step:981/1750 train_time:98090ms step_avg:99.99ms
step:982/1750 train_time:98192ms step_avg:99.99ms
step:983/1750 train_time:98296ms step_avg:100.00ms
step:984/1750 train_time:98399ms step_avg:100.00ms
step:985/1750 train_time:98503ms step_avg:100.00ms
step:986/1750 train_time:98606ms step_avg:100.01ms
step:987/1750 train_time:98709ms step_avg:100.01ms
step:988/1750 train_time:98812ms step_avg:100.01ms
step:989/1750 train_time:98916ms step_avg:100.02ms
step:990/1750 train_time:99018ms step_avg:100.02ms
step:991/1750 train_time:99122ms step_avg:100.02ms
step:992/1750 train_time:99224ms step_avg:100.02ms
step:993/1750 train_time:99330ms step_avg:100.03ms
step:994/1750 train_time:99433ms step_avg:100.03ms
step:995/1750 train_time:99537ms step_avg:100.04ms
step:996/1750 train_time:99640ms step_avg:100.04ms
step:997/1750 train_time:99742ms step_avg:100.04ms
step:998/1750 train_time:99845ms step_avg:100.04ms
step:999/1750 train_time:99948ms step_avg:100.05ms
step:1000/1750 train_time:100052ms step_avg:100.05ms
step:1000/1750 val_loss:3.5139 train_time:100150ms step_avg:100.15ms
step:1001/1750 train_time:100170ms step_avg:100.07ms
step:1002/1750 train_time:100268ms step_avg:100.07ms
step:1003/1750 train_time:100373ms step_avg:100.07ms
step:1004/1750 train_time:100477ms step_avg:100.08ms
step:1005/1750 train_time:100579ms step_avg:100.08ms
step:1006/1750 train_time:100682ms step_avg:100.08ms
step:1007/1750 train_time:100784ms step_avg:100.08ms
step:1008/1750 train_time:100887ms step_avg:100.09ms
step:1009/1750 train_time:100990ms step_avg:100.09ms
step:1010/1750 train_time:101093ms step_avg:100.09ms
step:1011/1750 train_time:101198ms step_avg:100.10ms
step:1012/1750 train_time:101302ms step_avg:100.10ms
step:1013/1750 train_time:101405ms step_avg:100.10ms
step:1014/1750 train_time:101508ms step_avg:100.11ms
step:1015/1750 train_time:101611ms step_avg:100.11ms
step:1016/1750 train_time:101716ms step_avg:100.11ms
step:1017/1750 train_time:101820ms step_avg:100.12ms
step:1018/1750 train_time:101923ms step_avg:100.12ms
step:1019/1750 train_time:102026ms step_avg:100.12ms
step:1020/1750 train_time:102129ms step_avg:100.13ms
step:1021/1750 train_time:102232ms step_avg:100.13ms
step:1022/1750 train_time:102336ms step_avg:100.13ms
step:1023/1750 train_time:102440ms step_avg:100.14ms
step:1024/1750 train_time:102543ms step_avg:100.14ms
step:1025/1750 train_time:102646ms step_avg:100.14ms
step:1026/1750 train_time:102749ms step_avg:100.14ms
step:1027/1750 train_time:102852ms step_avg:100.15ms
step:1028/1750 train_time:102956ms step_avg:100.15ms
step:1029/1750 train_time:103060ms step_avg:100.16ms
step:1030/1750 train_time:103162ms step_avg:100.16ms
step:1031/1750 train_time:103266ms step_avg:100.16ms
step:1032/1750 train_time:103369ms step_avg:100.16ms
step:1033/1750 train_time:103472ms step_avg:100.17ms
step:1034/1750 train_time:103576ms step_avg:100.17ms
step:1035/1750 train_time:103680ms step_avg:100.17ms
step:1036/1750 train_time:103782ms step_avg:100.18ms
step:1037/1750 train_time:103887ms step_avg:100.18ms
step:1038/1750 train_time:103989ms step_avg:100.18ms
step:1039/1750 train_time:104093ms step_avg:100.19ms
step:1040/1750 train_time:104198ms step_avg:100.19ms
step:1041/1750 train_time:104301ms step_avg:100.19ms
step:1042/1750 train_time:104405ms step_avg:100.20ms
step:1043/1750 train_time:104508ms step_avg:100.20ms
step:1044/1750 train_time:104612ms step_avg:100.20ms
step:1045/1750 train_time:104716ms step_avg:100.21ms
step:1046/1750 train_time:104820ms step_avg:100.21ms
step:1047/1750 train_time:104923ms step_avg:100.21ms
step:1048/1750 train_time:105027ms step_avg:100.22ms
step:1049/1750 train_time:105131ms step_avg:100.22ms
step:1050/1750 train_time:105235ms step_avg:100.22ms
step:1051/1750 train_time:105339ms step_avg:100.23ms
step:1052/1750 train_time:105442ms step_avg:100.23ms
step:1053/1750 train_time:105545ms step_avg:100.23ms
step:1054/1750 train_time:105647ms step_avg:100.23ms
step:1055/1750 train_time:105751ms step_avg:100.24ms
step:1056/1750 train_time:105855ms step_avg:100.24ms
step:1057/1750 train_time:105958ms step_avg:100.24ms
step:1058/1750 train_time:106062ms step_avg:100.25ms
step:1059/1750 train_time:106166ms step_avg:100.25ms
step:1060/1750 train_time:106269ms step_avg:100.25ms
step:1061/1750 train_time:106373ms step_avg:100.26ms
step:1062/1750 train_time:106477ms step_avg:100.26ms
step:1063/1750 train_time:106583ms step_avg:100.27ms
step:1064/1750 train_time:106688ms step_avg:100.27ms
step:1065/1750 train_time:106790ms step_avg:100.27ms
step:1066/1750 train_time:106894ms step_avg:100.28ms
step:1067/1750 train_time:106998ms step_avg:100.28ms
step:1068/1750 train_time:107103ms step_avg:100.28ms
step:1069/1750 train_time:107206ms step_avg:100.29ms
step:1070/1750 train_time:107309ms step_avg:100.29ms
step:1071/1750 train_time:107412ms step_avg:100.29ms
step:1072/1750 train_time:107516ms step_avg:100.29ms
step:1073/1750 train_time:107619ms step_avg:100.30ms
step:1074/1750 train_time:107723ms step_avg:100.30ms
step:1075/1750 train_time:107826ms step_avg:100.30ms
step:1076/1750 train_time:107929ms step_avg:100.31ms
step:1077/1750 train_time:108033ms step_avg:100.31ms
step:1078/1750 train_time:108138ms step_avg:100.31ms
step:1079/1750 train_time:108240ms step_avg:100.32ms
step:1080/1750 train_time:108345ms step_avg:100.32ms
step:1081/1750 train_time:108447ms step_avg:100.32ms
step:1082/1750 train_time:108550ms step_avg:100.32ms
step:1083/1750 train_time:108654ms step_avg:100.33ms
step:1084/1750 train_time:108759ms step_avg:100.33ms
step:1085/1750 train_time:108862ms step_avg:100.33ms
step:1086/1750 train_time:108965ms step_avg:100.34ms
step:1087/1750 train_time:109068ms step_avg:100.34ms
step:1088/1750 train_time:109171ms step_avg:100.34ms
step:1089/1750 train_time:109275ms step_avg:100.34ms
step:1090/1750 train_time:109379ms step_avg:100.35ms
step:1091/1750 train_time:109482ms step_avg:100.35ms
step:1092/1750 train_time:109585ms step_avg:100.35ms
step:1093/1750 train_time:109688ms step_avg:100.35ms
step:1094/1750 train_time:109792ms step_avg:100.36ms
step:1095/1750 train_time:109896ms step_avg:100.36ms
step:1096/1750 train_time:109999ms step_avg:100.36ms
step:1097/1750 train_time:110103ms step_avg:100.37ms
step:1098/1750 train_time:110206ms step_avg:100.37ms
step:1099/1750 train_time:110309ms step_avg:100.37ms
step:1100/1750 train_time:110413ms step_avg:100.38ms
step:1101/1750 train_time:110517ms step_avg:100.38ms
step:1102/1750 train_time:110620ms step_avg:100.38ms
step:1103/1750 train_time:110724ms step_avg:100.38ms
step:1104/1750 train_time:110828ms step_avg:100.39ms
step:1105/1750 train_time:110930ms step_avg:100.39ms
step:1106/1750 train_time:111035ms step_avg:100.39ms
step:1107/1750 train_time:111140ms step_avg:100.40ms
step:1108/1750 train_time:111243ms step_avg:100.40ms
step:1109/1750 train_time:111346ms step_avg:100.40ms
step:1110/1750 train_time:111449ms step_avg:100.40ms
step:1111/1750 train_time:111553ms step_avg:100.41ms
step:1112/1750 train_time:111659ms step_avg:100.41ms
step:1113/1750 train_time:111762ms step_avg:100.42ms
step:1114/1750 train_time:111866ms step_avg:100.42ms
step:1115/1750 train_time:111969ms step_avg:100.42ms
step:1116/1750 train_time:112072ms step_avg:100.42ms
step:1117/1750 train_time:112177ms step_avg:100.43ms
step:1118/1750 train_time:112281ms step_avg:100.43ms
step:1119/1750 train_time:112385ms step_avg:100.43ms
step:1120/1750 train_time:112488ms step_avg:100.44ms
step:1121/1750 train_time:112591ms step_avg:100.44ms
step:1122/1750 train_time:112696ms step_avg:100.44ms
step:1123/1750 train_time:112799ms step_avg:100.44ms
step:1124/1750 train_time:112903ms step_avg:100.45ms
step:1125/1750 train_time:113006ms step_avg:100.45ms
step:1125/1750 val_loss:3.4702 train_time:113104ms step_avg:100.54ms
step:1126/1750 train_time:113125ms step_avg:100.47ms
step:1127/1750 train_time:113226ms step_avg:100.47ms
step:1128/1750 train_time:113330ms step_avg:100.47ms
step:1129/1750 train_time:113434ms step_avg:100.47ms
step:1130/1750 train_time:113537ms step_avg:100.47ms
step:1131/1750 train_time:113640ms step_avg:100.48ms
step:1132/1750 train_time:113743ms step_avg:100.48ms
step:1133/1750 train_time:113847ms step_avg:100.48ms
step:1134/1750 train_time:113949ms step_avg:100.48ms
step:1135/1750 train_time:114053ms step_avg:100.49ms
step:1136/1750 train_time:114156ms step_avg:100.49ms
step:1137/1750 train_time:114261ms step_avg:100.49ms
step:1138/1750 train_time:114365ms step_avg:100.50ms
step:1139/1750 train_time:114470ms step_avg:100.50ms
step:1140/1750 train_time:114573ms step_avg:100.50ms
step:1141/1750 train_time:114676ms step_avg:100.50ms
step:1142/1750 train_time:114780ms step_avg:100.51ms
step:1143/1750 train_time:114883ms step_avg:100.51ms
step:1144/1750 train_time:114987ms step_avg:100.51ms
step:1145/1750 train_time:115091ms step_avg:100.52ms
step:1146/1750 train_time:115194ms step_avg:100.52ms
step:1147/1750 train_time:115297ms step_avg:100.52ms
step:1148/1750 train_time:115401ms step_avg:100.52ms
step:1149/1750 train_time:115506ms step_avg:100.53ms
step:1150/1750 train_time:115609ms step_avg:100.53ms
step:1151/1750 train_time:115712ms step_avg:100.53ms
step:1152/1750 train_time:115815ms step_avg:100.53ms
step:1153/1750 train_time:115918ms step_avg:100.54ms
step:1154/1750 train_time:116022ms step_avg:100.54ms
step:1155/1750 train_time:116127ms step_avg:100.54ms
step:1156/1750 train_time:116230ms step_avg:100.54ms
step:1157/1750 train_time:116335ms step_avg:100.55ms
step:1158/1750 train_time:116438ms step_avg:100.55ms
step:1159/1750 train_time:116542ms step_avg:100.55ms
step:1160/1750 train_time:116646ms step_avg:100.56ms
step:1161/1750 train_time:116749ms step_avg:100.56ms
step:1162/1750 train_time:116853ms step_avg:100.56ms
step:1163/1750 train_time:116956ms step_avg:100.56ms
step:1164/1750 train_time:117058ms step_avg:100.57ms
step:1165/1750 train_time:117163ms step_avg:100.57ms
step:1166/1750 train_time:117267ms step_avg:100.57ms
step:1167/1750 train_time:117371ms step_avg:100.57ms
step:1168/1750 train_time:117474ms step_avg:100.58ms
step:1169/1750 train_time:117578ms step_avg:100.58ms
step:1170/1750 train_time:117682ms step_avg:100.58ms
step:1171/1750 train_time:117789ms step_avg:100.59ms
step:1172/1750 train_time:117893ms step_avg:100.59ms
step:1173/1750 train_time:117997ms step_avg:100.59ms
step:1174/1750 train_time:118101ms step_avg:100.60ms
step:1175/1750 train_time:118206ms step_avg:100.60ms
step:1176/1750 train_time:118310ms step_avg:100.60ms
step:1177/1750 train_time:118414ms step_avg:100.61ms
step:1178/1750 train_time:118519ms step_avg:100.61ms
step:1179/1750 train_time:118623ms step_avg:100.61ms
step:1180/1750 train_time:118729ms step_avg:100.62ms
step:1181/1750 train_time:118834ms step_avg:100.62ms
step:1182/1750 train_time:118939ms step_avg:100.63ms
step:1183/1750 train_time:119044ms step_avg:100.63ms
step:1184/1750 train_time:119149ms step_avg:100.63ms
step:1185/1750 train_time:119253ms step_avg:100.64ms
step:1186/1750 train_time:119359ms step_avg:100.64ms
step:1187/1750 train_time:119465ms step_avg:100.64ms
step:1188/1750 train_time:119569ms step_avg:100.65ms
step:1189/1750 train_time:119674ms step_avg:100.65ms
step:1190/1750 train_time:119779ms step_avg:100.65ms
step:1191/1750 train_time:119884ms step_avg:100.66ms
step:1192/1750 train_time:119988ms step_avg:100.66ms
step:1193/1750 train_time:120092ms step_avg:100.66ms
step:1194/1750 train_time:120196ms step_avg:100.67ms
step:1195/1750 train_time:120302ms step_avg:100.67ms
step:1196/1750 train_time:120407ms step_avg:100.68ms
step:1197/1750 train_time:120512ms step_avg:100.68ms
step:1198/1750 train_time:120616ms step_avg:100.68ms
step:1199/1750 train_time:120721ms step_avg:100.68ms
step:1200/1750 train_time:120826ms step_avg:100.69ms
step:1201/1750 train_time:120931ms step_avg:100.69ms
step:1202/1750 train_time:121035ms step_avg:100.69ms
step:1203/1750 train_time:121139ms step_avg:100.70ms
step:1204/1750 train_time:121243ms step_avg:100.70ms
step:1205/1750 train_time:121348ms step_avg:100.70ms
step:1206/1750 train_time:121454ms step_avg:100.71ms
step:1207/1750 train_time:121559ms step_avg:100.71ms
step:1208/1750 train_time:121663ms step_avg:100.71ms
step:1209/1750 train_time:121768ms step_avg:100.72ms
step:1210/1750 train_time:121872ms step_avg:100.72ms
step:1211/1750 train_time:121977ms step_avg:100.72ms
step:1212/1750 train_time:122083ms step_avg:100.73ms
step:1213/1750 train_time:122189ms step_avg:100.73ms
step:1214/1750 train_time:122293ms step_avg:100.74ms
step:1215/1750 train_time:122398ms step_avg:100.74ms
step:1216/1750 train_time:122504ms step_avg:100.74ms
step:1217/1750 train_time:122609ms step_avg:100.75ms
step:1218/1750 train_time:122713ms step_avg:100.75ms
step:1219/1750 train_time:122819ms step_avg:100.75ms
step:1220/1750 train_time:122924ms step_avg:100.76ms
step:1221/1750 train_time:123028ms step_avg:100.76ms
step:1222/1750 train_time:123134ms step_avg:100.76ms
step:1223/1750 train_time:123239ms step_avg:100.77ms
step:1224/1750 train_time:123344ms step_avg:100.77ms
step:1225/1750 train_time:123450ms step_avg:100.78ms
step:1226/1750 train_time:123554ms step_avg:100.78ms
step:1227/1750 train_time:123661ms step_avg:100.78ms
step:1228/1750 train_time:123767ms step_avg:100.79ms
step:1229/1750 train_time:123872ms step_avg:100.79ms
step:1230/1750 train_time:123976ms step_avg:100.79ms
step:1231/1750 train_time:124081ms step_avg:100.80ms
step:1232/1750 train_time:124185ms step_avg:100.80ms
step:1233/1750 train_time:124289ms step_avg:100.80ms
step:1234/1750 train_time:124393ms step_avg:100.80ms
step:1235/1750 train_time:124497ms step_avg:100.81ms
step:1236/1750 train_time:124603ms step_avg:100.81ms
step:1237/1750 train_time:124709ms step_avg:100.82ms
step:1238/1750 train_time:124813ms step_avg:100.82ms
step:1239/1750 train_time:124917ms step_avg:100.82ms
step:1240/1750 train_time:125022ms step_avg:100.82ms
step:1241/1750 train_time:125127ms step_avg:100.83ms
step:1242/1750 train_time:125231ms step_avg:100.83ms
step:1243/1750 train_time:125336ms step_avg:100.83ms
step:1244/1750 train_time:125440ms step_avg:100.84ms
step:1245/1750 train_time:125544ms step_avg:100.84ms
step:1246/1750 train_time:125650ms step_avg:100.84ms
step:1247/1750 train_time:125755ms step_avg:100.85ms
step:1248/1750 train_time:125859ms step_avg:100.85ms
step:1249/1750 train_time:125963ms step_avg:100.85ms
step:1250/1750 train_time:126069ms step_avg:100.85ms
step:1250/1750 val_loss:3.4232 train_time:126170ms step_avg:100.94ms
step:1251/1750 train_time:126190ms step_avg:100.87ms
step:1252/1750 train_time:126283ms step_avg:100.87ms
step:1253/1750 train_time:126388ms step_avg:100.87ms
step:1254/1750 train_time:126492ms step_avg:100.87ms
step:1255/1750 train_time:126600ms step_avg:100.88ms
step:1256/1750 train_time:126704ms step_avg:100.88ms
step:1257/1750 train_time:126807ms step_avg:100.88ms
step:1258/1750 train_time:126912ms step_avg:100.88ms
step:1259/1750 train_time:127016ms step_avg:100.89ms
step:1260/1750 train_time:127121ms step_avg:100.89ms
step:1261/1750 train_time:127226ms step_avg:100.89ms
step:1262/1750 train_time:127332ms step_avg:100.90ms
step:1263/1750 train_time:127436ms step_avg:100.90ms
step:1264/1750 train_time:127542ms step_avg:100.90ms
step:1265/1750 train_time:127647ms step_avg:100.91ms
step:1266/1750 train_time:127752ms step_avg:100.91ms
step:1267/1750 train_time:127857ms step_avg:100.91ms
step:1268/1750 train_time:127961ms step_avg:100.92ms
step:1269/1750 train_time:128065ms step_avg:100.92ms
step:1270/1750 train_time:128170ms step_avg:100.92ms
step:1271/1750 train_time:128275ms step_avg:100.92ms
step:1272/1750 train_time:128379ms step_avg:100.93ms
step:1273/1750 train_time:128485ms step_avg:100.93ms
step:1274/1750 train_time:128589ms step_avg:100.93ms
step:1275/1750 train_time:128693ms step_avg:100.94ms
step:1276/1750 train_time:128798ms step_avg:100.94ms
step:1277/1750 train_time:128903ms step_avg:100.94ms
step:1278/1750 train_time:129007ms step_avg:100.94ms
step:1279/1750 train_time:129112ms step_avg:100.95ms
step:1280/1750 train_time:129218ms step_avg:100.95ms
step:1281/1750 train_time:129323ms step_avg:100.95ms
step:1282/1750 train_time:129429ms step_avg:100.96ms
step:1283/1750 train_time:129533ms step_avg:100.96ms
step:1284/1750 train_time:129637ms step_avg:100.96ms
step:1285/1750 train_time:129742ms step_avg:100.97ms
step:1286/1750 train_time:129848ms step_avg:100.97ms
step:1287/1750 train_time:129953ms step_avg:100.97ms
step:1288/1750 train_time:130057ms step_avg:100.98ms
step:1289/1750 train_time:130161ms step_avg:100.98ms
step:1290/1750 train_time:130265ms step_avg:100.98ms
step:1291/1750 train_time:130369ms step_avg:100.98ms
step:1292/1750 train_time:130474ms step_avg:100.99ms
step:1293/1750 train_time:130579ms step_avg:100.99ms
step:1294/1750 train_time:130683ms step_avg:100.99ms
step:1295/1750 train_time:130787ms step_avg:100.99ms
step:1296/1750 train_time:130892ms step_avg:101.00ms
step:1297/1750 train_time:130996ms step_avg:101.00ms
step:1298/1750 train_time:131102ms step_avg:101.00ms
step:1299/1750 train_time:131207ms step_avg:101.01ms
step:1300/1750 train_time:131311ms step_avg:101.01ms
step:1301/1750 train_time:131418ms step_avg:101.01ms
step:1302/1750 train_time:131525ms step_avg:101.02ms
step:1303/1750 train_time:131628ms step_avg:101.02ms
step:1304/1750 train_time:131733ms step_avg:101.02ms
step:1305/1750 train_time:131837ms step_avg:101.02ms
step:1306/1750 train_time:131941ms step_avg:101.03ms
step:1307/1750 train_time:132045ms step_avg:101.03ms
step:1308/1750 train_time:132149ms step_avg:101.03ms
step:1309/1750 train_time:132254ms step_avg:101.03ms
step:1310/1750 train_time:132359ms step_avg:101.04ms
step:1311/1750 train_time:132463ms step_avg:101.04ms
step:1312/1750 train_time:132567ms step_avg:101.04ms
step:1313/1750 train_time:132671ms step_avg:101.04ms
step:1314/1750 train_time:132776ms step_avg:101.05ms
step:1315/1750 train_time:132880ms step_avg:101.05ms
step:1316/1750 train_time:132985ms step_avg:101.05ms
step:1317/1750 train_time:133091ms step_avg:101.06ms
step:1318/1750 train_time:133199ms step_avg:101.06ms
step:1319/1750 train_time:133303ms step_avg:101.06ms
step:1320/1750 train_time:133408ms step_avg:101.07ms
step:1321/1750 train_time:133512ms step_avg:101.07ms
step:1322/1750 train_time:133617ms step_avg:101.07ms
step:1323/1750 train_time:133722ms step_avg:101.07ms
step:1324/1750 train_time:133826ms step_avg:101.08ms
step:1325/1750 train_time:133931ms step_avg:101.08ms
step:1326/1750 train_time:134036ms step_avg:101.08ms
step:1327/1750 train_time:134144ms step_avg:101.09ms
step:1328/1750 train_time:134248ms step_avg:101.09ms
step:1329/1750 train_time:134352ms step_avg:101.09ms
step:1330/1750 train_time:134456ms step_avg:101.10ms
step:1331/1750 train_time:134560ms step_avg:101.10ms
step:1332/1750 train_time:134664ms step_avg:101.10ms
step:1333/1750 train_time:134768ms step_avg:101.10ms
step:1334/1750 train_time:134873ms step_avg:101.10ms
step:1335/1750 train_time:134977ms step_avg:101.11ms
step:1336/1750 train_time:135083ms step_avg:101.11ms
step:1337/1750 train_time:135187ms step_avg:101.11ms
step:1338/1750 train_time:135290ms step_avg:101.11ms
step:1339/1750 train_time:135396ms step_avg:101.12ms
step:1340/1750 train_time:135502ms step_avg:101.12ms
step:1341/1750 train_time:135607ms step_avg:101.12ms
step:1342/1750 train_time:135711ms step_avg:101.13ms
step:1343/1750 train_time:135817ms step_avg:101.13ms
step:1344/1750 train_time:135922ms step_avg:101.13ms
step:1345/1750 train_time:136027ms step_avg:101.14ms
step:1346/1750 train_time:136132ms step_avg:101.14ms
step:1347/1750 train_time:136237ms step_avg:101.14ms
step:1348/1750 train_time:136344ms step_avg:101.15ms
step:1349/1750 train_time:136448ms step_avg:101.15ms
step:1350/1750 train_time:136553ms step_avg:101.15ms
step:1351/1750 train_time:136658ms step_avg:101.15ms
step:1352/1750 train_time:136762ms step_avg:101.16ms
step:1353/1750 train_time:136867ms step_avg:101.16ms
step:1354/1750 train_time:136972ms step_avg:101.16ms
step:1355/1750 train_time:137077ms step_avg:101.16ms
step:1356/1750 train_time:137182ms step_avg:101.17ms
step:1357/1750 train_time:137286ms step_avg:101.17ms
step:1358/1750 train_time:137391ms step_avg:101.17ms
step:1359/1750 train_time:137496ms step_avg:101.17ms
step:1360/1750 train_time:137602ms step_avg:101.18ms
step:1361/1750 train_time:137707ms step_avg:101.18ms
step:1362/1750 train_time:137811ms step_avg:101.18ms
step:1363/1750 train_time:137917ms step_avg:101.19ms
step:1364/1750 train_time:138021ms step_avg:101.19ms
step:1365/1750 train_time:138125ms step_avg:101.19ms
step:1366/1750 train_time:138229ms step_avg:101.19ms
step:1367/1750 train_time:138335ms step_avg:101.20ms
step:1368/1750 train_time:138439ms step_avg:101.20ms
step:1369/1750 train_time:138544ms step_avg:101.20ms
step:1370/1750 train_time:138651ms step_avg:101.20ms
step:1371/1750 train_time:138755ms step_avg:101.21ms
step:1372/1750 train_time:138859ms step_avg:101.21ms
step:1373/1750 train_time:138964ms step_avg:101.21ms
step:1374/1750 train_time:139069ms step_avg:101.21ms
step:1375/1750 train_time:139174ms step_avg:101.22ms
step:1375/1750 val_loss:3.3804 train_time:139275ms step_avg:101.29ms
step:1376/1750 train_time:139294ms step_avg:101.23ms
step:1377/1750 train_time:139390ms step_avg:101.23ms
step:1378/1750 train_time:139494ms step_avg:101.23ms
step:1379/1750 train_time:139599ms step_avg:101.23ms
step:1380/1750 train_time:139704ms step_avg:101.23ms
step:1381/1750 train_time:139809ms step_avg:101.24ms
step:1382/1750 train_time:139912ms step_avg:101.24ms
step:1383/1750 train_time:140017ms step_avg:101.24ms
step:1384/1750 train_time:140122ms step_avg:101.24ms
step:1385/1750 train_time:140227ms step_avg:101.25ms
step:1386/1750 train_time:140333ms step_avg:101.25ms
step:1387/1750 train_time:140439ms step_avg:101.25ms
step:1388/1750 train_time:140544ms step_avg:101.26ms
step:1389/1750 train_time:140650ms step_avg:101.26ms
step:1390/1750 train_time:140753ms step_avg:101.26ms
step:1391/1750 train_time:140858ms step_avg:101.26ms
step:1392/1750 train_time:140962ms step_avg:101.27ms
step:1393/1750 train_time:141067ms step_avg:101.27ms
step:1394/1750 train_time:141171ms step_avg:101.27ms
step:1395/1750 train_time:141278ms step_avg:101.27ms
step:1396/1750 train_time:141383ms step_avg:101.28ms
step:1397/1750 train_time:141489ms step_avg:101.28ms
step:1398/1750 train_time:141593ms step_avg:101.28ms
step:1399/1750 train_time:141698ms step_avg:101.29ms
step:1400/1750 train_time:141803ms step_avg:101.29ms
step:1401/1750 train_time:141908ms step_avg:101.29ms
step:1402/1750 train_time:142012ms step_avg:101.29ms
step:1403/1750 train_time:142117ms step_avg:101.30ms
step:1404/1750 train_time:142223ms step_avg:101.30ms
step:1405/1750 train_time:142327ms step_avg:101.30ms
step:1406/1750 train_time:142432ms step_avg:101.30ms
step:1407/1750 train_time:142536ms step_avg:101.31ms
step:1408/1750 train_time:142641ms step_avg:101.31ms
step:1409/1750 train_time:142746ms step_avg:101.31ms
step:1410/1750 train_time:142851ms step_avg:101.31ms
step:1411/1750 train_time:142955ms step_avg:101.31ms
step:1412/1750 train_time:143059ms step_avg:101.32ms
step:1413/1750 train_time:143163ms step_avg:101.32ms
step:1414/1750 train_time:143269ms step_avg:101.32ms
step:1415/1750 train_time:143375ms step_avg:101.32ms
step:1416/1750 train_time:143480ms step_avg:101.33ms
step:1417/1750 train_time:143584ms step_avg:101.33ms
step:1418/1750 train_time:143689ms step_avg:101.33ms
step:1419/1750 train_time:143793ms step_avg:101.33ms
step:1420/1750 train_time:143897ms step_avg:101.34ms
step:1421/1750 train_time:144002ms step_avg:101.34ms
step:1422/1750 train_time:144107ms step_avg:101.34ms
step:1423/1750 train_time:144211ms step_avg:101.34ms
step:1424/1750 train_time:144316ms step_avg:101.35ms
step:1425/1750 train_time:144421ms step_avg:101.35ms
step:1426/1750 train_time:144527ms step_avg:101.35ms
step:1427/1750 train_time:144631ms step_avg:101.35ms
step:1428/1750 train_time:144739ms step_avg:101.36ms
step:1429/1750 train_time:144845ms step_avg:101.36ms
step:1430/1750 train_time:144950ms step_avg:101.36ms
step:1431/1750 train_time:145059ms step_avg:101.37ms
step:1432/1750 train_time:145164ms step_avg:101.37ms
step:1433/1750 train_time:145269ms step_avg:101.37ms
step:1434/1750 train_time:145375ms step_avg:101.38ms
step:1435/1750 train_time:145480ms step_avg:101.38ms
step:1436/1750 train_time:145590ms step_avg:101.39ms
step:1437/1750 train_time:145696ms step_avg:101.39ms
step:1438/1750 train_time:145801ms step_avg:101.39ms
step:1439/1750 train_time:145907ms step_avg:101.39ms
step:1440/1750 train_time:146012ms step_avg:101.40ms
step:1441/1750 train_time:146121ms step_avg:101.40ms
step:1442/1750 train_time:146226ms step_avg:101.40ms
step:1443/1750 train_time:146332ms step_avg:101.41ms
step:1444/1750 train_time:146438ms step_avg:101.41ms
step:1445/1750 train_time:146544ms step_avg:101.41ms
step:1446/1750 train_time:146649ms step_avg:101.42ms
step:1447/1750 train_time:146755ms step_avg:101.42ms
step:1448/1750 train_time:146861ms step_avg:101.42ms
step:1449/1750 train_time:146968ms step_avg:101.43ms
step:1450/1750 train_time:147074ms step_avg:101.43ms
step:1451/1750 train_time:147180ms step_avg:101.43ms
step:1452/1750 train_time:147286ms step_avg:101.44ms
step:1453/1750 train_time:147391ms step_avg:101.44ms
step:1454/1750 train_time:147497ms step_avg:101.44ms
step:1455/1750 train_time:147604ms step_avg:101.45ms
step:1456/1750 train_time:147711ms step_avg:101.45ms
step:1457/1750 train_time:147817ms step_avg:101.45ms
step:1458/1750 train_time:147922ms step_avg:101.46ms
step:1459/1750 train_time:148029ms step_avg:101.46ms
step:1460/1750 train_time:148135ms step_avg:101.46ms
step:1461/1750 train_time:148240ms step_avg:101.47ms
step:1462/1750 train_time:148346ms step_avg:101.47ms
step:1463/1750 train_time:148452ms step_avg:101.47ms
step:1464/1750 train_time:148559ms step_avg:101.48ms
step:1465/1750 train_time:148665ms step_avg:101.48ms
step:1466/1750 train_time:148772ms step_avg:101.48ms
step:1467/1750 train_time:148879ms step_avg:101.49ms
step:1468/1750 train_time:148986ms step_avg:101.49ms
step:1469/1750 train_time:149092ms step_avg:101.49ms
step:1470/1750 train_time:149197ms step_avg:101.49ms
step:1471/1750 train_time:149303ms step_avg:101.50ms
step:1472/1750 train_time:149409ms step_avg:101.50ms
step:1473/1750 train_time:149516ms step_avg:101.50ms
step:1474/1750 train_time:149622ms step_avg:101.51ms
step:1475/1750 train_time:149730ms step_avg:101.51ms
step:1476/1750 train_time:149835ms step_avg:101.51ms
step:1477/1750 train_time:149942ms step_avg:101.52ms
step:1478/1750 train_time:150048ms step_avg:101.52ms
step:1479/1750 train_time:150154ms step_avg:101.52ms
step:1480/1750 train_time:150259ms step_avg:101.53ms
step:1481/1750 train_time:150367ms step_avg:101.53ms
step:1482/1750 train_time:150472ms step_avg:101.53ms
step:1483/1750 train_time:150579ms step_avg:101.54ms
step:1484/1750 train_time:150683ms step_avg:101.54ms
step:1485/1750 train_time:150790ms step_avg:101.54ms
step:1486/1750 train_time:150895ms step_avg:101.54ms
step:1487/1750 train_time:151000ms step_avg:101.55ms
step:1488/1750 train_time:151107ms step_avg:101.55ms
step:1489/1750 train_time:151214ms step_avg:101.55ms
step:1490/1750 train_time:151320ms step_avg:101.56ms
step:1491/1750 train_time:151426ms step_avg:101.56ms
step:1492/1750 train_time:151532ms step_avg:101.56ms
step:1493/1750 train_time:151641ms step_avg:101.57ms
step:1494/1750 train_time:151751ms step_avg:101.57ms
step:1495/1750 train_time:151857ms step_avg:101.58ms
step:1496/1750 train_time:151962ms step_avg:101.58ms
step:1497/1750 train_time:152068ms step_avg:101.58ms
step:1498/1750 train_time:152173ms step_avg:101.58ms
step:1499/1750 train_time:152278ms step_avg:101.59ms
step:1500/1750 train_time:152384ms step_avg:101.59ms
step:1500/1750 val_loss:3.3417 train_time:152484ms step_avg:101.66ms
step:1501/1750 train_time:152505ms step_avg:101.60ms
step:1502/1750 train_time:152602ms step_avg:101.60ms
step:1503/1750 train_time:152707ms step_avg:101.60ms
step:1504/1750 train_time:152814ms step_avg:101.61ms
step:1505/1750 train_time:152922ms step_avg:101.61ms
step:1506/1750 train_time:153027ms step_avg:101.61ms
step:1507/1750 train_time:153133ms step_avg:101.61ms
step:1508/1750 train_time:153240ms step_avg:101.62ms
step:1509/1750 train_time:153345ms step_avg:101.62ms
step:1510/1750 train_time:153450ms step_avg:101.62ms
step:1511/1750 train_time:153557ms step_avg:101.63ms
step:1512/1750 train_time:153663ms step_avg:101.63ms
step:1513/1750 train_time:153769ms step_avg:101.63ms
step:1514/1750 train_time:153875ms step_avg:101.63ms
step:1515/1750 train_time:153981ms step_avg:101.64ms
step:1516/1750 train_time:154087ms step_avg:101.64ms
step:1517/1750 train_time:154193ms step_avg:101.64ms
step:1518/1750 train_time:154301ms step_avg:101.65ms
step:1519/1750 train_time:154405ms step_avg:101.65ms
step:1520/1750 train_time:154511ms step_avg:101.65ms
step:1521/1750 train_time:154616ms step_avg:101.65ms
step:1522/1750 train_time:154723ms step_avg:101.66ms
step:1523/1750 train_time:154830ms step_avg:101.66ms
step:1524/1750 train_time:154935ms step_avg:101.66ms
step:1525/1750 train_time:155041ms step_avg:101.67ms
step:1526/1750 train_time:155146ms step_avg:101.67ms
step:1527/1750 train_time:155251ms step_avg:101.67ms
step:1528/1750 train_time:155359ms step_avg:101.67ms
step:1529/1750 train_time:155465ms step_avg:101.68ms
step:1530/1750 train_time:155570ms step_avg:101.68ms
step:1531/1750 train_time:155676ms step_avg:101.68ms
step:1532/1750 train_time:155783ms step_avg:101.69ms
step:1533/1750 train_time:155888ms step_avg:101.69ms
step:1534/1750 train_time:155995ms step_avg:101.69ms
step:1535/1750 train_time:156099ms step_avg:101.69ms
step:1536/1750 train_time:156205ms step_avg:101.70ms
step:1537/1750 train_time:156312ms step_avg:101.70ms
step:1538/1750 train_time:156419ms step_avg:101.70ms
step:1539/1750 train_time:156524ms step_avg:101.71ms
step:1540/1750 train_time:156633ms step_avg:101.71ms
step:1541/1750 train_time:156740ms step_avg:101.71ms
step:1542/1750 train_time:156845ms step_avg:101.72ms
step:1543/1750 train_time:156950ms step_avg:101.72ms
step:1544/1750 train_time:157057ms step_avg:101.72ms
step:1545/1750 train_time:157162ms step_avg:101.72ms
step:1546/1750 train_time:157269ms step_avg:101.73ms
step:1547/1750 train_time:157374ms step_avg:101.73ms
step:1548/1750 train_time:157479ms step_avg:101.73ms
step:1549/1750 train_time:157585ms step_avg:101.73ms
step:1550/1750 train_time:157691ms step_avg:101.74ms
step:1551/1750 train_time:157796ms step_avg:101.74ms
step:1552/1750 train_time:157903ms step_avg:101.74ms
step:1553/1750 train_time:158010ms step_avg:101.74ms
step:1554/1750 train_time:158115ms step_avg:101.75ms
step:1555/1750 train_time:158221ms step_avg:101.75ms
step:1556/1750 train_time:158327ms step_avg:101.75ms
step:1557/1750 train_time:158432ms step_avg:101.75ms
step:1558/1750 train_time:158539ms step_avg:101.76ms
step:1559/1750 train_time:158644ms step_avg:101.76ms
step:1560/1750 train_time:158750ms step_avg:101.76ms
step:1561/1750 train_time:158859ms step_avg:101.77ms
step:1562/1750 train_time:158964ms step_avg:101.77ms
step:1563/1750 train_time:159070ms step_avg:101.77ms
step:1564/1750 train_time:159175ms step_avg:101.77ms
step:1565/1750 train_time:159280ms step_avg:101.78ms
step:1566/1750 train_time:159387ms step_avg:101.78ms
step:1567/1750 train_time:159492ms step_avg:101.78ms
step:1568/1750 train_time:159598ms step_avg:101.78ms
step:1569/1750 train_time:159709ms step_avg:101.79ms
step:1570/1750 train_time:159816ms step_avg:101.79ms
step:1571/1750 train_time:159923ms step_avg:101.80ms
step:1572/1750 train_time:160029ms step_avg:101.80ms
step:1573/1750 train_time:160138ms step_avg:101.80ms
step:1574/1750 train_time:160243ms step_avg:101.81ms
step:1575/1750 train_time:160349ms step_avg:101.81ms
step:1576/1750 train_time:160455ms step_avg:101.81ms
step:1577/1750 train_time:160561ms step_avg:101.81ms
step:1578/1750 train_time:160668ms step_avg:101.82ms
step:1579/1750 train_time:160773ms step_avg:101.82ms
step:1580/1750 train_time:160879ms step_avg:101.82ms
step:1581/1750 train_time:160986ms step_avg:101.83ms
step:1582/1750 train_time:161094ms step_avg:101.83ms
step:1583/1750 train_time:161199ms step_avg:101.83ms
step:1584/1750 train_time:161305ms step_avg:101.83ms
step:1585/1750 train_time:161410ms step_avg:101.84ms
step:1586/1750 train_time:161519ms step_avg:101.84ms
step:1587/1750 train_time:161626ms step_avg:101.84ms
step:1588/1750 train_time:161732ms step_avg:101.85ms
step:1589/1750 train_time:161839ms step_avg:101.85ms
step:1590/1750 train_time:161945ms step_avg:101.85ms
step:1591/1750 train_time:162050ms step_avg:101.85ms
step:1592/1750 train_time:162157ms step_avg:101.86ms
step:1593/1750 train_time:162263ms step_avg:101.86ms
step:1594/1750 train_time:162370ms step_avg:101.86ms
step:1595/1750 train_time:162476ms step_avg:101.87ms
step:1596/1750 train_time:162584ms step_avg:101.87ms
step:1597/1750 train_time:162689ms step_avg:101.87ms
step:1598/1750 train_time:162795ms step_avg:101.87ms
step:1599/1750 train_time:162902ms step_avg:101.88ms
step:1600/1750 train_time:163010ms step_avg:101.88ms
step:1601/1750 train_time:163117ms step_avg:101.88ms
step:1602/1750 train_time:163224ms step_avg:101.89ms
step:1603/1750 train_time:163329ms step_avg:101.89ms
step:1604/1750 train_time:163435ms step_avg:101.89ms
step:1605/1750 train_time:163541ms step_avg:101.89ms
step:1606/1750 train_time:163647ms step_avg:101.90ms
step:1607/1750 train_time:163756ms step_avg:101.90ms
step:1608/1750 train_time:163862ms step_avg:101.90ms
step:1609/1750 train_time:163969ms step_avg:101.91ms
step:1610/1750 train_time:164075ms step_avg:101.91ms
step:1611/1750 train_time:164182ms step_avg:101.91ms
step:1612/1750 train_time:164289ms step_avg:101.92ms
step:1613/1750 train_time:164394ms step_avg:101.92ms
step:1614/1750 train_time:164499ms step_avg:101.92ms
step:1615/1750 train_time:164606ms step_avg:101.92ms
step:1616/1750 train_time:164712ms step_avg:101.93ms
step:1617/1750 train_time:164819ms step_avg:101.93ms
step:1618/1750 train_time:164926ms step_avg:101.93ms
step:1619/1750 train_time:165033ms step_avg:101.94ms
step:1620/1750 train_time:165141ms step_avg:101.94ms
step:1621/1750 train_time:165247ms step_avg:101.94ms
step:1622/1750 train_time:165353ms step_avg:101.94ms
step:1623/1750 train_time:165462ms step_avg:101.95ms
step:1624/1750 train_time:165567ms step_avg:101.95ms
step:1625/1750 train_time:165672ms step_avg:101.95ms
step:1625/1750 val_loss:3.3079 train_time:165774ms step_avg:102.01ms
step:1626/1750 train_time:165795ms step_avg:101.96ms
step:1627/1750 train_time:165889ms step_avg:101.96ms
step:1628/1750 train_time:165994ms step_avg:101.96ms
step:1629/1750 train_time:166098ms step_avg:101.96ms
step:1630/1750 train_time:166204ms step_avg:101.97ms
step:1631/1750 train_time:166309ms step_avg:101.97ms
step:1632/1750 train_time:166415ms step_avg:101.97ms
step:1633/1750 train_time:166521ms step_avg:101.97ms
step:1634/1750 train_time:166627ms step_avg:101.98ms
step:1635/1750 train_time:166733ms step_avg:101.98ms
step:1636/1750 train_time:166841ms step_avg:101.98ms
step:1637/1750 train_time:166948ms step_avg:101.98ms
step:1638/1750 train_time:167054ms step_avg:101.99ms
step:1639/1750 train_time:167160ms step_avg:101.99ms
step:1640/1750 train_time:167266ms step_avg:101.99ms
step:1641/1750 train_time:167373ms step_avg:101.99ms
step:1642/1750 train_time:167479ms step_avg:102.00ms
step:1643/1750 train_time:167585ms step_avg:102.00ms
step:1644/1750 train_time:167692ms step_avg:102.00ms
step:1645/1750 train_time:167797ms step_avg:102.00ms
step:1646/1750 train_time:167906ms step_avg:102.01ms
step:1647/1750 train_time:168013ms step_avg:102.01ms
step:1648/1750 train_time:168118ms step_avg:102.01ms
step:1649/1750 train_time:168223ms step_avg:102.02ms
step:1650/1750 train_time:168329ms step_avg:102.02ms
step:1651/1750 train_time:168435ms step_avg:102.02ms
step:1652/1750 train_time:168541ms step_avg:102.02ms
step:1653/1750 train_time:168647ms step_avg:102.02ms
step:1654/1750 train_time:168756ms step_avg:102.03ms
step:1655/1750 train_time:168863ms step_avg:102.03ms
step:1656/1750 train_time:168969ms step_avg:102.03ms
step:1657/1750 train_time:169076ms step_avg:102.04ms
step:1658/1750 train_time:169182ms step_avg:102.04ms
step:1659/1750 train_time:169290ms step_avg:102.04ms
step:1660/1750 train_time:169395ms step_avg:102.04ms
step:1661/1750 train_time:169501ms step_avg:102.05ms
step:1662/1750 train_time:169607ms step_avg:102.05ms
step:1663/1750 train_time:169713ms step_avg:102.05ms
step:1664/1750 train_time:169819ms step_avg:102.05ms
step:1665/1750 train_time:169924ms step_avg:102.06ms
step:1666/1750 train_time:170030ms step_avg:102.06ms
step:1667/1750 train_time:170136ms step_avg:102.06ms
step:1668/1750 train_time:170241ms step_avg:102.06ms
step:1669/1750 train_time:170347ms step_avg:102.07ms
step:1670/1750 train_time:170453ms step_avg:102.07ms
step:1671/1750 train_time:170559ms step_avg:102.07ms
step:1672/1750 train_time:170665ms step_avg:102.07ms
step:1673/1750 train_time:170771ms step_avg:102.07ms
step:1674/1750 train_time:170877ms step_avg:102.08ms
step:1675/1750 train_time:170982ms step_avg:102.08ms
step:1676/1750 train_time:171090ms step_avg:102.08ms
step:1677/1750 train_time:171198ms step_avg:102.09ms
step:1678/1750 train_time:171304ms step_avg:102.09ms
step:1679/1750 train_time:171410ms step_avg:102.09ms
step:1680/1750 train_time:171516ms step_avg:102.09ms
step:1681/1750 train_time:171622ms step_avg:102.10ms
step:1682/1750 train_time:171730ms step_avg:102.10ms
step:1683/1750 train_time:171836ms step_avg:102.10ms
step:1684/1750 train_time:171940ms step_avg:102.10ms
step:1685/1750 train_time:172047ms step_avg:102.10ms
step:1686/1750 train_time:172154ms step_avg:102.11ms
step:1687/1750 train_time:172263ms step_avg:102.11ms
step:1688/1750 train_time:172370ms step_avg:102.11ms
step:1689/1750 train_time:172478ms step_avg:102.12ms
step:1690/1750 train_time:172585ms step_avg:102.12ms
step:1691/1750 train_time:172692ms step_avg:102.12ms
step:1692/1750 train_time:172799ms step_avg:102.13ms
step:1693/1750 train_time:172907ms step_avg:102.13ms
step:1694/1750 train_time:173014ms step_avg:102.13ms
step:1695/1750 train_time:173121ms step_avg:102.14ms
step:1696/1750 train_time:173230ms step_avg:102.14ms
step:1697/1750 train_time:173342ms step_avg:102.15ms
step:1698/1750 train_time:173449ms step_avg:102.15ms
step:1699/1750 train_time:173555ms step_avg:102.15ms
step:1700/1750 train_time:173661ms step_avg:102.15ms
step:1701/1750 train_time:173769ms step_avg:102.16ms
step:1702/1750 train_time:173876ms step_avg:102.16ms
step:1703/1750 train_time:173982ms step_avg:102.16ms
step:1704/1750 train_time:174090ms step_avg:102.17ms
step:1705/1750 train_time:174196ms step_avg:102.17ms
step:1706/1750 train_time:174302ms step_avg:102.17ms
step:1707/1750 train_time:174409ms step_avg:102.17ms
step:1708/1750 train_time:174515ms step_avg:102.18ms
step:1709/1750 train_time:174623ms step_avg:102.18ms
step:1710/1750 train_time:174732ms step_avg:102.18ms
step:1711/1750 train_time:174842ms step_avg:102.19ms
step:1712/1750 train_time:174948ms step_avg:102.19ms
step:1713/1750 train_time:175054ms step_avg:102.19ms
step:1714/1750 train_time:175161ms step_avg:102.19ms
step:1715/1750 train_time:175267ms step_avg:102.20ms
step:1716/1750 train_time:175374ms step_avg:102.20ms
step:1717/1750 train_time:175480ms step_avg:102.20ms
step:1718/1750 train_time:175588ms step_avg:102.20ms
step:1719/1750 train_time:175696ms step_avg:102.21ms
step:1720/1750 train_time:175804ms step_avg:102.21ms
step:1721/1750 train_time:175911ms step_avg:102.21ms
step:1722/1750 train_time:176021ms step_avg:102.22ms
step:1723/1750 train_time:176129ms step_avg:102.22ms
step:1724/1750 train_time:176238ms step_avg:102.23ms
step:1725/1750 train_time:176350ms step_avg:102.23ms
step:1726/1750 train_time:176458ms step_avg:102.23ms
step:1727/1750 train_time:176564ms step_avg:102.24ms
step:1728/1750 train_time:176674ms step_avg:102.24ms
step:1729/1750 train_time:176780ms step_avg:102.24ms
step:1730/1750 train_time:176888ms step_avg:102.25ms
step:1731/1750 train_time:176997ms step_avg:102.25ms
step:1732/1750 train_time:177102ms step_avg:102.25ms
step:1733/1750 train_time:177212ms step_avg:102.26ms
step:1734/1750 train_time:177317ms step_avg:102.26ms
step:1735/1750 train_time:177426ms step_avg:102.26ms
step:1736/1750 train_time:177532ms step_avg:102.27ms
step:1737/1750 train_time:177639ms step_avg:102.27ms
step:1738/1750 train_time:177745ms step_avg:102.27ms
step:1739/1750 train_time:177852ms step_avg:102.27ms
step:1740/1750 train_time:177958ms step_avg:102.27ms
step:1741/1750 train_time:178069ms step_avg:102.28ms
step:1742/1750 train_time:178179ms step_avg:102.28ms
step:1743/1750 train_time:178286ms step_avg:102.29ms
step:1744/1750 train_time:178392ms step_avg:102.29ms
step:1745/1750 train_time:178498ms step_avg:102.29ms
step:1746/1750 train_time:178609ms step_avg:102.30ms
step:1747/1750 train_time:178715ms step_avg:102.30ms
step:1748/1750 train_time:178823ms step_avg:102.30ms
step:1749/1750 train_time:178931ms step_avg:102.30ms
step:1750/1750 train_time:179038ms step_avg:102.31ms
step:1750/1750 val_loss:3.2822 train_time:179139ms step_avg:102.37ms
peak memory allocated: 30724 MiB reserved: 45392 MiB
