import os
import sys
with open(sys.argv[0]) as f:
    code = f.read() # read the code of this file ASAP, for logging
import uuid
import time
import copy
import glob
from dataclasses import dataclass
from functools import lru_cache
from pathlib import Path

os.environ["PYTORCH_CUDA_ALLOC_CONF"] = "expandable_segments:True"
import torch
torch.empty(1, device="cuda", requires_grad=True).backward() # prevents a bug on some systems
from torch import Tensor, nn
import torch.nn.functional as F
import torch.distributed as dist
# use of FlexAttention contributed by @KoszarskyB
from torch.nn.attention.flex_attention import BlockMask, flex_attention
#torch._inductor.config.coordinate_descent_tuning = True # we have banned this flag for new records because it causes compilation to take 30min

# -----------------------------------------------------------------------------
# Custom operators: FP8 matmul by @YouJiacheng

@torch.library.custom_op("nanogpt::mm", mutates_args=())
def mm_op(x: Tensor, w: Tensor, x_s: float, w_s: float, grad_s: float) -> tuple[Tensor, Tensor, Tensor]:
    @torch.compile
    def impl(x: Tensor, w: Tensor):
        assert x.is_contiguous() and w.is_contiguous()
        x_f8 = x.div(x_s).to(torch.float8_e4m3fn)
        w_f8 = w.div(w_s).to(torch.float8_e4m3fn)
        out = torch._scaled_mm(
            x_f8,
            w_f8.T,
            out_dtype=torch.bfloat16,
            scale_a=x.new_tensor(x_s, dtype=torch.float32),
            scale_b=x.new_tensor(w_s, dtype=torch.float32),
            use_fast_accum=True,
        )
        return out, x_f8, w_f8

    return impl(x, w)

@mm_op.register_fake
def _(x: Tensor, w: Tensor, *_):
    assert x.ndim == w.ndim == 2
    assert x.shape[1] == w.shape[1]
    assert x.device == w.device
    assert x.is_contiguous() and w.is_contiguous()
    return x @ w.T, x.to(torch.float8_e4m3fn), w.to(torch.float8_e4m3fn)

@torch.library.custom_op("nanogpt::mm_backward", mutates_args=())
def mm_backward_op(g: Tensor, x_f8: Tensor, w_f8: Tensor, x_s: float, w_s: float, grad_s: float) -> tuple[Tensor, Tensor]:
    @torch.compile
    def impl(grad: Tensor, x_f8: Tensor, w_f8: Tensor):
        assert grad.is_contiguous()
        x_inv_s = grad.new_tensor(x_s, dtype=torch.float32)
        w_inv_s = grad.new_tensor(w_s, dtype=torch.float32)
        grad_inv_s = grad.new_tensor(grad_s, dtype=torch.float32)
        grad_f8 = grad.div(grad_s).to(torch.float8_e5m2)
        grad_x = torch._scaled_mm(
            grad_f8,
            w_f8.T.contiguous().T,
            out_dtype=torch.bfloat16,
            scale_a=grad_inv_s,
            scale_b=w_inv_s,
            use_fast_accum=False,
        )
        # faster than grad_f8_t @ x_f8, for (d_out, d_in) == (50304, 768)
        grad_w = torch._scaled_mm(
            x_f8.T.contiguous(),
            grad_f8.T.contiguous().T,
            out_dtype=torch.float32,
            scale_a=x_inv_s,
            scale_b=grad_inv_s,
            use_fast_accum=False,
        ).T
        return grad_x, grad_w

    return impl(g, x_f8, w_f8)

@mm_backward_op.register_fake
def _(g: Tensor, x_f8: Tensor, w_f8: Tensor, *_):
    return x_f8.to(torch.bfloat16), w_f8.to(torch.float32)

def backward(ctx, grad_out: Tensor, *_):
    x_f8, w_f8 = ctx.saved_tensors
    x_s, w_s, grad_s = ctx.scales
    grad_x, grad_w = torch.ops.nanogpt.mm_backward(
        grad_out, x_f8, w_f8, x_s, w_s, grad_s
    )
    return grad_x, grad_w, None, None, None

def setup_context(ctx: torch.autograd.function.FunctionCtx, inputs, output):
    *_, x_s, w_s, grad_s = inputs
    _, x_f8, w_f8 = output
    ctx.save_for_backward(x_f8, w_f8)
    ctx.scales = x_s, w_s, grad_s
    ctx.set_materialize_grads(False)

mm_op.register_autograd(backward, setup_context=setup_context)

# -----------------------------------------------------------------------------
# Muon optimizer

@torch.compile
def zeropower_via_newtonschulz5(G: Tensor, steps: int) -> Tensor:
    """
    Newton-Schulz iteration to compute the zeroth power / orthogonalization of G. We opt to use a
    quintic iteration whose coefficients are selected to maximize the slope at zero. For the purpose
    of minimizing steps, it turns out to be empirically effective to keep increasing the slope at
    zero even beyond the point where the iteration no longer converges all the way to one everywhere
    on the interval. This iteration therefore does not produce UV^T but rather something like US'V^T
    where S' is diagonal with S_{ii}' ~ Uniform(0.5, 1.5), which turns out not to hurt model
    performance at all relative to UV^T, where USV^T = G is the SVD.
    """
    assert G.ndim >= 2 # batched Muon implementation by @scottjmaddox, and put into practice in the record by @YouJiacheng
    X = G.bfloat16()
    if G.size(-2) > G.size(-1):
        X = X.mT

    # Ensure spectral norm is at most 1
    X = X / (X.norm(dim=(-2, -1), keepdim=True) + 1e-7)
    # Perform the NS iterations
    for a, b, c in [
        (3.8839, -3.9828, 1.0989),
        (3.7253, -3.8239, 1.0986),
        (3.5715, -3.6700, 1.0985),
        (3.4220, -3.5202, 1.0983),
        (3.2774, -3.3757, 1.0983),
        (3.1288, -3.2227, 1.0939),
        (2.7203, -2.6642, 0.9439),
    ]:
        A = X @ X.mT
        B = b * A + c * A @ A # quintic computation strategy adapted from suggestion by @jxbz, @leloykun, and @YouJiacheng
        X = a * X + B @ X
    
    if G.size(-2) > G.size(-1):
        X = X.mT
    return X

class Muon(torch.optim.Optimizer):
    """
    Muon - MomentUm Orthogonalized by Newton-schulz

    https://kellerjordan.github.io/posts/muon/

    Muon internally runs standard SGD-momentum, and then performs an orthogonalization post-
    processing step, in which each 2D parameter's update is replaced with the nearest orthogonal
    matrix. To efficiently orthogonalize each update, we use a Newton-Schulz iteration, which has
    the advantage that it can be stably run in bfloat16 on the GPU.

    Some warnings:
    - This optimizer should not be used for the embedding layer, the final fully connected layer,
    or any {0,1}-D parameters; those should all be optimized by a standard method (e.g., AdamW).
    - To use it with 4D convolutional filters, it works well to just flatten their last 3 dimensions.

    Arguments:
        lr: The learning rate used by the internal SGD.
        momentum: The momentum used by the internal SGD.
        nesterov: Whether to use Nesterov-style momentum in the internal SGD. (recommended)
        ns_steps: The number of Newton-Schulz iteration steps to use.
    """
    def __init__(self, params, lr=0.02, momentum=0.95, nesterov=True, ns_steps=5, rank=0, world_size=1):
        self.rank = rank
        self.world_size = world_size
        defaults = dict(lr=lr, momentum=momentum, nesterov=nesterov, ns_steps=ns_steps)
        params: list[Tensor] = [*params]
        param_groups = []
        for size in {p.numel() for p in params}:
            b = torch.empty(world_size, size, dtype=torch.bfloat16, device="cuda")
            group = dict(params=[p for p in params if p.numel() == size],
                         update_buffer=b, update_buffer_views=[b[i] for i in range(world_size)])
            param_groups.append(group)
        super().__init__(param_groups, defaults)

    @torch.no_grad()
    def step(self):
        for group in self.param_groups:
            update_buffer: Tensor = group["update_buffer"]
            update_buffer_views: list[Tensor] = group["update_buffer_views"]
            # generate weight updates in distributed fashion
            params: list[Tensor] = group["params"]
            handle = None
            params_world = None
            def update_prev(): # optimized Muon implementation contributed by @YouJiacheng
                handle.wait()
                for p_world, g_world in zip(params_world, update_buffer_views):
                    p_world.add_(g_world.view_as(p_world),
                                 alpha=-group["lr"] * max(1, p_world.size(-2) / p_world.size(-1))**0.5)
            for base_i in range(len(params))[::self.world_size]:
                if base_i + self.rank < len(params):
                    p = params[base_i + self.rank]
                    g = p.grad
                    assert g is not None
                    state = self.state[p]
                    if "momentum_buffer" not in state:
                        state["momentum_buffer"] = torch.zeros_like(g)
                    buf: Tensor = state["momentum_buffer"]
                    buf.lerp_(g, 1 - group["momentum"])
                    g = g.lerp_(buf, group["momentum"]) if group["nesterov"] else buf
                    g = zeropower_via_newtonschulz5(g, steps=group["ns_steps"]).flatten()
                else:
                    g = update_buffer_views[self.rank]
                if base_i > 0:
                    update_prev() # async all_gather instead of sync all_reduce by @YouJiacheng
                handle = dist.all_gather_into_tensor(update_buffer, g, async_op=True)
                params_world = params[base_i : base_i + self.world_size]
            update_prev()

# -----------------------------------------------------------------------------
# PyTorch nn.Module definitions for the model

def norm(x: Tensor):
    return F.rms_norm(x, (x.size(-1),))

class CastedLinear(nn.Linear):
    def __init__(self, in_features: int, out_features: int, use_fp8=False, x_s=1.0, w_s=1.0, grad_s=1.0):
        super().__init__(in_features, out_features, bias=False)
        self.use_fp8 = use_fp8
        self.x_s = x_s
        self.w_s = w_s
        self.grad_s = grad_s

    def reset_parameters(self) -> None:
        std = 0.5 * (self.in_features ** -0.5) # 0.5 is a bit better than the default 1/sqrt(3)
        bound = (3 ** 0.5) * std
        with torch.no_grad():
            self.weight.uniform_(-bound, bound)

    def forward(self, x: Tensor):
        if self.use_fp8 and self.training:
            _x = x.flatten(0, -2)
            out: Tensor = torch.ops.nanogpt.mm(_x, self.weight, x_s=self.x_s, w_s=self.w_s, grad_s=self.grad_s)[0]
            return out.reshape(*x.shape[:-1], -1)
        else:
            return F.linear(x, self.weight.type_as(x))

class Rotary(nn.Module):
    def __init__(self, dim: int, max_seq_len: int):
        super().__init__()
        # half-truncate RoPE by @YouJiacheng (w/ base freq tuning)
        angular_freq = (1 / 1024) ** torch.linspace(0, 1, steps=dim//4, dtype=torch.float32)
        angular_freq = torch.cat([angular_freq, angular_freq.new_zeros(dim//4)])
        t = torch.arange(max_seq_len, dtype=torch.float32)
        theta = torch.einsum("i,j -> ij", t, angular_freq)
        self.cos = nn.Buffer(theta.cos(), persistent=False)
        self.sin = nn.Buffer(theta.sin(), persistent=False)

    def forward(self, x_BTHD: Tensor):
        assert self.cos.size(0) >= x_BTHD.size(-3)
        cos, sin = self.cos[None, :x_BTHD.size(-3), None, :], self.sin[None, :x_BTHD.size(-3), None, :]
        x1, x2 = x_BTHD.to(dtype=torch.float32).chunk(2, dim=-1)
        y1 = x1 * cos + x2 * sin
        y2 = x1 * (-sin) + x2 * cos
        return torch.cat((y1, y2), 3).type_as(x_BTHD)

class CausalSelfAttention(nn.Module):
    def __init__(self, dim: int, num_heads: int, max_seq_len: int, head_dim=128):
        super().__init__()
        self.num_heads = num_heads
        self.head_dim = head_dim
        hdim = num_heads * head_dim
        std = 0.5 * (dim ** -0.5)
        bound = (3 ** 0.5) * std # improved init scale by @YouJiacheng
        # merged QKV weights: suggested by many, implemented by @fernbear.bsky.social, and further improved by @YouJiacheng
        # https://x.com/hi_tysam/status/1879699187107033311
        self.qkv_w = nn.Parameter(torch.empty(3, hdim, dim).uniform_(-bound, bound))
        self.lambdas = nn.Parameter(torch.tensor([0.5, 0.5]))
        self.rotary = Rotary(head_dim, max_seq_len)
        self.c_proj = CastedLinear(hdim, dim)
        self.c_proj.weight.detach().zero_() # zero init suggested by @Grad62304977

    def forward(self, x: Tensor, ve: Tensor | None, block_mask: BlockMask):
        B, T = x.size(0), x.size(1) # batch size, sequence length
        assert B == 1, "Must use batch size = 1 for FlexAttention"
        q, k, v = F.linear(x, self.qkv_w.flatten(end_dim=1).type_as(x)).view(B, T, 3 * self.num_heads, self.head_dim).chunk(3, dim=-2)
        q, k = norm(q), norm(k) # QK norm @Grad62304977
        q, k = self.rotary(q), self.rotary(k)
        if ve is not None:
            v = self.lambdas[0] * v + self.lambdas[1] * ve.view_as(v) # @KoszarskyB & @Grad62304977
        else: # skip mid-layers token value embeddings by @YouJiacheng
            v = self.lambdas[0] * v
        # scale the attention logits by given constant, instead of the default head_dim**-0.5, by @leloykun
        # inspired by learnable scalars used by @brendanh0gan https://x.com/hi_tysam/status/1879693583898591283
        y = flex_attention(q.transpose(1, 2), k.transpose(1, 2), v.transpose(1, 2), block_mask=block_mask, scale=15/self.head_dim).transpose(1, 2)
        y = y.contiguous().view(B, T, self.num_heads * self.head_dim) # re-assemble all head outputs side by side
        y = self.c_proj(y)
        return y

class MLP(nn.Module):
    def __init__(self, dim: int):
        super().__init__()
        hdim = 4 * dim
        self.c_fc = CastedLinear(dim, hdim)
        self.c_proj = CastedLinear(hdim, dim)
        self.c_proj.weight.detach().zero_() # zero init suggested by @Grad62304977

    def forward(self, x: Tensor):
        x = self.c_fc(x)
        x = F.relu(x).square() # https://arxiv.org/abs/2109.08668v2; ~1-2% better than GELU; suggested by @SKYLINEZ007 and @Grad62304977
        x = self.c_proj(x)
        return x

class Block(nn.Module):
    def __init__(self, dim: int, num_heads: int, max_seq_len: int, layer_idx: int):
        super().__init__()
        # skip attention of blocks.7 (the 8th layer) by @YouJiacheng
        self.attn = CausalSelfAttention(dim, num_heads, max_seq_len) if layer_idx != 7 else None
        self.mlp = MLP(dim)
        self.lambdas = nn.Parameter(torch.tensor([1., 0.]))

    def forward(self, x: Tensor, ve: Tensor | None, x0: Tensor, block_mask: BlockMask):
        x = self.lambdas[0] * x + self.lambdas[1] * x0
        if self.attn is not None:
            x = x + self.attn(norm(x), ve, block_mask)
        x = x + self.mlp(norm(x))
        return x

# -----------------------------------------------------------------------------
# The main model

def next_multiple_of_n(v: float | int, *, n: int):
    return next(x for x in range(n, int(v) + 1 + n, n) if x >= v)

class GPT(nn.Module):
    def __init__(self, vocab_size: int, num_layers: int, num_heads: int, model_dim: int, max_seq_len: int):
        super().__init__()
        self.embed = nn.Embedding(vocab_size, model_dim)
        # token value embeddings by @KoszarskyB - inspired by @Grad62304977's value residual implementation following https://arxiv.org/abs/2410.17897
        # value embedding code simplification inspired by @ragulpr https://github.com/KellerJordan/modded-nanogpt/pull/78
        self.value_embeds = nn.ModuleList([nn.Embedding(vocab_size, model_dim) for _ in range(3)])
        self.blocks = nn.ModuleList([Block(model_dim, num_heads, max_seq_len, i) for i in range(num_layers)])
        # there are only 50257 unique GPT-2 tokens; we extend to nearest multiple of 128 for efficiency.
        # suggested to me by @Grad62304977. this originates from Karpathy's experiments.
        self.lm_head = CastedLinear(model_dim, next_multiple_of_n(vocab_size, n=128), use_fp8=True, x_s=(768**0.5)/448, w_s=2**-9, grad_s=1/448)
        self.lm_head.weight.detach().zero_() # @Grad62304977
        # Add learnable skip connection weights for decoder layers
        assert num_layers % 2 == 0
        self.skip_weights = nn.Parameter(torch.ones(num_layers//2))

    def create_blockmasks(self, input_seq: Tensor, sliding_window_num_blocks: Tensor):
        BLOCK_SIZE = 128
        docs = (input_seq == 50256).cumsum(0)

        def document_causal(b, h, q_idx, kv_idx):
            causal_mask = q_idx >= kv_idx
            document_mask = docs[q_idx] == docs[kv_idx]
            return causal_mask & document_mask

        def dense_to_ordered(dense_blockmask: Tensor):
            num_blocks = dense_blockmask.sum(dim=-1, dtype=torch.int32)
            indices = dense_blockmask.argsort(dim=-1, descending=False, stable=True).flip(-1).to(torch.int32)
            return num_blocks[None, None].contiguous(), indices[None, None].contiguous()

        # manual block mask creation by @YouJiacheng
        assert len(input_seq) % BLOCK_SIZE == 0
        NUM_BLOCKS = len(input_seq) // BLOCK_SIZE
        block_idx = torch.arange(NUM_BLOCKS, dtype=torch.int32, device="cuda")
        causal_blockmask_any = block_idx[:, None] >= block_idx
        causal_blockmask_all = block_idx[:, None] > block_idx
        docs_low = docs.view(-1, BLOCK_SIZE)[:, 0].contiguous()
        docs_high = docs.view(-1, BLOCK_SIZE)[:, -1].contiguous()
        document_blockmask_any = (docs_low[:, None] <= docs_high) & (docs_high[:, None] >= docs_low)
        document_blockmask_all = (docs_low[:, None] == docs_high) & (docs_high[:, None] == docs_low)
        blockmask_any = causal_blockmask_any & document_blockmask_any
        blockmask_all = causal_blockmask_all & document_blockmask_all
        partial_kv_num_blocks, partial_kv_indices = dense_to_ordered(blockmask_any & ~blockmask_all)
        full_kv_num_blocks, full_kv_indices = dense_to_ordered(blockmask_all)
        def build_bm(window_size_blocks: Tensor) -> BlockMask:
            return BlockMask.from_kv_blocks(
                torch.clamp_max(partial_kv_num_blocks, torch.clamp_min(window_size_blocks - full_kv_num_blocks, 1)),
                partial_kv_indices,
                torch.clamp_max(full_kv_num_blocks, window_size_blocks - 1),
                full_kv_indices,
                BLOCK_SIZE=BLOCK_SIZE,
                mask_mod=document_causal,
            )
        # Long-short SWA block masks by @leloykun & @YouJiacheng, adapated from suggestion by @Grad62304977, following Gemma 2 paper
        return build_bm(sliding_window_num_blocks), build_bm(sliding_window_num_blocks // 2)

    def forward(self, input_seq: Tensor, target_seq: Tensor, sliding_window_num_blocks: Tensor):
        assert input_seq.ndim == 1

        ve = [value_embed(input_seq) for value_embed in self.value_embeds]
        # 012 ... 012 structure on token value embeddings by @YouJiacheng, improved on @leloykun's U-net structure
        ve = [ve[0], ve[1], ve[2]] + [None] * (len(self.blocks) - 6) + [ve[0], ve[1], ve[2]]
        assert len(ve) == len(self.blocks)

        long_bm, short_bm = self.create_blockmasks(input_seq, sliding_window_num_blocks)
        block_masks = [long_bm, short_bm, short_bm, short_bm, long_bm, short_bm, short_bm, long_bm, short_bm, short_bm, short_bm, long_bm]
        assert len(block_masks) == len(self.blocks)

        x = x0 = norm(self.embed(input_seq)[None]) # use of norm here by @Grad62304977

        # U-net design by @brendanh0gan
        skip_connections = []
        n = len(self.skip_weights)
        for i in range(len(self.blocks)):
            if i >= n:
                x = x + self.skip_weights[i - n] * skip_connections.pop()
            x = self.blocks[i](x, ve[i], x0, block_masks[i])
            if i < n:
                skip_connections.append(x)

        x = norm(x)
        logits = self.lm_head(x).float()
        # @Grad62304977 added tanh softcapping following Gemma 2 paper, @KoszarskyB reduced it from 30 to 15, @YouJiacheng shifted it by +15 (2*sigmoid(2*x)=tanh(x)+1)
        logits = 30 * torch.sigmoid(logits / 7.5)
        loss = F.cross_entropy(logits.view(-1, logits.size(-1)), target_seq, reduction='sum' if self.training else 'mean')
        return loss

# -----------------------------------------------------------------------------
# Our own simple Distributed Data Loader

def _load_data_shard(file: Path):
    header = torch.from_file(str(file), False, 256, dtype=torch.int32) # header is 256 int32
    assert header[0] == 20240520, "magic number mismatch in the data .bin file"
    assert header[1] == 1, "unsupported version"
    num_tokens = int(header[2]) # number of tokens (claimed)
    with file.open("rb", buffering=0) as f:
        tokens = torch.empty(num_tokens, dtype=torch.uint16, pin_memory=True) # avoid pin_memory copy by @YouJiacheng
        f.seek(256 * 4)
        nbytes = f.readinto(tokens.numpy()) # avoid bytes->array copy by @YouJiacheng
        assert nbytes == 2 * num_tokens, "number of tokens read does not match header"
    return tokens

def distributed_data_generator(filename_pattern: str, batch_size: int, rank : int, world_size : int):
    files = [Path(file) for file in sorted(glob.glob(filename_pattern))]
    assert batch_size % world_size == 0
    local_batch_size = batch_size // world_size
    file_iter = iter(files) # use itertools.cycle(files) instead if you want to do multi-epoch training
    tokens, pos = _load_data_shard(next(file_iter)), 0
    while True:
        if pos + batch_size + 1 >= len(tokens):
            tokens, pos = _load_data_shard(next(file_iter)), 0
        buf = tokens[pos + rank * local_batch_size:][:local_batch_size + 1]
        inputs = buf[:-1].to(device="cuda", dtype=torch.int32, non_blocking=True) # no sync on host side;
        targets = buf[1:].to(device="cuda", dtype=torch.int64, non_blocking=True) # H2D in another stream isn't helpful.
        pos += batch_size
        yield inputs, targets

# -----------------------------------------------------------------------------
# int main

@dataclass
class Hyperparameters:
    # data
    train_files = "data/fineweb10B/fineweb_train_*.bin" # input .bin to train on
    val_files = "data/fineweb10B/fineweb_val_*.bin" # input .bin to eval validation loss on
    val_tokens = 10485760 # how many tokens of validation data? it's important to keep this fixed for consistent comparisons
    train_seq_len = 48*1024 # FlexAttention sequence length
    val_seq_len = 4*64*1024 # FlexAttention sequence length for validation
    # optimization
    num_iterations = 1750 # number of iterations to run
    cooldown_frac = 0.4 # fraction of training spent cooling down the learning rate
    # architecture
    vocab_size = 50257
    # evaluation and logging
    val_loss_every = 125 # every how many steps to evaluate val loss? 0 for only at the end
    save_checkpoint = False
args = Hyperparameters()

# torchrun sets these env variables
rank = int(os.environ["RANK"])
world_size = int(os.environ["WORLD_SIZE"])
assert world_size == 8 # this code is designed for 8xH100
assert torch.cuda.is_available()
device = torch.device("cuda", int(os.environ["LOCAL_RANK"]))
torch.cuda.set_device(device)
dist.init_process_group(backend="nccl", device_id=device)
dist.barrier()
master_process = (rank == 0) # this process will do logging, checkpointing etc.

# begin logging
logfile = None
if master_process:
    run_id = uuid.uuid4()
    os.makedirs("logs", exist_ok=True)
    logfile = f"logs/{run_id}.txt"
    print(logfile)
def print0(s, console=False):
    if master_process:
        with open(logfile, "a") as f:
            if console:
                print(s)
            print(s, file=f)

# begin by printing this file (the Python code)
print0(code)
print0("="*100)
# log information about the hardware/software environment this is running on
print0(f"Running Python {sys.version}")
print0(f"Running PyTorch {torch.version.__version__} compiled for CUDA {torch.version.cuda}")
def nvidia_smi():
    import subprocess  # avoid top level import
    return subprocess.run(["nvidia-smi"], stdout=subprocess.PIPE, stderr=subprocess.PIPE, text=True).stdout
print0(nvidia_smi())
print0("="*100)

########################################
#    Construct model and optimizer     #
########################################

model: nn.Module = GPT(vocab_size=args.vocab_size, num_layers=12, num_heads=6, model_dim=768,
                       max_seq_len=max(args.train_seq_len, args.val_seq_len)).cuda()
for m in model.modules():
    if isinstance(m, nn.Embedding):
        m.bfloat16()
for param in model.parameters():
    dist.broadcast(param.detach(), 0)

# collect the parameters to optimize
hidden_matrix_params = [p for n, p in model.blocks.named_parameters() if p.ndim >= 2 and "embed" not in n]
embed_params = [p for n, p in model.named_parameters() if "embed" in n]
scalar_params = [p for p in model.parameters() if p.ndim < 2]
head_params = [model.lm_head.weight]

# init the optimizer(s)
adam_params = [dict(params=head_params, lr=0.22/768**0.5), dict(params=embed_params, lr=0.6), dict(params=scalar_params, lr=0.04)]
# small adam epsilon by @YouJiacheng. this is an alternate method of fixing the world_size dependence
# discovered by @fernbear.bsky.social https://x.com/hi_tysam/status/1879692937589875094
optimizer1 = torch.optim.Adam(adam_params, betas=(0.8, 0.95), eps=1e-10, fused=True)
optimizer2 = Muon(hidden_matrix_params, lr=0.05, momentum=0.95, rank=rank, world_size=world_size)
optimizers = [optimizer1, optimizer2]
for opt in optimizers:
    for group in opt.param_groups:
        group["initial_lr"] = group["lr"]

# learning rate schedule: stable then decay
def get_lr(step: int):
    x = step / args.num_iterations # progress in training
    assert 0 <= x < 1
    if x < 1 - args.cooldown_frac:
        return 1.0
    else:
        w = (1 - x) / args.cooldown_frac
        return w * 1.0 + (1 - w) * 0.1

# attention window size schedule: linearly increase
@lru_cache(1)
def get_window_size_blocks_helper(window_size: int):
    return torch.tensor(window_size // 128, dtype=torch.int32, pin_memory=True).cuda(non_blocking=True)
def get_window_size_blocks(step: int):
    x = step / args.num_iterations # progress in training
    assert 0 <= x <= 1
    # Linearly increase the block-wise sliding window size over training 128 -> 1792
    # increase by @fernbear.bsky.social; block-wise by @YouJiacheng
    window_size = next_multiple_of_n(1728 * x, n=128)
    return get_window_size_blocks_helper(window_size)

model: nn.Module = torch.compile(model, dynamic=False)

########################################
#            Warmup kernels            #
########################################

# Warmup the training kernels, then re-initialize the state so we aren't cheating
warmup_steps = 10
initial_state = dict(model=copy.deepcopy(model.state_dict()),
                     optimizers=[copy.deepcopy(opt.state_dict()) for opt in optimizers]) # save the initial state
for _ in range(warmup_steps):
    inputs = targets = torch.randint(0, args.vocab_size, size=(args.train_seq_len,), device="cuda")
    model(inputs.to(torch.int32), targets, get_window_size_blocks(0)).backward()
    for param in model.parameters():
        dist.all_reduce(param.grad, op=dist.ReduceOp.AVG)
    for opt in optimizers:
        opt.step()
    model.zero_grad(set_to_none=True)
model.load_state_dict(initial_state["model"])
for opt, opt_state in zip(optimizers, initial_state["optimizers"]):
    opt.load_state_dict(opt_state)
del initial_state

########################################
#        Training and validation       #
########################################

train_loader = distributed_data_generator(args.train_files, world_size * args.train_seq_len, rank, world_size)
training_time_ms = 0
# start the clock
torch.cuda.synchronize()
t0 = time.perf_counter()
# begin training
train_steps = args.num_iterations
for step in range(train_steps + 1):
    last_step = (step == train_steps)

    # --------------- VALIDATION SECTION -----------------
    if last_step or (args.val_loss_every > 0 and step % args.val_loss_every == 0):
        # stop the clock
        torch.cuda.synchronize()
        training_time_ms += 1000 * (time.perf_counter() - t0)
        model.eval()
        val_batch_size = world_size * args.val_seq_len
        assert args.val_tokens % val_batch_size == 0
        val_steps = args.val_tokens // val_batch_size
        val_loader = distributed_data_generator(args.val_files, val_batch_size, rank, world_size)
        val_loss = 0
        with torch.no_grad():
            for _ in range(val_steps):
                inputs, targets = next(val_loader)
                val_loss += model(inputs, targets, get_window_size_blocks(step))
        val_loss /= val_steps
        del val_loader
        dist.all_reduce(val_loss, op=dist.ReduceOp.AVG)
        print0(f"step:{step}/{train_steps} val_loss:{val_loss:.4f} train_time:{training_time_ms:.0f}ms step_avg:{training_time_ms/max(step, 1):.2f}ms", console=True)
        model.train()
        # start the clock again
        torch.cuda.synchronize()
        t0 = time.perf_counter()

    if last_step:
        if master_process and args.save_checkpoint:
            log = dict(step=step, code=code, model=model.state_dict(), optimizers=[opt.state_dict() for opt in optimizers])
            os.makedirs(f"logs/{run_id}", exist_ok=True)
            torch.save(log, f"logs/{run_id}/state_step{step:06d}.pt")
        # the last step only has the validation loop, so break to avoid training
        break

    # --------------- TRAINING SECTION -----------------
    inputs, targets = next(train_loader)
    model(inputs, targets, get_window_size_blocks(step)).backward()
    for param in model.parameters():
        dist.all_reduce(param.grad, op=dist.ReduceOp.AVG)
    # set optimization hyperparameters
    for opt in optimizers:
        for group in opt.param_groups:
            group["lr"] = group["initial_lr"] * get_lr(step)
    for group in optimizer2.param_groups:
        frac = min(step / 300, 1) # momentum warmup for muon
        group["momentum"] = (1 - frac) * 0.85 + frac * 0.95
    # step the optimizers
    for opt in optimizers:
        opt.step()
    # null the gradients
    model.zero_grad(set_to_none=True)
    # logging
    approx_training_time_ms = training_time_ms + 1000 * (time.perf_counter() - t0)
    print0(f"step:{step+1}/{train_steps} train_time:{approx_training_time_ms:.0f}ms step_avg:{approx_training_time_ms/(step + 1):.2f}ms", console=True)

print0(f"peak memory allocated: {torch.cuda.max_memory_allocated() // 1024 // 1024} MiB "
       f"reserved: {torch.cuda.max_memory_reserved() // 1024 // 1024} MiB", console=True)
dist.destroy_process_group()

====================================================================================================
Running Python 3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]
Running PyTorch 2.7.0.dev20250125+cu126 compiled for CUDA 12.6
Sun Feb 16 18:13:55 2025       
+-----------------------------------------------------------------------------------------+
| NVIDIA-SMI 550.90.07              Driver Version: 550.90.07      CUDA Version: 12.4     |
|-----------------------------------------+------------------------+----------------------+
| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |
| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |
|                                         |                        |               MIG M. |
|=========================================+========================+======================|
|   0  NVIDIA H100 80GB HBM3          On  |   00000000:19:00.0 Off |                    0 |
| N/A   32C    P0            113W /  700W |    7714MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   1  NVIDIA H100 80GB HBM3          On  |   00000000:3B:00.0 Off |                    0 |
| N/A   28C    P0            120W /  700W |    3452MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   2  NVIDIA H100 80GB HBM3          On  |   00000000:4C:00.0 Off |                    0 |
| N/A   27C    P0            112W /  700W |    3452MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   3  NVIDIA H100 80GB HBM3          On  |   00000000:5D:00.0 Off |                    0 |
| N/A   31C    P0            113W /  700W |    3452MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   4  NVIDIA H100 80GB HBM3          On  |   00000000:9B:00.0 Off |                    0 |
| N/A   31C    P0            116W /  700W |    3452MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   5  NVIDIA H100 80GB HBM3          On  |   00000000:BB:00.0 Off |                    0 |
| N/A   28C    P0            111W /  700W |    3452MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   6  NVIDIA H100 80GB HBM3          On  |   00000000:CB:00.0 Off |                    0 |
| N/A   30C    P0            111W /  700W |    3452MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
|   7  NVIDIA H100 80GB HBM3          On  |   00000000:DB:00.0 Off |                    0 |
| N/A   26C    P0            111W /  700W |    3212MiB /  81559MiB |      0%      Default |
|                                         |                        |             Disabled |
+-----------------------------------------+------------------------+----------------------+
                                                                                         
+-----------------------------------------------------------------------------------------+
| Processes:                                                                              |
|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |
|        ID   ID                                                               Usage      |
|=========================================================================================|
+-----------------------------------------------------------------------------------------+

====================================================================================================
step:0/1750 val_loss:10.8258 train_time:0ms step_avg:0.02ms
step:1/1750 train_time:75ms step_avg:74.56ms
step:2/1750 train_time:152ms step_avg:75.81ms
step:3/1750 train_time:244ms step_avg:81.49ms
step:4/1750 train_time:340ms step_avg:85.08ms
step:5/1750 train_time:437ms step_avg:87.37ms
step:6/1750 train_time:533ms step_avg:88.84ms
step:7/1750 train_time:629ms step_avg:89.87ms
step:8/1750 train_time:727ms step_avg:90.82ms
step:9/1750 train_time:823ms step_avg:91.46ms
step:10/1750 train_time:920ms step_avg:91.99ms
step:11/1750 train_time:1017ms step_avg:92.43ms
step:12/1750 train_time:1114ms step_avg:92.80ms
step:13/1750 train_time:1210ms step_avg:93.11ms
step:14/1750 train_time:1308ms step_avg:93.43ms
step:15/1750 train_time:1405ms step_avg:93.68ms
step:16/1750 train_time:1503ms step_avg:93.94ms
step:17/1750 train_time:1600ms step_avg:94.11ms
step:18/1750 train_time:1697ms step_avg:94.29ms
step:19/1750 train_time:1794ms step_avg:94.44ms
step:20/1750 train_time:1891ms step_avg:94.57ms
step:21/1750 train_time:1988ms step_avg:94.68ms
step:22/1750 train_time:2086ms step_avg:94.82ms
step:23/1750 train_time:2183ms step_avg:94.90ms
step:24/1750 train_time:2279ms step_avg:94.98ms
step:25/1750 train_time:2376ms step_avg:95.06ms
step:26/1750 train_time:2473ms step_avg:95.13ms
step:27/1750 train_time:2570ms step_avg:95.20ms
step:28/1750 train_time:2667ms step_avg:95.27ms
step:29/1750 train_time:2764ms step_avg:95.32ms
step:30/1750 train_time:2861ms step_avg:95.38ms
step:31/1750 train_time:2958ms step_avg:95.43ms
step:32/1750 train_time:3055ms step_avg:95.48ms
step:33/1750 train_time:3152ms step_avg:95.52ms
step:34/1750 train_time:3250ms step_avg:95.57ms
step:35/1750 train_time:3347ms step_avg:95.62ms
step:36/1750 train_time:3444ms step_avg:95.68ms
step:37/1750 train_time:3540ms step_avg:95.67ms
step:38/1750 train_time:3636ms step_avg:95.69ms
step:39/1750 train_time:3733ms step_avg:95.72ms
step:40/1750 train_time:3830ms step_avg:95.76ms
step:41/1750 train_time:3928ms step_avg:95.81ms
step:42/1750 train_time:4025ms step_avg:95.84ms
step:43/1750 train_time:4123ms step_avg:95.87ms
step:44/1750 train_time:4219ms step_avg:95.89ms
step:45/1750 train_time:4316ms step_avg:95.91ms
step:46/1750 train_time:4413ms step_avg:95.93ms
step:47/1750 train_time:4510ms step_avg:95.95ms
step:48/1750 train_time:4607ms step_avg:95.98ms
step:49/1750 train_time:4704ms step_avg:96.01ms
step:50/1750 train_time:4801ms step_avg:96.02ms
step:51/1750 train_time:4898ms step_avg:96.04ms
step:52/1750 train_time:4995ms step_avg:96.05ms
step:53/1750 train_time:5091ms step_avg:96.07ms
step:54/1750 train_time:5189ms step_avg:96.08ms
step:55/1750 train_time:5285ms step_avg:96.09ms
step:56/1750 train_time:5382ms step_avg:96.11ms
step:57/1750 train_time:5479ms step_avg:96.12ms
step:58/1750 train_time:5576ms step_avg:96.13ms
step:59/1750 train_time:5673ms step_avg:96.15ms
step:60/1750 train_time:5769ms step_avg:96.16ms
step:61/1750 train_time:5866ms step_avg:96.17ms
step:62/1750 train_time:5963ms step_avg:96.18ms
step:63/1750 train_time:6060ms step_avg:96.19ms
step:64/1750 train_time:6157ms step_avg:96.20ms
step:65/1750 train_time:6254ms step_avg:96.21ms
step:66/1750 train_time:6350ms step_avg:96.21ms
step:67/1750 train_time:6447ms step_avg:96.22ms
step:68/1750 train_time:6544ms step_avg:96.23ms
step:69/1750 train_time:6641ms step_avg:96.24ms
step:70/1750 train_time:6738ms step_avg:96.25ms
step:71/1750 train_time:6834ms step_avg:96.26ms
step:72/1750 train_time:6931ms step_avg:96.26ms
step:73/1750 train_time:7027ms step_avg:96.27ms
step:74/1750 train_time:7125ms step_avg:96.28ms
step:75/1750 train_time:7222ms step_avg:96.30ms
step:76/1750 train_time:7319ms step_avg:96.31ms
step:77/1750 train_time:7417ms step_avg:96.32ms
step:78/1750 train_time:7514ms step_avg:96.33ms
step:79/1750 train_time:7612ms step_avg:96.35ms
step:80/1750 train_time:7708ms step_avg:96.35ms
step:81/1750 train_time:7806ms step_avg:96.36ms
step:82/1750 train_time:7903ms step_avg:96.38ms
step:83/1750 train_time:8001ms step_avg:96.40ms
step:84/1750 train_time:8098ms step_avg:96.41ms
step:85/1750 train_time:8195ms step_avg:96.41ms
step:86/1750 train_time:8292ms step_avg:96.42ms
step:87/1750 train_time:8389ms step_avg:96.42ms
step:88/1750 train_time:8486ms step_avg:96.43ms
step:89/1750 train_time:8583ms step_avg:96.44ms
step:90/1750 train_time:8680ms step_avg:96.45ms
step:91/1750 train_time:8777ms step_avg:96.45ms
step:92/1750 train_time:8874ms step_avg:96.45ms
step:93/1750 train_time:8971ms step_avg:96.46ms
step:94/1750 train_time:9067ms step_avg:96.46ms
step:95/1750 train_time:9164ms step_avg:96.46ms
step:96/1750 train_time:9261ms step_avg:96.47ms
step:97/1750 train_time:9358ms step_avg:96.48ms
step:98/1750 train_time:9455ms step_avg:96.48ms
step:99/1750 train_time:9552ms step_avg:96.48ms
step:100/1750 train_time:9649ms step_avg:96.49ms
step:101/1750 train_time:9745ms step_avg:96.49ms
step:102/1750 train_time:9843ms step_avg:96.50ms
step:103/1750 train_time:9941ms step_avg:96.52ms
step:104/1750 train_time:10038ms step_avg:96.52ms
step:105/1750 train_time:10134ms step_avg:96.52ms
step:106/1750 train_time:10231ms step_avg:96.51ms
step:107/1750 train_time:10327ms step_avg:96.52ms
step:108/1750 train_time:10424ms step_avg:96.52ms
step:109/1750 train_time:10521ms step_avg:96.52ms
step:110/1750 train_time:10618ms step_avg:96.53ms
step:111/1750 train_time:10715ms step_avg:96.53ms
step:112/1750 train_time:10812ms step_avg:96.53ms
step:113/1750 train_time:10909ms step_avg:96.54ms
step:114/1750 train_time:11006ms step_avg:96.55ms
step:115/1750 train_time:11103ms step_avg:96.55ms
step:116/1750 train_time:11201ms step_avg:96.56ms
step:117/1750 train_time:11297ms step_avg:96.56ms
step:118/1750 train_time:11394ms step_avg:96.56ms
step:119/1750 train_time:11490ms step_avg:96.56ms
step:120/1750 train_time:11587ms step_avg:96.56ms
step:121/1750 train_time:11685ms step_avg:96.57ms
step:122/1750 train_time:12098ms step_avg:99.16ms
step:123/1750 train_time:12166ms step_avg:98.91ms
step:124/1750 train_time:12262ms step_avg:98.89ms
step:125/1750 train_time:12358ms step_avg:98.86ms
step:125/1750 val_loss:4.6397 train_time:12449ms step_avg:99.59ms
step:126/1750 train_time:12470ms step_avg:98.97ms
step:127/1750 train_time:12557ms step_avg:98.88ms
step:128/1750 train_time:12657ms step_avg:98.89ms
step:129/1750 train_time:12756ms step_avg:98.88ms
step:130/1750 train_time:12853ms step_avg:98.87ms
step:131/1750 train_time:12950ms step_avg:98.85ms
step:132/1750 train_time:13047ms step_avg:98.84ms
step:133/1750 train_time:13144ms step_avg:98.83ms
step:134/1750 train_time:13241ms step_avg:98.81ms
step:135/1750 train_time:13339ms step_avg:98.81ms
step:136/1750 train_time:13436ms step_avg:98.79ms
step:137/1750 train_time:13533ms step_avg:98.78ms
step:138/1750 train_time:13632ms step_avg:98.78ms
step:139/1750 train_time:13728ms step_avg:98.76ms
step:140/1750 train_time:13825ms step_avg:98.75ms
step:141/1750 train_time:13922ms step_avg:98.74ms
step:142/1750 train_time:14021ms step_avg:98.74ms
step:143/1750 train_time:14119ms step_avg:98.73ms
step:144/1750 train_time:14216ms step_avg:98.72ms
step:145/1750 train_time:14313ms step_avg:98.71ms
step:146/1750 train_time:14410ms step_avg:98.70ms
step:147/1750 train_time:14508ms step_avg:98.69ms
step:148/1750 train_time:14605ms step_avg:98.68ms
step:149/1750 train_time:14702ms step_avg:98.67ms
step:150/1750 train_time:14800ms step_avg:98.67ms
step:151/1750 train_time:14898ms step_avg:98.66ms
step:152/1750 train_time:14996ms step_avg:98.66ms
step:153/1750 train_time:15093ms step_avg:98.65ms
step:154/1750 train_time:15191ms step_avg:98.64ms
step:155/1750 train_time:15288ms step_avg:98.63ms
step:156/1750 train_time:15386ms step_avg:98.63ms
step:157/1750 train_time:15484ms step_avg:98.62ms
step:158/1750 train_time:15582ms step_avg:98.62ms
step:159/1750 train_time:15681ms step_avg:98.62ms
step:160/1750 train_time:15778ms step_avg:98.61ms
step:161/1750 train_time:15875ms step_avg:98.60ms
step:162/1750 train_time:15972ms step_avg:98.60ms
step:163/1750 train_time:16070ms step_avg:98.59ms
step:164/1750 train_time:16167ms step_avg:98.58ms
step:165/1750 train_time:16264ms step_avg:98.57ms
step:166/1750 train_time:16362ms step_avg:98.57ms
step:167/1750 train_time:16460ms step_avg:98.56ms
step:168/1750 train_time:16557ms step_avg:98.55ms
step:169/1750 train_time:16654ms step_avg:98.54ms
step:170/1750 train_time:16751ms step_avg:98.53ms
step:171/1750 train_time:16848ms step_avg:98.52ms
step:172/1750 train_time:16945ms step_avg:98.52ms
step:173/1750 train_time:17042ms step_avg:98.51ms
step:174/1750 train_time:17140ms step_avg:98.50ms
step:175/1750 train_time:17238ms step_avg:98.50ms
step:176/1750 train_time:17335ms step_avg:98.50ms
step:177/1750 train_time:17433ms step_avg:98.49ms
step:178/1750 train_time:17529ms step_avg:98.48ms
step:179/1750 train_time:17628ms step_avg:98.48ms
step:180/1750 train_time:17724ms step_avg:98.47ms
step:181/1750 train_time:17822ms step_avg:98.46ms
step:182/1750 train_time:17920ms step_avg:98.46ms
step:183/1750 train_time:18018ms step_avg:98.46ms
step:184/1750 train_time:18114ms step_avg:98.45ms
step:185/1750 train_time:18212ms step_avg:98.44ms
step:186/1750 train_time:18309ms step_avg:98.44ms
step:187/1750 train_time:18406ms step_avg:98.43ms
step:188/1750 train_time:18504ms step_avg:98.42ms
step:189/1750 train_time:18602ms step_avg:98.42ms
step:190/1750 train_time:18699ms step_avg:98.42ms
step:191/1750 train_time:18797ms step_avg:98.41ms
step:192/1750 train_time:18895ms step_avg:98.41ms
step:193/1750 train_time:18992ms step_avg:98.40ms
step:194/1750 train_time:19089ms step_avg:98.40ms
step:195/1750 train_time:19186ms step_avg:98.39ms
step:196/1750 train_time:19283ms step_avg:98.39ms
step:197/1750 train_time:19381ms step_avg:98.38ms
step:198/1750 train_time:19479ms step_avg:98.38ms
step:199/1750 train_time:19576ms step_avg:98.37ms
step:200/1750 train_time:19674ms step_avg:98.37ms
step:201/1750 train_time:19771ms step_avg:98.36ms
step:202/1750 train_time:19868ms step_avg:98.36ms
step:203/1750 train_time:19966ms step_avg:98.35ms
step:204/1750 train_time:20063ms step_avg:98.35ms
step:205/1750 train_time:20161ms step_avg:98.34ms
step:206/1750 train_time:20259ms step_avg:98.34ms
step:207/1750 train_time:20356ms step_avg:98.34ms
step:208/1750 train_time:20453ms step_avg:98.33ms
step:209/1750 train_time:20551ms step_avg:98.33ms
step:210/1750 train_time:20648ms step_avg:98.32ms
step:211/1750 train_time:20746ms step_avg:98.32ms
step:212/1750 train_time:20844ms step_avg:98.32ms
step:213/1750 train_time:20941ms step_avg:98.32ms
step:214/1750 train_time:21039ms step_avg:98.31ms
step:215/1750 train_time:21136ms step_avg:98.31ms
step:216/1750 train_time:21233ms step_avg:98.30ms
step:217/1750 train_time:21331ms step_avg:98.30ms
step:218/1750 train_time:21427ms step_avg:98.29ms
step:219/1750 train_time:21525ms step_avg:98.29ms
step:220/1750 train_time:21623ms step_avg:98.28ms
step:221/1750 train_time:21720ms step_avg:98.28ms
step:222/1750 train_time:21818ms step_avg:98.28ms
step:223/1750 train_time:21916ms step_avg:98.28ms
step:224/1750 train_time:22015ms step_avg:98.28ms
step:225/1750 train_time:22113ms step_avg:98.28ms
step:226/1750 train_time:22211ms step_avg:98.28ms
step:227/1750 train_time:22308ms step_avg:98.27ms
step:228/1750 train_time:22405ms step_avg:98.27ms
step:229/1750 train_time:22503ms step_avg:98.26ms
step:230/1750 train_time:22601ms step_avg:98.26ms
step:231/1750 train_time:22698ms step_avg:98.26ms
step:232/1750 train_time:22796ms step_avg:98.26ms
step:233/1750 train_time:22894ms step_avg:98.26ms
step:234/1750 train_time:22991ms step_avg:98.25ms
step:235/1750 train_time:23088ms step_avg:98.25ms
step:236/1750 train_time:23186ms step_avg:98.24ms
step:237/1750 train_time:23283ms step_avg:98.24ms
step:238/1750 train_time:23381ms step_avg:98.24ms
step:239/1750 train_time:23479ms step_avg:98.24ms
step:240/1750 train_time:23576ms step_avg:98.23ms
step:241/1750 train_time:23674ms step_avg:98.23ms
step:242/1750 train_time:23771ms step_avg:98.23ms
step:243/1750 train_time:23868ms step_avg:98.22ms
step:244/1750 train_time:23965ms step_avg:98.22ms
step:245/1750 train_time:24063ms step_avg:98.22ms
step:246/1750 train_time:24161ms step_avg:98.22ms
step:247/1750 train_time:24260ms step_avg:98.22ms
step:248/1750 train_time:24358ms step_avg:98.22ms
step:249/1750 train_time:24455ms step_avg:98.21ms
step:250/1750 train_time:24553ms step_avg:98.21ms
step:250/1750 val_loss:4.1120 train_time:24645ms step_avg:98.58ms
step:251/1750 train_time:24665ms step_avg:98.27ms
step:252/1750 train_time:24754ms step_avg:98.23ms
step:253/1750 train_time:24855ms step_avg:98.24ms
step:254/1750 train_time:24952ms step_avg:98.24ms
step:255/1750 train_time:25051ms step_avg:98.24ms
step:256/1750 train_time:25148ms step_avg:98.23ms
step:257/1750 train_time:25245ms step_avg:98.23ms
step:258/1750 train_time:25343ms step_avg:98.23ms
step:259/1750 train_time:25440ms step_avg:98.22ms
step:260/1750 train_time:25538ms step_avg:98.22ms
step:261/1750 train_time:25634ms step_avg:98.22ms
step:262/1750 train_time:25731ms step_avg:98.21ms
step:263/1750 train_time:25830ms step_avg:98.21ms
step:264/1750 train_time:25929ms step_avg:98.22ms
step:265/1750 train_time:26028ms step_avg:98.22ms
step:266/1750 train_time:26126ms step_avg:98.22ms
step:267/1750 train_time:26225ms step_avg:98.22ms
step:268/1750 train_time:26323ms step_avg:98.22ms
step:269/1750 train_time:26421ms step_avg:98.22ms
step:270/1750 train_time:26519ms step_avg:98.22ms
step:271/1750 train_time:26618ms step_avg:98.22ms
step:272/1750 train_time:26714ms step_avg:98.21ms
step:273/1750 train_time:26812ms step_avg:98.21ms
step:274/1750 train_time:26910ms step_avg:98.21ms
step:275/1750 train_time:27008ms step_avg:98.21ms
step:276/1750 train_time:27106ms step_avg:98.21ms
step:277/1750 train_time:27205ms step_avg:98.21ms
step:278/1750 train_time:27303ms step_avg:98.21ms
step:279/1750 train_time:27402ms step_avg:98.21ms
step:280/1750 train_time:27500ms step_avg:98.21ms
step:281/1750 train_time:27599ms step_avg:98.22ms
step:282/1750 train_time:27697ms step_avg:98.22ms
step:283/1750 train_time:27796ms step_avg:98.22ms
step:284/1750 train_time:27894ms step_avg:98.22ms
step:285/1750 train_time:27992ms step_avg:98.22ms
step:286/1750 train_time:28090ms step_avg:98.22ms
step:287/1750 train_time:28188ms step_avg:98.21ms
step:288/1750 train_time:28286ms step_avg:98.22ms
step:289/1750 train_time:28384ms step_avg:98.21ms
step:290/1750 train_time:28481ms step_avg:98.21ms
step:291/1750 train_time:28579ms step_avg:98.21ms
step:292/1750 train_time:28677ms step_avg:98.21ms
step:293/1750 train_time:28775ms step_avg:98.21ms
step:294/1750 train_time:28872ms step_avg:98.21ms
step:295/1750 train_time:28970ms step_avg:98.20ms
step:296/1750 train_time:29069ms step_avg:98.21ms
step:297/1750 train_time:29167ms step_avg:98.20ms
step:298/1750 train_time:29266ms step_avg:98.21ms
step:299/1750 train_time:29364ms step_avg:98.21ms
step:300/1750 train_time:29462ms step_avg:98.21ms
step:301/1750 train_time:29560ms step_avg:98.21ms
step:302/1750 train_time:29658ms step_avg:98.20ms
step:303/1750 train_time:29756ms step_avg:98.20ms
step:304/1750 train_time:29854ms step_avg:98.20ms
step:305/1750 train_time:29951ms step_avg:98.20ms
step:306/1750 train_time:30049ms step_avg:98.20ms
step:307/1750 train_time:30147ms step_avg:98.20ms
step:308/1750 train_time:30245ms step_avg:98.20ms
step:309/1750 train_time:30343ms step_avg:98.20ms
step:310/1750 train_time:30441ms step_avg:98.20ms
step:311/1750 train_time:30539ms step_avg:98.20ms
step:312/1750 train_time:30637ms step_avg:98.19ms
step:313/1750 train_time:30734ms step_avg:98.19ms
step:314/1750 train_time:30832ms step_avg:98.19ms
step:315/1750 train_time:30929ms step_avg:98.19ms
step:316/1750 train_time:31027ms step_avg:98.19ms
step:317/1750 train_time:31126ms step_avg:98.19ms
step:318/1750 train_time:31224ms step_avg:98.19ms
step:319/1750 train_time:31322ms step_avg:98.19ms
step:320/1750 train_time:31420ms step_avg:98.19ms
step:321/1750 train_time:31518ms step_avg:98.19ms
step:322/1750 train_time:31616ms step_avg:98.19ms
step:323/1750 train_time:31714ms step_avg:98.19ms
step:324/1750 train_time:31812ms step_avg:98.19ms
step:325/1750 train_time:31910ms step_avg:98.18ms
step:326/1750 train_time:32008ms step_avg:98.18ms
step:327/1750 train_time:32106ms step_avg:98.18ms
step:328/1750 train_time:32205ms step_avg:98.19ms
step:329/1750 train_time:32303ms step_avg:98.19ms
step:330/1750 train_time:32401ms step_avg:98.19ms
step:331/1750 train_time:32499ms step_avg:98.18ms
step:332/1750 train_time:32596ms step_avg:98.18ms
step:333/1750 train_time:32694ms step_avg:98.18ms
step:334/1750 train_time:32792ms step_avg:98.18ms
step:335/1750 train_time:32890ms step_avg:98.18ms
step:336/1750 train_time:32988ms step_avg:98.18ms
step:337/1750 train_time:33086ms step_avg:98.18ms
step:338/1750 train_time:33184ms step_avg:98.18ms
step:339/1750 train_time:33281ms step_avg:98.17ms
step:340/1750 train_time:33378ms step_avg:98.17ms
step:341/1750 train_time:33476ms step_avg:98.17ms
step:342/1750 train_time:33574ms step_avg:98.17ms
step:343/1750 train_time:33672ms step_avg:98.17ms
step:344/1750 train_time:33769ms step_avg:98.17ms
step:345/1750 train_time:33867ms step_avg:98.17ms
step:346/1750 train_time:33964ms step_avg:98.16ms
step:347/1750 train_time:34062ms step_avg:98.16ms
step:348/1750 train_time:34159ms step_avg:98.16ms
step:349/1750 train_time:34257ms step_avg:98.16ms
step:350/1750 train_time:34355ms step_avg:98.16ms
step:351/1750 train_time:34452ms step_avg:98.15ms
step:352/1750 train_time:34550ms step_avg:98.15ms
step:353/1750 train_time:34648ms step_avg:98.15ms
step:354/1750 train_time:34747ms step_avg:98.15ms
step:355/1750 train_time:34845ms step_avg:98.16ms
step:356/1750 train_time:34944ms step_avg:98.16ms
step:357/1750 train_time:35042ms step_avg:98.16ms
step:358/1750 train_time:35140ms step_avg:98.16ms
step:359/1750 train_time:35238ms step_avg:98.16ms
step:360/1750 train_time:35336ms step_avg:98.15ms
step:361/1750 train_time:35433ms step_avg:98.15ms
step:362/1750 train_time:35531ms step_avg:98.15ms
step:363/1750 train_time:35629ms step_avg:98.15ms
step:364/1750 train_time:35727ms step_avg:98.15ms
step:365/1750 train_time:35825ms step_avg:98.15ms
step:366/1750 train_time:35923ms step_avg:98.15ms
step:367/1750 train_time:36020ms step_avg:98.15ms
step:368/1750 train_time:36117ms step_avg:98.15ms
step:369/1750 train_time:36216ms step_avg:98.15ms
step:370/1750 train_time:36313ms step_avg:98.14ms
step:371/1750 train_time:36410ms step_avg:98.14ms
step:372/1750 train_time:36508ms step_avg:98.14ms
step:373/1750 train_time:36607ms step_avg:98.14ms
step:374/1750 train_time:36705ms step_avg:98.14ms
step:375/1750 train_time:36803ms step_avg:98.14ms
step:375/1750 val_loss:3.9104 train_time:36896ms step_avg:98.39ms
step:376/1750 train_time:36916ms step_avg:98.18ms
step:377/1750 train_time:37007ms step_avg:98.16ms
step:378/1750 train_time:37108ms step_avg:98.17ms
step:379/1750 train_time:37206ms step_avg:98.17ms
step:380/1750 train_time:37304ms step_avg:98.17ms
step:381/1750 train_time:37401ms step_avg:98.17ms
step:382/1750 train_time:37499ms step_avg:98.16ms
step:383/1750 train_time:37597ms step_avg:98.16ms
step:384/1750 train_time:37694ms step_avg:98.16ms
step:385/1750 train_time:37793ms step_avg:98.16ms
step:386/1750 train_time:37891ms step_avg:98.16ms
step:387/1750 train_time:37989ms step_avg:98.16ms
step:388/1750 train_time:38086ms step_avg:98.16ms
step:389/1750 train_time:38184ms step_avg:98.16ms
step:390/1750 train_time:38282ms step_avg:98.16ms
step:391/1750 train_time:38382ms step_avg:98.16ms
step:392/1750 train_time:38482ms step_avg:98.17ms
step:393/1750 train_time:38582ms step_avg:98.17ms
step:394/1750 train_time:38682ms step_avg:98.18ms
step:395/1750 train_time:38781ms step_avg:98.18ms
step:396/1750 train_time:38882ms step_avg:98.19ms
step:397/1750 train_time:38982ms step_avg:98.19ms
step:398/1750 train_time:39082ms step_avg:98.20ms
step:399/1750 train_time:39182ms step_avg:98.20ms
step:400/1750 train_time:39282ms step_avg:98.21ms
step:401/1750 train_time:39382ms step_avg:98.21ms
step:402/1750 train_time:39481ms step_avg:98.21ms
step:403/1750 train_time:39580ms step_avg:98.21ms
step:404/1750 train_time:39680ms step_avg:98.22ms
step:405/1750 train_time:39780ms step_avg:98.22ms
step:406/1750 train_time:39880ms step_avg:98.23ms
step:407/1750 train_time:39980ms step_avg:98.23ms
step:408/1750 train_time:40080ms step_avg:98.24ms
step:409/1750 train_time:40180ms step_avg:98.24ms
step:410/1750 train_time:40281ms step_avg:98.25ms
step:411/1750 train_time:40380ms step_avg:98.25ms
step:412/1750 train_time:40480ms step_avg:98.25ms
step:413/1750 train_time:40580ms step_avg:98.26ms
step:414/1750 train_time:40679ms step_avg:98.26ms
step:415/1750 train_time:40779ms step_avg:98.26ms
step:416/1750 train_time:40878ms step_avg:98.26ms
step:417/1750 train_time:40977ms step_avg:98.27ms
step:418/1750 train_time:41077ms step_avg:98.27ms
step:419/1750 train_time:41177ms step_avg:98.28ms
step:420/1750 train_time:41277ms step_avg:98.28ms
step:421/1750 train_time:41378ms step_avg:98.28ms
step:422/1750 train_time:41477ms step_avg:98.29ms
step:423/1750 train_time:41577ms step_avg:98.29ms
step:424/1750 train_time:41677ms step_avg:98.30ms
step:425/1750 train_time:41777ms step_avg:98.30ms
step:426/1750 train_time:41878ms step_avg:98.30ms
step:427/1750 train_time:41977ms step_avg:98.31ms
step:428/1750 train_time:42078ms step_avg:98.31ms
step:429/1750 train_time:42178ms step_avg:98.32ms
step:430/1750 train_time:42278ms step_avg:98.32ms
step:431/1750 train_time:42378ms step_avg:98.32ms
step:432/1750 train_time:42478ms step_avg:98.33ms
step:433/1750 train_time:42577ms step_avg:98.33ms
step:434/1750 train_time:42678ms step_avg:98.34ms
step:435/1750 train_time:42777ms step_avg:98.34ms
step:436/1750 train_time:42877ms step_avg:98.34ms
step:437/1750 train_time:42977ms step_avg:98.35ms
step:438/1750 train_time:43077ms step_avg:98.35ms
step:439/1750 train_time:43177ms step_avg:98.35ms
step:440/1750 train_time:43278ms step_avg:98.36ms
step:441/1750 train_time:43377ms step_avg:98.36ms
step:442/1750 train_time:43477ms step_avg:98.36ms
step:443/1750 train_time:43577ms step_avg:98.37ms
step:444/1750 train_time:43677ms step_avg:98.37ms
step:445/1750 train_time:43777ms step_avg:98.37ms
step:446/1750 train_time:43876ms step_avg:98.38ms
step:447/1750 train_time:43976ms step_avg:98.38ms
step:448/1750 train_time:44076ms step_avg:98.38ms
step:449/1750 train_time:44176ms step_avg:98.39ms
step:450/1750 train_time:44275ms step_avg:98.39ms
step:451/1750 train_time:44376ms step_avg:98.39ms
step:452/1750 train_time:44476ms step_avg:98.40ms
step:453/1750 train_time:44576ms step_avg:98.40ms
step:454/1750 train_time:44676ms step_avg:98.41ms
step:455/1750 train_time:44776ms step_avg:98.41ms
step:456/1750 train_time:44875ms step_avg:98.41ms
step:457/1750 train_time:44976ms step_avg:98.42ms
step:458/1750 train_time:45075ms step_avg:98.42ms
step:459/1750 train_time:45175ms step_avg:98.42ms
step:460/1750 train_time:45274ms step_avg:98.42ms
step:461/1750 train_time:45374ms step_avg:98.43ms
step:462/1750 train_time:45474ms step_avg:98.43ms
step:463/1750 train_time:45574ms step_avg:98.43ms
step:464/1750 train_time:45674ms step_avg:98.44ms
step:465/1750 train_time:45774ms step_avg:98.44ms
step:466/1750 train_time:45874ms step_avg:98.44ms
step:467/1750 train_time:45974ms step_avg:98.45ms
step:468/1750 train_time:46074ms step_avg:98.45ms
step:469/1750 train_time:46174ms step_avg:98.45ms
step:470/1750 train_time:46274ms step_avg:98.46ms
step:471/1750 train_time:46374ms step_avg:98.46ms
step:472/1750 train_time:46475ms step_avg:98.46ms
step:473/1750 train_time:46576ms step_avg:98.47ms
step:474/1750 train_time:46677ms step_avg:98.47ms
step:475/1750 train_time:46777ms step_avg:98.48ms
step:476/1750 train_time:46876ms step_avg:98.48ms
step:477/1750 train_time:46976ms step_avg:98.48ms
step:478/1750 train_time:47076ms step_avg:98.49ms
step:479/1750 train_time:47176ms step_avg:98.49ms
step:480/1750 train_time:47276ms step_avg:98.49ms
step:481/1750 train_time:47376ms step_avg:98.49ms
step:482/1750 train_time:47476ms step_avg:98.50ms
step:483/1750 train_time:47576ms step_avg:98.50ms
step:484/1750 train_time:47676ms step_avg:98.50ms
step:485/1750 train_time:47777ms step_avg:98.51ms
step:486/1750 train_time:47877ms step_avg:98.51ms
step:487/1750 train_time:47977ms step_avg:98.52ms
step:488/1750 train_time:48077ms step_avg:98.52ms
step:489/1750 train_time:48177ms step_avg:98.52ms
step:490/1750 train_time:48278ms step_avg:98.53ms
step:491/1750 train_time:48377ms step_avg:98.53ms
step:492/1750 train_time:48477ms step_avg:98.53ms
step:493/1750 train_time:48577ms step_avg:98.53ms
step:494/1750 train_time:48676ms step_avg:98.54ms
step:495/1750 train_time:48776ms step_avg:98.54ms
step:496/1750 train_time:48876ms step_avg:98.54ms
step:497/1750 train_time:48976ms step_avg:98.54ms
step:498/1750 train_time:49076ms step_avg:98.55ms
step:499/1750 train_time:49175ms step_avg:98.55ms
step:500/1750 train_time:49275ms step_avg:98.55ms
step:500/1750 val_loss:3.7584 train_time:49369ms step_avg:98.74ms
step:501/1750 train_time:49388ms step_avg:98.58ms
step:502/1750 train_time:49481ms step_avg:98.57ms
step:503/1750 train_time:49583ms step_avg:98.57ms
step:504/1750 train_time:49683ms step_avg:98.58ms
step:505/1750 train_time:49782ms step_avg:98.58ms
step:506/1750 train_time:49881ms step_avg:98.58ms
step:507/1750 train_time:49980ms step_avg:98.58ms
step:508/1750 train_time:50080ms step_avg:98.58ms
step:509/1750 train_time:50181ms step_avg:98.59ms
step:510/1750 train_time:50281ms step_avg:98.59ms
step:511/1750 train_time:50380ms step_avg:98.59ms
step:512/1750 train_time:50481ms step_avg:98.60ms
step:513/1750 train_time:50582ms step_avg:98.60ms
step:514/1750 train_time:50682ms step_avg:98.60ms
step:515/1750 train_time:50783ms step_avg:98.61ms
step:516/1750 train_time:50884ms step_avg:98.61ms
step:517/1750 train_time:50983ms step_avg:98.61ms
step:518/1750 train_time:51083ms step_avg:98.62ms
step:519/1750 train_time:51183ms step_avg:98.62ms
step:520/1750 train_time:51283ms step_avg:98.62ms
step:521/1750 train_time:51383ms step_avg:98.62ms
step:522/1750 train_time:51483ms step_avg:98.63ms
step:523/1750 train_time:51583ms step_avg:98.63ms
step:524/1750 train_time:51683ms step_avg:98.63ms
step:525/1750 train_time:51783ms step_avg:98.63ms
step:526/1750 train_time:51883ms step_avg:98.64ms
step:527/1750 train_time:51983ms step_avg:98.64ms
step:528/1750 train_time:52083ms step_avg:98.64ms
step:529/1750 train_time:52183ms step_avg:98.64ms
step:530/1750 train_time:52283ms step_avg:98.65ms
step:531/1750 train_time:52384ms step_avg:98.65ms
step:532/1750 train_time:52484ms step_avg:98.65ms
step:533/1750 train_time:52585ms step_avg:98.66ms
step:534/1750 train_time:52685ms step_avg:98.66ms
step:535/1750 train_time:52785ms step_avg:98.66ms
step:536/1750 train_time:52885ms step_avg:98.67ms
step:537/1750 train_time:52985ms step_avg:98.67ms
step:538/1750 train_time:53085ms step_avg:98.67ms
step:539/1750 train_time:53185ms step_avg:98.67ms
step:540/1750 train_time:53286ms step_avg:98.68ms
step:541/1750 train_time:53387ms step_avg:98.68ms
step:542/1750 train_time:53486ms step_avg:98.68ms
step:543/1750 train_time:53587ms step_avg:98.69ms
step:544/1750 train_time:53687ms step_avg:98.69ms
step:545/1750 train_time:53788ms step_avg:98.69ms
step:546/1750 train_time:53888ms step_avg:98.70ms
step:547/1750 train_time:53988ms step_avg:98.70ms
step:548/1750 train_time:54089ms step_avg:98.70ms
step:549/1750 train_time:54189ms step_avg:98.71ms
step:550/1750 train_time:54290ms step_avg:98.71ms
step:551/1750 train_time:54390ms step_avg:98.71ms
step:552/1750 train_time:54490ms step_avg:98.71ms
step:553/1750 train_time:54590ms step_avg:98.72ms
step:554/1750 train_time:54691ms step_avg:98.72ms
step:555/1750 train_time:54791ms step_avg:98.72ms
step:556/1750 train_time:54891ms step_avg:98.73ms
step:557/1750 train_time:54991ms step_avg:98.73ms
step:558/1750 train_time:55091ms step_avg:98.73ms
step:559/1750 train_time:55192ms step_avg:98.73ms
step:560/1750 train_time:55292ms step_avg:98.74ms
step:561/1750 train_time:55393ms step_avg:98.74ms
step:562/1750 train_time:55494ms step_avg:98.74ms
step:563/1750 train_time:55594ms step_avg:98.75ms
step:564/1750 train_time:55694ms step_avg:98.75ms
step:565/1750 train_time:55794ms step_avg:98.75ms
step:566/1750 train_time:55895ms step_avg:98.75ms
step:567/1750 train_time:55995ms step_avg:98.76ms
step:568/1750 train_time:56095ms step_avg:98.76ms
step:569/1750 train_time:56195ms step_avg:98.76ms
step:570/1750 train_time:56296ms step_avg:98.76ms
step:571/1750 train_time:56397ms step_avg:98.77ms
step:572/1750 train_time:56498ms step_avg:98.77ms
step:573/1750 train_time:56599ms step_avg:98.78ms
step:574/1750 train_time:56700ms step_avg:98.78ms
step:575/1750 train_time:56801ms step_avg:98.78ms
step:576/1750 train_time:56901ms step_avg:98.79ms
step:577/1750 train_time:57003ms step_avg:98.79ms
step:578/1750 train_time:57104ms step_avg:98.80ms
step:579/1750 train_time:57204ms step_avg:98.80ms
step:580/1750 train_time:57304ms step_avg:98.80ms
step:581/1750 train_time:57405ms step_avg:98.80ms
step:582/1750 train_time:57507ms step_avg:98.81ms
step:583/1750 train_time:57607ms step_avg:98.81ms
step:584/1750 train_time:57707ms step_avg:98.81ms
step:585/1750 train_time:57807ms step_avg:98.81ms
step:586/1750 train_time:57907ms step_avg:98.82ms
step:587/1750 train_time:58007ms step_avg:98.82ms
step:588/1750 train_time:58107ms step_avg:98.82ms
step:589/1750 train_time:58207ms step_avg:98.82ms
step:590/1750 train_time:58307ms step_avg:98.83ms
step:591/1750 train_time:58407ms step_avg:98.83ms
step:592/1750 train_time:58507ms step_avg:98.83ms
step:593/1750 train_time:58607ms step_avg:98.83ms
step:594/1750 train_time:58707ms step_avg:98.83ms
step:595/1750 train_time:58806ms step_avg:98.83ms
step:596/1750 train_time:58906ms step_avg:98.84ms
step:597/1750 train_time:59006ms step_avg:98.84ms
step:598/1750 train_time:59107ms step_avg:98.84ms
step:599/1750 train_time:59207ms step_avg:98.84ms
step:600/1750 train_time:59307ms step_avg:98.85ms
step:601/1750 train_time:59407ms step_avg:98.85ms
step:602/1750 train_time:59507ms step_avg:98.85ms
step:603/1750 train_time:59607ms step_avg:98.85ms
step:604/1750 train_time:59708ms step_avg:98.85ms
step:605/1750 train_time:59808ms step_avg:98.86ms
step:606/1750 train_time:59908ms step_avg:98.86ms
step:607/1750 train_time:60008ms step_avg:98.86ms
step:608/1750 train_time:60108ms step_avg:98.86ms
step:609/1750 train_time:60209ms step_avg:98.86ms
step:610/1750 train_time:60309ms step_avg:98.87ms
step:611/1750 train_time:60410ms step_avg:98.87ms
step:612/1750 train_time:60510ms step_avg:98.87ms
step:613/1750 train_time:60610ms step_avg:98.87ms
step:614/1750 train_time:60710ms step_avg:98.88ms
step:615/1750 train_time:60811ms step_avg:98.88ms
step:616/1750 train_time:60911ms step_avg:98.88ms
step:617/1750 train_time:61011ms step_avg:98.88ms
step:618/1750 train_time:61112ms step_avg:98.89ms
step:619/1750 train_time:61213ms step_avg:98.89ms
step:620/1750 train_time:61314ms step_avg:98.89ms
step:621/1750 train_time:61414ms step_avg:98.90ms
step:622/1750 train_time:61514ms step_avg:98.90ms
step:623/1750 train_time:61614ms step_avg:98.90ms
step:624/1750 train_time:61715ms step_avg:98.90ms
step:625/1750 train_time:61815ms step_avg:98.90ms
step:625/1750 val_loss:3.6705 train_time:61910ms step_avg:99.06ms
step:626/1750 train_time:61929ms step_avg:98.93ms
step:627/1750 train_time:62024ms step_avg:98.92ms
step:628/1750 train_time:62126ms step_avg:98.93ms
step:629/1750 train_time:62227ms step_avg:98.93ms
step:630/1750 train_time:62326ms step_avg:98.93ms
step:631/1750 train_time:62426ms step_avg:98.93ms
step:632/1750 train_time:62525ms step_avg:98.93ms
step:633/1750 train_time:62625ms step_avg:98.93ms
step:634/1750 train_time:62724ms step_avg:98.93ms
step:635/1750 train_time:62825ms step_avg:98.94ms
step:636/1750 train_time:62926ms step_avg:98.94ms
step:637/1750 train_time:63028ms step_avg:98.94ms
step:638/1750 train_time:63129ms step_avg:98.95ms
step:639/1750 train_time:63230ms step_avg:98.95ms
step:640/1750 train_time:63330ms step_avg:98.95ms
step:641/1750 train_time:63430ms step_avg:98.95ms
step:642/1750 train_time:63530ms step_avg:98.96ms
step:643/1750 train_time:63630ms step_avg:98.96ms
step:644/1750 train_time:63731ms step_avg:98.96ms
step:645/1750 train_time:63831ms step_avg:98.96ms
step:646/1750 train_time:63932ms step_avg:98.97ms
step:647/1750 train_time:64033ms step_avg:98.97ms
step:648/1750 train_time:64133ms step_avg:98.97ms
step:649/1750 train_time:64233ms step_avg:98.97ms
step:650/1750 train_time:64333ms step_avg:98.97ms
step:651/1750 train_time:64435ms step_avg:98.98ms
step:652/1750 train_time:64538ms step_avg:98.98ms
step:653/1750 train_time:64639ms step_avg:98.99ms
step:654/1750 train_time:64742ms step_avg:98.99ms
step:655/1750 train_time:64844ms step_avg:99.00ms
step:656/1750 train_time:64945ms step_avg:99.00ms
step:657/1750 train_time:65047ms step_avg:99.01ms
step:658/1750 train_time:65149ms step_avg:99.01ms
step:659/1750 train_time:65250ms step_avg:99.01ms
step:660/1750 train_time:65352ms step_avg:99.02ms
step:661/1750 train_time:65453ms step_avg:99.02ms
step:662/1750 train_time:65555ms step_avg:99.03ms
step:663/1750 train_time:65657ms step_avg:99.03ms
step:664/1750 train_time:65759ms step_avg:99.04ms
step:665/1750 train_time:65863ms step_avg:99.04ms
step:666/1750 train_time:65964ms step_avg:99.04ms
step:667/1750 train_time:66066ms step_avg:99.05ms
step:668/1750 train_time:66167ms step_avg:99.05ms
step:669/1750 train_time:66269ms step_avg:99.06ms
step:670/1750 train_time:66371ms step_avg:99.06ms
step:671/1750 train_time:66473ms step_avg:99.06ms
step:672/1750 train_time:66575ms step_avg:99.07ms
step:673/1750 train_time:66676ms step_avg:99.07ms
step:674/1750 train_time:66779ms step_avg:99.08ms
step:675/1750 train_time:66882ms step_avg:99.08ms
step:676/1750 train_time:66984ms step_avg:99.09ms
step:677/1750 train_time:67085ms step_avg:99.09ms
step:678/1750 train_time:67187ms step_avg:99.10ms
step:679/1750 train_time:67289ms step_avg:99.10ms
step:680/1750 train_time:67391ms step_avg:99.10ms
step:681/1750 train_time:67492ms step_avg:99.11ms
step:682/1750 train_time:67593ms step_avg:99.11ms
step:683/1750 train_time:67694ms step_avg:99.11ms
step:684/1750 train_time:67796ms step_avg:99.12ms
step:685/1750 train_time:67898ms step_avg:99.12ms
step:686/1750 train_time:68001ms step_avg:99.13ms
step:687/1750 train_time:68103ms step_avg:99.13ms
step:688/1750 train_time:68205ms step_avg:99.14ms
step:689/1750 train_time:68307ms step_avg:99.14ms
step:690/1750 train_time:68408ms step_avg:99.14ms
step:691/1750 train_time:68510ms step_avg:99.15ms
step:692/1750 train_time:68611ms step_avg:99.15ms
step:693/1750 train_time:68713ms step_avg:99.15ms
step:694/1750 train_time:68815ms step_avg:99.16ms
step:695/1750 train_time:68917ms step_avg:99.16ms
step:696/1750 train_time:69020ms step_avg:99.17ms
step:697/1750 train_time:69122ms step_avg:99.17ms
step:698/1750 train_time:69224ms step_avg:99.17ms
step:699/1750 train_time:69325ms step_avg:99.18ms
step:700/1750 train_time:69427ms step_avg:99.18ms
step:701/1750 train_time:69528ms step_avg:99.18ms
step:702/1750 train_time:69629ms step_avg:99.19ms
step:703/1750 train_time:69731ms step_avg:99.19ms
step:704/1750 train_time:69833ms step_avg:99.19ms
step:705/1750 train_time:69936ms step_avg:99.20ms
step:706/1750 train_time:70038ms step_avg:99.20ms
step:707/1750 train_time:70140ms step_avg:99.21ms
step:708/1750 train_time:70242ms step_avg:99.21ms
step:709/1750 train_time:70345ms step_avg:99.22ms
step:710/1750 train_time:70446ms step_avg:99.22ms
step:711/1750 train_time:70548ms step_avg:99.22ms
step:712/1750 train_time:70649ms step_avg:99.23ms
step:713/1750 train_time:70750ms step_avg:99.23ms
step:714/1750 train_time:70851ms step_avg:99.23ms
step:715/1750 train_time:70955ms step_avg:99.24ms
step:716/1750 train_time:71056ms step_avg:99.24ms
step:717/1750 train_time:71158ms step_avg:99.24ms
step:718/1750 train_time:71262ms step_avg:99.25ms
step:719/1750 train_time:71364ms step_avg:99.25ms
step:720/1750 train_time:71466ms step_avg:99.26ms
step:721/1750 train_time:71567ms step_avg:99.26ms
step:722/1750 train_time:71669ms step_avg:99.26ms
step:723/1750 train_time:71770ms step_avg:99.27ms
step:724/1750 train_time:71872ms step_avg:99.27ms
step:725/1750 train_time:71974ms step_avg:99.27ms
step:726/1750 train_time:72076ms step_avg:99.28ms
step:727/1750 train_time:72177ms step_avg:99.28ms
step:728/1750 train_time:72280ms step_avg:99.29ms
step:729/1750 train_time:72383ms step_avg:99.29ms
step:730/1750 train_time:72484ms step_avg:99.29ms
step:731/1750 train_time:72586ms step_avg:99.30ms
step:732/1750 train_time:72688ms step_avg:99.30ms
step:733/1750 train_time:72790ms step_avg:99.30ms
step:734/1750 train_time:72891ms step_avg:99.31ms
step:735/1750 train_time:72992ms step_avg:99.31ms
step:736/1750 train_time:73094ms step_avg:99.31ms
step:737/1750 train_time:73197ms step_avg:99.32ms
step:738/1750 train_time:73299ms step_avg:99.32ms
step:739/1750 train_time:73402ms step_avg:99.33ms
step:740/1750 train_time:73503ms step_avg:99.33ms
step:741/1750 train_time:73605ms step_avg:99.33ms
step:742/1750 train_time:73706ms step_avg:99.33ms
step:743/1750 train_time:73807ms step_avg:99.34ms
step:744/1750 train_time:73909ms step_avg:99.34ms
step:745/1750 train_time:74010ms step_avg:99.34ms
step:746/1750 train_time:74111ms step_avg:99.34ms
step:747/1750 train_time:74213ms step_avg:99.35ms
step:748/1750 train_time:74317ms step_avg:99.35ms
step:749/1750 train_time:74419ms step_avg:99.36ms
step:750/1750 train_time:74521ms step_avg:99.36ms
step:750/1750 val_loss:3.6052 train_time:74617ms step_avg:99.49ms
step:751/1750 train_time:74637ms step_avg:99.38ms
step:752/1750 train_time:74736ms step_avg:99.38ms
step:753/1750 train_time:74840ms step_avg:99.39ms
step:754/1750 train_time:74941ms step_avg:99.39ms
step:755/1750 train_time:75043ms step_avg:99.39ms
step:756/1750 train_time:75144ms step_avg:99.40ms
step:757/1750 train_time:75246ms step_avg:99.40ms
step:758/1750 train_time:75347ms step_avg:99.40ms
step:759/1750 train_time:75449ms step_avg:99.41ms
step:760/1750 train_time:75551ms step_avg:99.41ms
step:761/1750 train_time:75653ms step_avg:99.41ms
step:762/1750 train_time:75757ms step_avg:99.42ms
step:763/1750 train_time:75860ms step_avg:99.42ms
step:764/1750 train_time:75961ms step_avg:99.43ms
step:765/1750 train_time:76062ms step_avg:99.43ms
step:766/1750 train_time:76164ms step_avg:99.43ms
step:767/1750 train_time:76266ms step_avg:99.43ms
step:768/1750 train_time:76367ms step_avg:99.44ms
step:769/1750 train_time:76469ms step_avg:99.44ms
step:770/1750 train_time:76571ms step_avg:99.44ms
step:771/1750 train_time:76674ms step_avg:99.45ms
step:772/1750 train_time:76776ms step_avg:99.45ms
step:773/1750 train_time:76878ms step_avg:99.45ms
step:774/1750 train_time:76980ms step_avg:99.46ms
step:775/1750 train_time:77081ms step_avg:99.46ms
step:776/1750 train_time:77183ms step_avg:99.46ms
step:777/1750 train_time:77284ms step_avg:99.46ms
step:778/1750 train_time:77385ms step_avg:99.47ms
step:779/1750 train_time:77487ms step_avg:99.47ms
step:780/1750 train_time:77590ms step_avg:99.47ms
step:781/1750 train_time:77693ms step_avg:99.48ms
step:782/1750 train_time:77795ms step_avg:99.48ms
step:783/1750 train_time:77898ms step_avg:99.49ms
step:784/1750 train_time:78000ms step_avg:99.49ms
step:785/1750 train_time:78102ms step_avg:99.49ms
step:786/1750 train_time:78204ms step_avg:99.50ms
step:787/1750 train_time:78306ms step_avg:99.50ms
step:788/1750 train_time:78407ms step_avg:99.50ms
step:789/1750 train_time:78509ms step_avg:99.50ms
step:790/1750 train_time:78612ms step_avg:99.51ms
step:791/1750 train_time:78715ms step_avg:99.51ms
step:792/1750 train_time:78817ms step_avg:99.52ms
step:793/1750 train_time:78919ms step_avg:99.52ms
step:794/1750 train_time:79021ms step_avg:99.52ms
step:795/1750 train_time:79122ms step_avg:99.53ms
step:796/1750 train_time:79224ms step_avg:99.53ms
step:797/1750 train_time:79326ms step_avg:99.53ms
step:798/1750 train_time:79428ms step_avg:99.53ms
step:799/1750 train_time:79530ms step_avg:99.54ms
step:800/1750 train_time:79633ms step_avg:99.54ms
step:801/1750 train_time:79736ms step_avg:99.55ms
step:802/1750 train_time:79838ms step_avg:99.55ms
step:803/1750 train_time:79941ms step_avg:99.55ms
step:804/1750 train_time:80042ms step_avg:99.56ms
step:805/1750 train_time:80145ms step_avg:99.56ms
step:806/1750 train_time:80247ms step_avg:99.56ms
step:807/1750 train_time:80349ms step_avg:99.56ms
step:808/1750 train_time:80452ms step_avg:99.57ms
step:809/1750 train_time:80554ms step_avg:99.57ms
step:810/1750 train_time:80656ms step_avg:99.58ms
step:811/1750 train_time:80758ms step_avg:99.58ms
step:812/1750 train_time:80860ms step_avg:99.58ms
step:813/1750 train_time:80961ms step_avg:99.58ms
step:814/1750 train_time:81063ms step_avg:99.59ms
step:815/1750 train_time:81164ms step_avg:99.59ms
step:816/1750 train_time:81266ms step_avg:99.59ms
step:817/1750 train_time:81369ms step_avg:99.59ms
step:818/1750 train_time:81471ms step_avg:99.60ms
step:819/1750 train_time:81573ms step_avg:99.60ms
step:820/1750 train_time:81676ms step_avg:99.60ms
step:821/1750 train_time:81777ms step_avg:99.61ms
step:822/1750 train_time:81879ms step_avg:99.61ms
step:823/1750 train_time:81980ms step_avg:99.61ms
step:824/1750 train_time:82082ms step_avg:99.61ms
step:825/1750 train_time:82183ms step_avg:99.62ms
step:826/1750 train_time:82285ms step_avg:99.62ms
step:827/1750 train_time:82388ms step_avg:99.62ms
step:828/1750 train_time:82490ms step_avg:99.63ms
step:829/1750 train_time:82592ms step_avg:99.63ms
step:830/1750 train_time:82695ms step_avg:99.63ms
step:831/1750 train_time:82797ms step_avg:99.64ms
step:832/1750 train_time:82900ms step_avg:99.64ms
step:833/1750 train_time:83001ms step_avg:99.64ms
step:834/1750 train_time:83104ms step_avg:99.65ms
step:835/1750 train_time:83205ms step_avg:99.65ms
step:836/1750 train_time:83308ms step_avg:99.65ms
step:837/1750 train_time:83410ms step_avg:99.65ms
step:838/1750 train_time:83512ms step_avg:99.66ms
step:839/1750 train_time:83615ms step_avg:99.66ms
step:840/1750 train_time:83717ms step_avg:99.66ms
step:841/1750 train_time:83819ms step_avg:99.67ms
step:842/1750 train_time:83921ms step_avg:99.67ms
step:843/1750 train_time:84024ms step_avg:99.67ms
step:844/1750 train_time:84126ms step_avg:99.68ms
step:845/1750 train_time:84227ms step_avg:99.68ms
step:846/1750 train_time:84329ms step_avg:99.68ms
step:847/1750 train_time:84431ms step_avg:99.68ms
step:848/1750 train_time:84534ms step_avg:99.69ms
step:849/1750 train_time:84637ms step_avg:99.69ms
step:850/1750 train_time:84738ms step_avg:99.69ms
step:851/1750 train_time:84840ms step_avg:99.69ms
step:852/1750 train_time:84942ms step_avg:99.70ms
step:853/1750 train_time:85044ms step_avg:99.70ms
step:854/1750 train_time:85147ms step_avg:99.70ms
step:855/1750 train_time:85248ms step_avg:99.71ms
step:856/1750 train_time:85351ms step_avg:99.71ms
step:857/1750 train_time:85453ms step_avg:99.71ms
step:858/1750 train_time:85555ms step_avg:99.71ms
step:859/1750 train_time:85657ms step_avg:99.72ms
step:860/1750 train_time:85759ms step_avg:99.72ms
step:861/1750 train_time:85861ms step_avg:99.72ms
step:862/1750 train_time:85963ms step_avg:99.73ms
step:863/1750 train_time:86065ms step_avg:99.73ms
step:864/1750 train_time:86167ms step_avg:99.73ms
step:865/1750 train_time:86269ms step_avg:99.73ms
step:866/1750 train_time:86371ms step_avg:99.74ms
step:867/1750 train_time:86473ms step_avg:99.74ms
step:868/1750 train_time:86575ms step_avg:99.74ms
step:869/1750 train_time:86677ms step_avg:99.74ms
step:870/1750 train_time:86779ms step_avg:99.75ms
step:871/1750 train_time:86881ms step_avg:99.75ms
step:872/1750 train_time:86982ms step_avg:99.75ms
step:873/1750 train_time:87084ms step_avg:99.75ms
step:874/1750 train_time:87185ms step_avg:99.75ms
step:875/1750 train_time:87288ms step_avg:99.76ms
step:875/1750 val_loss:3.5543 train_time:87385ms step_avg:99.87ms
step:876/1750 train_time:87404ms step_avg:99.78ms
step:877/1750 train_time:87499ms step_avg:99.77ms
step:878/1750 train_time:87603ms step_avg:99.78ms
step:879/1750 train_time:87705ms step_avg:99.78ms
step:880/1750 train_time:87807ms step_avg:99.78ms
step:881/1750 train_time:87909ms step_avg:99.78ms
step:882/1750 train_time:88011ms step_avg:99.79ms
step:883/1750 train_time:88113ms step_avg:99.79ms
step:884/1750 train_time:88216ms step_avg:99.79ms
step:885/1750 train_time:88318ms step_avg:99.79ms
step:886/1750 train_time:88420ms step_avg:99.80ms
step:887/1750 train_time:88521ms step_avg:99.80ms
step:888/1750 train_time:88624ms step_avg:99.80ms
step:889/1750 train_time:88727ms step_avg:99.81ms
step:890/1750 train_time:88829ms step_avg:99.81ms
step:891/1750 train_time:88931ms step_avg:99.81ms
step:892/1750 train_time:89033ms step_avg:99.81ms
step:893/1750 train_time:89134ms step_avg:99.81ms
step:894/1750 train_time:89237ms step_avg:99.82ms
step:895/1750 train_time:89339ms step_avg:99.82ms
step:896/1750 train_time:89441ms step_avg:99.82ms
step:897/1750 train_time:89542ms step_avg:99.82ms
step:898/1750 train_time:89644ms step_avg:99.83ms
step:899/1750 train_time:89747ms step_avg:99.83ms
step:900/1750 train_time:89849ms step_avg:99.83ms
step:901/1750 train_time:89951ms step_avg:99.83ms
step:902/1750 train_time:90054ms step_avg:99.84ms
step:903/1750 train_time:90156ms step_avg:99.84ms
step:904/1750 train_time:90258ms step_avg:99.84ms
step:905/1750 train_time:90359ms step_avg:99.84ms
step:906/1750 train_time:90461ms step_avg:99.85ms
step:907/1750 train_time:90563ms step_avg:99.85ms
step:908/1750 train_time:90665ms step_avg:99.85ms
step:909/1750 train_time:90767ms step_avg:99.85ms
step:910/1750 train_time:90870ms step_avg:99.86ms
step:911/1750 train_time:90974ms step_avg:99.86ms
step:912/1750 train_time:91077ms step_avg:99.87ms
step:913/1750 train_time:91180ms step_avg:99.87ms
step:914/1750 train_time:91285ms step_avg:99.87ms
step:915/1750 train_time:91388ms step_avg:99.88ms
step:916/1750 train_time:91491ms step_avg:99.88ms
step:917/1750 train_time:91595ms step_avg:99.89ms
step:918/1750 train_time:91700ms step_avg:99.89ms
step:919/1750 train_time:91803ms step_avg:99.89ms
step:920/1750 train_time:91906ms step_avg:99.90ms
step:921/1750 train_time:92010ms step_avg:99.90ms
step:922/1750 train_time:92114ms step_avg:99.91ms
step:923/1750 train_time:92218ms step_avg:99.91ms
step:924/1750 train_time:92321ms step_avg:99.91ms
step:925/1750 train_time:92423ms step_avg:99.92ms
step:926/1750 train_time:92526ms step_avg:99.92ms
step:927/1750 train_time:92631ms step_avg:99.93ms
step:928/1750 train_time:92734ms step_avg:99.93ms
step:929/1750 train_time:92838ms step_avg:99.93ms
step:930/1750 train_time:92940ms step_avg:99.94ms
step:931/1750 train_time:93043ms step_avg:99.94ms
step:932/1750 train_time:93146ms step_avg:99.94ms
step:933/1750 train_time:93251ms step_avg:99.95ms
step:934/1750 train_time:93354ms step_avg:99.95ms
step:935/1750 train_time:93458ms step_avg:99.96ms
step:936/1750 train_time:93562ms step_avg:99.96ms
step:937/1750 train_time:93665ms step_avg:99.96ms
step:938/1750 train_time:93769ms step_avg:99.97ms
step:939/1750 train_time:93872ms step_avg:99.97ms
step:940/1750 train_time:93977ms step_avg:99.98ms
step:941/1750 train_time:94080ms step_avg:99.98ms
step:942/1750 train_time:94185ms step_avg:99.98ms
step:943/1750 train_time:94289ms step_avg:99.99ms
step:944/1750 train_time:94392ms step_avg:99.99ms
step:945/1750 train_time:94496ms step_avg:100.00ms
step:946/1750 train_time:94600ms step_avg:100.00ms
step:947/1750 train_time:94704ms step_avg:100.00ms
step:948/1750 train_time:94807ms step_avg:100.01ms
step:949/1750 train_time:94910ms step_avg:100.01ms
step:950/1750 train_time:95013ms step_avg:100.01ms
step:951/1750 train_time:95117ms step_avg:100.02ms
step:952/1750 train_time:95220ms step_avg:100.02ms
step:953/1750 train_time:95323ms step_avg:100.02ms
step:954/1750 train_time:95426ms step_avg:100.03ms
step:955/1750 train_time:95530ms step_avg:100.03ms
step:956/1750 train_time:95633ms step_avg:100.03ms
step:957/1750 train_time:95737ms step_avg:100.04ms
step:958/1750 train_time:95840ms step_avg:100.04ms
step:959/1750 train_time:95944ms step_avg:100.05ms
step:960/1750 train_time:96046ms step_avg:100.05ms
step:961/1750 train_time:96149ms step_avg:100.05ms
step:962/1750 train_time:96254ms step_avg:100.06ms
step:963/1750 train_time:96358ms step_avg:100.06ms
step:964/1750 train_time:96461ms step_avg:100.06ms
step:965/1750 train_time:96565ms step_avg:100.07ms
step:966/1750 train_time:96668ms step_avg:100.07ms
step:967/1750 train_time:96772ms step_avg:100.07ms
step:968/1750 train_time:96877ms step_avg:100.08ms
step:969/1750 train_time:96980ms step_avg:100.08ms
step:970/1750 train_time:97083ms step_avg:100.09ms
step:971/1750 train_time:97186ms step_avg:100.09ms
step:972/1750 train_time:97291ms step_avg:100.09ms
step:973/1750 train_time:97394ms step_avg:100.10ms
step:974/1750 train_time:97498ms step_avg:100.10ms
step:975/1750 train_time:97602ms step_avg:100.10ms
step:976/1750 train_time:97705ms step_avg:100.11ms
step:977/1750 train_time:97809ms step_avg:100.11ms
step:978/1750 train_time:97912ms step_avg:100.11ms
step:979/1750 train_time:98017ms step_avg:100.12ms
step:980/1750 train_time:98120ms step_avg:100.12ms
step:981/1750 train_time:98223ms step_avg:100.13ms
step:982/1750 train_time:98325ms step_avg:100.13ms
step:983/1750 train_time:98429ms step_avg:100.13ms
step:984/1750 train_time:98533ms step_avg:100.14ms
step:985/1750 train_time:98638ms step_avg:100.14ms
step:986/1750 train_time:98741ms step_avg:100.14ms
step:987/1750 train_time:98844ms step_avg:100.15ms
step:988/1750 train_time:98947ms step_avg:100.15ms
step:989/1750 train_time:99052ms step_avg:100.15ms
step:990/1750 train_time:99155ms step_avg:100.16ms
step:991/1750 train_time:99259ms step_avg:100.16ms
step:992/1750 train_time:99362ms step_avg:100.16ms
step:993/1750 train_time:99466ms step_avg:100.17ms
step:994/1750 train_time:99570ms step_avg:100.17ms
step:995/1750 train_time:99674ms step_avg:100.17ms
step:996/1750 train_time:99778ms step_avg:100.18ms
step:997/1750 train_time:99881ms step_avg:100.18ms
step:998/1750 train_time:99984ms step_avg:100.18ms
step:999/1750 train_time:100087ms step_avg:100.19ms
step:1000/1750 train_time:100191ms step_avg:100.19ms
step:1000/1750 val_loss:3.5163 train_time:100289ms step_avg:100.29ms
step:1001/1750 train_time:100309ms step_avg:100.21ms
step:1002/1750 train_time:100403ms step_avg:100.20ms
step:1003/1750 train_time:100510ms step_avg:100.21ms
step:1004/1750 train_time:100614ms step_avg:100.21ms
step:1005/1750 train_time:100717ms step_avg:100.22ms
step:1006/1750 train_time:100820ms step_avg:100.22ms
step:1007/1750 train_time:100922ms step_avg:100.22ms
step:1008/1750 train_time:101024ms step_avg:100.22ms
step:1009/1750 train_time:101127ms step_avg:100.22ms
step:1010/1750 train_time:101230ms step_avg:100.23ms
step:1011/1750 train_time:101335ms step_avg:100.23ms
step:1012/1750 train_time:101441ms step_avg:100.24ms
step:1013/1750 train_time:101545ms step_avg:100.24ms
step:1014/1750 train_time:101648ms step_avg:100.24ms
step:1015/1750 train_time:101752ms step_avg:100.25ms
step:1016/1750 train_time:101857ms step_avg:100.25ms
step:1017/1750 train_time:101961ms step_avg:100.26ms
step:1018/1750 train_time:102064ms step_avg:100.26ms
step:1019/1750 train_time:102167ms step_avg:100.26ms
step:1020/1750 train_time:102270ms step_avg:100.26ms
step:1021/1750 train_time:102372ms step_avg:100.27ms
step:1022/1750 train_time:102477ms step_avg:100.27ms
step:1023/1750 train_time:102580ms step_avg:100.27ms
step:1024/1750 train_time:102684ms step_avg:100.28ms
step:1025/1750 train_time:102787ms step_avg:100.28ms
step:1026/1750 train_time:102891ms step_avg:100.28ms
step:1027/1750 train_time:102995ms step_avg:100.29ms
step:1028/1750 train_time:103099ms step_avg:100.29ms
step:1029/1750 train_time:103203ms step_avg:100.29ms
step:1030/1750 train_time:103306ms step_avg:100.30ms
step:1031/1750 train_time:103409ms step_avg:100.30ms
step:1032/1750 train_time:103513ms step_avg:100.30ms
step:1033/1750 train_time:103617ms step_avg:100.31ms
step:1034/1750 train_time:103720ms step_avg:100.31ms
step:1035/1750 train_time:103824ms step_avg:100.31ms
step:1036/1750 train_time:103927ms step_avg:100.32ms
step:1037/1750 train_time:104030ms step_avg:100.32ms
step:1038/1750 train_time:104134ms step_avg:100.32ms
step:1039/1750 train_time:104238ms step_avg:100.33ms
step:1040/1750 train_time:104341ms step_avg:100.33ms
step:1041/1750 train_time:104443ms step_avg:100.33ms
step:1042/1750 train_time:104547ms step_avg:100.33ms
step:1043/1750 train_time:104650ms step_avg:100.34ms
step:1044/1750 train_time:104754ms step_avg:100.34ms
step:1045/1750 train_time:104859ms step_avg:100.34ms
step:1046/1750 train_time:104963ms step_avg:100.35ms
step:1047/1750 train_time:105067ms step_avg:100.35ms
step:1048/1750 train_time:105171ms step_avg:100.35ms
step:1049/1750 train_time:105276ms step_avg:100.36ms
step:1050/1750 train_time:105380ms step_avg:100.36ms
step:1051/1750 train_time:105483ms step_avg:100.36ms
step:1052/1750 train_time:105586ms step_avg:100.37ms
step:1053/1750 train_time:105690ms step_avg:100.37ms
step:1054/1750 train_time:105793ms step_avg:100.37ms
step:1055/1750 train_time:105897ms step_avg:100.38ms
step:1056/1750 train_time:106001ms step_avg:100.38ms
step:1057/1750 train_time:106105ms step_avg:100.38ms
step:1058/1750 train_time:106207ms step_avg:100.39ms
step:1059/1750 train_time:106312ms step_avg:100.39ms
step:1060/1750 train_time:106416ms step_avg:100.39ms
step:1061/1750 train_time:106521ms step_avg:100.40ms
step:1062/1750 train_time:106625ms step_avg:100.40ms
step:1063/1750 train_time:106730ms step_avg:100.40ms
step:1064/1750 train_time:106834ms step_avg:100.41ms
step:1065/1750 train_time:106937ms step_avg:100.41ms
step:1066/1750 train_time:107041ms step_avg:100.41ms
step:1067/1750 train_time:107144ms step_avg:100.42ms
step:1068/1750 train_time:107249ms step_avg:100.42ms
step:1069/1750 train_time:107352ms step_avg:100.42ms
step:1070/1750 train_time:107456ms step_avg:100.43ms
step:1071/1750 train_time:107560ms step_avg:100.43ms
step:1072/1750 train_time:107664ms step_avg:100.43ms
step:1073/1750 train_time:107767ms step_avg:100.44ms
step:1074/1750 train_time:107870ms step_avg:100.44ms
step:1075/1750 train_time:107974ms step_avg:100.44ms
step:1076/1750 train_time:108078ms step_avg:100.44ms
step:1077/1750 train_time:108180ms step_avg:100.45ms
step:1078/1750 train_time:108283ms step_avg:100.45ms
step:1079/1750 train_time:108387ms step_avg:100.45ms
step:1080/1750 train_time:108492ms step_avg:100.46ms
step:1081/1750 train_time:108595ms step_avg:100.46ms
step:1082/1750 train_time:108699ms step_avg:100.46ms
step:1083/1750 train_time:108802ms step_avg:100.46ms
step:1084/1750 train_time:108906ms step_avg:100.47ms
step:1085/1750 train_time:109010ms step_avg:100.47ms
step:1086/1750 train_time:109113ms step_avg:100.47ms
step:1087/1750 train_time:109217ms step_avg:100.48ms
step:1088/1750 train_time:109320ms step_avg:100.48ms
step:1089/1750 train_time:109424ms step_avg:100.48ms
step:1090/1750 train_time:109529ms step_avg:100.49ms
step:1091/1750 train_time:109633ms step_avg:100.49ms
step:1092/1750 train_time:109738ms step_avg:100.49ms
step:1093/1750 train_time:109841ms step_avg:100.49ms
step:1094/1750 train_time:109944ms step_avg:100.50ms
step:1095/1750 train_time:110048ms step_avg:100.50ms
step:1096/1750 train_time:110152ms step_avg:100.50ms
step:1097/1750 train_time:110256ms step_avg:100.51ms
step:1098/1750 train_time:110359ms step_avg:100.51ms
step:1099/1750 train_time:110462ms step_avg:100.51ms
step:1100/1750 train_time:110566ms step_avg:100.51ms
step:1101/1750 train_time:110668ms step_avg:100.52ms
step:1102/1750 train_time:110774ms step_avg:100.52ms
step:1103/1750 train_time:110877ms step_avg:100.52ms
step:1104/1750 train_time:110982ms step_avg:100.53ms
step:1105/1750 train_time:111085ms step_avg:100.53ms
step:1106/1750 train_time:111188ms step_avg:100.53ms
step:1107/1750 train_time:111292ms step_avg:100.54ms
step:1108/1750 train_time:111397ms step_avg:100.54ms
step:1109/1750 train_time:111501ms step_avg:100.54ms
step:1110/1750 train_time:111604ms step_avg:100.54ms
step:1111/1750 train_time:111708ms step_avg:100.55ms
step:1112/1750 train_time:111812ms step_avg:100.55ms
step:1113/1750 train_time:111916ms step_avg:100.55ms
step:1114/1750 train_time:112020ms step_avg:100.56ms
step:1115/1750 train_time:112124ms step_avg:100.56ms
step:1116/1750 train_time:112227ms step_avg:100.56ms
step:1117/1750 train_time:112331ms step_avg:100.56ms
step:1118/1750 train_time:112434ms step_avg:100.57ms
step:1119/1750 train_time:112539ms step_avg:100.57ms
step:1120/1750 train_time:112643ms step_avg:100.57ms
step:1121/1750 train_time:112746ms step_avg:100.58ms
step:1122/1750 train_time:112849ms step_avg:100.58ms
step:1123/1750 train_time:112951ms step_avg:100.58ms
step:1124/1750 train_time:113055ms step_avg:100.58ms
step:1125/1750 train_time:113159ms step_avg:100.59ms
step:1125/1750 val_loss:3.4715 train_time:113256ms step_avg:100.67ms
step:1126/1750 train_time:113278ms step_avg:100.60ms
step:1127/1750 train_time:113372ms step_avg:100.60ms
step:1128/1750 train_time:113476ms step_avg:100.60ms
step:1129/1750 train_time:113579ms step_avg:100.60ms
step:1130/1750 train_time:113682ms step_avg:100.60ms
step:1131/1750 train_time:113787ms step_avg:100.61ms
step:1132/1750 train_time:113890ms step_avg:100.61ms
step:1133/1750 train_time:113992ms step_avg:100.61ms
step:1134/1750 train_time:114096ms step_avg:100.61ms
step:1135/1750 train_time:114199ms step_avg:100.62ms
step:1136/1750 train_time:114304ms step_avg:100.62ms
step:1137/1750 train_time:114409ms step_avg:100.62ms
step:1138/1750 train_time:114512ms step_avg:100.63ms
step:1139/1750 train_time:114615ms step_avg:100.63ms
step:1140/1750 train_time:114721ms step_avg:100.63ms
step:1141/1750 train_time:114825ms step_avg:100.64ms
step:1142/1750 train_time:114929ms step_avg:100.64ms
step:1143/1750 train_time:115032ms step_avg:100.64ms
step:1144/1750 train_time:115135ms step_avg:100.64ms
step:1145/1750 train_time:115238ms step_avg:100.64ms
step:1146/1750 train_time:115343ms step_avg:100.65ms
step:1147/1750 train_time:115448ms step_avg:100.65ms
step:1148/1750 train_time:115551ms step_avg:100.65ms
step:1149/1750 train_time:115654ms step_avg:100.66ms
step:1150/1750 train_time:115758ms step_avg:100.66ms
step:1151/1750 train_time:115862ms step_avg:100.66ms
step:1152/1750 train_time:115966ms step_avg:100.67ms
step:1153/1750 train_time:116069ms step_avg:100.67ms
step:1154/1750 train_time:116173ms step_avg:100.67ms
step:1155/1750 train_time:116276ms step_avg:100.67ms
step:1156/1750 train_time:116380ms step_avg:100.67ms
step:1157/1750 train_time:116485ms step_avg:100.68ms
step:1158/1750 train_time:116589ms step_avg:100.68ms
step:1159/1750 train_time:116693ms step_avg:100.68ms
step:1160/1750 train_time:116796ms step_avg:100.69ms
step:1161/1750 train_time:116900ms step_avg:100.69ms
step:1162/1750 train_time:117004ms step_avg:100.69ms
step:1163/1750 train_time:117108ms step_avg:100.69ms
step:1164/1750 train_time:117212ms step_avg:100.70ms
step:1165/1750 train_time:117315ms step_avg:100.70ms
step:1166/1750 train_time:117418ms step_avg:100.70ms
step:1167/1750 train_time:117522ms step_avg:100.70ms
step:1168/1750 train_time:117626ms step_avg:100.71ms
step:1169/1750 train_time:117730ms step_avg:100.71ms
step:1170/1750 train_time:117835ms step_avg:100.71ms
step:1171/1750 train_time:117940ms step_avg:100.72ms
step:1172/1750 train_time:118045ms step_avg:100.72ms
step:1173/1750 train_time:118150ms step_avg:100.72ms
step:1174/1750 train_time:118254ms step_avg:100.73ms
step:1175/1750 train_time:118358ms step_avg:100.73ms
step:1176/1750 train_time:118463ms step_avg:100.73ms
step:1177/1750 train_time:118567ms step_avg:100.74ms
step:1178/1750 train_time:118672ms step_avg:100.74ms
step:1179/1750 train_time:118776ms step_avg:100.74ms
step:1180/1750 train_time:118881ms step_avg:100.75ms
step:1181/1750 train_time:118987ms step_avg:100.75ms
step:1182/1750 train_time:119092ms step_avg:100.75ms
step:1183/1750 train_time:119197ms step_avg:100.76ms
step:1184/1750 train_time:119303ms step_avg:100.76ms
step:1185/1750 train_time:119407ms step_avg:100.77ms
step:1186/1750 train_time:119513ms step_avg:100.77ms
step:1187/1750 train_time:119619ms step_avg:100.77ms
step:1188/1750 train_time:119724ms step_avg:100.78ms
step:1189/1750 train_time:119828ms step_avg:100.78ms
step:1190/1750 train_time:119933ms step_avg:100.78ms
step:1191/1750 train_time:120038ms step_avg:100.79ms
step:1192/1750 train_time:120142ms step_avg:100.79ms
step:1193/1750 train_time:120247ms step_avg:100.79ms
step:1194/1750 train_time:120351ms step_avg:100.80ms
step:1195/1750 train_time:120456ms step_avg:100.80ms
step:1196/1750 train_time:120562ms step_avg:100.80ms
step:1197/1750 train_time:120665ms step_avg:100.81ms
step:1198/1750 train_time:120769ms step_avg:100.81ms
step:1199/1750 train_time:120874ms step_avg:100.81ms
step:1200/1750 train_time:120980ms step_avg:100.82ms
step:1201/1750 train_time:121085ms step_avg:100.82ms
step:1202/1750 train_time:121189ms step_avg:100.82ms
step:1203/1750 train_time:121293ms step_avg:100.83ms
step:1204/1750 train_time:121398ms step_avg:100.83ms
step:1205/1750 train_time:121503ms step_avg:100.83ms
step:1206/1750 train_time:121609ms step_avg:100.84ms
step:1207/1750 train_time:121714ms step_avg:100.84ms
step:1208/1750 train_time:121818ms step_avg:100.84ms
step:1209/1750 train_time:121923ms step_avg:100.85ms
step:1210/1750 train_time:122027ms step_avg:100.85ms
step:1211/1750 train_time:122132ms step_avg:100.85ms
step:1212/1750 train_time:122239ms step_avg:100.86ms
step:1213/1750 train_time:122345ms step_avg:100.86ms
step:1214/1750 train_time:122449ms step_avg:100.86ms
step:1215/1750 train_time:122553ms step_avg:100.87ms
step:1216/1750 train_time:122660ms step_avg:100.87ms
step:1217/1750 train_time:122765ms step_avg:100.87ms
step:1218/1750 train_time:122870ms step_avg:100.88ms
step:1219/1750 train_time:122975ms step_avg:100.88ms
step:1220/1750 train_time:123079ms step_avg:100.88ms
step:1221/1750 train_time:123184ms step_avg:100.89ms
step:1222/1750 train_time:123290ms step_avg:100.89ms
step:1223/1750 train_time:123395ms step_avg:100.90ms
step:1224/1750 train_time:123500ms step_avg:100.90ms
step:1225/1750 train_time:123606ms step_avg:100.90ms
step:1226/1750 train_time:123710ms step_avg:100.91ms
step:1227/1750 train_time:123817ms step_avg:100.91ms
step:1228/1750 train_time:123924ms step_avg:100.92ms
step:1229/1750 train_time:124028ms step_avg:100.92ms
step:1230/1750 train_time:124132ms step_avg:100.92ms
step:1231/1750 train_time:124236ms step_avg:100.92ms
step:1232/1750 train_time:124341ms step_avg:100.93ms
step:1233/1750 train_time:124445ms step_avg:100.93ms
step:1234/1750 train_time:124550ms step_avg:100.93ms
step:1235/1750 train_time:124654ms step_avg:100.93ms
step:1236/1750 train_time:124760ms step_avg:100.94ms
step:1237/1750 train_time:124865ms step_avg:100.94ms
step:1238/1750 train_time:124970ms step_avg:100.95ms
step:1239/1750 train_time:125075ms step_avg:100.95ms
step:1240/1750 train_time:125180ms step_avg:100.95ms
step:1241/1750 train_time:125286ms step_avg:100.96ms
step:1242/1750 train_time:125389ms step_avg:100.96ms
step:1243/1750 train_time:125494ms step_avg:100.96ms
step:1244/1750 train_time:125599ms step_avg:100.96ms
step:1245/1750 train_time:125704ms step_avg:100.97ms
step:1246/1750 train_time:125810ms step_avg:100.97ms
step:1247/1750 train_time:125914ms step_avg:100.97ms
step:1248/1750 train_time:126019ms step_avg:100.98ms
step:1249/1750 train_time:126123ms step_avg:100.98ms
step:1250/1750 train_time:126228ms step_avg:100.98ms
step:1250/1750 val_loss:3.4238 train_time:126329ms step_avg:101.06ms
step:1251/1750 train_time:126349ms step_avg:101.00ms
step:1252/1750 train_time:126445ms step_avg:100.99ms
step:1253/1750 train_time:126551ms step_avg:101.00ms
step:1254/1750 train_time:126656ms step_avg:101.00ms
step:1255/1750 train_time:126762ms step_avg:101.01ms
step:1256/1750 train_time:126866ms step_avg:101.01ms
step:1257/1750 train_time:126972ms step_avg:101.01ms
step:1258/1750 train_time:127076ms step_avg:101.01ms
step:1259/1750 train_time:127181ms step_avg:101.02ms
step:1260/1750 train_time:127285ms step_avg:101.02ms
step:1261/1750 train_time:127391ms step_avg:101.02ms
step:1262/1750 train_time:127496ms step_avg:101.03ms
step:1263/1750 train_time:127600ms step_avg:101.03ms
step:1264/1750 train_time:127706ms step_avg:101.03ms
step:1265/1750 train_time:127811ms step_avg:101.04ms
step:1266/1750 train_time:127916ms step_avg:101.04ms
step:1267/1750 train_time:128020ms step_avg:101.04ms
step:1268/1750 train_time:128125ms step_avg:101.05ms
step:1269/1750 train_time:128229ms step_avg:101.05ms
step:1270/1750 train_time:128334ms step_avg:101.05ms
step:1271/1750 train_time:128439ms step_avg:101.05ms
step:1272/1750 train_time:128542ms step_avg:101.06ms
step:1273/1750 train_time:128650ms step_avg:101.06ms
step:1274/1750 train_time:128754ms step_avg:101.06ms
step:1275/1750 train_time:128859ms step_avg:101.07ms
step:1276/1750 train_time:128964ms step_avg:101.07ms
step:1277/1750 train_time:129068ms step_avg:101.07ms
step:1278/1750 train_time:129173ms step_avg:101.07ms
step:1279/1750 train_time:129278ms step_avg:101.08ms
step:1280/1750 train_time:129384ms step_avg:101.08ms
step:1281/1750 train_time:129487ms step_avg:101.08ms
step:1282/1750 train_time:129594ms step_avg:101.09ms
step:1283/1750 train_time:129698ms step_avg:101.09ms
step:1284/1750 train_time:129803ms step_avg:101.09ms
step:1285/1750 train_time:129909ms step_avg:101.10ms
step:1286/1750 train_time:130014ms step_avg:101.10ms
step:1287/1750 train_time:130119ms step_avg:101.10ms
step:1288/1750 train_time:130223ms step_avg:101.10ms
step:1289/1750 train_time:130328ms step_avg:101.11ms
step:1290/1750 train_time:130432ms step_avg:101.11ms
step:1291/1750 train_time:130537ms step_avg:101.11ms
step:1292/1750 train_time:130641ms step_avg:101.12ms
step:1293/1750 train_time:130746ms step_avg:101.12ms
step:1294/1750 train_time:130851ms step_avg:101.12ms
step:1295/1750 train_time:130956ms step_avg:101.12ms
step:1296/1750 train_time:131060ms step_avg:101.13ms
step:1297/1750 train_time:131165ms step_avg:101.13ms
step:1298/1750 train_time:131270ms step_avg:101.13ms
step:1299/1750 train_time:131375ms step_avg:101.14ms
step:1300/1750 train_time:131480ms step_avg:101.14ms
step:1301/1750 train_time:131587ms step_avg:101.14ms
step:1302/1750 train_time:131693ms step_avg:101.15ms
step:1303/1750 train_time:131797ms step_avg:101.15ms
step:1304/1750 train_time:131902ms step_avg:101.15ms
step:1305/1750 train_time:132006ms step_avg:101.15ms
step:1306/1750 train_time:132111ms step_avg:101.16ms
step:1307/1750 train_time:132216ms step_avg:101.16ms
step:1308/1750 train_time:132320ms step_avg:101.16ms
step:1309/1750 train_time:132425ms step_avg:101.16ms
step:1310/1750 train_time:132531ms step_avg:101.17ms
step:1311/1750 train_time:132636ms step_avg:101.17ms
step:1312/1750 train_time:132740ms step_avg:101.17ms
step:1313/1750 train_time:132844ms step_avg:101.18ms
step:1314/1750 train_time:132949ms step_avg:101.18ms
step:1315/1750 train_time:133053ms step_avg:101.18ms
step:1316/1750 train_time:133158ms step_avg:101.18ms
step:1317/1750 train_time:133263ms step_avg:101.19ms
step:1318/1750 train_time:133370ms step_avg:101.19ms
step:1319/1750 train_time:133475ms step_avg:101.19ms
step:1320/1750 train_time:133580ms step_avg:101.20ms
step:1321/1750 train_time:133684ms step_avg:101.20ms
step:1322/1750 train_time:133789ms step_avg:101.20ms
step:1323/1750 train_time:133894ms step_avg:101.21ms
step:1324/1750 train_time:133999ms step_avg:101.21ms
step:1325/1750 train_time:134105ms step_avg:101.21ms
step:1326/1750 train_time:134209ms step_avg:101.21ms
step:1327/1750 train_time:134317ms step_avg:101.22ms
step:1328/1750 train_time:134421ms step_avg:101.22ms
step:1329/1750 train_time:134526ms step_avg:101.22ms
step:1330/1750 train_time:134631ms step_avg:101.23ms
step:1331/1750 train_time:134735ms step_avg:101.23ms
step:1332/1750 train_time:134839ms step_avg:101.23ms
step:1333/1750 train_time:134944ms step_avg:101.23ms
step:1334/1750 train_time:135048ms step_avg:101.24ms
step:1335/1750 train_time:135153ms step_avg:101.24ms
step:1336/1750 train_time:135258ms step_avg:101.24ms
step:1337/1750 train_time:135362ms step_avg:101.24ms
step:1338/1750 train_time:135467ms step_avg:101.25ms
step:1339/1750 train_time:135573ms step_avg:101.25ms
step:1340/1750 train_time:135678ms step_avg:101.25ms
step:1341/1750 train_time:135782ms step_avg:101.25ms
step:1342/1750 train_time:135887ms step_avg:101.26ms
step:1343/1750 train_time:135994ms step_avg:101.26ms
step:1344/1750 train_time:136098ms step_avg:101.26ms
step:1345/1750 train_time:136203ms step_avg:101.27ms
step:1346/1750 train_time:136308ms step_avg:101.27ms
step:1347/1750 train_time:136413ms step_avg:101.27ms
step:1348/1750 train_time:136520ms step_avg:101.28ms
step:1349/1750 train_time:136625ms step_avg:101.28ms
step:1350/1750 train_time:136729ms step_avg:101.28ms
step:1351/1750 train_time:136835ms step_avg:101.28ms
step:1352/1750 train_time:136940ms step_avg:101.29ms
step:1353/1750 train_time:137045ms step_avg:101.29ms
step:1354/1750 train_time:137149ms step_avg:101.29ms
step:1355/1750 train_time:137254ms step_avg:101.29ms
step:1356/1750 train_time:137358ms step_avg:101.30ms
step:1357/1750 train_time:137462ms step_avg:101.30ms
step:1358/1750 train_time:137567ms step_avg:101.30ms
step:1359/1750 train_time:137672ms step_avg:101.30ms
step:1360/1750 train_time:137779ms step_avg:101.31ms
step:1361/1750 train_time:137883ms step_avg:101.31ms
step:1362/1750 train_time:137989ms step_avg:101.31ms
step:1363/1750 train_time:138094ms step_avg:101.32ms
step:1364/1750 train_time:138198ms step_avg:101.32ms
step:1365/1750 train_time:138302ms step_avg:101.32ms
step:1366/1750 train_time:138407ms step_avg:101.32ms
step:1367/1750 train_time:138513ms step_avg:101.33ms
step:1368/1750 train_time:138616ms step_avg:101.33ms
step:1369/1750 train_time:138722ms step_avg:101.33ms
step:1370/1750 train_time:138828ms step_avg:101.33ms
step:1371/1750 train_time:138932ms step_avg:101.34ms
step:1372/1750 train_time:139036ms step_avg:101.34ms
step:1373/1750 train_time:139142ms step_avg:101.34ms
step:1374/1750 train_time:139247ms step_avg:101.34ms
step:1375/1750 train_time:139352ms step_avg:101.35ms
step:1375/1750 val_loss:3.3801 train_time:139452ms step_avg:101.42ms
step:1376/1750 train_time:139471ms step_avg:101.36ms
step:1377/1750 train_time:139567ms step_avg:101.36ms
step:1378/1750 train_time:139673ms step_avg:101.36ms
step:1379/1750 train_time:139777ms step_avg:101.36ms
step:1380/1750 train_time:139882ms step_avg:101.36ms
step:1381/1750 train_time:139987ms step_avg:101.37ms
step:1382/1750 train_time:140092ms step_avg:101.37ms
step:1383/1750 train_time:140197ms step_avg:101.37ms
step:1384/1750 train_time:140302ms step_avg:101.37ms
step:1385/1750 train_time:140406ms step_avg:101.38ms
step:1386/1750 train_time:140512ms step_avg:101.38ms
step:1387/1750 train_time:140618ms step_avg:101.38ms
step:1388/1750 train_time:140722ms step_avg:101.39ms
step:1389/1750 train_time:140827ms step_avg:101.39ms
step:1390/1750 train_time:140932ms step_avg:101.39ms
step:1391/1750 train_time:141037ms step_avg:101.39ms
step:1392/1750 train_time:141141ms step_avg:101.39ms
step:1393/1750 train_time:141245ms step_avg:101.40ms
step:1394/1750 train_time:141350ms step_avg:101.40ms
step:1395/1750 train_time:141456ms step_avg:101.40ms
step:1396/1750 train_time:141561ms step_avg:101.40ms
step:1397/1750 train_time:141667ms step_avg:101.41ms
step:1398/1750 train_time:141772ms step_avg:101.41ms
step:1399/1750 train_time:141877ms step_avg:101.41ms
step:1400/1750 train_time:141982ms step_avg:101.42ms
step:1401/1750 train_time:142086ms step_avg:101.42ms
step:1402/1750 train_time:142190ms step_avg:101.42ms
step:1403/1750 train_time:142296ms step_avg:101.42ms
step:1404/1750 train_time:142402ms step_avg:101.43ms
step:1405/1750 train_time:142507ms step_avg:101.43ms
step:1406/1750 train_time:142612ms step_avg:101.43ms
step:1407/1750 train_time:142717ms step_avg:101.43ms
step:1408/1750 train_time:142822ms step_avg:101.44ms
step:1409/1750 train_time:142926ms step_avg:101.44ms
step:1410/1750 train_time:143032ms step_avg:101.44ms
step:1411/1750 train_time:143137ms step_avg:101.44ms
step:1412/1750 train_time:143241ms step_avg:101.45ms
step:1413/1750 train_time:143345ms step_avg:101.45ms
step:1414/1750 train_time:143451ms step_avg:101.45ms
step:1415/1750 train_time:143556ms step_avg:101.45ms
step:1416/1750 train_time:143661ms step_avg:101.46ms
step:1417/1750 train_time:143765ms step_avg:101.46ms
step:1418/1750 train_time:143870ms step_avg:101.46ms
step:1419/1750 train_time:143975ms step_avg:101.46ms
step:1420/1750 train_time:144080ms step_avg:101.46ms
step:1421/1750 train_time:144184ms step_avg:101.47ms
step:1422/1750 train_time:144289ms step_avg:101.47ms
step:1423/1750 train_time:144394ms step_avg:101.47ms
step:1424/1750 train_time:144499ms step_avg:101.47ms
step:1425/1750 train_time:144604ms step_avg:101.48ms
step:1426/1750 train_time:144710ms step_avg:101.48ms
step:1427/1750 train_time:144814ms step_avg:101.48ms
step:1428/1750 train_time:144922ms step_avg:101.49ms
step:1429/1750 train_time:145027ms step_avg:101.49ms
step:1430/1750 train_time:145133ms step_avg:101.49ms
step:1431/1750 train_time:145240ms step_avg:101.50ms
step:1432/1750 train_time:145346ms step_avg:101.50ms
step:1433/1750 train_time:145451ms step_avg:101.50ms
step:1434/1750 train_time:145557ms step_avg:101.50ms
step:1435/1750 train_time:145663ms step_avg:101.51ms
step:1436/1750 train_time:145773ms step_avg:101.51ms
step:1437/1750 train_time:145879ms step_avg:101.52ms
step:1438/1750 train_time:145985ms step_avg:101.52ms
step:1439/1750 train_time:146091ms step_avg:101.52ms
step:1440/1750 train_time:146197ms step_avg:101.53ms
step:1441/1750 train_time:146306ms step_avg:101.53ms
step:1442/1750 train_time:146412ms step_avg:101.53ms
step:1443/1750 train_time:146518ms step_avg:101.54ms
step:1444/1750 train_time:146625ms step_avg:101.54ms
step:1445/1750 train_time:146730ms step_avg:101.54ms
step:1446/1750 train_time:146837ms step_avg:101.55ms
step:1447/1750 train_time:146943ms step_avg:101.55ms
step:1448/1750 train_time:147048ms step_avg:101.55ms
step:1449/1750 train_time:147156ms step_avg:101.56ms
step:1450/1750 train_time:147262ms step_avg:101.56ms
step:1451/1750 train_time:147367ms step_avg:101.56ms
step:1452/1750 train_time:147473ms step_avg:101.57ms
step:1453/1750 train_time:147578ms step_avg:101.57ms
step:1454/1750 train_time:147684ms step_avg:101.57ms
step:1455/1750 train_time:147792ms step_avg:101.58ms
step:1456/1750 train_time:147899ms step_avg:101.58ms
step:1457/1750 train_time:148006ms step_avg:101.58ms
step:1458/1750 train_time:148112ms step_avg:101.59ms
step:1459/1750 train_time:148219ms step_avg:101.59ms
step:1460/1750 train_time:148324ms step_avg:101.59ms
step:1461/1750 train_time:148430ms step_avg:101.60ms
step:1462/1750 train_time:148537ms step_avg:101.60ms
step:1463/1750 train_time:148642ms step_avg:101.60ms
step:1464/1750 train_time:148750ms step_avg:101.60ms
step:1465/1750 train_time:148856ms step_avg:101.61ms
step:1466/1750 train_time:148962ms step_avg:101.61ms
step:1467/1750 train_time:149070ms step_avg:101.62ms
step:1468/1750 train_time:149177ms step_avg:101.62ms
step:1469/1750 train_time:149283ms step_avg:101.62ms
step:1470/1750 train_time:149388ms step_avg:101.62ms
step:1471/1750 train_time:149494ms step_avg:101.63ms
step:1472/1750 train_time:149600ms step_avg:101.63ms
step:1473/1750 train_time:149708ms step_avg:101.63ms
step:1474/1750 train_time:149815ms step_avg:101.64ms
step:1475/1750 train_time:149922ms step_avg:101.64ms
step:1476/1750 train_time:150028ms step_avg:101.64ms
step:1477/1750 train_time:150135ms step_avg:101.65ms
step:1478/1750 train_time:150242ms step_avg:101.65ms
step:1479/1750 train_time:150347ms step_avg:101.65ms
step:1480/1750 train_time:150453ms step_avg:101.66ms
step:1481/1750 train_time:150561ms step_avg:101.66ms
step:1482/1750 train_time:150666ms step_avg:101.66ms
step:1483/1750 train_time:150772ms step_avg:101.67ms
step:1484/1750 train_time:150878ms step_avg:101.67ms
step:1485/1750 train_time:150984ms step_avg:101.67ms
step:1486/1750 train_time:151090ms step_avg:101.68ms
step:1487/1750 train_time:151196ms step_avg:101.68ms
step:1488/1750 train_time:151302ms step_avg:101.68ms
step:1489/1750 train_time:151409ms step_avg:101.69ms
step:1490/1750 train_time:151515ms step_avg:101.69ms
step:1491/1750 train_time:151622ms step_avg:101.69ms
step:1492/1750 train_time:151729ms step_avg:101.70ms
step:1493/1750 train_time:151837ms step_avg:101.70ms
step:1494/1750 train_time:151945ms step_avg:101.70ms
step:1495/1750 train_time:152051ms step_avg:101.71ms
step:1496/1750 train_time:152157ms step_avg:101.71ms
step:1497/1750 train_time:152262ms step_avg:101.71ms
step:1498/1750 train_time:152367ms step_avg:101.71ms
step:1499/1750 train_time:152473ms step_avg:101.72ms
step:1500/1750 train_time:152578ms step_avg:101.72ms
step:1500/1750 val_loss:3.3421 train_time:152679ms step_avg:101.79ms
step:1501/1750 train_time:152700ms step_avg:101.73ms
step:1502/1750 train_time:152797ms step_avg:101.73ms
step:1503/1750 train_time:152902ms step_avg:101.73ms
step:1504/1750 train_time:153008ms step_avg:101.73ms
step:1505/1750 train_time:153115ms step_avg:101.74ms
step:1506/1750 train_time:153221ms step_avg:101.74ms
step:1507/1750 train_time:153327ms step_avg:101.74ms
step:1508/1750 train_time:153434ms step_avg:101.75ms
step:1509/1750 train_time:153540ms step_avg:101.75ms
step:1510/1750 train_time:153646ms step_avg:101.75ms
step:1511/1750 train_time:153752ms step_avg:101.76ms
step:1512/1750 train_time:153859ms step_avg:101.76ms
step:1513/1750 train_time:153965ms step_avg:101.76ms
step:1514/1750 train_time:154070ms step_avg:101.76ms
step:1515/1750 train_time:154176ms step_avg:101.77ms
step:1516/1750 train_time:154282ms step_avg:101.77ms
step:1517/1750 train_time:154389ms step_avg:101.77ms
step:1518/1750 train_time:154497ms step_avg:101.78ms
step:1519/1750 train_time:154602ms step_avg:101.78ms
step:1520/1750 train_time:154709ms step_avg:101.78ms
step:1521/1750 train_time:154814ms step_avg:101.78ms
step:1522/1750 train_time:154921ms step_avg:101.79ms
step:1523/1750 train_time:155027ms step_avg:101.79ms
step:1524/1750 train_time:155133ms step_avg:101.79ms
step:1525/1750 train_time:155239ms step_avg:101.80ms
step:1526/1750 train_time:155346ms step_avg:101.80ms
step:1527/1750 train_time:155451ms step_avg:101.80ms
step:1528/1750 train_time:155558ms step_avg:101.80ms
step:1529/1750 train_time:155663ms step_avg:101.81ms
step:1530/1750 train_time:155769ms step_avg:101.81ms
step:1531/1750 train_time:155876ms step_avg:101.81ms
step:1532/1750 train_time:155982ms step_avg:101.82ms
step:1533/1750 train_time:156088ms step_avg:101.82ms
step:1534/1750 train_time:156194ms step_avg:101.82ms
step:1535/1750 train_time:156299ms step_avg:101.82ms
step:1536/1750 train_time:156405ms step_avg:101.83ms
step:1537/1750 train_time:156513ms step_avg:101.83ms
step:1538/1750 train_time:156620ms step_avg:101.83ms
step:1539/1750 train_time:156726ms step_avg:101.84ms
step:1540/1750 train_time:156834ms step_avg:101.84ms
step:1541/1750 train_time:156941ms step_avg:101.84ms
step:1542/1750 train_time:157047ms step_avg:101.85ms
step:1543/1750 train_time:157153ms step_avg:101.85ms
step:1544/1750 train_time:157260ms step_avg:101.85ms
step:1545/1750 train_time:157366ms step_avg:101.86ms
step:1546/1750 train_time:157472ms step_avg:101.86ms
step:1547/1750 train_time:157578ms step_avg:101.86ms
step:1548/1750 train_time:157684ms step_avg:101.86ms
step:1549/1750 train_time:157791ms step_avg:101.87ms
step:1550/1750 train_time:157897ms step_avg:101.87ms
step:1551/1750 train_time:158002ms step_avg:101.87ms
step:1552/1750 train_time:158109ms step_avg:101.87ms
step:1553/1750 train_time:158215ms step_avg:101.88ms
step:1554/1750 train_time:158320ms step_avg:101.88ms
step:1555/1750 train_time:158427ms step_avg:101.88ms
step:1556/1750 train_time:158533ms step_avg:101.88ms
step:1557/1750 train_time:158639ms step_avg:101.89ms
step:1558/1750 train_time:158745ms step_avg:101.89ms
step:1559/1750 train_time:158852ms step_avg:101.89ms
step:1560/1750 train_time:158957ms step_avg:101.90ms
step:1561/1750 train_time:159066ms step_avg:101.90ms
step:1562/1750 train_time:159173ms step_avg:101.90ms
step:1563/1750 train_time:159278ms step_avg:101.91ms
step:1564/1750 train_time:159383ms step_avg:101.91ms
step:1565/1750 train_time:159490ms step_avg:101.91ms
step:1566/1750 train_time:159596ms step_avg:101.91ms
step:1567/1750 train_time:159701ms step_avg:101.92ms
step:1568/1750 train_time:159808ms step_avg:101.92ms
step:1569/1750 train_time:159919ms step_avg:101.92ms
step:1570/1750 train_time:160026ms step_avg:101.93ms
step:1571/1750 train_time:160132ms step_avg:101.93ms
step:1572/1750 train_time:160238ms step_avg:101.93ms
step:1573/1750 train_time:160348ms step_avg:101.94ms
step:1574/1750 train_time:160453ms step_avg:101.94ms
step:1575/1750 train_time:160559ms step_avg:101.94ms
step:1576/1750 train_time:160664ms step_avg:101.94ms
step:1577/1750 train_time:160771ms step_avg:101.95ms
step:1578/1750 train_time:160878ms step_avg:101.95ms
step:1579/1750 train_time:160984ms step_avg:101.95ms
step:1580/1750 train_time:161090ms step_avg:101.96ms
step:1581/1750 train_time:161199ms step_avg:101.96ms
step:1582/1750 train_time:161305ms step_avg:101.96ms
step:1583/1750 train_time:161411ms step_avg:101.97ms
step:1584/1750 train_time:161517ms step_avg:101.97ms
step:1585/1750 train_time:161623ms step_avg:101.97ms
step:1586/1750 train_time:161732ms step_avg:101.97ms
step:1587/1750 train_time:161840ms step_avg:101.98ms
step:1588/1750 train_time:161946ms step_avg:101.98ms
step:1589/1750 train_time:162052ms step_avg:101.98ms
step:1590/1750 train_time:162158ms step_avg:101.99ms
step:1591/1750 train_time:162263ms step_avg:101.99ms
step:1592/1750 train_time:162371ms step_avg:101.99ms
step:1593/1750 train_time:162477ms step_avg:101.99ms
step:1594/1750 train_time:162583ms step_avg:102.00ms
step:1595/1750 train_time:162691ms step_avg:102.00ms
step:1596/1750 train_time:162798ms step_avg:102.00ms
step:1597/1750 train_time:162903ms step_avg:102.01ms
step:1598/1750 train_time:163010ms step_avg:102.01ms
step:1599/1750 train_time:163118ms step_avg:102.01ms
step:1600/1750 train_time:163225ms step_avg:102.02ms
step:1601/1750 train_time:163333ms step_avg:102.02ms
step:1602/1750 train_time:163439ms step_avg:102.02ms
step:1603/1750 train_time:163545ms step_avg:102.02ms
step:1604/1750 train_time:163652ms step_avg:102.03ms
step:1605/1750 train_time:163757ms step_avg:102.03ms
step:1606/1750 train_time:163862ms step_avg:102.03ms
step:1607/1750 train_time:163973ms step_avg:102.04ms
step:1608/1750 train_time:164079ms step_avg:102.04ms
step:1609/1750 train_time:164186ms step_avg:102.04ms
step:1610/1750 train_time:164292ms step_avg:102.04ms
step:1611/1750 train_time:164399ms step_avg:102.05ms
step:1612/1750 train_time:164505ms step_avg:102.05ms
step:1613/1750 train_time:164612ms step_avg:102.05ms
step:1614/1750 train_time:164717ms step_avg:102.06ms
step:1615/1750 train_time:164824ms step_avg:102.06ms
step:1616/1750 train_time:164930ms step_avg:102.06ms
step:1617/1750 train_time:165038ms step_avg:102.06ms
step:1618/1750 train_time:165145ms step_avg:102.07ms
step:1619/1750 train_time:165253ms step_avg:102.07ms
step:1620/1750 train_time:165360ms step_avg:102.07ms
step:1621/1750 train_time:165466ms step_avg:102.08ms
step:1622/1750 train_time:165574ms step_avg:102.08ms
step:1623/1750 train_time:165683ms step_avg:102.08ms
step:1624/1750 train_time:165788ms step_avg:102.09ms
step:1625/1750 train_time:165892ms step_avg:102.09ms
step:1625/1750 val_loss:3.3080 train_time:165994ms step_avg:102.15ms
step:1626/1750 train_time:166014ms step_avg:102.10ms
step:1627/1750 train_time:166108ms step_avg:102.09ms
step:1628/1750 train_time:166214ms step_avg:102.10ms
step:1629/1750 train_time:166319ms step_avg:102.10ms
step:1630/1750 train_time:166425ms step_avg:102.10ms
step:1631/1750 train_time:166531ms step_avg:102.10ms
step:1632/1750 train_time:166637ms step_avg:102.11ms
step:1633/1750 train_time:166744ms step_avg:102.11ms
step:1634/1750 train_time:166850ms step_avg:102.11ms
step:1635/1750 train_time:166956ms step_avg:102.11ms
step:1636/1750 train_time:167063ms step_avg:102.12ms
step:1637/1750 train_time:167171ms step_avg:102.12ms
step:1638/1750 train_time:167277ms step_avg:102.12ms
step:1639/1750 train_time:167385ms step_avg:102.13ms
step:1640/1750 train_time:167491ms step_avg:102.13ms
step:1641/1750 train_time:167599ms step_avg:102.13ms
step:1642/1750 train_time:167704ms step_avg:102.13ms
step:1643/1750 train_time:167810ms step_avg:102.14ms
step:1644/1750 train_time:167917ms step_avg:102.14ms
step:1645/1750 train_time:168023ms step_avg:102.14ms
step:1646/1750 train_time:168130ms step_avg:102.14ms
step:1647/1750 train_time:168239ms step_avg:102.15ms
step:1648/1750 train_time:168344ms step_avg:102.15ms
step:1649/1750 train_time:168451ms step_avg:102.15ms
step:1650/1750 train_time:168557ms step_avg:102.16ms
step:1651/1750 train_time:168664ms step_avg:102.16ms
step:1652/1750 train_time:168770ms step_avg:102.16ms
step:1653/1750 train_time:168876ms step_avg:102.16ms
step:1654/1750 train_time:168985ms step_avg:102.17ms
step:1655/1750 train_time:169092ms step_avg:102.17ms
step:1656/1750 train_time:169198ms step_avg:102.17ms
step:1657/1750 train_time:169305ms step_avg:102.18ms
step:1658/1750 train_time:169411ms step_avg:102.18ms
step:1659/1750 train_time:169519ms step_avg:102.18ms
step:1660/1750 train_time:169624ms step_avg:102.18ms
step:1661/1750 train_time:169730ms step_avg:102.19ms
step:1662/1750 train_time:169838ms step_avg:102.19ms
step:1663/1750 train_time:169945ms step_avg:102.19ms
step:1664/1750 train_time:170052ms step_avg:102.19ms
step:1665/1750 train_time:170158ms step_avg:102.20ms
step:1666/1750 train_time:170265ms step_avg:102.20ms
step:1667/1750 train_time:170370ms step_avg:102.20ms
step:1668/1750 train_time:170476ms step_avg:102.20ms
step:1669/1750 train_time:170582ms step_avg:102.21ms
step:1670/1750 train_time:170687ms step_avg:102.21ms
step:1671/1750 train_time:170793ms step_avg:102.21ms
step:1672/1750 train_time:170900ms step_avg:102.21ms
step:1673/1750 train_time:171006ms step_avg:102.22ms
step:1674/1750 train_time:171112ms step_avg:102.22ms
step:1675/1750 train_time:171218ms step_avg:102.22ms
step:1676/1750 train_time:171325ms step_avg:102.22ms
step:1677/1750 train_time:171433ms step_avg:102.23ms
step:1678/1750 train_time:171540ms step_avg:102.23ms
step:1679/1750 train_time:171646ms step_avg:102.23ms
step:1680/1750 train_time:171752ms step_avg:102.23ms
step:1681/1750 train_time:171858ms step_avg:102.24ms
step:1682/1750 train_time:171968ms step_avg:102.24ms
step:1683/1750 train_time:172073ms step_avg:102.24ms
step:1684/1750 train_time:172178ms step_avg:102.24ms
step:1685/1750 train_time:172284ms step_avg:102.25ms
step:1686/1750 train_time:172391ms step_avg:102.25ms
step:1687/1750 train_time:172499ms step_avg:102.25ms
step:1688/1750 train_time:172606ms step_avg:102.25ms
step:1689/1750 train_time:172713ms step_avg:102.26ms
step:1690/1750 train_time:172820ms step_avg:102.26ms
step:1691/1750 train_time:172927ms step_avg:102.26ms
step:1692/1750 train_time:173034ms step_avg:102.27ms
step:1693/1750 train_time:173142ms step_avg:102.27ms
step:1694/1750 train_time:173248ms step_avg:102.27ms
step:1695/1750 train_time:173357ms step_avg:102.28ms
step:1696/1750 train_time:173467ms step_avg:102.28ms
step:1697/1750 train_time:173580ms step_avg:102.29ms
step:1698/1750 train_time:173688ms step_avg:102.29ms
step:1699/1750 train_time:173794ms step_avg:102.29ms
step:1700/1750 train_time:173901ms step_avg:102.29ms
step:1701/1750 train_time:174008ms step_avg:102.30ms
step:1702/1750 train_time:174115ms step_avg:102.30ms
step:1703/1750 train_time:174221ms step_avg:102.30ms
step:1704/1750 train_time:174329ms step_avg:102.31ms
step:1705/1750 train_time:174435ms step_avg:102.31ms
step:1706/1750 train_time:174542ms step_avg:102.31ms
step:1707/1750 train_time:174650ms step_avg:102.31ms
step:1708/1750 train_time:174756ms step_avg:102.32ms
step:1709/1750 train_time:174864ms step_avg:102.32ms
step:1710/1750 train_time:174973ms step_avg:102.32ms
step:1711/1750 train_time:175083ms step_avg:102.33ms
step:1712/1750 train_time:175189ms step_avg:102.33ms
step:1713/1750 train_time:175295ms step_avg:102.33ms
step:1714/1750 train_time:175401ms step_avg:102.33ms
step:1715/1750 train_time:175508ms step_avg:102.34ms
step:1716/1750 train_time:175615ms step_avg:102.34ms
step:1717/1750 train_time:175721ms step_avg:102.34ms
step:1718/1750 train_time:175828ms step_avg:102.34ms
step:1719/1750 train_time:175936ms step_avg:102.35ms
step:1720/1750 train_time:176045ms step_avg:102.35ms
step:1721/1750 train_time:176152ms step_avg:102.35ms
step:1722/1750 train_time:176264ms step_avg:102.36ms
step:1723/1750 train_time:176371ms step_avg:102.36ms
step:1724/1750 train_time:176481ms step_avg:102.37ms
step:1725/1750 train_time:176591ms step_avg:102.37ms
step:1726/1750 train_time:176700ms step_avg:102.38ms
step:1727/1750 train_time:176808ms step_avg:102.38ms
step:1728/1750 train_time:176917ms step_avg:102.38ms
step:1729/1750 train_time:177024ms step_avg:102.38ms
step:1730/1750 train_time:177131ms step_avg:102.39ms
step:1731/1750 train_time:177239ms step_avg:102.39ms
step:1732/1750 train_time:177346ms step_avg:102.39ms
step:1733/1750 train_time:177455ms step_avg:102.40ms
step:1734/1750 train_time:177561ms step_avg:102.40ms
step:1735/1750 train_time:177668ms step_avg:102.40ms
step:1736/1750 train_time:177775ms step_avg:102.41ms
step:1737/1750 train_time:177883ms step_avg:102.41ms
step:1738/1750 train_time:177991ms step_avg:102.41ms
step:1739/1750 train_time:178098ms step_avg:102.41ms
step:1740/1750 train_time:178204ms step_avg:102.42ms
step:1741/1750 train_time:178314ms step_avg:102.42ms
step:1742/1750 train_time:178423ms step_avg:102.42ms
step:1743/1750 train_time:178531ms step_avg:102.43ms
step:1744/1750 train_time:178638ms step_avg:102.43ms
step:1745/1750 train_time:178744ms step_avg:102.43ms
step:1746/1750 train_time:178855ms step_avg:102.44ms
step:1747/1750 train_time:178961ms step_avg:102.44ms
step:1748/1750 train_time:179070ms step_avg:102.44ms
step:1749/1750 train_time:179179ms step_avg:102.45ms
step:1750/1750 train_time:179284ms step_avg:102.45ms
step:1750/1750 val_loss:3.2822 train_time:179387ms step_avg:102.51ms
peak memory allocated: 30724 MiB reserved: 45392 MiB
